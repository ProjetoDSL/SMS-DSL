% Encoding: UTF-8

@InProceedings{20142317789510,
  author    = {Rompf, Tiark and Sujeeth, Arvind K. and Brown, Kevin J. and Lee, Hyouk Joong and Chafi, Hassan and Olukotun, Kunle},
  title     = {Surgical precision JIT compilers},
  year      = {2014},
  pages     = {41 - 52},
  address   = {Edinburgh, United kingdom},
  note      = {Abstract interpretations;Compiler construction;Compiler optimizations;Just-in-time compilation;Natural interfaces;Optimizing compilers;Partial evaluation;Translation strategies;},
  abstract  = {Just-in-time (JIT) compilation of running programs provides more optimization opportunities than offline compilation. Modern JIT compilers, such as those in virtual machines like Oracle's HotSpot for Java or Google's V8 for JavaScript, rely on dynamic profiling as their key mechanism to guide optimizations. While these JIT compilers offer good average performance, their behavior is a black box and the achieved performance is highly unpredictable. In this paper, we propose to turn JIT compilation into a precision tool by adding two essential and generic metaprogramming facilities: First, allow programs to invoke JIT compilation explicitly. This enables controlled specialization of arbitrary code at runtime, in the style of partial evaluation. It also enables the JIT compiler to report warnings and errors to the program when it is unable to compile a code path in the demanded way. Second, allow the JIT compiler to call back into the program to perform compiletime computation. This lets the program itself define the translation strategy for certain constructs on the fly and gives rise to a powerful JIT macro facility that enables "smart" libraries to supply domainspecific compiler optimizations or safety checks. We present Lancet, a JIT compiler framework for Java bytecode that enables such a tight, two-way integration with the running program. Lancet itself was derived from a high-level Java bytecode interpreter: staging the interpreter using LMS (Lightweight Modular Staging) produced a simple bytecode compiler. Adding abstract interpretation turned the simple compiler into an optimizing compiler. This fact provides compelling evidence for the scalability of the staged-interpreter approach to compiler construction. In the case of Lancet, JIT macros also provide a natural interface to existing LMS-based toolchains such as the Delite parallelism and DSL framework, which can now serve as accelerator macros for arbitrary JVM bytecode. Copyright &copy; 2014 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
  key       = {Program compilers},
  keywords  = {Java programming language;Just in time production;Macros;Program translators;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2594291.2594316},
}


@inproceedings{20144500172258,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Qualitative approach for inverse kinematic modeling of a Compact Bionic Handling Assistant trunk},
journal = {Proceedings of the International Joint Conference on Neural Networks},
author = {Melingui, A. and Merzouki, R. and Mbede, J.B. and Escande, C. and Daachi, B. and Benoudjit, N.},
year = {2014},
pages = {754 - 761},
address = {Beijing, China},
abstract = {Compact Bionic Handling Assistant (CBHA) is a continuum manipulator, with pneumatic-based actuation and compliant gripper. This bionic arm is attached to a mobile robot named Robotino. Inspired by the elephant's trunk, it can reproduce biological behaviors of trunks, tentacles, or snakes. Unlike rigid link robot manipulators, the development of high performance control algorithm of continuum robot manipulators remains a challenge, particularly due to their complex mechanical design, hyper-redundancy and presence of uncertainties. Numerous studies have been investigated for modeling of such complex systems. Such continuum robots, like the CBHA present a set of nonlinearities and uncertainties, making difficult to build an accurate analytical model, which can be used for control strategies development. Hence, learning approach becomes a suitable tool in such scenarios in order to capture un-modeled nonlinear behaviors of the continuous robots. In this paper, we present a qualitative modeling approach, based on neuronal model of the inverse kinematic of CBHA. A penalty term constraint is added to the inverse objective function into Distal Supervised Learning (DSL) scheme to select one particular inverse model from the redundancy manifold. The inverse kinematic neuronal model is validated by conducting a real-time implementation on a CBHA trunk. &copy; 2014 IEEE.},
key = {Manipulators},
keywords = {Algorithms;Bionics;Complex networks;Control nonlinearities;Flexible manipulators;Industrial robots;Inverse kinematics;Inverse problems;Kinematics;Machine design;Modular robots;Real time control;Redundancy;Robot applications;Robots;},
note = {Biological behavior;Distal supervised learning;High performance control;Inverse kinematic models;Nonlinear behavior;Objective functions;Qualitative approach;Real-time implementations;},
URL = {http://dx.doi.org/10.1109/IJCNN.2014.6889947},
} 

@InProceedings{20132816489871,
  author    = {Golabczak, Marcin and Jacquet, Philippe and Nouveau, Corinne and Fliti, Romain},
  title     = {Tribological investigations of TiC+a-C:H coatings manufactured on X38CrMoV5-1 steel using PVD technology},
  year      = {2013},
  volume    = {334-335},
  pages     = {97 - 104},
  address   = {Istanbul, Turkey},
  note      = {Cathodic arc evaporation;High temperature condition;High temperature tribometer;Low friction coefficients;Pin-on-disc-tests;Pvd methods;Temperature conditions;Tribological investigations;},
  abstract  = {X38CrMoV5-1 steel is a typical tool steel commonly used in forging and plastic moulding industry for production of ejectors, slides, dies, etc. In plastics moulding a lot of these parts sustain relative movement. Because of this, some seizing or micro-welding may appear, especially when lubrication is not used. For many years, the different types of protective coatings were developed to avoid such problems. Most of the obtained solutions relate to the manufacturing of low friction coatings obtained by different nitriding processes and by CVD or PVD methods. In this article, the friction coefficients and the wear resistances of TiC+a-C:H protective coatings manufactured on X38CrMoV5-1 steel samples by using PVD technology are studied. The investigations are based on tribometer tests in different temperature conditions. The process of deposition of PVD coatings was realized by using multisource, hybrid factory-scale equipment of type URM 079. This equipment allows for deposition of coatings by a physical method. The tribological tests were performed using a precision high temperature tribometer under ambient and high temperature conditions with a steel and corundum balls as a counter-samples. In this paper, the results of these tribological tests are presented. It is shown that the measured friction coefficient of steel samples with PVD coatings is significantly lower than the friction coefficient of uncoated steel. It is also shown that X38CrMoV5-1 steel samples with manufactured TiC+a-C:H coatings are characterized by a very low friction coefficient and high wear resistance. &copy; (2013) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {10120386},
  journal   = {Defect and Diffusion Forum},
  key       = {Titanium carbide},
  keywords  = {Deposition;Diffusion in solids;Friction;High temperature operations;Plastics molding;Protective coatings;Tool steel;Tribology;Wear resistance;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/DDF.334-335.97},
}

@InProceedings{20155101683446,
  author    = {Ignaszak, Z. and Popielarski, P.},
  title     = {Effective modeling of phenomena in over-moisture zone existing in porous sand mould using the simplified simulation systems applied in foundry},
  year      = {2015},
  volume    = {365},
  pages     = {200 - 206},
  address   = {Paris, France},
  note      = {Sand moulds;Simulation systems;Technological properties;Technological tools;Thermal coefficients;Thermo-physical property;Validation;Virtualizations;},
  abstract  = {The problem concerns the thermo-physical properties of the mould material to which the liquid metal is poured (foundry industry). In the foundry processes the sand mould fulfils an auxiliary role only as technological tool, but its physical and technological properties determine the quality of the casting. The study includes the iron plate casting experiments poured in multi-component porous sand mould. The temperature fields of casting and in different zones of the mould were recorded. The determining of the thermo-physical properties of mould sand in over-moisture zone using simulation tests in Procast system was the goal of our study. An originality of the related research is an attempt to take into account the effects of the global thermal phenomena occurring in the quartz sand bonded by bentonite-water binder, using the apparent thermal coefficients. The majority of foundry simulation systems are not capable to modeling the phase transformation of water into vapor, vapor transport and its condensation in porous media (mould). In these cases the application of apparent coefficients is an effective way. &copy; (2015) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {10120386},
  journal   = {Defect and Diffusion Forum},
  key       = {Foundry sand},
  keywords  = {Casting;Diffusion in solids;Foundries;Heat transfer;Liquids;Mass transfer;Moisture;Molds;Physical properties;Porous materials;Sand;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/DDF.365.200},
}

@InProceedings{20155101683449,
  author    = {Campos, Daniel Baracuy Da Cunha and Conrado, Libia De Sousa and Morais, Crislene Rodrigues Silva},
  title     = {Physical - Chemistry characterization of Sweet Sorghum bagasse in nature and delignificate with NaOH to produce bioethanol},
  year      = {2015},
  volume    = {365},
  pages     = {219 - 225},
  address   = {Paris, France},
  note      = {Independent variables;Lignocellulosic;Lignocellulosic wastes;Physico-chemical characterization;Sodium hydroxides;Sweet sorghum;Sweet sorghum bagasse;Time-dependent variables;},
  abstract  = {Lignocellulosic wastes are the most abundant in the world and there is currently a global concern to harness them as biomass to produce cellulosic ethanol, being possible due to the materials being rich in cellulose. The main goal of this work is to produce the delignification from Sweet Sorghum waste free from extractives as well as the physico-chemical characterization in the natural state after being delignificated aiming to remove the lignin that acts as a barrier preventing access of the enzyme to the cellulose in the enzymatic hydrolysis processes. The following tests were performed: moisture, ash, cellulose, lignin, hemicelluloses, AR, extractives, XRD and SEM. Aftter the procedure of delignification, it was characterized as cellulose, lignin, XRD and SEM to check if there was removal of the lignin and if there was no change in crystallinity. The characterization showed that the Sweet Sorghum waste is a viable alternative for the production of bioethanol and proved to be an important source of cellulose presenting a content of glucose of 45.99 &plusmn; 0.63% and a lignin content of 14.63 &plusmn; 0.23%. The Sweet Sorghum waste was deslignificated by pulping with sodium hydroxide (NaOH) process, using as an experimental tool design type 2<sup>3</sup>with 3 replications at the center point, to evaluate the effect of independent variables temperature, such as concentration of the NaOH solution and the time dependent variable in the delignification. The planning showed through the Pareto's diagram that the most influential variable in the process was the concentration which showed a response of 75.1258 and a greater interaction occurred on the variables temperature and concentration with a response of 1.653117. The regression model as well as being a statistically significant predictor, also presents a reason F calculated and F tabulated of 10.10 and achieving a maximum yield of 57.85% delignification. After delignification processes the waste showed a rate of 5.81 &plusmn; 0.18% lignin and 43.13 &plusmn; 0.53% cellulose, as well as an increase in crystallinity, verified by analysis of SEM and XRD. &copy; (2015) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {10120386},
  journal   = {Defect and Diffusion Forum},
  key       = {Characterization},
  keywords  = {Bioethanol;Cellulose;Cellulosic ethanol;Delignification;Diffusion in solids;Enzymatic hydrolysis;Ethanol;Heat transfer;Lignin;Mass transfer;Physical chemistry;Regression analysis;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/DDF.365.219},
}

@InProceedings{20142617869398,
  author    = {Notario, B. and Pinto, J. and Solorzano, E. and Escudero, J. and Martin-De Leon, J. and Velasco, D. and Rodriguez-Perez, M.A.},
  title     = {In-Situ optical analysis of structural changes in polylactic acid (PLA) during the gas dissolution process},
  year      = {2014},
  volume    = {353},
  pages     = {131 - 136},
  address   = {Madrid, Spain},
  note      = {Crystallization process;Glass windows;In-situ characterization;Nondestructive tools;Optical measurement;Optical parameter;Poly lactic acid;Temporal evolution;},
  abstract  = {An own-designed pressure vessel with glass windows has been employed to perform an in-situ characterization of the temporal evolution of the crystallization process of an amorphous polylactic acid (PLA) under different controlled CO2 pressures and temperatures. It has been proven that crystallinity can be related to optical parameters such as transmissivity, obtaining information about the whole process by optical measurements. The method has the advantage of measuring insitu over bulk samples with a non-destructive tool. The obtained results have shown some unexpected trends that have been explained taking into account the complex phenomena occurring during the crystallization process of PLA in the presence of CO2 at high pressure &copy;(2014) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {10120386},
  journal   = {Defect and Diffusion Forum},
  key       = {Polyesters},
  keywords  = {Carbon dioxide;Diffusion;Diffusion in solids;Glass;Optical data processing;Polymers;Pressure vessels;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/DDF.353.131},
}

@InProceedings{20142617869382,
  author    = {De Oliveira, Iran Rodrigues and Amico, Sandro Campos and Souza, Jeferson Avila and De Lima, Antonio Gilson Barbosa},
  title     = {Resin transfer molding process: A numerical analysis},
  year      = {2014},
  volume    = {353},
  pages     = {44 - 49},
  address   = {Madrid, Spain},
  note      = {Computational fluid flow;Fibrous media;Granulometries;Injection pressures;Numerical results;Rectilinear flow;Resin flows;Room temperature;},
  abstract  = {This work aims to investigate the infiltration of a CaCO3 filled resin using experiments and the PAM-RTM software. A preform of glass fiber mat, with dimensions 320 x 150 x 3.6 mm, has been used for experiments conducted at room temperature, with injection pressure of 0.25bar. The resin contained 10 and 40% CaCO3 content with particle size 38i&grave;m. The numerical results were evaluated by direct comparison with experimental data. The flat flow-front profile of the rectilinear flow was reached approximately halfway the length of the mold. It was observed, that the speed of the filling decreases with increasing CaCO3 content and,the higher the amount of CaCO3 in the resin, the lower the permeability of the reinforcement that is found. The reduction in permeability is due to the presence of calcium carbonate particles between the fibers, hindering the resin flow in the fibrous media. The computational fluid flow analysis with the PAM-RTM proved to be an accurate tool study for the processing of composite materials. &copy; (2014) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {10120386},
  journal   = {Defect and Diffusion Forum},
  key       = {Resins},
  keywords  = {Diffusion in solids;Experiments;Flow simulation;Pressure;Resin transfer molding;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/DDF.353.44},
}

@InProceedings{20122015025518,
  author    = {Valicek, Jan and Harnicarova, Marta and Cep, Robert and Rokosz, Krzysztof and Lukianowicz, Czeslaw and Kozak, Drazan and Zelenak, Michal and Kotial, Pavol},
  title     = {Surface quality control of materials being cut by laser with respect to corrosion resistance},
  year      = {2012},
  volume    = {326-328},
  pages     = {324 - 329},
  address   = {Algarve, Portugal},
  note      = {Analytical approximation;Basic equations;Deformation properties;Direct impact;Input variables;Laser cutting;Laser performance;Laser power;Material property;Mechanical balance;Prediction equations;Stress-strain;Traverse speed;},
  abstract  = {In the field of laser cutting, the research area is oriented mainly to understanding of the mechanism of removal, as well as to the combination of factors entering the process. This process of disintegration of materials presents a problem of analytical approximation, elaboration, and description [1 - 5]. Compared with previous approach to a solution, we have chosen our own way and we focus on mechanical respectively stress-strain parameters of the material being cut and the mechanical balance system: material properties - tool properties - deformation properties. We shall present here the basic forms of prediction equations for calculating the roughness of cutting walls, as well as other equations which were derived by modifying the basic equations for different application purposes, especially to calculate the optimum traverse speed v<inf>popt</inf>, optimal laser performance W<inf>lasopt</inf> and technologically important ratio IND<inf>vpwopt</inf> = v<inf>popt</inf>/W <inf>lasopt</inf>. These contain easily available input variables for substitution. The basic forms, including the modified forms are aimed at predicting the quality of cut with its depth limits. The paper presents the method of optimization of the ratio between the traverse speed v<inf>p</inf> and laser power W<inf>las</inf> which minimizes the final surface roughness after cutting with a direct impact on corrosion resistance of materials. &copy; (2012) Trans Tech Publications.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {10120386},
  journal   = {Defect and Diffusion Forum},
  key       = {Corrosion resistance},
  keywords  = {Control;Diffusion in solids;Heat transfer;Liquids;Mass transfer;Mechanical properties;Microstructure;Nanostructured materials;Optimization;Surface properties;Surface roughness;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/DDF.326-328.324},
}


@inproceedings{20122015025580,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Diffusion of oxygen and nitrogen in the Ti-15Mo alloy used for biomedical applications},
journal = {Defect and Diffusion Forum},
author = {Junior, Jose Roberto Severino Martins and Nogueira, Renata Abdallah and De Araujo, Raul Oliveira and Grandini, Carlos Roberto},
volume = {326-328},
year = {2012},
pages = {696 - 701},
issn = {10120386},
address = {Algarve, Portugal},
abstract = {The Ti-15Mo alloy is a promising material for use as a biomaterial because of its excellent corrosion resistance and its good combination of mechanical properties, such as fatigue, hardness, and wears resistance. This alloy has a body-centered predominantly cubic crystalline structure and the addition of interstitial atoms, such as oxygen and nitrogen, strongly alters its mechanical properties. Mechanical spectroscopy is a powerful tool to study the interaction of interstitial elements with the matrix metal or substitutional solutes, providing information such as the distribution and the concentration of interstitial elements. The objective of this paper is to study of the effects of heavy interstitial elements, such as oxygen and nitrogen, on the anelastic properties of the Ti-15Mo alloy by using mechanical spectroscopy measurements. In this study, the diffusion coefficients, pre-exponential factors, and activation energies were calculated for the oxygen in the Ti-15Mo alloy. &copy; (2012) Trans Tech Publications.},
key = {Molybdenum},
keywords = {Activation energy;Biological materials;Biomaterials;Corrosion resistance;Diffusion;Diffusion in solids;Heat transfer;Liquids;Mass transfer;Mechanical properties;Medical applications;Microstructure;Molybdenum alloys;Nanostructured materials;Nitrogen;Oxygen;Titanium alloys;},
note = {Anelastic properties;Biomedical applications;Cubic crystalline;Excellent corrosion resistances;Interstitial atoms;Interstitial elements;Matrix metal;Mechanical spectroscopy;Preexponential factor;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/DDF.326-328.696},
} 


@inproceedings{20122015025550,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Creep behavior of the inconel 718 superalloy},
journal = {Defect and Diffusion Forum},
author = {Sugahara, T. and Martinolli, K. and Reis, D.A.P. and Moura Neto, C. and Couto, A.A. and Piorino Neto, F. and Barboza, M.J.R.},
volume = {326-328},
year = {2012},
pages = {509 - 514},
issn = {10120386},
address = {Algarve, Portugal},
abstract = {A superalloy is an alloy developed for elevated temperature service, where relatively severe mechanical stressing is encountered, and where high surface stability is frequently required. High temperature deformation of Ni-base superalloys is very important since the blades and discs of aero engine turbine, because need to work at elevated temperature for an expected long period. The nickel-base alloy Inconel 718 has being investigated because it is one of the most widely used superalloys. The objective of this work was to evaluate the creep behavior of the Inconel 718 focusing on the determination of the experimental parameters related to the primary and secondary creep states. Constant load creep tests were conducted with at 650, 675 and 700&deg;C and the range of stress was from 625 to 814 MPa to according to ASTM E139 standard. The relation between primary creep time and steady-state creep rate, obeyed the equation for both atmospherics conditions at 650, 675 and 700&deg;C. The microstructural characterization employing the technique of scanning electron microscopy has been a valuable tool for understanding the mechanisms of creep. &copy; (2012) Trans Tech Publications.},
key = {Creep},
keywords = {Atmospheric electricity;Diffusion in solids;Heat transfer;High temperature operations;Liquids;Mass transfer;Microstructure;Nanostructured materials;Scanning electron microscopy;Superalloys;Turbomachine blades;},
note = {Aero-engine turbines;Constant load creep tests;Creep behaviors;Elevated temperature;Experimental parameters;High temperature deformation;Inconel-718;Mechanical stressing;Micro-structural characterization;Ni-base superalloys;Nickel base alloys;Primary creep;Secondary creep;Steady state creep rate;Surface stability;},
URL = {http://dx.doi.org/10.4028/www.scientific.net/DDF.326-328.509},
} 


@inproceedings{20164302937237,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Leveraging model driven engineering in software product line architectures},
journal = {ACM International Conference Proceeding Series},
author = {Trask, Bruce and Roman, Angel},
volume = {16-23-September-2016},
year = {2016},
pages = {310 - },
address = {Beijing, China},
abstract = {The process of Developing Software Product Line Architectures can be a complex task. However, the use of Model Driven Engineering (MDE) techniques can facilitate the development of SPLAs by introducing Domain Specific Languages, Graphical Editors, and Generators. Together these are considered the sacred triad of MDE. Key to understanding MDE and how it fits into SPLAs is to know exactly what each part of the trinity means, how it relates to the other parts, and what the various implementations are for each. This tutorial will demonstrate the use of the Eclipse Modeling Framework (EMF) and the Sirius Graphical Framework to create an actual MDE solution as applied to a sample SPLA. These tools collectively form what is called a Language Workbench. During this tutorial we will also illustrate how to model the visual artifacts of our Domain Model and generate a Domain Specific Graphical Editor from a Domain Specific Language. &copy; 2016 ACM.},
key = {Software design},
keywords = {Computer programming languages;Computer software;Embedded systems;Graphical user interfaces;Problem oriented languages;Visual languages;},
note = {Domain specific languages;Eclipse modeling framework;Graphical editors;Language workbenches;Leveraging model;Model-driven Engineering;Software product line architecture;Visual artifacts;},
URL = {http://dx.doi.org/10.1145/2934466.2956654},
} 

@InProceedings{20164302937248,
  author    = {Lillack, Max and Berger, Thorsten and Hebig, Regina},
  title     = {Experiences from reengineering and modularizing a legacy software generator with a projectional language workbench},
  year      = {2016},
  volume    = {16-23-September-2016},
  pages     = {346 - 353},
  address   = {Beijing, China},
  note      = {Critical software;Generation process;Individual customers;Language extensibilities;Language workbenches;Legacy software;Meta Programming;Model to text transformations;},
  abstract  = {We present a case study of migrating a legacy language infrastructure and its codebase to a projectional language workbench. Our subject is the generator tool ADS used for generating COBOL code for critical software systems. We decompose the ADS language into smaller sub-languages, which we implement as individual DSLs in the projectional language workbench JetBrains Meta Programming System (MPS). Our focus is on ADS' preprocessor sub-language, used to realize static variability by conditionally including or parameterizing target code. The modularization of ADS supports future extensions and tailoring the language infrastructure to the needs of individual customers. We re-implement the generation process of target code as chained model-to-model and model-to-text transformations. For migrating existing ADS code, we implement an importer relying on a parser in order to create a model in MPS. We validate the approach using an ADS codebase for handling car registrations in the Netherlands. Our case study shows the feasibility and benefits (e.g., language extensibility and modern editors) of the migration, but also smaller caveats (e.g., small syntax adaptations, the necessity of import tools, and providing training to developers). Our experiences are useful for practitioners attempting a similar migration of legacy generators to a projectional language workbench. &copy; 2016 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Deceleration},
  keywords  = {Codes (symbols);Computer software;Modular construction;Syntactics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2934466.2962733},
}


@inproceedings{20163502742316,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Canopus: A Domain-Specific Language for Modeling Performance Testing},
journal = {Proceedings - 2016 IEEE International Conference on Software Testing, Verification and Validation, ICST 2016},
author = {Bernardino, Maicon and Zorzo, Avelino F. and Rodrigues, Elder M.},
year = {2016},
pages = {157 - 167},
address = {Chicago, IL, United states},
abstract = {Despite all the efforts to reduce the cost of the testing phase in software development, it is still one of the most expensive phases. In order to continue to minimize those costs, in this paper, we propose a Domain-Specific Language (DSL), built on top of MetaEdit+ language workbench, to model performance testing for web applications. Our DSL, called Canopus, was developed in the context of a collaboration between our university and a Technology Development Laboratory (TDL) from an Information Technology (IT) company. We present, in this paper, the Canopus metamodels, its domain analysis, a process that integrates Canopus to Model-Based Performance Testing, and applied it to an industrial case study. &copy; 2016 IEEE.},
key = {Software testing},
keywords = {Computational linguistics;Computer programming languages;Model checking;Modeling languages;Problem oriented languages;Software design;Verification;},
note = {Domain specific languages;Domain specific modeling;Industrial case study;Language workbenches;Model based testing;Model performance;Performance testing;Technology development;},
URL = {http://dx.doi.org/10.1109/ICST.2016.13},
} 

@InProceedings{20162602546943,
  author    = {Voelter, Markus and Molotnikov, Zaur and Kolb, Bernd},
  title     = {Towards improving software security using language engineering and mbeddr C},
  year      = {2015},
  pages     = {55 - 62},
  address   = {Pittsburgh, PA, United states},
  note      = {Domain specific languages;Empirical evaluations;IDEs;Language engineering;Language extensions;Language workbenches;Modular extension;Software security;},
  abstract  = {This paper explores the use of domain-specific languages for improving software security, which deals with developing software in a way that is not maliciously exploitable. Specifically we demonstrate how modular extension of the C programming language can help with technical and process-related aspects of software security. Some of these examples are already implemented, some are analytical extrapolations from related work we have done in the past; a detailed empirical evaluation has not yet been done. We rely on mbeddr, an extensible version of C developed with the JetBrains MPS language workbench. We conclude the paper with a discussion of the potential drawbacks of the approach and how these can be addressed in the future. Copyright Is Held By The Owner/author(s).},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {DSM 2015 - Proceedings of the Workshop on Domain-Specific Modeling},
  key       = {C (programming language)},
  keywords  = {Computational linguistics;Computer programming languages;Modeling languages;Models;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2846696.2846698},
}


@inproceedings{20160801977282,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Using C language extensions for developing embedded software: A case study},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Voelter, Markus and Van Deursen, Arie and Kolb, Bernd and Eberle, Stephan},
volume = {25-30-Oct-2015},
year = {2015},
pages = {655 - 674},
address = {Pittsburgh, PA, United states},
abstract = {We report on an industrial case study on developing the embedded software for a smart meter using the C programming language and domain-specific extensions of C such as components, physical units, state machines, registers and interrupts. We find that the extensions help significantly with managing the complexity of the software. They improve testability mainly by supporting hardware-independent testing, as illustrated by low integration efforts. The extensions also do not incur significant overhead regarding memory consumption and performance. Our case study relies on mbeddr, an extensible version of C. mbeddr, in turn, builds on the MPS language workbench which supports modular extension of languages and IDEs. &copy; 2015 ACM.},
key = {C (programming language)},
keywords = {Computational linguistics;Computer programming languages;Computer systems programming;Embedded software;Integration testing;Object oriented programming;Problem oriented languages;},
note = {Domain specific languages;Hardware independent;Industrial case study;Language engineering;Language extensions;Language workbenches;Memory consumption;Modular extension;},
URL = {http://dx.doi.org/10.1145/2814270.2814276},
} 

@InProceedings{20154501495155,
  author    = {Deantoni, Julien and Diallo, Issa Papa and Teodorov, Ciprian and Champeau, Joel and Combemale, Benoit},
  title     = {Towards a meta-language for the concurrency concern in DSLs},
  year      = {2015},
  volume    = {2015-April},
  pages     = {313 - 316},
  address   = {Grenoble, France},
  note      = {Analysis techniques;Complex software;Concurrency constraints;Domain specific languages;Industrial processs;Language workbenches;Meta language;Synchronous data flow;},
  abstract  = {Concurrency is of primary interest in the development of complex software-intensive systems, as well as the deployment on modern platforms. Furthermore, Domain-Specific Languages (DSLs) are increasingly used in industrial processes to separate and abstract the various concerns of complex systems. However, reifying the definition of the DSL concurrency remains a challenge. This not only prevents leveraging the concurrency concern of a particular domain or platform, but it also hinders: a) the development of a complete understanding of the DSL semantics; b) the effectiveness of concurrency-aware analysis techniques; c) the analysis of the deployment on parallel architectures. In this paper, we introduce the key ideas leading toward MoCCML, a dedicated meta-language for formally specifying the concurrency concern within the definition of a DSL. The concurrency constraints can reflect the knowledge in a particular domain, but also the constraints of a particular platform. MoCCML comes with a complete language workbench to help a DSL designer in the definition of the concurrency directly within the concepts of the DSL itself, and a generic workbench to simulate and analyze any model conforming to this DSL. MoCCML is illustrated on the definition of an lightweight extension of SDF (Synchronous Data Flow [1]). &copy; 2015 EDAA.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {15301591},
  journal   = {Proceedings -Design, Automation and Test in Europe, DATE},
  key       = {Computational linguistics},
  keywords  = {Computer programming languages;Parallel architectures;Problem oriented languages;Response time (computer systems);Semantics;},
  language  = {English},
}


@inproceedings{20155201722487,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Languagelab - a meta-modelling environment},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Gjosaeter, Terje and Prinz, Andreas},
volume = {9369},
year = {2015},
pages = {91 - 105},
issn = {03029743},
address = {Berlin, Germany},
abstract = {In the Language Lab language workbench, we build on a component-based approach to language specification that facilitates the specification of all aspects of a computer language in a consistent manner, taking into account best practices in meta-modelling and language design. The workbench allows operation on a suitable abstraction level, and also focuses on user-friendliness and a low threshold to getting started, in order to make it useful for teaching of meta-modelling and language design and specification. The platform is open for third party language modules and facilitates rapid prototyping of DSLs, re-use of language modules, and experiments with multiple concrete syntaxes. The platform also allows interested parties to develop Language Lab modules that can further add to the features and capabilities of the Language Lab platform. &copy; Springer International Publishing Switzerland 2015.},
key = {Modeling languages},
keywords = {Computational linguistics;DSL;Specifications;Systems analysis;},
note = {Component based approach;Development environment;Language;Language specification;Language workbenches;Meta-modelling;User friendliness;Workbenches;},
URL = {http://dx.doi.org/10.1007/978-3-319-24912-4_8},
} 

@InProceedings{20153701272054,
  author    = {Erdweg, Sebastian and Van Der Storm, Tijs and Volter, Markus and Tratt, Laurence and Bosman, Remi and Cook, William R. and Gerritsen, Albert and Hulshout, Angelo and Kelly, Steven and Loh, Alex and Konat, Gabriel and Molina, Pedro J. and Palatnik, Martin and Pohjonen, Risto and Schindler, Eugen and Schindler, Klemens and Solmi, Riccardo and Vergu, Vlad and Visser, Eelco and Van Der Vlist, Kevin and Wachsmuth, Guido and Van Der Woning, Jimi},
  title     = {Evaluating and comparing language workbenches: Existing results and benchmarks for the future},
  year      = {2015},
  volume    = {44},
  pages     = {24 - 47},
  note      = {Bench-mark problems;Domain specific languages;Empirical data;Generic features;Language workbenches;Questionnaire language;},
  abstract  = {Language workbenches are environments for simplifying the creation and use of computer languages. The annual Language Workbench Challenge (LWC) was launched in 2011 to allow the many academic and industrial researchers in this area an opportunity to quantitatively and qualitatively compare their approaches. We first describe all four LWCs to date, before focussing on the approaches used, and results generated, during the third LWC. We give various empirical data for ten approaches from the third LWC. We present a generic feature model within which the approaches can be understood and contrasted. Finally, based on our experiences of the existing LWCs, we propose a number of benchmark problems for future LWCs. &copy; 2015 Elsevier Ltd. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {14778424},
  journal   = {Computer Languages, Systems and Structures},
  key       = {Computational linguistics},
  keywords  = {Benchmarking;Computer programming languages;Problem oriented languages;Surveying;Surveys;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.cl.2015.08.007},
}

@Article{20153501222624,
  author    = {Voelter, Markus and Warmer, Jos and Kolb, Bernd},
  title     = {Projecting a Modular Future},
  journal   = {IEEE Software},
  year      = {2015},
  volume    = {32},
  number    = {5},
  pages     = {46 - 52},
  note      = {Domain specific languages;Language engineering;Language workbenches;mbeddr;Meta Programming;MPS;projectional editing;},
  abstract  = {Two innovations are enhancing programming languages' capabilities. First, modularity lets you combine independently developed languages without changing their respective definitions. A language is no longer a fixed quantity; you can extend it with domain-specific constructs as needed. Second, projectional editing lets you build editors and IDEs that don't require parsers. Such editors and IDEs support a range of tightly integrated notations, including textual, symbolic, tabular, and graphical notations. In addition, by avoiding parsers, they avoid grammar composition's well-known limitations. Three examples illustrate how these two innovations affect programming-language design. A set of modular extensions of C for embedded programming enables efficient code generation and formal analysis. A language for requirements engineering flexibly combines structured and unstructured (prose) data. Finally, a language for defining insurance rules uses mathematical notation. These examples all rely on the open source JetBrains MPS (Meta Programming System) language workbench. This article is part of a special issue on Software Architecture. &copy; 1984-2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {07407459},
  key       = {C (programming language)},
  keywords  = {Computational linguistics;Computer programming languages;Formal methods;Object oriented programming;Open source software;Open systems;Problem oriented languages;Software design;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/MS.2014.103},
}

@InProceedings{20153601229013,
  title     = {ACM International Conference Proceeding Series},
  year      = {2015},
  volume    = {2015-March},
  pages     = {AOSA -},
  address   = {Fort Collins, CO, United states},
  abstract  = {The proceedings contain 17 papers. The topics discussed include: a theory of modularity for automated software development; feature modeling and traceability for concern-driven software development with TouchCORE; subjective, multidimensional modularity with Korz Harold Ossher David Ungar Doug Kimelman; a language workbench for implementing your favorite extension to AspectJ&lowast;; towards the use of slicing techniques for an efficient invariant checking; composition challenges for sensor data visualization; first-class domain specific aspect languages&lowast;; on liberating programs from the von Neumann architecture via event-based modularization; demanding first-class equality for domain specific aspect languages&lowast;; and visualization algorithms for feature models in concern-driven software development.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {ACM International Conference Proceeding Series},
  language  = {English},
}

@InProceedings{20153601228999,
  author    = {Hadas, Arik and Lorenz, David H.},
  title     = {A language workbench for implementing your favorite extension to AspectJ},
  year      = {2015},
  volume    = {2015-March},
  pages     = {19 - 20},
  address   = {Fort Collins, CO, United states},
  note      = {Aspect-J;Aspect-Oriented Programming (AOP);Domain specific;Domain specific languages;Join point;Language workbenches;Spoofax;},
  abstract  = {Many extensions to AspectJ are proposed and prototyped. However, without a supportive language workbench the proper evaluation and production of these extensions is often prohibitively costly. We demonstrate a novel language workbench for creating such extensions, comprising AWESOME and Spoofax. The implementation of two advanced extensions to AspectJ are illustrated: explicit join points (EJPs) and closure join points (CJPs). Not only were these extensions fully implemented from scratch with reasonable effort, but also our implementations support advanced features that were omitted in the original prototypes. The demonstration will provide a hands-on overview of the process of implementing EJPs and CJPs in our workbench and how one can implement other extensions with relative ease.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Computational linguistics},
  keywords  = {Aspect oriented programming;Computer programming languages;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2735386.2735924},
}


@inproceedings{20153601229006,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Demanding first-class equality for domain specific aspect languages},
journal = {ACM International Conference Proceeding Series},
author = {Hadas, Arik and Lorenz, David H.},
volume = {2015-March},
year = {2015},
pages = {35 - 38},
address = {Fort Collins, CO, United states},
abstract = {Domain specific aspect languages (DSALs) are programming languages that are both domain specific and aspect-oriented. However, DSALs seem to be second-class. On the one hand, language workbenches handle only DSLs that are not aspect-oriented, making it difficult to develop new DSALs. On the other hand, development tools for general purpose aspect-oriented languages do not work with DSALs, making it difficult to use them. In this work we present an approach for building a modular DSAL workbench that produces first-class DSALs. A DSAL is said to be first-class if development tools treat it as a general purpose AOP language. Specifically, this means that first-class DSALs for Java can be used with tools that work with AspectJ. For concreteness, we illustrate the approach by describing our implementation of a DSAL workbench, comprising the Spoofax language workbench and the AWESOME composition framework, for programming with first-class DSALs in Java.},
key = {Aspect oriented programming},
keywords = {Computational linguistics;Computer programming languages;High level languages;Java programming language;Problem oriented languages;},
note = {Aspect-Oriented Programming (AOP);AWESOME;Domain specific;Domain specific languages;Language workbenches;Spoofax;},
URL = {http://dx.doi.org/10.1145/2735386.2735388},
} 

@InProceedings{20153401194473,
  author    = {Haber, Arne and Look, Markus and Perez, Antonio Navarro and Nazari, Pedram Mir Seyed and Rumpe, Bernhard and Volkel, Steven and Wortmann, Andreas},
  title     = {Integration of heterogeneous modeling languages via extensible and composable language components},
  year      = {2015},
  pages     = {19 - 31},
  address   = {Angers, Loire Valley, France},
  note      = {Heterogeneous modeling;Language engineering;Language inheritances;Language integration;Language workbenches;MDE;Model-driven Engineering;Traditional models;},
  abstract  = {Effective model-driven engineering of complex systems requires to appropriately describe different specific system aspects. To this end, efficient integration of different heterogeneous modeling languages is essential. Modeling language integaration is onerous and requires in-depth conceptual and technical knowledge and effort. Traditional modeling lanugage integration approches require language engineers to compose monolithic language aggregates for a specific task or project. Adapting these aggregates to different contexts requires vast effort and makes these hardly reusable. This contribution presents a method for the engineering of grammarbased language components that can be independently developed, are syntactically composable, and ultimately reusable. To this end, it introduces the concepts of language aggregation, language embedding, and language inheritance, as well as their realization in the language workbench MontiCore. The result is a generalizable, systematic, and efficient syntax-oriented composition of languages that allows the agile employment of modeling languages efficiently tailored for individual software projects. Copyright &copy; 2015 SCITEPRESS - Science and Technology Publications.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {MODELSWARD 2015 - 3rd International Conference on Model-Driven Engineering and Software Development, Proceedings},
  key       = {Modeling languages},
  keywords  = {Aggregates;Computational linguistics;Integration;Software design;},
  language  = {English},
}

@InProceedings{20153401194495,
  author    = {Huang, Changyun and Osaka, Ataru and Kamei, Yasutaka and Ubayashi, Naoyasu},
  title     = {Automated DSL construction based on software product lines},
  year      = {2015},
  pages     = {247 - 254},
  address   = {Angers, Loire Valley, France},
  note      = {Domain knowledge;Domain specific languages;Execution platforms;Language workbenches;Mining software repositories;Research fields;Software abstractions;Software Product Line;},
  abstract  = {DSL (Domain-Specific Language) is one of the important approaches for software abstraction. In the past decades, DSLs have been provided by expert engineers familiar with domain knowledge and programming language processors. It is not easy for ordinary programmers to construct DSLs for their own purposes. To deal with this problem, we propose a language workbench called Argyle that can automatically generate a DSL by only specifying a set of functions needed to the DSL and an execution platform supported by the DSL. Argyle is based on software product lines and consists of the following two steps: 1) development of the core assets for constructing a family of DSLs and 2) DSL configuration using these core assets. To demonstrate the effectiveness of our approach, we developed a prototype DSL for supporting MSR (Mining Software Repositories), the most active research field in software engineering. Copyright &copy; 2015 SCITEPRESS - Science and Technology Publications.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {MODELSWARD 2015 - 3rd International Conference on Model-Driven Engineering and Software Development, Proceedings},
  key       = {Software design},
  keywords  = {Computational linguistics;Computer programming languages;Computer software;DSL;Problem oriented languages;Software engineering;Software prototyping;},
  language  = {English},
}

@InProceedings{20152801029956,
  author    = {Korenkov, Yuriy and Loginov, Ivan and Lazdin, Arthur},
  title     = {PEG-based language workbench},
  year      = {2015},
  volume    = {2015-June},
  number    = {June},
  pages     = {75 - 81},
  address   = {Yaroslavl, Russia},
  note      = {Domain specific languages;Integrated development environment;Language workbenches;Parsing expression grammars;},
  abstract  = {In this article we present a new tool for language-oriented programming which provides to user convenient means to describe the domain specific languages in the form of language based on parsing expression grammars and helpful tools for grammar debugging. Also we consider the sample of using this toolkit as a part of an integrated development environment. &copy; 2015 FRUCT Oy.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {23057254},
  journal   = {Conference of Open Innovation Association, FRUCT},
  key       = {Computational linguistics},
  keywords  = {Computer programming languages;Formal languages;Innovation;Problem oriented languages;Web services;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/FRUCT.2015.7117975},
}

@InProceedings{20162602546941,
  author    = {Degueule, Thomas and Combemale, Benoit and Blouin, Arnaud and Barais, Olivier},
  title     = {Reusing legacy DSLs with melange},
  year      = {2015},
  pages     = {45 - 46},
  address   = {Pittsburgh, PA, United states},
  note      = {Domain specific languages;Language reuse;Language workbenches;Melange;Model typing;},
  abstract  = {The proliferation of independently-developed and constantly-evolving domain-specific languages (DSLs) in many domains raises new challenges for the software language engineering community. Instead of starting the definition of new DSLs from scratch, language designers would benefit from the reuse of previously defined DSLs. While the support for engineering isolated DSLs is getting more and more mature, there is still little support in language workbenches for importing, assembling, and customizing legacy languages to form new ones. Melange is a new language workbench where new DSLs are built by assembling pieces of syntax and semantics. These pieces can be imported and subsequently extended, restricted, or customized to fit specific requirements. The demonstration will introduce the audience to the main features of Melange through the definition of an executable DSL for the design and execution of Internet of Things systems. Specifically, we will show how such a language can be obtained from the assembly of other popular languages while maintaining the compatibility with their tools and transformations. &copy; 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {DSM 2015 - Proceedings of the Workshop on Domain-Specific Modeling},
  key       = {Computational linguistics},
  keywords  = {Computer programming languages;Problem oriented languages;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2846696.2846697},
}

@Article{20143600051435,
  author    = {Jezequel, Jean-Marc and Combemale, Benoit and Barais, Olivier and Monperrus, Martin and Fouquet, Francois},
  title     = {Mashup of metalanguages and its implementation in the Kermeta language workbench},
  journal   = {Software and Systems Modeling},
  year      = {2015},
  volume    = {14},
  number    = {2},
  pages     = {905 - 920},
  note      = {Behavioral semantics;Design and implementations;Domain specific languages;Language implementations;Language workbenches;Model-driven Engineering;Run-time performance;Software languages;},
  abstract  = {With the growing use of domain-specific languages (DSL) in industry, DSL design and implementation goes far beyond an activity for a few experts only and becomes a challenging task for thousands of software engineers. DSL implementation indeed requires engineers to care for various concerns, from abstract syntax, static semantics, behavioral semantics, to extra-functional issues such as runtime performance. This paper presents an approach that uses one metalanguage per language implementation concern. We show that the usage and combination of those metalanguages is simple and intuitive enough to deserve the term mashup. We evaluate the approach by completely implementing the non-trivial fUML modeling language, a semantically sound and executable subset of the Unified Modeling Language (UML). &copy; 2013, Springer-Verlag Berlin Heidelberg.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16191366},
  key       = {Unified Modeling Language},
  keywords  = {Computational linguistics;Computer programming languages;Modeling languages;Problem oriented languages;Semantics;Visual languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s10270-013-0354-4},
}

@InProceedings{20153601229004,
  author    = {Hadas, Arik and Lorenz, David H.},
  title     = {First-class domain specific aspect languages},
  year      = {2015},
  volume    = {2015-March},
  pages     = {29 - 30},
  address   = {Fort Collins, CO, United states},
  note      = {Aspect-Oriented Programming (AOP);Composition frameworks;Domain specific;Domain specific languages;Language workbenches;Program source codes;Second class;Spoofax;},
  abstract  = {Programming in a domain specific aspect language (DSAL) typically involves some language workbench for transforming the DSAL code and some AOP composition framework for weaving the transformed code. However, DSAL development remains second-class in two respects. Unlike programming in a general purpose aspect language, compiling DSAL code requires preprocessing that makes the program source code incompatible with existing AOP tools. Unlike defining a domain specific language, defining a DSAL requires weaving semantics whose specification is not supported in the language workbench. In this work we present a DSAL workbench solution in which DSALs are first-class DSLs as well as first-class AOP languages. We illustrate the approach by integrating the Spoofax language workbench and the AWESOME composition framework into such a DSAL workbench.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Aspect oriented programming},
  keywords  = {Codes (symbols);Computational linguistics;Computer programming languages;Problem oriented languages;Semantics;Weaving;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2735386.2735929},
}


@article{20130916070127,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {DPF workbench: A multi-level language workbench for MDE},
title = {DPF-tooriistakast: Mitmetasandilised keeleprotsessorid mudel-orienteeritud projekteerimiseks},
journal = {Proceedings of the Estonian Academy of Sciences},
author = {Lamo, Yngve and Wang, Xiaoliang and Mantz, Florian and Bech, Oyvind and Sandven, Anders and Rutle, Adrian},
volume = {62},
number = {1},
year = {2013},
pages = {3 - 15},
issn = {17366046},
abstract = {This paper presents the DPF Workbench, a language workbench for (meta)modelling and code generation. The DPF Workbench includes a graphical specification editor for the Diagram Predicate Framework (DPF), which provides a graph-based formalization of (meta)modelling and model transformation. The tool offers functionality for fully diagrammatic specifications of domain-specific modelling languages. Moreover, the DPF Workbench supports the development of metamodelling hierarchies with an arbitrary number of metalevels; i.e. each model at a metalevel can be used as a metamodel for the metalevel below. The DPF Workbench facilitates the generation of domain-specific diagrammatic editors out of these metamodels. The conformance relations between adjacent metalevels are checked using typing morphisms and validation of diagrammatic constraints. In addition, the DPF Workbench provides a signature editor for the definition of software constraints and their corresponding validators. The code generator is a newly added component that facilitates the generation of software from models defined in the DPF Workbench. The features of the DPF Workbench are illustrated by a running example presenting a metamodelling hierarchy for business process modelling and sketching how these models can be transformed to programs by the code generation facility.},
key = {Network components},
keywords = {Automatic programming;Computer simulation languages;Program compilers;Specifications;},
note = {Arbitrary number;Business process modelling;Code Generation;Code generators;Diagram predicate framework;Diagrammatic constraints;Diagrammatic specifications;Domain specific;Domain-Specific Modelling Languages;Graph-based;Language workbenches;Meta levels;Meta model;Meta-modelling;Metamodeling;Model transformation;Model-driven Engineering;Morphisms;Multi-level languages;},
URL = {http://dx.doi.org/10.3176/proc.2013.1.02},
} 

@InProceedings{20150800554585,
  author    = {Ebrahimi, Amir Hossein and Johansson, Pierre E. C. and Bengtsson, Kristofer and Akesson, Knut},
  title     = {Managing product and production variety - A language workbench approach},
  year      = {2014},
  volume    = {17},
  number    = {C},
  pages     = {338 - 344},
  address   = {Windsor, ON N9B 1K3, Canada},
  note      = {Managment;Mass customization;Process platforms;Product life cycle management;Product platforms;Variability;},
  abstract  = {Product platforms are commonly used in industries with complex products and high competition like the car and truck industry to allow a customer to order a product that satisfy its unique needs. A consequence of product variety is that manufacturing and assembly processes need to deal with this variety as well. If the variety is low and changes of the product occur infrequently then the variety may be handled by designing the production system for a small set of typical products. But as the variety increases and changes become frequent the necessity for integrated product and production information model is high, to partially solve this problem Product Life Cycle Management (PLM) systems aim at providing an integrated model to all categories of users, e.g. product designers, product preparation engineers, line builders and shop-floor workers. All users need to access the information in the platform and refine and modify the information to reflect new knowledge that has been acquired. Today, most often multiple systems are used where some systems may store information in a structured way but often unstructured text documents are also used. This easily results in redundant information models and automated analysis is not feasible or not event possible because of issues regarding cohesion and traceability of information. The contribution in this paper is to discuss how a new type of tool for building domain specific languages and editors using language workbench approach can be used to support the different user categories in their tasks working with variability of a product and production system while at the same time provide cohesion and traceability of information. &copy; 2014 Elsevier B.V.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {22128271},
  journal   = {Procedia CIRP},
  key       = {Life cycle},
  keywords  = {Adhesion;Competition;Computational linguistics;Computer programming languages;Customer satisfaction;Human resource management;Industrial management;Information management;Information theory;Manufacture;Problem oriented languages;Product design;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.procir.2014.01.100},
}

@InProceedings{20144700224299,
  author    = {Szabo, Tamas and Voelter, Markus and Kolb, Bernd and Ratiu, Daniel and Schaetz, Bernhard},
  title     = {Mbeddr - Extensible languages for embedded software development},
  year      = {2014},
  pages     = {13 - 15},
  address   = {Portland, OR, United states},
  note      = {Development process;Domain specific languages;Extensible languages;Extensible set;Extension module;Language constructs;Language workbenches;Mathematical notations;},
  abstract  = {In this industrial presentation we will demonstrate mbeddr, an extensible set of integrated languages for embedded software development. After discussing the context of the talk, we will give details about the mbeddr architecture, which relies on the MPS language workbench. Then we will elaborate on the extension modules and show how they fit with safety-critical development processes. Finally we will point out how the existing languages can be extended by the user by giving some real-world examples, including a language construct that could have prevented the Apple "goto fail" bug as well as mathematical notations. Copyright is held by the owner/author(s).},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {HILT 2014 - Proceedings of the ACM Conference on High Integrity Language Technology},
  key       = {Software design},
  keywords  = {Computational linguistics;Computer programming languages;Embedded software;Embedded systems;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2663171.2663186},
}


@article{20144300123237,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Language design with the spoofax language workbench},
journal = {IEEE Software},
author = {Wachsmuth, Guido H. and Konat, Gabriel D. P. and Visser, Eelco},
volume = {31},
number = {5},
year = {2014},
pages = {35 - 43},
issn = {07407459},
abstract = {IDEs are essential for programming language developers, and state-of-the-art IDE support is mandatory for programming languages to be successful. Although IDE features for mainstream programming languages are typically implemented manually, this often isn't feasible for programming languages that must be developed with significantly fewer resources. The Spoofax language workbench is a platform for developing textual programming languages with state-of-the-art IDE support. Spoofax is a comprehensive environment that integrates syntax definition, name binding, type analysis, program transformation, code generation, and declarative specification of IDE components. It also provides high-level languages for each of these aspects. These languages are highly declarative, abstracting over the implementation of IDE features and letting engineers focus on language design. &copy; 2014 IEEE.},
key = {High level languages},
keywords = {Computer programming languages;DSL;Integrodifferential equations;Mathematical programming;Object oriented programming;Production;Software engineering;Syntactics;},
note = {Design languages;Design Methodology;IDE;Integrated development environment;Integrated environment;Programming environment;Spoofax;},
URL = {http://dx.doi.org/10.1109/MS.2014.100},
} 

@InProceedings{20134616975558,
  author    = {Thomas, Ulrike and Hirzinger, Gerd and Rumpe, Bernhard and Schulze, Christoph and Wortmann, Andreas},
  title     = {A new skill based robot programming language using UML/P Statecharts},
  year      = {2013},
  pages     = {461 - 466},
  address   = {Karlsruhe, Germany},
  note      = {Abstract levels;Domain specific languages;Eclipse plugin;Generic graphical editors;Language workbenches;Level of abstraction;Levels of detail;Light weight robots;},
  abstract  = {This paper introduces the new robot programming language LightRocks(Light Weight Robot Coding for Skills), a domain specific language (DSL) for robot programming. The language offers three different level of abstraction for robot programming. On lowest level skills are coded by domain experts. On a more abstract level these skills are supposed to be combined by shop floor workers or technicians to define tasks. The language is designed to allow as much flexibility as necessary on the lowest level of abstraction and is kept as simple as possible with the more abstract layers. A Statechart like model is used to describe the different levels of detail. For this we apply the UML/P and the language workbench MontiCore. To this end we are able to generate code while hiding controller specific implementation details. In addition the development in LightRocks is supported by a generic graphical editor implemented as an Eclipse plugin. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {10504729},
  journal   = {Proceedings - IEEE International Conference on Robotics and Automation},
  key       = {Robotics},
  keywords  = {Abstracting;Computer programming languages;Robot programming;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICRA.2013.6630615},
}

@InProceedings{20144800258215,
  author    = {Voelter, Markus and Lisson, Sascha},
  title     = {Supporting diverse notations in MPS' projectional editor},
  year      = {2014},
  volume    = {1236},
  pages     = {7 - 16},
  address   = {Valencia, Spain},
  note      = {Language workbenches;Real-world system;Underlying language;},
  abstract  = {To be able to build effective DSLs, these DSLs must not just use language concepts that are aligned with their respective domain, but also use notations that correspond closely to established domain notations - and those are often not purely textual or graphical. The underlying language workbench must support these notations, and combining different notations in a single editor must be supported as well in order to support the coherent definitions of systems that use several DSLs. In this paper we provide an overview over the notations supported by JetBrains MPS. MPS is a language workbench that uses a projectional editor, which, by its very nature, can deal with many different notational styles, including text, prose, math tables and graphics. The various supported notations are illustrated with examples from real-world systems.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  language  = {English},
}

@InProceedings{20140117164406,
  author    = {Erdweg, Sebastian and Van Der Storm, Tijs and Volter, Markus and Boersma, Meinte and Bosman, Remi and Cook, William R. and Gerritsen, Albert and Hulshout, Angelo and Kelly, Steven and Loh, Alex and Konat, Gabriel D. P. and Molina, Pedro J. and Palatnik, Martin and Pohjonen, Risto and Schindler, Eugen and Schindler, Klemens and Solmi, Riccardo and Vergu, Vlad A. and Visser, Eelco and Van Der Vlist, Kevin and Wachsmuth, Guido H. and Van Der Woning, Jimi},
  title     = {The state of the art in language workbenches: Conclusions from the language workbench challenge},
  year      = {2013},
  volume    = {8225 LNCS},
  pages     = {197 - 217},
  address   = {Indianapolis, IN, United states},
  note      = {Active area;Design spaces;Domain specific;Domain specific languages;Feature modeling;High-level mechanism;Language workbenches;State of the art;},
  abstract  = {Language workbenches are tools that provide high-level mechanisms for the implementation of (domain-specific) languages. Language workbenches are an active area of research that also receives many contributions from industry. To compare and discuss existing language workbenches, the annual Language Workbench Challenge was launched in 2011. Each year, participants are challenged to realize a given domain-specific language with their workbenches as a basis for discussion and comparison. In this paper, we describe the state of the art of language workbenches as observed in the previous editions of the Language Workbench Challenge. In particular, we capture the design space of language workbenches in a feature model and show where in this design space the participants of the 2013 Language Workbench Challenge reside. We compare these workbenches based on a DSL for questionnaires that was realized in all workbenches. &copy; 2013 Springer International Publishing.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Computer programming languages},
  keywords  = {Problem oriented languages;Surveys;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-02654-1_11},
}

@InProceedings{20140117164416,
  author    = {Combemale, Benoit and De Antoni, Julien and Larsen, Matias Vara and Mallet, Frederic and Barais, Olivier and Baudry, Benoit and France, Robert B.},
  title     = {Reifying concurrency for executable metamodeling},
  year      = {2013},
  volume    = {8225 LNCS},
  pages     = {365 - 384},
  address   = {Indianapolis, IN, United states},
  note      = {Behavioral semantics;Concurrency modeling;Concurrency semantics;Domain specific modeling languages;Execution environments;Language workbenches;Meta-modeling technique;Models of computation;},
  abstract  = {Current metamodeling techniques can be used to specify the syntax and semantics of domain specific modeling languages (DSMLs). Still, there is little support for explicitly specifying concurrency semantics of DSMLs. Often, such semantics are provided by the implicit concurrency model of the execution environment supported by the language workbench used to implement the DSMLs. The lack of an explicit concurrency model has several drawbacks: it prevents from developing a complete understanding of the DSML's behavioral semantics, as well as effective concurrency-aware analysis techniques, and explicit models of semantic variants. This work reifies concurrency as a metamodeling facility, leveraging formalization work from the concurrency theory and models of computation (MoC) community. The essential contribution of this paper is a language workbench for binding domain-specific concepts and models of computation through an explicit event structure at the metamodel level. We present a case study that serves to demonstrate the utility of the novel metamodeling facilities and clarify the scope of the approach. &copy; 2013 Springer International Publishing.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Semantics},
  keywords  = {Computer programming languages;Formal logic;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-02654-1_20},
}

@Article{20132616444306,
  author    = {Voelter, Markus and Ratiu, Daniel and Kolb, Bernd and Schaetz, Bernhard},
  title     = {Mbeddr: Instantiating a language workbench in the embedded software domain},
  journal   = {Automated Software Engineering},
  year      = {2013},
  volume    = {20},
  number    = {3},
  pages     = {339 - 390},
  note      = {Commercial projects;Domain specific languages;Extensible languages;Language workbenches;Multistage transformation;Program Verification;Requirements tracings;Small organizations;},
  abstract  = {Tools can boost software developer productivity, but building custom tools is prohibitively expensive, especially for small organizations. For example, embedded programmers often have to use low-level C with limited IDE support, and integrated into an off-the-shelf tool chain in an ad-hoc way. To address these challenges, we have built mbeddr, an extensible language and IDE for embedded software development based on C. mbeddr is a large-scale instantiation of the Jetbrains MPS language workbench. Exploiting its capabilities for language modularization and composition, projectional editing and multi-stage transformation, mbeddr is an open and modular framework that lets third parties add extensions to C with minimal effort and without invasive changes. End users can combine extensions in programs as needed. To illustrate the approach, in this paper we discuss mbeddr's support for state machines, components, decision tables, requirements tracing, product line variability and program verification and outline their implementation. We also present our experience with building mbeddr, which shows that relying on language workbenches dramatically reduces the effort of building customized, modular and extensible languages and IDEs to the point where this is affordable by small organizations. Finally, we report on the experience of using mbeddr in a commercial project, which illustrates the benefits to end users. &copy; 2013 Springer Science+Business Media New York.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {09288910},
  key       = {C (programming language)},
  keywords  = {Decision tables;Embedded software;Embedded systems;Integrodifferential equations;Modular construction;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s10515-013-0120-4},
}


@inproceedings{20144200107490,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Leveraging Model Driven Engineering in Software Product Line Architectures},
journal = {ACM International Conference Proceeding Series},
author = {Trask, Bruce and Roman, Angel},
volume = {1},
year = {2014},
pages = {360 - 361},
address = {Florence, Italy},
abstract = {The process of Developing Software Product Line Architectures can be a complex task. However, the use of Model Driven Engineering (MDE) techniques can facilitate the development of SPLAs by introducing Domain Specific Languages, Graphical Editors, and Generators. Together these are considered the sacred triad of MDE. Key to understanding MDE and how it fits into SPLAs is to know exactly what each part of the trinity means, how it relates to the other parts, and what the various implementations are for each. This tutorial will demonstrate the use of the Eclipse Modeling Framework (EMF) and Eclipse's Graphical Modeling Framework (GMF) to create an actual MDE solution as applied to a sample SPLA. These tools collectively form what is called a Language Workbench. During this tutorial we will also illustrate how to model the visual artifacts of our Domain Model and generate a Domain Specific Graphical Editor using GMF. Copyright is held by the owner/author(s).},
key = {Software design},
keywords = {Computer programming languages;Computer software;DSL;Embedded systems;Models;Problem oriented languages;Requirements engineering;},
note = {Abstraction;Constraint;Domain specific;Domain-specific testing;Graphical;Language workbenches;MDE;Meta model;Refinement;Textual;Traceability;Transformation;},
URL = {http://dx.doi.org/10.1145/2648511.2648558},
} 


@inproceedings{20130515948841,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Declarative name binding and scope rules},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Konat, Gabriel and Kats, Lennart and Wachsmuth, Guido and Visser, Eelco},
volume = {7745 LNCS},
year = {2013},
pages = {311 - 331},
issn = {03029743},
address = {Dresden, Germany},
abstract = {In textual software languages, names are used to reference elements like variables, methods, classes, etc. Name resolution analyses these names in order to establish references between definition and use sites of elements. In this paper, we identify recurring patterns for name bindings in programming languages and introduce a declarative metalanguage for the specification of name bindings in terms of namespaces, definition sites, use sites, and scopes. Based on such declarative name binding specifications, we provide a language-parametric algorithm for static name resolution during compile-time. We discuss the integration of the algorithm into the Spoofax Language Workbench and show how its results can be employed in semantic editor services like reference resolution, constraint checking, and content completion. &copy; 2013 Springer-Verlag Berlin Heidelberg.},
key = {Object oriented programming},
keywords = {Semantics;Specifications;},
note = {Compile time;Language workbenches;Name resolution;Name-binding;Namespaces;Reference resolution;Textual software;},
URL = {http://dx.doi.org/10.1007/978-3-642-36089-3_18},
} 

@InProceedings{20133916778178,
  author    = {Van Rest, Oskar and Wachsmuth, Guido and Steel, Jim R. H. and Suc, Jorn Guy and Visser, Eelco},
  title     = {Robust Real-Time Synchronization between Textual and Graphical Editors},
  year      = {2013},
  volume    = {7909 LNCS},
  pages     = {92 - 107},
  address   = {Budapest, Hungary},
  note      = {Graphical editors;Graphical modeling frameworks;Integrated development environment;Language workbenches;Robust synchronization;Spoofax;},
  abstract  = {In modern Integrated Development Environments (IDEs), textual editors are interactive and can handle intermediate, incomplete, or otherwise erroneous texts while still providing editor services such as syntax highlighting, error marking, outline views, and hover help. In this paper, we present an approach for the robust synchronization of interactive textual and graphical editors. The approach recovers from errors during parsing and text-to-model synchronization, preserves textual and graphical layout in the presence of erroneous texts and models, and provides synchronized editor services such as selection sharing and navigation between editors. It was implemented for synchronizing textual editors generated by the Spoofax language workbench and graphical editors generated by the Graphical Modeling Framework. &copy; 2013 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Synchronization},
  keywords  = {Mathematical models;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-38883-5_11},
}

@InProceedings{20143017985102,
  author    = {Ebrahimi, Amir Hossein and Johansson, Pierre E.C. and Bengtsson, Kristofer and Akesson, Knut},
  title     = {Managing product and production variety -A language workbench approach},
  year      = {2014},
  volume    = {17},
  pages     = {338 - 344},
  address   = {Windsor, ON, Canada},
  note      = {Managment;Mass customization;Process platforms;Product life cycle management;Product platforms;Variability;},
  abstract  = {Product platforms are commonly used in industries with complex products and high competition like the car and truck industry to allow a customer to order a product that satisfy its unique needs. A consequence of product variety is that manufacturing and assembly processes need to deal with this variety as well. If the variety is low and changes of the product occur infrequently then the variety may be handled by designing the production system for a small set of typical products. But as the variety increases and changes become frequent the necessity for integrated product and production information model is high, to partially solve this problem Product Life Cycle Management (PLM) systems aim at providing an integrated model to all categories of users, e.g. product designers, product preparation engineers, line builders and shop-floor workers. All users need to access the information in the platform and refine and modify the information to reflect new knowledge that has been acquired. Today, most often multiple systems are used where some systems may store information in a structured way but often unstructured text documents are also used. This easily results in redundant information models and automated analysis is not feasible or not event possible because of issues regarding cohesion and traceability of information. The contribution in this paper is to discuss how a new type of tool for building domain specific languages and editors using language workbench approach can be used to support the different user categories in their tasks working with variability of a product and production system while at the same time provide cohesion and traceability of information. &copy; 2014 Published by Elsevier B.V.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {22128271},
  journal   = {Procedia CIRP},
  key       = {Product design},
  keywords  = {Adhesion;Competition;Computer programming languages;Customer satisfaction;Human resource management;Industrial management;Information theory;Manufacture;Production engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.procir.2014.01.100},
}


@inproceedings{20133716723857,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Using language engineering to lift languages and analyses at the domain level},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Ratiu, Daniel and Voelter, Markus and Kolb, Bernd and Schaetz, Bernhard},
volume = {7871 LNCS},
year = {2013},
pages = {465 - 471},
issn = {03029743},
address = {Moffett Field, CA, United states},
abstract = {Developers who use C model checkers have to overcome three usability challenges: First, it is difficult to express application level properties as C-level verification conditions, due to the abstraction gap. Second, without advanced IDE support, it is difficult to interpret the counterexamples produced by the model checker and understand what went wrong in terms of application level properties. Third, most C model checkers support only a subset of C and it is easy for developers to inadvertently use C constructs outside this subset. In this paper we report on our preliminary experience with using the MPS language workbench to integrate the CBMC model checker with a set of domain-specific extensions of C for developing embedded software. Higher level language constructs such as components and decision tables makes it easier for end users to bridge the abstraction gap, to write verification conditions and to interpret the analysis results. Furthermore, the use of language workbenches allows the definition of analyzable language subsets, making the implementation of analyses simpler and their use more predictable. &copy; 2013 Springer-Verlag.},
key = {C (programming language)},
keywords = {Abstracting;Decision tables;Model checking;NASA;},
note = {Abstraction gap;Application level;Domain levels;Domain specific;Higher-level languages;Language engineering;Language workbenches;Verification condition;},
URL = {http://dx.doi.org/10.1007/978-3-642-38088-4_35},
} 

@InProceedings{20140117164410,
  author    = {Wachsmuth, Guido H. and Konat, Gabriel D. P. and Vergu, Vlad A. and Groenewegen, Danny M. and Visser, Eelco},
  title     = {A language independent task engine for incremental name and type analysis},
  year      = {2013},
  volume    = {8225 LNCS},
  pages     = {260 - 280},
  address   = {Indianapolis, IN, United states},
  note      = {Language independents;Language workbenches;Large project;Name resolution;Second phase;Spoofax;Task levels;Type analysis;},
  abstract  = {IDEs depend on incremental name and type analysis for responsive feedback for large projects. In this paper, we present a language-independent approach for incremental name and type analysis. Analysis consists of two phases. The first phase analyzes lexical scopes and binding instances and creates deferred analysis tasks. A task captures a single name resolution or type analysis step. Tasks might depend on other tasks and are evaluated in the second phase. Incrementality is supported on file and task level. When a file changes, only this file is recollected and only those tasks are reevaluated, which are affected by the changes in the collected data. The analysis does neither re-parse nor re-traverse unchanged files, even if they are affected by changes in other files. We implemented the approach as part of the Spoofax Language Workbench and evaluated it for the WebDSL web programming language. &copy; 2013 Springer International Publishing.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Computer programming languages},
  keywords  = {Artificial intelligence;Computer science;Computers;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-02654-1_15},
}

@InProceedings{20140517250453,
  author    = {Kelly, Steven},
  title     = {Empirical comparison of language workbenches},
  year      = {2013},
  pages     = {33 - 38},
  address   = {Indianapolis, IN, United states},
  note      = {Comparison;Experiment design;Language workbenches;Qualitative;Quantitative;},
  abstract  = {Production use of Domain-Specific Modeling languages has consistently shown productivity increase by a factor of 5-10. However, the spread of DSM has been slowed by projects stalling even before the language was built, often citing problems with the chosen tool. With a wide variety of language workbench tools for DSM, there is a need for objective empirical tool comparison - particularly as the little research so far shows a range of 50 times more effort between the most and least efficient tools. This article looks at existing empirical research and an experimental design for a future comparison. We aim at increasing objectivity and repeatability while keeping overall effort practical, and providing worthwhile returns for the participants. Copyright is held by the owner/author(s).},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {DSM 2013 - Proceedings of the 2013 ACM Workshop on Domain-Specific Modeling},
  key       = {Tools},
  keywords  = {Design of experiments;Specification languages;Surveying;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2541928.2541935},
}

@InProceedings{20143718153630,
  author    = {Zhu, Xi and Phung, Congchi and Pareto, Lars and Ehnebom, Staffan and Krekola, Mikael and Christerson, Magnus and Helander, Mats},
  title     = {An industrial case study on using language workbench technology for realizing model-driven engineering},
  year      = {2014},
  pages     = {17 - 29},
  address   = {Lisbon, Portugal},
  note      = {Domain specific languages;Language workbenches;Model-driven Engineering;Projectional editor;Software interfaces;},
  abstract  = {Model Driven Engineering (MDE) is a proven approach to improve software development processes by automation. However, traditional development of MDE tooling requires a high upfront cost. Recent developments in language workbench technologies promise to significantly reduce these investment costs. By providing domain experts with targeted projections, the speed and quality of delivering customer value is improved. This paper provides results from an industrial case study in the telecommunications domain and compares the value of using a language workbench to traditional MDE technologies. Evaluation of the approach was based on qualitative research strategy which involved a proof of concept implementation and effort estimations by tooling experts. Our results, using the Intentional Domain Workbench, indicate that applying a language workbench promises significant improvements in several aspects of MDE based software development. Most notably in this paper: (1) improved speed in development of domain specific tooling and (2) improved speed in software development process re-engineering. Copyright &copy; 2014 SCITEPRESS - Science and Technology Publications. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {MODELSWARD 2014 - Proceedings of the 2nd International Conference on Model-Driven Engineering and Software Development},
  key       = {Software design},
  keywords  = {Problem oriented languages;},
  language  = {English},
}

@InProceedings{20150400440185,
  author    = {Herrera, Adolfo Sanchez-Barbudo},
  title     = {Enhancing xtext for general purpose languages},
  year      = {2014},
  volume    = {1321},
  address   = {Valencia, Spain},
  note      = {Automatically generated;Domain specific languages;General purpose languages;Language workbenches;Operational languages;Source code generation;Source codes;Textual language;},
  abstract  = {Xtext is a popular language workbench conceived to support development of tooling (e.g. parsers and editors) for textual languages. Although Xtext offers strong support for source code generation when building tooling for Domain Specific Languages (DSL), the amount of hand-written source code required to give support to complex General Purpose Languages (GPL) is still significant. This research investigates techniques for reducing the amount of hand-written source code for supporting GPLs, via the development of new DSLs from which source code can be automatically generated. In particular, these techniques will be researched in the context of the OCL and QVT Operational languages. Copyright &copy; 2014 for the individual papers by the papers' authors.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {Computational linguistics},
  keywords  = {Codes (symbols);Computer programming languages;Problem oriented languages;},
  language  = {English},
}


@inproceedings{20124315587620,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Growing a language environment with editor libraries},
journal = {ACM SIGPLAN Notices},
author = {Erdweg, Sebastian and Katsy, Lennart C.L. and Rendel, Tillmann and Kastner, Christian and Ostermann, Klaus and Vissery, Eelco},
volume = {47},
number = {3},
year = {2012},
pages = {167 - 176},
issn = {15232867},
abstract = {different (possibly domain-specific) languages, which are often deeply interspersed even in single files. While many proposals exist on how to integrate languages semantically and syntactically, the question of how to support this scenario in integrated development environments (IDEs) remains open: How can standard IDE services, such as syntax highlighting, outlining, or reference resolving, be provided in an extensible and compositional way, such that an open mix of languages is supported in a single file? Based on our library-based syntactic extension language for Java, SugarJ, we propose to make IDEs extensible by organizing editor services in editor libraries. Editor libraries are libraries written in the object language, SugarJ, and hence activated and composed through regular import statements on a file-by-file basis. We have implemented an IDE for editor libraries on top of SugarJ and the Eclipse-based Spoofax language workbench. We have validated editor libraries by evolving this IDE into a fully-fledged and schema-aware XML editor as well as an extensible LATEX editor, which we used for writing this paper &copy; 2011 ACM.},
key = {Java programming language},
keywords = {Integrodifferential equations;Libraries;Syntactics;},
note = {Domain specific;Extension languages;Integrated development environment;Language environment;Language extensibility;Language workbenches;XML-editors;},
URL = {http://dx.doi.org/10.1145/2189751.2047891},
} 


@inproceedings{20123115288004,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Language modularity with the MPS language workbench},
journal = {Proceedings - International Conference on Software Engineering},
author = {Voelter, Markus and Pech, Vaclav},
year = {2012},
pages = {1449 - 1450},
issn = {02705257},
address = {Zurich, Switzerland},
abstract = {JetBrains MPS is a comprehensive environment for language engineering. New languages can be defined as standalone languages or as modular extensions of existing languages. Since MPS is a projectional editor, syntactic forms other than text are possible, including tables or mathematical symbols. This demo will show MPS based on mbeddr C, a novel approach for embedded software development that makes use of incremental language extension on the basis of C. &copy; 2012 IEEE.},
key = {C (programming language)},
keywords = {Embedded software;Software engineering;},
note = {Language engineering;Language extensions;Language workbenches;Modular extension;},
URL = {http://dx.doi.org/10.1109/ICSE.2012.6227070},
} 

@InProceedings{20124815720879,
  author    = {Bockisch, Christoph and Sewe, Andreas},
  title     = {The ALIA4J approach to efficient language implementation},
  year      = {2012},
  pages     = {19 - 20},
  address   = {Tucson, AZ, United states},
  note      = {Advanced dispatching;Adventure games;Compiler implementation;Domain specific;Java virtual machines;Language implementations;Machine codes;Meta model;Modern languages;Modular implementation;},
  abstract  = {New programming languages are frequently designed to improve upon other languages or to simplify programs through domain-specific abstracts. They are often implemented as transformations to an established (intermediate) language (IL). But while many new languages overlap in the semantics of their core concepts, re-using the corresponding transformations is limited by existing compiler implementation frameworks. In the ALIA4J approach, we have identified dispatching as fundamental to most abstract mechanisms and provide a metamodel of dispatching as a rich, extensible IL. Based on this meta-model, the semantics of new atomic language concepts can be implemented in a modular and portable fashion. For the execution of the IL, we provide both platform-independent and platform-dependent Java Virtual Machine extensions, the latter of which allows the modular implementation of machine code optimizations. In this demo, participants get an overview of advanced dispatching and the ALIA4J approach. By the example of a language for text-based adventure games, they will see the usage of ALIA4J as back-end for a language developed in a modern Language Workbench. Finally, the implementation of new atomic language concepts and their optimization is demonstrated.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {SPLASH'12 - Proceedings of the 2012 ACM Conference on Systems, Programming, and Applications: Software for Humanity},
  key       = {Computer systems programming},
  keywords  = {Abstracting;Optimization;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2384716.2384726},
}

@InProceedings{20124815720915,
  author    = {Voelter, Markus and Ratiu, Daniel and Schaetz, Bernhard and Kolb, Bernd},
  title     = {Mbeddr: An extensible c-based programming language and IDE for embedded systems},
  year      = {2012},
  pages     = {121 - 140},
  address   = {Tucson, AZ, United states},
  note      = {Development environment;DSLs;In-buildings;Language extensions;Language workbenches;Low-level programs;Modular language;Open Source Software;Type systems;},
  abstract  = {While the C programming language provides good sup-port for writing efficient, low-level code, it is not ad-equate for deffining higher-level abstracts relevant to embedded software. In this paper we present the mbeddr technology stack that supports extension of C with constructs adequate for embedded systems. In mbeddr, efficient low-level programs can be written using the well-known concepts from C. Higher-level domain-speciffic abstracts can be seamlessly inte-grated into C by means of modular language exten-sion regarding syntax, type system, semantics and IDE. In the paper we show how language extension can ad-dress the challenges of embedded software development and report on our experience in building these exten-sions. We show that language workbenches deliver on the promise of signifficantly reducing the effort of lan-guage engineering and the construction of correspond-ing IDEs. mbeddr is built on top of the JetBrains MPS language workbench. Both MPS and mbeddr are open source software.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {SPLASH'12 - Proceedings of the 2012 ACM Conference on Systems, Programming, and Applications: Software for Humanity},
  key       = {C (programming language)},
  keywords  = {Abstracting;Computer systems programming;Embedded software;Embedded systems;Formal methods;Integrodifferential equations;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2384716.2384767},
}


@inproceedings{20134316896253,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Generation technique for Django MVC web framework using the stratego transformation language},
journal = {2013 36th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2013 - Proceedings},
author = {Annenkov, D.V. and Cherkashin, E.A.},
year = {2013},
pages = {1084 - 1087},
address = {Opatija, Croatia},
abstract = {Domain Specific Languages (DSL) allows one to raise level of abstraction, improve development productivity, and establish an equitable communication between domain experts and developers. Language-oriented programming (LOP) is a new paradigm based on DSL construction, allowing separating domain-specific and technology-specific aspects of a system under development. LOP shares some ideas with model-driven architecture and model-driven development. Spoofax language workbench is used as a primary tool for DSL design, and based on Stratego, a transformation language with programmable rewriting strategies, and Syntax Definition Formalism as language for grammar definition. As an example of DSL a simple textual language for domain modeling is considered. Rewriting rules and strategies are used as an uniform approach to generate, validate DSL code, and make arbitrary abstract syntax tree transformations. Rules for code generation implemented using so called string interpolation technique. Source DSL code translated to python code that can be deployed within Django web framework resulting to a web-application with create/update/delete functionality on a corresponding database. Developed DSL is an example of definition by transformation approach. To get real benefits from DSL we need to add more domain specific features in DSL. &copy; 2013 MIPRO.},
key = {Aspect oriented programming},
keywords = {Communication systems;Information technology;Microelectronics;XML;},
note = {Abstract Syntax Trees;Development productivity;Domain specific languages;Generation techniques;Interpolation techniques;Model driven architectures;Model driven development;Transformation languages;},
} 

@InProceedings{20161302173488,
  author    = {Pescador, Ana and Garmendia, Antonio and Guerra, Esther and Sanchez Cuadrado, Jesus Sanchez and De Lara, Juan},
  title     = {Pattern-based development of Domain-Specific Modelling Languages},
  year      = {2015},
  pages     = {166 - 175},
  address   = {Ottawa, ON, Canada},
  note      = {Design alternatives;Design and implementations;Domain-Specific Modelling Languages;Dynamic semantic;Graphical modelling;Meta-modelling;Model-driven Engineering;Modelling environment;},
  abstract  = {Model-Driven Engineering (MDE) promotes the use of models to conduct all phases of software development in an automated way. Models are frequently defined using Domain- Specific Modelling Languages (DSMLs), which many times need to be developed for the domain at hand. However, while constructing DSMLs is a recurring activity in MDE, there is scarce support for gathering, reusing and enacting knowledge for their design and implementation. This forces the development of every new DSML to start from scratch. To alleviate this problem, we propose the construction of DSMLs and their modelling environments aided by patterns which gather knowledge of specific domains, design alternatives, concrete syntax, dynamic semantics and functionality for the modelling environment. They may have associated services, realized via components. Our approach is supported by a tool that enables the construction of DSMLs through the application of patterns, and synthesizes a graphical modelling environment according to them. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {2015 ACM/IEEE 18th International Conference on Model Driven Engineering Languages and Systems, MODELS 2015 - Proceedings},
  key       = {Modeling languages},
  keywords  = {Computational linguistics;Semantics;Software design;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/MODELS.2015.7338247},
}

@InProceedings{20154001332105,
  author    = {Lopes, Felipe A. and Santos, Marcelo and Fidalgo, Robson and Fernandes, Stenio},
  title     = {Model-driven networking: A novel approach for SDN applications development},
  year      = {2015},
  pages     = {770 - 773},
  address   = {Ottawa, ON, Canada},
  note      = {Application development;Applications development;Domain specific modeling languages;Domain-Specific Modelling Languages;Level of abstraction;Model-driven Engineering;Software defined networking (SDN);Software-defined networkings;},
  abstract  = {Software-Defined Networking (SDN) has been receiving a great deal of attention from both academic and industry communities. One reason to this interest is that SDN enables the network programmability, through an external controller, which supports applications and policies built from SDN programming languages, thus breaking the traditional bind between control and data plane. Nevertheless, the application development in this context is still complex for such recent technology. Moreover, there is a strong need for methodologies and tools that explore the abstraction levels potentials supported by SDN. This paper presents a new approach based on the Model-Driven Engineering (MDE) paradigm, called Model-Driven Networking (MDN). MDN relies on a Domain-Specific Modelling Language (DSML) to create SDN applications. We argue that MDN raises the level of abstraction on development, thus reducing the complexity to implement SDN applications and avoiding inconsistent policies. In order to show the relevance and the technological viability of our proposal, we have specified a DSML and have built a tool for creating SDN applications using the MDN approach. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the 2015 IFIP/IEEE International Symposium on Integrated Network Management, IM 2015},
  key       = {Computer systems programming},
  keywords  = {Abstracting;Complex networks;Computational linguistics;Embedded systems;Modeling languages;Network management;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/INM.2015.7140372},
}

@InProceedings{20124415616560,
  author    = {De Lara, Juan and Guerra, Esther and Sanchez-Cuadrado, Jesus},
  title     = {Abstracting modelling languages: A reutilization approach},
  year      = {2012},
  volume    = {7328 LNCS},
  pages     = {127 - 143},
  address   = {Gdansk, Poland},
  note      = {Abstraction;Abstraction techniques;Domain-specific modelling;Genericity;Meta-modelling;Model-driven Engineering;Modelling language;Proof of concept;Re-utilization;Target systems;},
  abstract  = {Model-Driven Engineering automates the development of information systems. This approach is based on the use of Domain-Specific Modelling Languages (DSMLs) for the description of the relevant aspects of the systems to be built. The increasing complexity of the target systems has raised the need for abstraction techniques able to produce simpler versions of the models, but retaining certain properties of interest. However, developing such abstractions for each DSML from scratch is a time and resource consuming activity. Our solution to this situation is a number of techniques to build reusable abstractions that are defined once and can be reused over families of modelling languages sharing certain requirements. As a proof of concept, we present a catalogue of reusable abstractions, together with an implementation in the MetaDepth multi-level meta-modelling tool. &copy; 2012 Springer-Verlag Berlin Heidelberg.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Abstracting},
  keywords  = {Computer programming languages;Information systems;Systems engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-31095-9_9},
}

@InProceedings{20160801980917,
  author    = {Malavolta, Ivano and Muccini, Henry and Sebastiani, Marco},
  title     = {Automatically Bridging UML Profiles to MOF Metamodels},
  year      = {2015},
  pages     = {259 - 266},
  address   = {Madeira, Portugal},
  note      = {Automatically generated;Domain specific modeling languages;Domain-specific application;ITS applications;Metamodeling;Model transformation;Model transformation technique;Model-driven Engineering;},
  abstract  = {In Model-Driven Engineering, UML profiles and MOF-based Domain Specific Modeling Languages (DSMLs) are the most used approaches for describing domain specific applications. The choice of the right approach depends on several aspects, such as tool support, expressivity, complexity of models, company policies. In general, profiled UML models are very much used since they are intuitive for designers and model editors already exist, however they are intrinsically complex for model manipulation (e.g., Transformation, analysis), conversely, domain specific models are more concise and easy to be manipulated, but they require an initial effort in terms of designers training and model editors development. In this paper we propose an approach that allows getting the best of the two worlds: on one side designers can use UML profiles familiar to them, on the other side DSML models (automatically generated from profiled UML models) enable a better model manipulation. Our approach is based on an automatic bridge between UML profiles and MOF metamodels (which are the main artifacts of MOF-based DSMLs). The bridge is transparent to the user since it autonomously operates both on UML profiles and all the involved models. The bridge is realized through model transformation techniques in the Eclipse platform. In this paper we show its application on a case study based on SysML. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings - 41st Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2015},
  key       = {Unified Modeling Language},
  keywords  = {Application programs;Embedded systems;Java programming language;Modeling languages;Software engineering;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SEAA.2015.64},
}

@InProceedings{20150600491078,
  author    = {Cosentino, Valerio and Tisi, Massimo and Izquierdo, Javier Luis Canovas},
  title     = {A model-driven approach to generate external DSLs from object-oriented APIs},
  year      = {2015},
  volume    = {8939},
  pages     = {423 - 435},
  address   = {Pec pod Sn????kou, Czech republic},
  note      = {Applications programming interfaces;Code abstraction;Development environment;Domain specific languages;General-purpose programming language;Model driven approach;Model-driven Engineering;User customizations;},
  abstract  = {Developers in modern general-purpose programming languages create reusable code libraries by encapsulating them in Applications Programming Interfaces (APIs). Domain-specific languages (DSLs) can be developed as an alternative method for code abstraction and distribution, sometimes preferable to APIs because of their expressivity and tailored development environment. However the cost of implementing a fully functional development environment for a DSL is generally higher. In this paper we propose DSLit, a prototype-tool that, given an existing API, reduces the cost of developing a corresponding DSL by analyzing the API, automatically generating a semantically equivalent DSL with its complete development environment, and allowing for user customization. To build this bridge between the API and DSL technical spaces we make use of existing Model-Driven Engineering (MDE) techniques, further promoting the vision of MDE as a unifying technical space. &copy; Springer-Verlag Berlin Heidelberg 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Application programming interfaces (API)},
  keywords  = {Bridges;Computational linguistics;Computer programming languages;Computer systems programming;Object oriented programming;Problem oriented languages;},
  language  = {English},
}

@InProceedings{20133116563140,
  author    = {Brettschneider, Matthias and Haberlein, Tobias},
  title     = {From arrows to netlists describing hardware},
  year      = {2013},
  volume    = {7973 LNCS},
  number    = {PART 3},
  pages     = {128 - 143},
  address   = {Ho Chi Minh City, Viet nam},
  note      = {Algebraic structures;Cyclic redundancy check;Fixed numbers;Functional domains;Higher-order;Novel concept;Structure forms;Vector arrows;},
  abstract  = {This paper describes how to transform a functional domain specific langauge (DSL) into hardware represented by a netlist. In earlier papers we proposed the usage of an algebraic structure called "arrows" (basically an abstraction of Haskell's higher-order type (&rarr) for describing DSLs. This structure forms the basis of a novel concept that gives the developer a tool at hand to describe hardware functionally in a natural way. Aside of that an arrow provides not only a tool to synthesize, but to verify and reason about the input DSL. We have taken this concept to the next stage, from a static size length arrow into a fixed size length vector arrows fitting much better to logic gates with a fixed number of in- and output pins. There are many sound possibilities to use the algebraic arrow data structure to model hardware. This paper presents some of them which showed to be most useful. A simple example, the implementation of a cyclic redundancy check (CRC) algorithm, is used to illustrate the presented techniques. &copy; 2013 Springer-Verlag Berlin Heidelberg.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Hardware},
  keywords  = {Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-39646-5_10},
}

@InProceedings{20131516185170,
  author    = {Dinkelaker, Tom and Eichberg, Michael and Mezini, Mira},
  title     = {Incremental concrete syntax for embedded languages with support for separate compilation},
  year      = {2013},
  volume    = {78},
  number    = {6},
  pages     = {615 - 632},
  note      = {Domain specific languages;Embedded domain-specific languages;Embedded Languages;Embeddings;General-purpose programming language;Language design;Program transformations;Separate compilation;},
  abstract  = {Embedded domain-specific languages (EDSLs) are known to improve the productivity of developers. However, for many domains no DSL implementation is available and two important reasons for this are: First, the effort to implement EDSLs that provide the domain's established syntax (called concrete syntax) is very high. Second, the EDSL and its underlying general-purpose programming language (GPL) are typically tightly integrated. This hampers reusability across different GPLs. Besides these implementation issues, the productivity gains of using EDSLs are also limited by the lack of explicit tool support for EDSL users - such as syntax highlighting or code analyses. In this paper, we present an approach that significantly reduces the necessary effort to implement embedded DSLs with concrete syntax. The idea is to use island grammars to specify the EDSL's concrete syntax. This enables the developer to implement the embedded DSL as a library and to incrementally specify the concrete syntax using meta-data. Only those parts of the EDSL's grammar need to be specified that deviate from the grammar of the GPL. By analyzing an EDSL's implementation using reflection, it is possible to provide tool support for EDSLs without having the developer implement it explicitly, such as syntax highlighting. An evaluation demonstrates the feasibility of our approach by embedding a real-world DSL into a GPL. &copy; 2012 Elsevier B.V. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {01676423},
  journal   = {Science of Computer Programming},
  key       = {Syntactics},
  keywords  = {Problem oriented languages;Productivity;Program processors;Reusability;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.scico.2012.12.002},
}

@InProceedings{20141317521684,
  author    = {Ostermayer, Ludwig and Sun, Geng and Seipel, Dietmar},
  title     = {Simplifying the development of rules using domain specific languages in DROOLS},
  year      = {2013},
  number    = {1306 REPORT NO.},
  pages     = {198 - 212},
  address   = {Kiel, Germany},
  note      = {Business rules;Development process;Domain specific;Domain specific languages;DROOLS;PROLOG;Resolution mechanisms;Rule-based approach;},
  abstract  = {The open-source business logic integration platform DROOLS supports a declarative, rule-based approach for problem solving. However, rules are implemented in a JAVA-based way in DROOLS, which is difficult to understand for non-programmers. The rules for a given scenario are usually provided in natural language by non-programmers, for instance business analysts; for controlling the correctness of the implemented rules, it is crucial to integrate these business analysts into the coding phase. To bridge the gap between programmers and non-programmers, Domain Specific Languages (DSLs) allow for implementing rules in a language that is closer to natural language. In a DSL, rules can be written, read, and modified much easier, even by non-programmers. DROOLS offers a DSL editor, but both developing a DSL and implementing rules within the DSL is still difficult. Thus, in this paper, we present a tool, DSLR Generator, which simplifies the creation of DSLs and the implementation of rules within the DSL. A graphical user interface supports the user step by step in the development process. Reusable and generic DSL templates can be used to write rules in a more readable format. The maintenance of the meta-data for the rules in DROOLS is supported, too. With DSLs, it becomes easier to write rules in DROOLS that can also be parsed in PROLOG. Although the evaluation mechanism of DROOLS is much different from the resolution mechanism of PROLOG, we can support the rule development process by PROLOG technology: the rules could be analyzed, verified, or transformed by PROLOG software. &copy; Springer-Verlag Berlin Heidelberg 2011.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {21926247},
  journal   = {Technische Berichte des Instituts fur Informatik der Christian-Albrechts-Universitat zu Kiel},
  key       = {Logic programming},
  keywords  = {Computer programming languages;Graphical user interfaces;Knowledge management;Management science;},
  language  = {English},
}

@InProceedings{20131116108950,
  author    = {Alhosban, Fuad and Burd, Liz},
  title     = {Aural instruction with visualization in E-Learning},
  year      = {2012},
  pages     = {IEEE Education Society; ASEE Educational Research and Methods Division; IEEE Computer Society -},
  address   = {Seattle, WA, United states},
  note      = {Aural Instructions;Cognitive loads;Computer science students;Prototype learning;Qualitative data;Quantitative data;Sensory channels;Structure-learning;Student response;Visualisations;Written feedback;},
  abstract  = {This research investigates the effectiveness of using aural instructions together with visualisation in teaching some concepts of data structures to novice computer science students. A prototype learning system, known as the Data Structure Learning (DSL) tool, was developed and used first in a short mini study that showed that, used together with visualisations of algorithms, aural instructions produced faster student response times than did textual instructions. This result suggested that the additional use of the auditory sensory channel did indeed reduce the cognitive load. The tool was then used in a second, longitudinal, study over two academic terms in which students studying the Data Structures module were offered the opportunity to use the DSL approach with either aural or textual instructions. Both the quantitative data provided by the automatic recording of DSL use and an end-of-study questionnaire showed appreciation by students of the help the tool had provided and enthusiasm for its future use and development. These findings were supported by qualitative data provided by student written feedback at the end of each task, by interviews at the end of the experiment and by interest from the lecturer in integrating use of the tool with the teaching of the module. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {15394565},
  journal   = {Proceedings - Frontiers in Education Conference, FIE},
  key       = {Data structures},
  keywords  = {Computer science;Data integration;E-learning;Flow visualization;Students;Visualization;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/FIE.2012.6462290},
}

@InProceedings{20164402960527,
  author    = {Vaquero-Melchor, Diego and Garmendia, Antonio and Guerra, Esther and De Lara, Juan},
  title     = {Towards enabling mobile domain-specific modelling},
  year      = {2016},
  pages     = {117 - 122},
  address   = {Lisbon, Portugal},
  note      = {Application area;Domain specific languages;Domain-specific modelling;Graphical modelling;Mobile applications;Model-driven Engineering;Position papers;Prototype tools;},
  abstract  = {Model-Driven Engineering (MDE) promotes an active use of models in all phases of software development. In this paradigm, the design and usage of Domain-Specific Languages (DSL) for modelling in a certain application area is frequent. While in MDE, modelling has been traditionally supported by desktop computers, in this position paper we analyse useful scenarios for modelling using mobile devices, like smartphones or tablets. Moreover, we present a working architecture and a prototype tool, called DSL-comet, which enable collaborative mobile modelling and integrate seamlessly desktop and mobile graphical modelling environments. Copyright &copy; 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ICSOFT 2016 - Proceedings of the 11th International Joint Conference on Software Technologies},
  key       = {Modeling languages},
  keywords  = {Computer programming languages;Digital subscriber lines;Mobile devices;Mobile telecommunication systems;Personal computers;Problem oriented languages;Software design;},
  language  = {English},
}

@InProceedings{20162302462744,
  author    = {Caracciolo, Andrea and Lungu, Mircea and Truffer, Oskar and Levitin, Kirill and Nierstrasz, Oscar},
  title     = {Evaluating an Architecture Conformance Monitoring Solution},
  year      = {2016},
  pages     = {41 - 44},
  address   = {Osaka, Japan},
  note      = {Architectural rules;Conformance checking;Conformance monitoring;empirical;evaluation;Executable specifications;Industrial projects;Technical specifications;},
  abstract  = {Architectural rules are often defined but rarely tested. Current tools offer limited functionality and often require significant effort to be configured, automated and integrated within existing platforms. We propose a platform that is aimed at reducing the overall cost of setting up and maintaining an architectural conformance monitoring environment by decoupling the conceptual representation of a user-defined rule from its technical specification prescribed by the underlying analysis tools. The user is no longer expected to encode her constraints according to the syntax of the chosen tool, but can use a simple high-level DSL that is automatically compiled to an executable specification through custom adapters developed to support the interaction with existing off-the-shelf tools. In this paper we analyze three case studies to show how this approach can be successfully adopted to support truly diverse industrial projects. By discussing qualitative aspects of the approach, we investigate limitations and opportunities for improving general quality assessment solutions in general and DSL-based conformance tools in particular. &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings - 7th International Workshop on Empirical Software Engineering in Practice, IWESEP 2016},
  key       = {Software engineering},
  keywords  = {Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/IWESEP.2016.12},
}


@inproceedings{20142117747100,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Compiling CAO: From cryptographic specifications to C implementations},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Barbosa, Manuel and Castro, David and Silva, Paulo F.},
volume = {8414 LNCS},
year = {2014},
pages = {240 - 244},
issn = {03029743},
address = {Grenoble, France},
abstract = {We present a compiler for CAO, an imperative DSL for the cryptographic domain. The tool takes high-level cryptographic algorithm specifications and translates them into C implementations through a series of security-aware transformations and optimizations. The compiler back-end is highly configurable, allowing the targeting of very disparate platforms in terms of memory requirements and computing power. &copy; 2014 Springer-Verlag.},
key = {Program compilers},
keywords = {Cryptography;Specifications;},
note = {Computing power;Cryptographic algorithms;Memory requirements;Security-aware;},
URL = {http://dx.doi.org/10.1007/978-3-642-54792-8_13},
} 


@inproceedings{20133716723852,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {OnTrack: An open tooling environment for railway verification},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {James, Phillip and Trumble, Matthew and Treharne, Helen and Roggenbach, Markus and Schneider, Steve},
volume = {7871 LNCS},
year = {2013},
pages = {435 - 440},
issn = {03029743},
address = {Moffett Field, CA, United states},
abstract = {OnTrack automates workflows for railway verification, starting with graphical scheme plans and finishing with automatically generated formal models set up for verification. OnTrack is grounded on an established domain specification language (DSL) and is generic in the formal specification language used. Using a DSL allows the formulation of abstractions that work for verification in several formal specification languages. Here, we demonstrate the workflow using CSP||B and suggest how to extend the tool with further formal specification languages. &copy; 2013 Springer-Verlag.},
key = {Specification languages},
keywords = {Formal methods;NASA;Railroads;},
note = {Automatically generated;Formal model;Formal specification language;Work-flows;},
URL = {http://dx.doi.org/10.1007/978-3-642-38088-4_30},
} 


@inproceedings{20130515948842,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {On the reusable specification of non-functional properties in DSLs},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Duran, Francisco and Zschaler, Steffen and Troya, Javier},
volume = {7745 LNCS},
year = {2013},
pages = {332 - 351},
issn = {03029743},
address = {Dresden, Germany},
abstract = {Domain-specific languages (DSLs) are an important tool for effective system development. They provide concepts that are close to the problem domain and allow analysis as well as generation of full solution implementations. However, this comes at the cost of having to develop a new language for every new domain. To make their development efficient, we must be able to construct DSLs as much as possible from reusable building blocks. In this paper, we discuss how such building blocks can be constructed for the specification and analysis of a range of non-functional properties, such as, for example, throughput, response time, or reliability properties. We assume DSL semantics to be provided through a set of transformation rules, which enables a range of analyses based on model checking. We demonstrate new concepts for defining language modules for the specification of non-functional properties, show how these can be integrated with base DSL specifications, and provide a number of syntactic conditions that we prove maintain the semantics of the base DSL even in the presence of non-functional-property specifications. &copy; 2013 Springer-Verlag Berlin Heidelberg.},
key = {Specifications},
keywords = {Model checking;Problem oriented languages;Reliability analysis;Semantics;},
note = {Building blockes;Domain specific languages;Non functional properties;Problem domain;Reliability properties;Reusable specifications;System development;Transformation rules;},
URL = {http://dx.doi.org/10.1007/978-3-642-36089-3_19},
} 


@inproceedings{20143318062563,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {3rd Symposium on Languages, Applications and Technologies, SLATE 2014},
journal = {OpenAccess Series in Informatics},
volume = {38},
year = {2014},
pages = {Computer Science and Technology Center (CCTC); Efacec; Polytechnic Institute of Braganca (IPB); Portuguese Foundation for Sci. and Technol. (FCT) - },
issn = {21906807},
address = {Braganca, Portugal},
abstract = {The proceedings contain 24 papers. The topics discussed include: leveraging program comprehension with concern-oriented source code projections; comment-based concept location over system dependency graphs; ReCooPLa: a DSL for coordination-based reconfiguration of software architectures; a workflow description language to orchestrate multi-lingual resources; unfuzzying fuzzy parsing; contract-Java: design by contract in Java with safe error handling; plagiarism detection: a tool survey and comparison; target code selection by tilling AST with the use of tree pattern pushdown automation; assigning polarity automatically to the synsets of a Wordnet-like resource; detecting a tweet's topic within a large number of Portuguese Twitter trends; Rocchio's model based on vector space basis change for pseudo relevance feedback; language identification: a neural network approach; and LemPORT: a high-accuracy cross-platform Lemmatizer for Portuguese.},
} 

@InProceedings{20160601888481,
  author    = {Azadmanesh, Mohammad R. and Hauswirth, Matthias},
  title     = {SQL for deep dynamic analysis?},
  year      = {2015},
  pages     = {2 - 7},
  address   = {Pittsburgh, PA, United states},
  note      = {Dynamic analysis tools;Information flows;Interactive user interfaces;Program execution;Program trace;Query-based analysis;Relational Database;Trace information;},
  abstract  = {If we develop a new dynamic analysis tool, how should we expose its functionalities? Through an interactive user interface, a DSL, a specific API, or in some other way? In this paper, we discuss how to use an already existing language familiar to most software engineers, SQL, to perform deep dynamic analyses. The goal is to explore the trade-off between expressiveness and ease-of-use. We use BLAST as the dynamic analysis tool and map its trace information to a relational database. We find that, even though SQL is expressive enough for deep analysis of program executions and information flow, it is not quite straight forward to express some of the queries software engineers might be interested in. However, it removes the burden of learning a new language from scratch, which could make it worthwhile as an option in some cases. &copy; 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {WODA 2015 - Proceedings of the 13th International Workshop on Dynamic Analysis},
  key       = {Trace analysis},
  keywords  = {Application programming interfaces (API);Computational linguistics;Dynamic analysis;Economic and social effects;Query processing;User interfaces;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2823363.2823365},
}


@inproceedings{20161802314908,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Code transformation by direct transformation of ASTs},
journal = {IWST 2015 - Proceedings of the 10th International Workshop on Smalltalk Technologies, in conjunction with the 23rd International Smalltalk Joint Conference},
author = {Rizun, M. and Bach, J.-C. and Ducasse, S.},
year = {2015},
pages = {ACM Special Interest Group on Programming Languages; ESUG - },
address = {Brescia, Italy},
abstract = {Software evolves to be adapted to the environment, due to bugs, new features and design changes. Code transformations can be done manually, but that is a tedious and errorprone task. Therefore automated tools are used to assist developers in this maintenance operation. The Pharo environment includes its own refactoring tool -the Rewrite Engine-that allows one to transform methods by directly specifying parts of the AST to be rewritten. In addition, it proposes a parse tree transformation engine. However this tool and the used DSL to express the patterns for matching and transforming trees are complex to understand and master. In this context, writing a transformation rule is not a trivial task. We present a graphical tool built on the top of the Rewrite Engine - the Rewrite Tool - that abstracts the creation of transformation rules and proposes high-level AST operations that are simpler to understand than syntactic descriptions. It helps to automate the process of code transformation with a user-friendly interface. Copyright &copy; 2015 ACM.},
key = {Codes (symbols)},
keywords = {Cosine transforms;Engines;Forestry;Program debugging;},
note = {Code transformation;Maintenance operations;Refactoring tools;Refactorings;Rewriting;Transform methods;Transformation rules;User friendly interface;},
URL = {http://dx.doi.org/10.1145/2811237.2811297},
} 


@inproceedings{20144600206314,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {2014 IEEE 4th International Model-Driven Requirements Engineering Workshop, MoDRE 2014 - Proceedings},
journal = {2014 IEEE 4th International Model-Driven Requirements Engineering Workshop, MoDRE 2014 - Proceedings},
year = {2014},
address = {Karlskrona, Sweden},
abstract = {The proceedings contain 10 papers. The topics discussed include: model driven requirements engineering: mapping the field and beyond; goal modeling for sustainability: the case of time; context transformations for goal models; a DSL for importing models in a requirements management system; SnapMind: a framework to support consistency and validation of model-based requirements in agile development; experimental evaluation of a tool for change impact prediction in requirements models: design, results, and lessons learned; a requirements engineering methodology combining models and controlled natural language; understanding and closing the gap between requirements on system and subsystem level; and requirement traceability: a model-based approach.},
} 

@InProceedings{20164002874844,
  author    = {Szabo, Tamas and Alperovich, Simon and Voelter, Markus and Erdweg, Sebastian},
  title     = {An extensible framework for variable-precision data-flow analyses in MPS},
  year      = {2016},
  pages     = {870 - 875},
  address   = {Singapore, Singapore},
  note      = {Data-ow Analysis;Domain specific languages;Extensible framework;General purpose languages;Inter-procedural analysis;Language compositions;Language workbenches;Program understanding;},
  abstract  = {Data-ow analyses are used as part of many software engineering tasks: they are the foundations of program understanding, refactorings and optimized code generation. Similar to general-purpose languages (GPLs), state-of-the-art domain-specific languages (DSLs) also require sophisticated data-ow analyses. However, as a consequence of the different economies of DSL development and their typically relatively fast evolution, the effort for developing and evolving such analyses must be lowered compared to GPLs. This tension can be resolved with dedicated support for data-ow analyses in language workbenches. In this tool paper we present MPS-DF, which is the component in the MPS language workbench that supports the definition of data-ow analyses for DSLs. Language developers can define data-ow graph builders declaratively as part of a language definition and compute analysis results efficiently based on these data-ow graphs. MPS-DF is extensible such that it does not compromise the support for language composition in MPS. Additionally, clients of MPSDF analyses can run the analyses with variable precision thus trading off precision for performance. This allows clients to tailor an analysis to a particular use case. Demo video of MPS-DF: https://youtu.be/laNDAZCe2jM. &copy; 2016 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {ASE 2016 - Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
  key       = {Data flow analysis},
  keywords  = {Computer programming languages;Graphical user interfaces;Problem oriented languages;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2970276.2970296},
}

@InProceedings{20140617289821,
  title     = {Proceedings - 17th IEEE International Enterprise Distributed Object Computing Conference Workshops, EDOCW 2013},
  year      = {2013},
  pages     = {IEEE Communications Society; IEEE Computer Society -},
  address   = {Vancouver, BC, Canada},
  abstract  = {The proceedings contain 44 papers. The topics discussed include: business building blocks as coordination mechanism for enterprise transformations; improving process robustness through domain-specific model transformations; determining the necessity of human intervention when migrating models of an evolved DSL; model-based integrated planning for logistics service contracts; eScienceSWaT - towards an eScience software engineering methodology; analyzing task and technology characteristics for enterprise architecture management tool support; handling concurrent changes in collaborative process model development: a change-pattern based approach; designing of virtual factory information system by enterprise portal; the relational database engine: an efficient validator of temporal properties on event traces; methodical development of modeling tools (MeDMoT'13); and dilemmas in enterprise architecture research and practice from a perspective of feral information systems.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {15417719},
  journal   = {Proceedings - IEEE International Enterprise Distributed Object Computing Workshop, EDOC},
  language  = {English},
}


@inproceedings{20161202136340,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {28th International Workshop on Languages and Compilers for Parallel Computing, LCPC 2015},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {9519},
year = {2016},
pages = {1 - 319},
issn = {03029743},
address = {Raleigh, NC, United states},
abstract = {The proceedings contain 19 papers. The special focus in this conference is on Programming Models and Optimizing Framework. The topics include: Low-overhead fault-tolerance support using disc programming model; efficient support for range queries and range updates using contention adapting search trees; polyhedral optimizations for a data-flow graph language; interactive composition of compiler optimizations; asynchronous nested parallelism for dynamic applications in distributed memory; multigrain parallelization for model-based design applications using the OSCAR compiler; extending shared address programming for accelerator clusters; petal tool for analyzing and transforming legacy MPI applications; automatic and efficient data host-device communication for many-core coprocessors; topology-aware parallelism for NUMA copying collectors; an embedded DSL for high performance declarative communication with correctness guarantees in C++; parallel nearest-neighbor units for learned dictionaries; conc-trees for functional and parallel programming; practical floating-point divergence detection; SMT solving for the theory of ordering constraints and an efficient, portable and generic library for successive cancellation decoding of polar codes.},
} 

@InProceedings{20140517250442,
  author    = {Wasserman, Louis},
  title     = {Scalable, example-based refactorings with Refaster},
  year      = {2013},
  pages     = {25 - 28},
  address   = {Indianapolis, IN, United states},
  note      = {Error prones;Global;Guava;Java;Large-scale;OpenJDK;Refactorings;Refaster;Syntax tree;},
  abstract  = {We discuss Refaster, a tool that uses normal, compilable before-and-after examples of Java code to specify a Java refactoring. Refaster has been used successfully by the Java Core Libraries Team at Google to perform a wide variety of refactorings across Google's massive Java codebase. Our main contribution is that a large class of useful refactorings can be expressed in pure Java, without a specialized DSL, while keeping the tool easily accessible to average Java developers. Copyright is held by the owner/author(s).},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {WRT 2013 - Proceedings of the 2013 ACM Workshop on Refactoring Tools},
  key       = {Tools},
  keywords  = {Libraries;Trees (mathematics);},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2541348.2541355},
}

@InProceedings{20130716009036,
  title     = {Proceedings of the 12th Workshop on OCL and Textual Modelling, OCL 2012 - Being Part of the ACM/IEEE 15th International Conference on Model Driven Engineering Languages and Systems, MODELS 2012},
  year      = {2012},
  pages     = {IEEE CS; ACM Special Interest Group on Software Engineering (SIGSOFT) -},
  address   = {Innsbruck, Austria},
  abstract  = {The proceedings contain 13 papers. The topics discussed include: tool supported OCL refactoring catalogue; an extensible OCL virtual machine and code generator; featherweight OCL: a study for the consistent semantics of OCL 2.3 in HOL; on the use of an internal DSL for enriching EMF models; library for model querying - lQuery; ontology driven design of EMF metamodels and well-formedness constraints; modeling and executing ConcurTaskTrees using a UML-and SOIL-based metamodel; automatic generation of test models and properties from UML models with OCL constraints; transformation rules from UML4MBT meta-model to SMT meta-model for model animation; model-based formal specification of a DSL library for a qualified code generator; the secret life of OCL constraints; and experiences using OCL for business rules on financial messaging.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the 12th Workshop on OCL and Textual Modelling, OCL 2012 - Being Part of the ACM/IEEE 15th International Conference on Model Driven Engineering Languages and Systems, MODELS 2012},
  language  = {English},
}

@Article{20142017717982,
  author    = {Hamlaoui, Mahmoud El and Ebersold, Sophie and Anwar, Adil and Coulette, Bernard and Nassar, Mahmoud},
  title     = {Towards a framework for heterogeneous models matching},
  journal   = {Journal of Software Engineering},
  year      = {2014},
  volume    = {8},
  number    = {3},
  pages     = {132 - 151},
  note      = {Consistency;Correspondences;Domain specific languages;Heterogeneity;Point of view;},
  abstract  = {The overall goal of our approach is to relate models of a given domain that are created by different actors and thus are generally heterogeneous that is, described in different DSL (Domain Specific Languages). Instead of building a single global model, we propose to organize the different source models as a network of models which provides a global view of the system through a virtual global model. The matching of these models is done in a shared model of correspondences. We focus in this study on the elaboration of the model of correspondences, through a transformation called "refine" . The approach is illustrated by a representative use case (a Bug Tracking System) and supported by a modeling tool called HMS (Heterogeneous Matching Suite). &copy; 2014 Academic Journals Inc.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {18194311},
  key       = {Computer programming languages},
  keywords  = {Computer software;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.3923/jse.2014.132.151},
}

@InProceedings{20154101357446,
  author    = {Caracciolo, Andrea and Lungu, Mircea Filip and Nierstrasz, Oscar},
  title     = {A Unified Approach to Architecture Conformance Checking},
  year      = {2015},
  pages     = {41 - 50},
  address   = {Montreal, QC, Canada},
  note      = {Conformance checking;Declarative Languages;High costs;Test specifications;Unified approach;},
  abstract  = {Software erosion can be controlled by periodically checking for consistency between the de facto architecture and its theoretical counterpart. Studies show that this process is often not automated and that developers still rely heavily on manual reviews, despite the availability of a large number of tools. This is partially due to the high cost involved in setting up and maintaining tool-specific and incompatible test specifications that replicate otherwise documented invariants. To reduce this cost, our approach consists in unifying the functionality provided by existing tools under the umbrella of a common business-readable DSL. By using a declarative language, we are able to write tool-agnostic rules that are simple enough to be understood by untrained stakeholders and, at the same time, can be interpreted as a rigorous specification for checking architecture conformance. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings - 12th Working IEEE/IFIP Conference on Software Architecture, WICSA 2015},
  key       = {Specifications},
  keywords  = {Architecture;Erosion;Software architecture;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/WICSA.2015.11},
}


@inproceedings{20160101760918,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {4th International Symposium on Languages, Applications and Technologies, SLATE 2015},
journal = {Communications in Computer and Information Science},
volume = {563},
year = {2015},
pages = {1 - 270},
issn = {18650929},
address = {Madrid, Spain},
abstract = {The proceedings contain 26 papers. The special focus in this conference is on Human-Human Languages and Human-Computer Languages. The topics include: Speech features for discriminating stress using branch and bound wrapper search; oriya morphological analyzer using lttoolbox; exploiting twitter for the semantic enrichment of telecommunication alarms; meaning inference of abbreviations appearing in clinical studies; experiments on enlarging a lexical ontology; using unstructured profile information for gender classification of portuguese and english twitter users; yet another suite of multilingual NLP tools; towards a DSL for educational data mining; a metric to measure the understanding degree of WSDL descriptions; combining processing with racket; batched evaluation of full-sharing multithreaded tabling; browsing the parse space; a syntax-directed model transformation framework based on attribute grammars; an ast-based tool, spector, for plagiarism detection; towards the generation of graphical modelling environments aided by patterns; tree string path subsequences automaton and its use for indexing xml documents; a structural approach to assess graph-based exercises; a service for gamification of learning activities; engaging researchers in data management with labtablet, an electronic laboratory notebook; an efficient representation of RDF datasets; reducing large semantic graphs to improve semantic relatedness; a mixed approach for the representation of nutritional information through XML-to-OWL mappings; automatic generation of CVs from online social networks and knowledge identification from requirements specification.},
} 

@Article{20150500476458,
  author    = {Kikava, Filip and Collet, Philippe and France, Robert B.},
  title     = {SIGMA: Scala internal domain-specific languages for model manipulations},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year      = {2014},
  volume    = {8767},
  pages     = {569 - 585},
  note      = {Domain specific languages;Eclipse modeling framework;General purpose languages;General purpose programming;Levels of abstraction;Model consistency checking;Model to text transformations;Model transformation;},
  abstract  = {Model manipulation environments automate model operations such as model consistency checking and model transformation. A number of external model manipulation Domain-Specific Languages (DSL) have been proposed, in particular for the Eclipse Modeling Framework (EMF). While their higher levels of abstraction result in gains in expressiveness over general-purpose languages, their limitations in versatility, performance, and tool support together with the need to learn new languages may significantly contribute to accidental complexities. &copy; Springer International Publishing Switzerland 2014.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  key       = {Model checking},
  keywords  = {Computational linguistics;Computer programming languages;Modeling languages;Problem oriented languages;},
  language  = {English},
}

@Article{20160601894198,
  author    = {El Hamlaoui, Mahmoud and Ebersold, Sophie and Anwar, Adil and Coulette, Bernard and Nassar, Mahmoud},
  title     = {Towards a framework for heterogeneous models matching},
  journal   = {Journal of Software Engineering},
  year      = {2014},
  volume    = {8},
  number    = {3},
  pages     = {132 - 151},
  note      = {Consistency;Correspondences;Domain specific languages;Heterogeneity;Point of view;},
  abstract  = {The overall goal of our approach is to relate models of a given domain that are created by different actors and thus are generally heterogeneous that is, described in different DSL (Domain Specific Languages). Instead of building a single global model, we propose to organize the different source models as a network of models which provides a global view of the system through a virtual global model. The matching of these models is done in a shared model of correspondences. We focus in this study on the elaboration of the model of correspondences, through a transformation called "refine". The approach is illustrated by a representative use case (a Bug Tracking System) and supported by a modeling tool called HMS (Heterogeneous Matching Suite). &copy; 2014 Academic Journals Inc.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {18194311},
  key       = {Graphical user interfaces},
  keywords  = {Computational linguistics;Computer programming languages;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.3923/jse.2014.132.151},
}


@inproceedings{20161202119698,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {What is essential?  a pilot survey on views about the requirements metamodel of reqT.org},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Regnell, Bjorn},
volume = {9619},
year = {2016},
pages = {232 - 239},
issn = {03029743},
address = {Gothenburg, Sweden},
abstract = {[Context &amp; motivation] This research preview paper presents ongoing work on the metamodel of a free software requirements modeling tool called reqT that is developed in an educational context. The work aims to make an initial validation of a survey instrument that elicits views on the metamodel of the reqT tool, which aims to engage computer science students in Requirements Engineering (RE) through an open source DSL embedded in the Scala programming language. [Question] The research question is: Which RE concepts are essential to include in the metamodel for a requirements engineering tool in an educational context? [Principal ideas] A survey instrument is developed, with a list of 92 concepts (49 entities, 15 relations and 28 attributes) and a set of questions for each concept, to elicit the respondents&rsquo; views on the usage and interpretation of each concept. [Contribution] The survey is initially validated in a pilot study involving 14 Swedish RE scholars as subjects. The survey results indicate that the survey is feasible. The analysis of the responses suggest that many of the concepts in the metamodel are used frequently by the respondents and there is a large degree of agreement among the respondents about the meaning of the concepts. The results are encouraging for future work on empirical validation of the relevance of the reqT metamodel. &copy; Springer International Publishing Switzerland 2016.},
key = {Surveys},
keywords = {Computational linguistics;Computer aided software engineering;Computer programming;Computer programming languages;Computer software selection and evaluation;Education;Engineering education;Engineering research;Open source software;Problem oriented languages;Requirements engineering;Software engineering;},
note = {Computer science students;Educational context;Embedded domain specific languages;Empirical Software Engineering;Empirical validation;Meta model;Requirements MetaModel;Research questions;},
URL = {http://dx.doi.org/10.1007/978-3-319-30282-9_16},
} 

@InProceedings{20155201733103,
  author    = {Caracciolo, Andrea},
  title     = {A Unified Approach to Automatic Testing of Architectural Constraints},
  year      = {2015},
  volume    = {2},
  pages     = {871 - 874},
  address   = {Florence, Italy},
  note      = {Architectural constraints;Architectural decision;Conformance checking;Coordination frameworks;Error-prone process;Human-readable;Non-functional requirements;Unified approach;},
  abstract  = {Architectural decisions are often encoded in the form of constraints and guidelines. Non-functional requirements can be ensured by checking the conformance of the implementation against this kind of invariant. Conformance checking is often a costly and error-prone process that involves the use of multiple tools, differing in effectiveness, complexity and scope of applicability. To reduce the overall effort entailed by this activity, we propose a novel approach that supports verification of human-readable declarative rules through the use of adapted off-the-shelf tools. Our approach consists of a rule specification DSL, called Dicto, and a tool coordination framework, called Probo. The approach has been implemented in a soon to be evaluated prototype. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {02705257},
  journal   = {Proceedings - International Conference on Software Engineering},
  key       = {Software engineering},
  keywords  = {Automatic testing;Software architecture;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICSE.2015.281},
}


@inproceedings{20140417229523,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Chisel-Q: Designing quantum circuits with a scala embedded language},
journal = {2013 IEEE 31st International Conference on Computer Design, ICCD 2013},
author = {Liu, Xiao and Kubiatowicz, John},
year = {2013},
pages = {427 - 434},
address = {Asheville, NC, United states},
abstract = {We introduce Chisel-Q, a high-level functional language for generating quantum circuits. Chisel-Q permits quantum computing algorithms to be constructed using the meta-language features of Scala and its embedded DSL Chisel. With Chisel-Q, designers of quantum computing algorithms gain access to high-level, modern language features and abstractions. We describe a synthesis flow that transforms Chisel-Q into an explicit quantum circuit in the Quantum Assembly Language (QASM) format. We also discuss several optimizations to reduce the generated hardware cost. The Chisel-Q tool includes resource and performance estimation which can be used to compare different implementations of the same functionality. We compare the output of the generic Chisel-Q synthesis flow with hand-tuned versions of well-known quantum circuits. &copy; 2013 IEEE.},
key = {Tools},
keywords = {Algorithms;Computer aided design;High level languages;Logic circuits;Quantum computers;Quantum optics;},
note = {Assembly language;Embedded Languages;Functional languages;Hardware cost;Modern languages;Performance estimation;Quantum circuit;Quantum Computing;},
URL = {http://dx.doi.org/10.1109/ICCD.2013.6657075},
} 

@InProceedings{20153401194484,
  author    = {Kovesdan, Gabor and Asztalos, Mark and Lengyel, Laszlo},
  title     = {Aggregate Callback: A design pattern for flexible and robust runtime model building},
  year      = {2015},
  pages     = {149 - 156},
  address   = {Angers, Loire Valley, France},
  note      = {Agility;Code Generation;Design Patterns;Domain specific modeling;Model transformation;},
  abstract  = {In modern software engineering environments, tools that use Domain-Specific Languages (DSLs) are often applied. The usual workflow of such tools is that the textual input written in the DSL is parsed and a semantic model is instantiated. This model is later passed to another software component that processes it, e.g. a model transformation, a code generator or a simulator. Building the semantic model inside the parser is often a complex task. The model must be built in such a way that the constraints of the problem domain are enforced so that the consistency of the output is guaranteed. This paper presents a design pattern, referred as Aggregate Callback that supports enforcing constraints in the model and thus helps creating correct models. We have found that the Aggregate Callback pattern is useful for tool developers that build models in their applications. Copyright &copy; 2015 SCITEPRESS - Science and Technology Publications.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {MODELSWARD 2015 - 3rd International Conference on Model-Driven Engineering and Software Development, Proceedings},
  key       = {Software design},
  keywords  = {Aggregates;Automatic programming;Computer programming languages;Computer software;Models;Network components;Problem oriented languages;Program compilers;Semantics;Software engineering;},
  language  = {English},
}


@inproceedings{20154701570912,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {8th International Conference on Graph Transformation, ICGT 2015},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {9151},
year = {2015},
pages = {1 - 282},
issn = {03029743},
address = {LAquila, Italy},
abstract = {The proceedings contain 21 papers. The special focus in this conference is on Foundations and Applications. The topics include: Polymorphic sesqui-pushout graph rewriting; predictive top-down parsing for hyperedge replacement grammars; algebraic graph rewriting with controlled embedding; proving termination of graph transformation systems using weighted type graphs over semirings; towards local confluence analysis for amalgamated graph transformation; multi-amalgamated triple graph grammars; reconfigurable petri nets with transition priorities and inhibitor arcs; reachability in graph transformation systems and slice languages; equational reasoning with context-free families of string diagrams; translating essential OCL invariants to nested graph constraints focusing on set operations; characterizing conflicts between rule application and rule evolution in graph transformation systems; graph pattern matching as an embedded clojure DSL; using graph transformations for formalizing prescriptions and monitoring adherence; towards compliance verification between global and local process models; inductive invariant checking with partial negative application conditions; tool support for multi-amalgamated triple graph grammars; using coverability analysis for verifying graph transformation systems and local search-based pattern matching features in EMF-INCQUERY.},
} 

@InProceedings{20161902365252,
  author    = {Bui, Thi Mai Anh and Ziane, Mikal and Stinckwich, Serge and Ho, Tuong Vinh and Roche, Benjamin and Papoulias, Nick},
  title     = {Separation of concerns in epidemiological modelling},
  year      = {2016},
  pages     = {196 - 200},
  address   = {Malaga, Spain},
  note      = {Compartmental model;Computer implementations;Domain specific languages;Infectious disease;Modelling and simulations;Separation of concerns;Spatial regions;Stochastic Automata;},
  abstract  = {Modelling and simulation have been heavily used in epidemiology, for instance to study the transmission of infectious diseases, their pathogenicity and their propagation. A major hindrance to modelling in epidemiology is the mixing of concerns that ought to be separated. The most obvious one is the computer implementation that should not be mixed with domain aspects. But several domain concerns should also be separated from the core epidemiological ones. These include the distribution of the studied populations into spatial regions, age intervals, sexes, species, viral strains...We propose an approach that relies on a mathematical model of the dynamics of a compartment-based population. The separation of domain concerns is provided by expressing each one as a stochastic automaton and combining them with a tensor sum. A DSL, Kendrick, and a tool, support this approach that has been validated on several case studies. &copy; 2016 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {MODULARITY Companion 2016 - Companion Proceedings of the 15th International Conference on Modularity},
  key       = {Modeling languages},
  keywords  = {Computer programming languages;Problem oriented languages;Stochastic systems;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2892664.2892699},
}

@InProceedings{20131616208336,
  author    = {Cherrueau, Ronan-Alexandre and Chebaro, Omar and Sudholt, Mario},
  title     = {Flexible aspect-based service adaptation for accountability properties in the cloud},
  year      = {2013},
  pages     = {13 - 17},
  address   = {Fukuoka, Japan},
  note      = {Accountability;AOP;Security and privacy;Service adaptation;Service compositions;Service infrastructure;Service orchestration;Service-based applications;},
  abstract  = {Accountability properties, i.e., security and privacy properties for trustworthy data stewardship, are becoming increasingly important for Cloud applications. Frequently, they have to be enforced on large-scale service-based applications. In this paper we argue that real-world service infrastructures are best modeled in terms of three abstraction levels and that (partially invasive) adaptations involving all levels are needed to handle accountability properties. We motivate these issues for the case of secure logging, a basic accountability property of Cloud applications. We propose an initial version of a DSL for flexible and expressive control over the execution of service compositions on the three abstraction levels: service orchestrations, interceptors and service implementations. We also present a corresponding prototype tool and infrastructure for the manipulation of service compositions at all three levels that we have implemented over Apache CXF. Finally, we show how our method can be applied to enable secure logging in previously logging-agnostic applications. Copyright &copy; 2013 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {VariComp 2013 - Proceedings of the 4th International Workshop on Variability and Composition},
  key       = {Abstracting},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2451617.2451621},
}

@InProceedings{20140417225659,
  author    = {Lavrischeva, Ekaterina and Ostrovski, Alexei and Radetskiy, Igor},
  title     = {Approach to e-learning fundamental aspects of software engineering},
  year      = {2012},
  volume    = {848},
  pages     = {176 - 187},
  address   = {Kherson, Ukraine},
  note      = {Computer science students;Developing projects;Eclipse environment;Product-lines;Programming methodology;Reusable components;Software industry;Software resources;},
  abstract  = {New theoretical and applied aspects of software engineering are introduced, viz.: technologies of developing programs and reusable components with MS.NET, CORBA, Java, Eclipse environments; assembling them into applied systems and their families; embedding components into the modern environments for shared usage; modeling applied domains in ontological DSLlike languages with tools like MS DSL Tools, Workflow, Eclipse-DSL, and Prote&acute;ge&acute;. These aspects are implemented in the instrumental and technological complex (ITC). They are oriented towards improving software industry based on the readymade software resources (reuses, assets, services, artifacts). The ITC is represented by a web site with modern design, the contents of which has no known counterparts. The site is introduced as a tool for developing various kinds of programs and systems in the corresponding product lines, as well as for teaching computer science students the subject of software engineering.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {Software engineering},
  keywords  = {Computer programming;Computer software reusability;E-learning;Industrial applications;Industrial research;Information technology;Interoperability;Java programming language;Knowledge management;Tools;},
  language  = {English},
}


@inproceedings{20121915007187,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Use cases for context aware model-checking},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Raji, Amine and Dhaussy, Philippe},
volume = {7167 LNCS},
year = {2012},
pages = {202 - 216},
issn = {03029743},
address = {Wellington, New zealand},
abstract = {Despite technical improvements in current verification tools, the increasing size of developed systems makes the detection of design defects more difficult. Context-aware Model-Checking is an effective technique for automating software verifications considering specific environmental conditions. Unfortunately, few existing approaches provide support for this crucial task and mainly rely on significant effort and expertise of the engineer. We previously proposed a DSL (called CDL) to facilitate the formalization of requirements and contexts. Experiences has shown that manually writing CDL models is difficult and error prone task. In this paper, we propose a tool-supported framework to automatically generate CDL models using eXtended Use Cases (XUC). XUC models consistently link use cases with scenarios with respect to the domain specification vocabulary of the model to be checked. We also propose a requirements specification language to fill the gap between textual requirements and CDL properties. An industrial case study is presented to illustrate the effectiveness of XUCs to generate correct and complete CDL models for formal model analysis. &copy; 2012 Springer-Verlag Berlin Heidelberg.},
key = {Model checking},
keywords = {Industrial applications;Software engineering;Specification languages;},
note = {Context-Aware;Design defects;Environmental conditions;Error prone tasks;Formal model;Industrial case study;Requirements specification language;Software verification;Technical improvement;Verification tools;},
URL = {http://dx.doi.org/10.1007/978-3-642-29645-1_21},
} 


@inproceedings{20153201116773,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Generation of large random models for benchmarking},
journal = {CEUR Workshop Proceedings},
author = {Scheidgen, Markus},
volume = {1406},
year = {2015},
pages = {1 - 10},
issn = {16130073},
address = {L'Aquila, Italy},
abstract = {Since model driven engineering (MDE) is applied to larger and more complex system, the memory and execution time performance of model processing tools and frameworks has become important. Benchmarks are a valuable tool to evaluate performance and hence assess scalability. But, benchmarks rely on reasonably large models that are unbiased, can be shaped to distinct use-case scenarios, and are "real" enough (e.g. non-uniform) to cause real-world behavior (especially when mechanisms that exploit repetitive patterns like caching, compression, JIT-compilation, etc. are involved). Creating large models is expensive and erroneous, and neither existing models nor uniform synthetic models cover all three of the wanted properties. In this paper, we use randomness to generate unbiased, non-uniform models. Furthermore, we use distributions and parametrization to shape these models to simulate different use-case scenarios. We present a meta-model-based framework that allows us to describe and create randomly generated models based on a meta-model and a description written in a specifically developed generator DSL. We use a random code generator for an object-oriented programming language as case study and compare our result to non-randomly and synthetically created code, as well as to existing Java-code.},
key = {Object oriented programming},
keywords = {Benchmarking;Codes (symbols);Java programming language;},
note = {Jit compilations;Model processing;Model-driven Engineering;Parametrizations;Random Model;Repetitive pattern;Synthetic models;Use case scenario;},
} 


@inproceedings{20144700235617,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Hardware system synthesis from Domain-Specific Languages},
journal = {Conference Digest - 24th International Conference on Field Programmable Logic and Applications, FPL 2014},
author = {George, Nithin and Lee, Hyoukjoong and Novo, David and Rompf, Tiark and Brown, Kevin J. and Sujeeth, Arvind K. and Odersky, Martin and Olukotun, Kunle and Ienne, Paolo},
year = {2014},
pages = {Altera; BEEcube; Cadence; et al.; Sigasi; Xilinx - },
address = {Munich, Germany},
abstract = {Field Programmable Gate Arrays (FPGAs) are very versatile devices, but their complicated programming model has stymied their widespread usage. While modern High-Level Synthesis (HLS) tools provide better programming models, the interface they offer is still too low-level. In order to produce good quality hardware designs with these tools, the users are forced to manually perform optimizations that demand detailed knowledge of both the application and the implementation platform. Additionally, many HLS tools only generate isolated hardware modules that the user still needs to integrate into a system design before generating the FPGA bitstream. These problems make HLS tools difficult to use for application developers who have little hardware design knowledge. To address these problems, we propose an automated methodology to generate FPGA bitstreams from high-level programs written in Domain-Specific Languages (DSLs). We leverage the domain-knowledge conveyed by the DSL and its domain-specific semantics to extract application parallelism, perform optimizations and also identify a suitable system-architecture for the implementation, thereby, relieving the user from most of the hardware-level details. We demonstrate the high productivity and high design quality this approach offers by automatically generating hardware systems from applications written in OptiML, a machine-learning DSL. To evaluate our methodology, we use four OptiML applications and show that we can easily generate different solutions which achieve different trade-offs between performance and area. More importantly, the results reveal that our generated hardware achieves much better performance compared to the one obtained from using the HLS tool without platform-specific optimizations.},
key = {High level languages},
keywords = {Design;Field programmable gate arrays (FPGA);Hardware;Knowledge management;Problem oriented languages;Product design;Semantics;},
note = {Application developers;Better performance;Domain specific languages;High productivity;High-level program;High-level synthesis;Implementation platforms;Programming models;},
URL = {http://dx.doi.org/10.1109/FPL.2014.6927454},
} 


@inproceedings{20161602265345,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Lightweight, generative variant exploration for high-performance graphics applications},
journal = {GPCE 2015 - Proceedings of the 2015 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
author = {Selgrad, Kai and Lier, Alexander and Koferl, Franz and Stamminger, Marc and Lohmann, Daniel},
year = {2015},
pages = {141 - 150},
address = {Pittsburgh, PA, United states},
abstract = {Rendering performance is an everlasting goal of computer graphics and significant driver for advances in both, hardware architecture and algorithms. Thereby, it has become possible to apply advanced computer graphics technology even in low-cost embedded appliances, such as car instruments. Yet, to come up with an efficient implementation, developers have to put enormous efforts into hardware/problem-specific tailoring, fine-tuning, and domain exploration, which requires profound expert knowledge. If a good solution has been found, there is a high probability that it does not work as well with other architectures or even the next hardware generation. Generative DSL-based approaches could mitigate these efforts and provide for an efficient exploration of algorithmic variants and hardware-specific tuning ideas. However, in vertically organized industries, such as automotive, suppliers are reluctant to introduce these techniques as they fear loss of control, high introduction costs, and additional constraints imposed by the OEM with respect to software and tool-chain certification. Moreover, suppliers do not want to share their generic solutions with the OEM, but only concrete instances. To this end, we propose a light-weight and incremental approach for meta programming of graphics applications. Our approach relies on an existing formulation of C-like languages that is amenable to meta programming, which we extend to become a lightweight language to combine algorithmic features. Our method provides a concise notation for meta programs and generates easily sharable output in the appropriate C-style target language.},
key = {C (programming language)},
keywords = {Algorithmic languages;Algorithms;Automatic programming;Computational linguistics;Computer graphics;Computer hardware;Hardware;Ray tracing;Reconfigurable hardware;Software prototyping;},
note = {Algorithmic variants;Code Generation;Computer graphics technology;Efficient implementation;Graphics applications;Hardware architecture;Incremental approach;Rendering performance;},
URL = {http://dx.doi.org/10.1145/2814204.2814220},
} 

@InProceedings{20155001675860,
  author    = {Aouini, Zied and Kortebi, Abdesselem and Ghamri-Doudane, Yacine},
  title     = {Traffic monitoring in home networks: Enhancing diagnosis and performance tracking},
  year      = {2015},
  pages     = {545 - 550},
  address   = {Dubrovnik, Croatia},
  note      = {Architectural approach;Band-width utilization;Experimental evaluation;Experimental testbed;Network Monitoring;Network traffic monitoring;Passive measurements;Resource consumption;},
  abstract  = {Home network complexity is dramatically growing in terms of topology (devices and connectivity technologies) and services leading to increasingly challenging management issues. In this context, enabling a better visibility of home network traffic usage and performance is a crucial step to provide efficient self-care and customer care. In this paper, we study home network traffic monitoring architectural approaches. In particular, we study the feasibility of a Home Gateway based flow monitoring approach, which will allow enhancing home network diagnostic and performance tracking. Our experimental evaluation aims at providing a better understanding of deployment possibilities and limits. The obtained experimental results, based on an open source tool, are promising in terms of resource consumption (an average load of 6,6% and 18MB for CPU and memory respectively ) as well as bandwidth utilization (average 156 Kbps) for typical DSL access speed scenario. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {IWCMC 2015 - 11th International Wireless Communications and Mobile Computing Conference},
  key       = {Home networks},
  keywords  = {Carrier communication;Complex networks;Computer networks;Gateways (computer networks);Mobile computing;Personal communication systems;Wireless telecommunication systems;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/IWCMC.2015.7289142},
}

@Article{20140817345281,
  author    = {Leitner, Andrea and Preschern, Christopher and Kreiner, Christian},
  title     = {Effective development of automation systems through domain-specific modeling in a small enterprise context},
  journal   = {Software and Systems Modeling},
  year      = {2014},
  volume    = {13},
  number    = {1},
  pages     = {35 - 54},
  note      = {Automation systems;Cost modeling;Domain specific modeling;Software Product Line;System development process;},
  abstract  = {High development and maintenance costs and a high error rate are the major problems in the development of automation systems, which are mainly caused by bad communication and inefficient reuse methods. To overcome these problems, we propose a more systematic reuse approach. Though systematic reuse approaches such as software product lines are appealing, they tend to involve rather burdensome development and management processes. This paper focuses on small enterprises. Since such companies are often unable to perform a "big bang" adoption of the software product line, we suggest an incremental, more lightweight process to transition from single-system development to software product line development. Besides the components of the transition process, this paper discusses tool selection, DSL technology, stakeholder communication support, and business considerations. Although based on problems from the automation system domain, we believe the approach may be general enough to be applicable in other domains as well. The approach has proven successful in two case studies. First, we applied it to a research project for the automation of a logistics lab model, and in the second case (a real-life industry case), we investigated the approaches suitability for fish farm automation systems. Several metrics were collected throughout the evolution of each case, and this paper presents the data for single system development, clone&amp;own and software product line development. The results and observable effects are compared, discussed, and finally summarized in a list of lessons learned. &copy; 2012 Springer-Verlag Berlin Heidelberg.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16191366},
  key       = {Automation},
  keywords  = {Communication;Computer software;Enterprise resource planning;Industry;Research;Software design;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s10270-012-0289-1},
}

@InProceedings{20161302149609,
  author    = {Lopez-Fernandez, Jesus J. and Guerra, Esther and De Lara, Juan},
  title     = {Example-based validation of domain-specific visual languages},
  year      = {2015},
  pages     = {101 - 112},
  address   = {Pittsburgh, PA, United states},
  note      = {Computer science students;Domain specific;Domain specific languages;Domain-specific visual language;Meta model;Meta-modelling;Model-driven Engineering;Validation and verification;},
  abstract  = {The definition of Domain-Specific Languages (DSLs) is a recurrent activity in Model-Driven Engineering. However, their construction is many times an ad-hoc proceb, partly due to the lack of tools enabling a proper engineering of DSLs and promoting domain experts to play an active role. The focus of this paper is on the validation of meta-models for visual DSLs. For this purpose, we propose a language and tool support for describing properties that in-stances of meta-models should (or should not) meet. Then, our system uses a model finder to produce example models, enriched with a graphical concrete syntax, that confirm or refute the abumptions of the meta-model developer. Our language complements metaBest, a framework for the validation and verification of meta-models that includes two other languages for unit testing and specification-based test-ing of meta-models. A salient feature of our approach is that it fosters interaction with domain experts by the use, proceb-ing and creation of informal drawings constructed in editors liked yED or Dia. We abeb the usefulneb of the approach in the validation of a DSL for house blueprints, with the par-Ticipation of 26 4th year computer science students. &copy; 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {SLE 2015 - Proceedings of the 2015 ACM SIGPLAN International Conference on Software Language Engineering},
  key       = {Visual languages},
  keywords  = {Computational linguistics;Computer programming languages;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2814251.2814256},
}

@Article{20123515385010,
  author    = {Hrncic, Dejan and Mernik, Marjan and Bryant, Barrett R.},
  title     = {Improving grammar inference by a memetic algorithm},
  journal   = {IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews},
  year      = {2012},
  volume    = {42},
  number    = {5},
  pages     = {692 - 703},
  note      = {Domain experts;Domain specific languages;Grammar inference;Grammatical inferences;Inference process;Memetic algorithms;Semantics of programming languages;Software languages;},
  abstract  = {A memetic algorithm, a novel approach for solving NP-hard problems, has been applied in this paper for grammatical inference in the field of domain-specific languages (DSLs). DSLs are often designed by domain experts who have no knowledge about the syntax and semantics of programming languages. However, they are able to write sample programs to accomplish their goals and illustrate the features of their language. Grammatical inference is a technique to infer a context-free grammar from a set of positive (and negative) samples. This paper shows that grammatical inference may assist domain experts and software language engineers in developing DSLs by automatically producing a grammar, which describes a set of sample DSL programs. A memetic-algorithm-based tool is developed, which greatly improves results and robustness of the inference process. &copy; 1998-2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {10946977},
  key       = {Evolutionary algorithms},
  keywords  = {Computational complexity;Computational grammars;Inference engines;Problem oriented languages;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/TSMCC.2012.2186802},
}

@InProceedings{20122215073872,
  author    = {Barateiro, Jose and Borbinha, Jose},
  title     = {Managing risk data: From spreadsheets to information systems},
  year      = {2012},
  pages     = {673 - 676},
  address   = {Yasmine Hammamet, Tunisia},
  note      = {Control mechanism;Domain specific languages;Integrated solutions;Management efforts;Risk information;Risk management framework;Specific activity;},
  abstract  = {The goal of Risk Management is to define prevention and control mechanisms to address the risks attached to specific activities and valuable assets. Many Risk Management efforts operate in silos with narrowly focused, functionally driven, and disjointed activities. That fact leads to a fragmented view of risks, where each activity uses its own language, customs and metrics. That limits an organization-wide perception of risks, where interdependent risks are not anticipated, controlled or managed. The lack of integrated solutions to manage risk information, lead the experts to use spreadsheets as their main tool, impeding collaboration, communication and reuse of risk information. In order to address these issues, this paper presents a solution that integrates a Risk Management framework, including a XML-based Domain Specific Language for Risk Management. The proposed framework is supported by an information system to manage the definition or risks. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the Mediterranean Electrotechnical Conference - MELECON},
  key       = {Risk perception},
  keywords  = {Information systems;Risk management;Spreadsheets;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/MELCON.2012.6196521},
}

@InProceedings{20162702563910,
  author    = {Li, Pei and Brunet, Elisabeth and Trahay, Francois and Parrot, Christian and Thomas, Gael and Namyst, Raymond},
  title     = {Automatic OpenCL code generation for multi-device heterogeneous architectures},
  year      = {2015},
  volume    = {2015-December},
  pages     = {959 - 968},
  address   = {Beijing, China},
  note      = {Accelerator data;Code Generation;Domain specific languages;Heterogeneous architectures;Lines of code;Multiple devices;OpenCL;Programming tools;},
  abstract  = {Using multiple accelerators, such as GPUs or Xeon Phis, is attractive to improve the performance of large data parallel applications and to increase the size of their workloads. However, writing an application for multiple accelerators remains today challenging because going from a single accelerator to multiple ones indeed requires to deal with potentially non-uniform domain decomposition, inter-accelerator data movements, and dynamic load balancing. Writing such code manually is time consuming and error-prone. In this paper, we propose a new programming tool called STEPOCL along with a new domain specific language designed to simplify the development of an application for multiple accelerators. We evaluate both the performance and the usefulness of STEPOCL with three applications and show that: (i) the performance of an application written with STEPOCL scales linearly with the number of accelerators, (ii) the performance of an application written using STEPOCL competes with a handwritten version, (iii) larger workloads run on multiple devices that do not fit in the memory of a single device, (iv) thanks to STEPOCL, the number of lines of code required to write an application for multiple accelerators is roughly divided by ten. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {01903918},
  journal   = {Proceedings of the International Conference on Parallel Processing},
  key       = {Automatic programming},
  keywords  = {Acceleration;Codes (symbols);Computer aided software engineering;Computer programming languages;Domain decomposition methods;Memory architecture;Network components;Network management;Particle accelerators;Problem oriented languages;Program processors;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICPP.2015.105},
}

@InProceedings{20122815232152,
  author    = {Gunter, Manuel},
  title     = {Introducing MapLan to map banking survey data into a time series database},
  year      = {2012},
  pages     = {528 - 533},
  address   = {Berlin, Germany},
  note      = {Business needs;Data lineage;Data mappings;Data transformation;Domain specific languages;Heterogeneous schemas;Monetary policies;Statistical database;Statistical datas;Survey data;Time Series Database;},
  abstract  = {In order to fulfill its monetary policy function, the Swiss National Bank (SNB) collects statistical data on the economy. The SNB stores results of the regularly held surveys in a specialized database (primary), ordered by surveys and survey forms. After validation the data has to be transferred in another specialized database (secondary) where it can be accessed by economists. The secondary database keeps the data in time series that are hierarchically arranged by statistical taxonomies. The data transfer from the primary to the secondary database feeds 1.5 million time series. Mapping and transformation logic was hard-coded in legacy programs. They were cumbersome to manage and intransparent to the economists in charge. In this paper we describe a novel approach called MapLan, a Java-based data mapping system featuring a domain specific language. The MapLan system not only performs the data transformation and mapping, it also produces complete data lineage information. This paper shows in practice that domain specific languages are an efficient tool to solve two pressing data mapping and transformation problems of statistical databases. One problem is that of mapping the large and heterogeneous schemas of statistical databases in an efficient and manageable way. The other problem is the business need for complete data lineage of the target time series. &copy; 2012 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Metadata},
  keywords  = {Data transfer;Economics;Java programming language;Mapping;Surveys;Time series;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2247596.2247658},
}

@InProceedings{20160401839486,
  author    = {Vinogradov, Sergey and Ozhigin, Artem and Ratiu, Daniel},
  title     = {Modern model-based development approach for embedded systems practical experience},
  year      = {2015},
  pages     = {56 - 59},
  address   = {Rome, Italy},
  note      = {Application requirements;Control functionality;Development environment;Domain specific languages;Language engineering;Model based development;Multi paradigm modeling;Practical experience;},
  abstract  = {Control functionality of modern rail vehicles is getting more and more complex. It contains several modules such as the traction control unit or the central control unit, as well as input and output stations, such as driver's cab terminals and process I/Os. A plethora of devices are connected to the vehicle and train bus and are able to communicate. The functions of the vehicle control and traction systems are configured by using function blocks from which loadable programs are generated. The languages used to program the control units are well established in the field. However, one-size-fits-all approach cannot adequately address the increased complexity of the software in modern trains. In this paper we describe our preliminary experience with using the multi-paradigm modeling tool 'mbeddr' in the railway domain. The following aspects have been in focus during the work: a) matching the application requirements and domain specific language used for implementation; b) integration of model-based approach into traditional product lifecycle; c) reengineering existing functionality using modeling and code generation capabilities of mbeddr. The system example we chose was the application logic of automated train driving system implemented in development environment of Siemens process automation framework. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {1st IEEE International Symposium on Systems Engineering, ISSE 2015 - Proceedings},
  key       = {C (programming language)},
  keywords  = {Computational linguistics;Computer programming languages;Control system synthesis;Embedded systems;Life cycle;Modeling languages;Problem oriented languages;Systems engineering;Traction control;Vehicles;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SysEng.2015.7302512},
}

@InProceedings{20154001325461,
  author    = {Sharma, Vibhu Saujanya and Ramnani, Roshni R. and Sengupta, Shubhashis},
  title     = {A framework for identifying and analyzing non-functional requirements from text},
  year      = {2014},
  pages     = {1 - 8},
  address   = {Hyderabad, India},
  note      = {Domain specific languages;Multiple features;NAtural language processing;Natural language requirements;NFRs;Non-functional requirements;Requirement analysis;Technical architecture;},
  abstract  = {Early identification of Non-Functional Requirements (NFRs) is important as this has direct bearing on the design and architecture of the system. NFRs form the basis for architects to create the technical architecture of the system which acts as the scaffolding in which the functionality of the same is delivered. Failure to identify and analyze NFRs early-on can result in unclassified, incomplete or conicting NFRs, and this typically results in costly rework in later stages of the software development. In practice, this activity is primarily done manually. In this paper, we present a framework to automatically detect and classify non-functional requirements from textual natural language requirements. Our approach to identify NFRs is based on extracting multiple features by parsing the natural language requirement whereby the presence of a certain combination of and relationship among the features uniquely identifies the requirement as an NFR of a particular category. These features are specified as pattern based rules which can be specified in a human readable language through the use of a domain specific language that we have defined. This enables great ease and exibility in creating and extending rules. Our approach has been implemented as a prototype tool and here we also present the results of applying our approach on a publicly available requirement corpus. Copyright &copy; 2014 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {4th International Workshop on the Twin Peaks of Requirements and Architecture, TwinPeaks 2014 - Proceedings},
  key       = {Natural language processing systems},
  keywords  = {Computational linguistics;Computer architecture;Computer programming languages;Problem oriented languages;Scaffolds;Software design;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2593861.2593862},
}


@inproceedings{20143318062546,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Converting ontologies into DSLs},
journal = {OpenAccess Series in Informatics},
author = {Fonseca, Joao M. Sousa and Pereira, Maria Joao Varanda and Henriques, Pedro Rangel},
volume = {38},
year = {2014},
pages = {85 - 92},
issn = {21906807},
address = {Braganca, Portugal},
abstract = {This paper presents a project whose main objective is to explore the Ontological-based development of Domain Specific Languages (DSL), more precisely, of their underlying Grammar. After reviewing the basic concepts characterizing Ontologies and Domain-Specific Languages, we introduce a tool, Onto2Gra, that takes profit of the knowledge described by the ontology and automatically generates a grammar for a DSL that allows to discourse about the domain described by that ontology. This approach represents a rigorous method to create, in a secure and effective way, a grammar for a new specialized language restricted to a concrete domain. The usual process of creating a grammar from the scratch is, as every creative action, difficult, slow and error prone; so this proposal is, from a Grammar Engineering point of view, of uttermost importance. After the grammar generation phase, the Grammar Engineer can manipulate it to add syntactic sugar to improve the final language quality or even to add semantic actions. The Onto2Gra project is composed of three engines. The main one is OWL2DSL, the component that converts an OWL ontology into an attribute grammar. The two additional modules are Onto2OWL, converts ontologies written in OntoDL (a light-weight DSL to describe ontologies) into standard OWL, and DDesc2OWL, converts domain instances written in the DSL generated by OWL2DSL into the initial OWL ontology. &copy; Joa&tilde;o Manuel Sousa Fonseca, Maria Joa&tilde;o Varanda Pereira, and Pedro Rangel Henriques.},
key = {Birds},
keywords = {Computer programming languages;DSL;Ontology;Problem oriented languages;Query languages;Semantic Web;Semantics;Slate;},
note = {Attribute grammars;Concrete domains;Domain specific languages;Grammar;Grammar engineering;OWL;RDF;Syntactic sugars;},
URL = {http://dx.doi.org/10.4230/OASIcs.SLATE.2014.85},
} 


@article{20143600051361,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Corpus-based analysis of domain-specific languages},
journal = {Software and Systems Modeling},
author = {Tairas, Robert and Cabot, Jordi},
volume = {14},
number = {2},
year = {2015},
pages = {889 - 904},
issn = {16191366},
abstract = {As more domain-specific languages (DSLs) are designed and developed, the need to evaluate these languages becomes an essential part of the overall DSL life cycle. Corpus-based analysis can serve as an evaluation mechanism to identify characteristics of the language after it has been deployed by looking at how end-users employ it in practice. This analysis that is based on actual usage of the language brings a new perspective which can be considered by a language engineer when working toward improving the language. In this paper, we describe our utilization of corpus-based analysis techniques and exemplify them on the evaluation of the Puppet and ATL DSLs. We also outline an Eclipse plug-in, which is a generic corpus-based DSL analysis tool that can accommodate the evaluation of different DSLs. &copy; 2013, Springer-Verlag Berlin Heidelberg.},
key = {Computational linguistics},
keywords = {Computer programming languages;DSL;Life cycle;Problem oriented languages;},
note = {Analysis;ATL;Corpus;Domain specific languages;Puppet;},
URL = {http://dx.doi.org/10.1007/s10270-013-0352-6},
} 

@InProceedings{20163202693899,
  author    = {Schmid, Klaus and Eichelberger, Holger},
  title     = {EASy-Producer - from product lines to variability-rich software ecosystems},
  year      = {2015},
  volume    = {20-24-July-2015},
  pages     = {390 - 391},
  address   = {Nashville, TN, United states},
  note      = {Easy-producer;Industrial case study;Light-weight engineering;Open source tools;Product derivation;Software ecosystems;Software Product Line;Variability model;},
  abstract  = {The EASy-Producer product line environment is a novel opensource tool that supports the lightweight engineering of software product lines and variability-rich software ecosystems. It has been applied in several industrial case studies, showing its practical applicability both from a stability and a capability point of view. The tool set integrates both, interactive configuration capabilities and a DSL-based approach to variability modeling, configuration definition and product derivation. The goal of the tutorial is to provide the participants with an overview of the tool. However, the main focus will be on a brief introduction of the DSLs. After participating in the tutorial, the participants will understand the capabilities of the toolset and will have a basic practical understanding of how to use it to define software ecosystems and derive products from them. &copy; 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Ecosystems},
  keywords  = {Computer software;DSL;Ecology;Software design;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2791060.2791112},
}

@InProceedings{20152801026292,
  author    = {Zhang, Weiqing and Moller-Pedersen, Birger},
  title     = {Tool integration models},
  year      = {2013},
  volume    = {1},
  pages     = {485 - 494},
  address   = {Bangkok, Thailand},
  note      = {Artifact;Code Generation;Integration models;Role;Tool integration;},
  abstract  = {This paper presents an extension of a previously presented tool integration approach: tool integration for different scenarios may be specified as integration models, and these integration models can be executed or form the basis of code generation for implementing integration on different platforms. Integration models cover both the data and behavior parts of tool integration. The benefits of separating the details of integration models from the models being integrated through tool integration are illustrated and it is indicated what a DSL for making integration models would be. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {15301362},
  journal   = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
  key       = {Integration},
  keywords  = {Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/APSEC.2013.70},
}

@Article{20160201793936,
  author    = {Dejanovi, I. and Milosavljevi, G. and Vaderna, R.},
  title     = {Arpeggio: A flexible PEG parser for Python},
  journal   = {Knowledge-Based Systems},
  year      = {2016},
  volume    = {95},
  pages     = {71 - 74},
  note      = {Domain specific languages;Free and open source softwares;Packrat;Parser;Parsing expression grammars;Python;Python programming language;TextX;},
  abstract  = {Arpeggio is a recursive descent parser with full backtracking and memoization based on PEG (Parsing Expression Grammar) grammars. This category of parsers is known as packrat parsers. It is implemented in the Python programming language and works as a grammar interpreter. Arpeggio has a very good support for error reporting, debugging, and grammar and parse tree visualization. It is used in industrial environments and teaching Domain-Specific Languages course at the Faculty of Technical Sciences in Novi Sad. Arpeggio is a foundation of a high-level DSL meta-language and tool - textX. It is a free and open-source software available at GitHub under MIT license. &copy; 2015 Elsevier B.V. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {09507051},
  key       = {Computational linguistics},
  keywords  = {Computer programming;Computer programming languages;DSL;Formal languages;High level languages;Open source software;Open systems;Polyethylene glycols;Problem oriented languages;Software engineering;Teaching;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.knosys.2015.12.004},
}


@inproceedings{20124415616595,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Wiki refactoring as mind map reshaping},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Puente, Gorka and Diaz, Oscar},
volume = {7328 LNCS},
year = {2012},
pages = {646 - 661},
issn = {03029743},
address = {Gdansk, Poland},
abstract = {Wikis' organic growth inevitably leads to wiki degradation and the need for regular wiki refactoring. So far, wiki refactoring is a manual, time-consuming and error-prone activity. We strive to ease wiki refactoring by using mind maps as a graphical representation of the wiki structure, and mind map manipulations as a way to express refactoring. This paper (i) defines the semantics of common refactoring operations based on Wikipedia best practices, (ii) advocates for the use of mind maps as a visualization of wikis for refactoring, and (iii) introduces a DSL for wiki refactoring built on top of FreeMind, a mind mapping tool. Thus, wikis are depicted as FreeMind maps, and map manipulations are interpreted as refactoring operations over the wiki. The rationales for the use of a DSL are based not only on reliability grounds but also on facilitating end-user participation. &copy; 2012 Springer-Verlag Berlin Heidelberg.},
key = {Schematic diagrams},
keywords = {DSL;Information systems;Semantics;Systems engineering;Websites;},
note = {End users;Error prones;Graphical representations;Mind maps;Mind-mapping;Organic growth;Refactorings;Wiki;Wikipedia;},
URL = {http://dx.doi.org/10.1007/978-3-642-31095-9_42},
} 


@inproceedings{20123415364585,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Web-based tool integration: A web augmentation approach},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Diaz, Oscar and De Sosa, Josune and Arellano, Cristobal and Trujillo, Salvador},
volume = {7387 LNCS},
year = {2012},
pages = {431 - 434},
issn = {03029743},
address = {Berlin, Germany},
abstract = {Desktop tools are steadily being turned into web applications. Tool integration then becomes a question of website integration. This work uses Web Augmentation techniques for this purpose. An integration layer is deployed on top of the existing Web-based tools that augments the rendering of those tools for the integration experience. Layers are specified through a statechart-like DSL and transformed into JavaScript. &copy; 2012 Springer-Verlag.},
key = {Integration},
keywords = {Websites;},
note = {Javascript;Tool integration;WEB application;Web augmentation;Web-based tools;},
URL = {http://dx.doi.org/10.1007/978-3-642-31753-8_37},
} 


@inproceedings{20144600205095,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Developing user interfaces with EMF parsley},
journal = {ICSOFT-PT 2014 - Proceedings of the 9th International Conference on Software Paradigm Trends},
author = {Bettini, Lorenzo},
year = {2014},
pages = {58 - 66},
address = {Vienna, Austria},
abstract = {In this paper we describe the main features of EMF Parsley, a new Eclipse project for implementing applications based on the Eclipse Modeling Framework (EMF). EMF Parsley aims at complementing the EMF reflective mechanisms with respect to rapidly creating user interfaces based on models, without having to deal with internal details and setup code. In particular, EMF Parsley uses injection mechanisms to easily customize all the aspects of such applications. Moreover, it provides a set of reusable user interface components like trees, tables and detail forms that manage the model with the introspective EMF capabilities, together with reusable views, editors and dialogs. Besides project wizards, to easily create projects based on EMF Parsley, the main developing tool is a DSL, implemented with Xtext/Xbase, that provides a rapid customization mechanism. Copyright &copy; 2014 SCITEPRESS - Science and Technology Publications.},
key = {User interfaces},
keywords = {DSL;Electric potential;Models;},
note = {Eclipse;Eclipse modeling framework;Injection mechanisms;Rapid customization;User interface components;},
} 

@InProceedings{20153001064750,
  author    = {Figay, Nicolas and Ghodous, Parisa and Shariat, Bezhad and Exposito, Ernesto and Tchoffa, David and Kermad, Lyes and Dafaoui, El Mouloudi and Vosgien, Thomas},
  title     = {Model based enterprise modeling for testing plm interoperability in dynamic manufacturing network},
  year      = {2015},
  volume    = {213},
  pages     = {141 - 153},
  address   = {Nimes, France},
  note      = {Digital business ecosystems;Dynamic manufacturing networks;Enterprise modeling;Interoperability framework;MDA;Model to model transformation;PLM;Simulation;},
  abstract  = {When willing to prepare and to build operational Product Life cycle Management interoperability within a Dynamic Manufacturing Network (DMN) in a mature digital business ecosystem such as Aeronautic, Space and Defense, the approaches proposed by the Enterprise Application Interoperability are insufficient when willing to address the existing interoperability brakes Some of these brakes have been addressed in project such as IMAGINE and SIP@ SystemX, allowing to experiment innovative way of using standards based enterprise modeling and also to identify some additional gaps for applying model base enterprise modeling to PLM interoperability within a DMN. After defining the business and the scientific contexts, the paper describes this new approach which consists in federating the usage of several PLM, Business, Information and ICT standard through the usage of an enterprise modeling standardized language, ArchiMate, and associated modeling tool Archi created using ArchiMate as an EMF DSL. The defined methodology is based on producing a set of DMN blueprints and associated templates. Then, through model to model transformation, other more detailed models using more specialized languages are created and used for software component generation and deployment enterprise hub platform based on standards. Using the methodology, the associated framework and the developed resulting from our research activity, we are now able to prepare and build interoperability within a DMN. Ability of preserving investment performed with the legacy and reducing risks associated to future evolution was demonstrated through IMAGINE Aeronautic Lab experimentation within SIP. Such experimentation also highlighted some issues related to model based engineering in such a context, and allowed identifying needs for new extensions of the federative PLM interoperability framework for Collaborative Networked Product Development initiated during the ATHENA project. It will be addressed in future work. &copy; IFIP International Federation for Information Processing 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {18651348},
  journal   = {Lecture Notes in Business Information Processing},
  key       = {Interoperability},
  keywords  = {Clouds;Computational linguistics;DSL;Enterprise resource planning;Life cycle;Manufacture;Modeling languages;Modems;Product development;Project management;Standards;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-662-47157-9_13},
}


@inproceedings{20134616964632,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {QReal DSM platform: An environment for creation of specific visual IDEs},
journal = {ENASE 2013 - Proceedings of the 8th International Conference on Evaluation of Novel Approaches to Software Engineering},
author = {Kuzenkova, Anastasiia and Deripaska, Anna and Bryksin, Timofey and Litvinov, Yurii and Polyakov, Vladimir},
year = {2013},
pages = {205 - 211},
address = {Angers, France},
abstract = {This article describes a QReal technology designed for rapid creation of domain-specific languages ("DSL"). Domain-specific modeling ("DSM") is a promising paradigm which provides enhanced development productivity (3 to 10 times in selected cases compared to common development methodologies). This fact contributes to the interest in the DSM support tools. QReal is a research project having an objective of creating a prototype of such a tool. Overview of QReal basic metamodeling capabilities such as abstract and concrete syntax definition is provided in the article, as well as the description of some advanced capabilities such as defining semantics of visual language, constraints and refactoring support. Two cases of successful application of this technology to creating domain-specific solutions are presented and future work directions are addressed. Copyright &copy; 2013 SCITEPRESS.},
key = {Software engineering},
keywords = {Abstracting;DSL;Problem oriented languages;Semantics;Tools;Visual languages;},
note = {Concrete syntax;Development methodology;Development productivity;Domain specific;Domain specific languages;Domain specific modeling;DSM platforms;Metamodeling;},
} 

@InProceedings{20143718149646,
  author    = {Nisar, Kashif and Osman, Wan Rozaini Sheik and Altrad, Abdallah M.M.},
  title     = {Modeling of Broadband over In-Door Power Line Network in Malaysia},
  year      = {2014},
  volume    = {265 AISC},
  pages     = {213 - 222},
  address   = {Phuket, Thailand},
  note      = {Channel transfer functions;Data communication networks;Digital Subscriber Line (DSL);High-speed digital transmission;Information and Communication Technologies;Infrastructure deployments;Low voltages;Power lines communication;},
  abstract  = {Malaysia is considered the eighth Asian country out of the top 15 countries in household broadband penetration at 34.5%. Users in rural areas who cannot receive Digital Subscriber Line (DSL) or cable modem services. In addition, owing to the high cost of Information and Communication Technology (ICT) infrastructure deployment in the rural areas, delay in broadband services is being experienced. Therefore, the Power Lines Communication (PLC) technology could have the potential to provide a broadband access through the entire electricity grid. Broadband PLC uses power lines as a high-speed digital transmission channel. This paper investigates low voltage Channel Transfer Function (CTF) of PLC technology for the purpose of data transmission regarding Malaysia electrical cable specification by using Matlab-Simulink simulation tool. Since that could help Malaysia licensable activities to provide Broadband PLC service out of harm's way of other data communication networks. &copy; Springer International Publishing Switzerland 2014.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {21945357},
  journal   = {Advances in Intelligent Systems and Computing},
  key       = {Telecommunication lines},
  keywords  = {Broadband networks;Cables;Electric lines;Modems;Rural areas;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-06538-0_21},
}

@InProceedings{20134316872069,
  author    = {Kulkarni, Abhishek and Newton, Ryan R.},
  title     = {Embrace, defend, extend: A methodology for embedding preexisting DSLs : Case in point, streamHs: Streamit in haskell},
  year      = {2013},
  pages     = {27 - 34},
  address   = {Boston, MA, United states},
  note      = {Auto-parallelizing;Domain specific languages;DSL-technologies;Embedded Languages;Haskell;Higher efficiency;Parallel;Programming abstractions;},
  abstract  = {Domain-specific languages offer programming abstractions that enable higher efficiency, productivity and portability specific to a given application domain. Domain-specific languages such as StreamIt have valuable auto-parallelizing code-generators, but they require learning a new language and tool-chain and may not integrate easily with a larger application. One solution is to transform such standalone DSLs into embedded languages within a generalpurpose host language. This prospect comes with its own challenges, namely the compile-time and runtime integration of the two languages. In this paper, we address these challenges, presenting our solutions in the context of a prototype embedding of StreamIt in Haskell. By demonstrating this methodology, we hope to encourage more reuse of DSL technology, and fewer short-lived reimplementations of existing techniques. &copy; 2013 by the Association for Computing Machinery, Inc. (ACM).},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
  key       = {Functional programming},
  keywords  = {Acoustic streaming;Computer programming languages;Parallel architectures;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2505351.2505355},
}

@InProceedings{20131316145284,
  author    = {Goldschmidt, Thomas and Becker, Steffen and Burger, Erik},
  title     = {Towards a tool-oriented taxonomy of view-based modelling},
  year      = {2012},
  volume    = {P-201},
  pages     = {59 - 74},
  address   = {Bamberg, Germany},
  note      = {Comprehensive analysis;Domain-specific modelling;Domain-Specific Modelling Languages;Feature-based classification;Model-driven Engineering;Specific problems;View-based;},
  abstract  = {The separation of view and model is one of the key concepts of Model-Driven Engineering (MDE). Having different views on a central model helps modellers to focus on specific aspects. Approaches for the creation of Domain-Specific Modelling Languages (DSML) allow language engineers to define languages tailored for specific problems. To be able to build DSMLs that also benefit from view-based modelling a common understanding of the properties of both paradigms is required. However, research has not yet considered the combination of both paradigms, namely view-based domain specific modelling to a larger extent. Especially, a comprehensive analysis of a view's properties (e.g., partial, overlapping, editable, persistent, etc.) has not been conducted. Thus, it is also still unclear to which extent view-based modelling is understood by current DSML approaches and what a common understanding if this paradigm is. In this paper, we explore view-based modelling in a tool-oriented way. Furthermore, we analyse the properties of the view-based domain-specific modelling concept and provide a feature-based classification of these properties.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16175468},
  journal   = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
  language  = {English},
}

@InProceedings{20145100336818,
  author    = {Moreno-Delgado, Antonio and Duran, Francisco},
  title     = {The movie database case: Solutions using maude and the maude-based e-motions tool},
  year      = {2014},
  volume    = {1305},
  pages     = {116 - 124},
  address   = {York, United kingdom},
  note      = {General purpose languages;Maude specifications;Real-time languages;Rewriting logic;Simulation and analysis;},
  abstract  = {The paper presents solutions for the TTC 2014 Movie Database Case, both in the e-Motions DSML and in the rewriting-logic formal language Maude. The DSMLs defined in e-Motions are automatically transformed into Maude specifications, which are then used for simulation and analysis purposes. e-Motions is a general purpose language, in which real-time languages may be modeled, with full support for OCL and other advanced features. The fact that the solutions given directly in Maude lack the overhead included by e-Motions to deal with all those extra features not needed in the current case study, makes these solutions much more efficient, and able to deal with bigger problems. Copyright &copy; 2014.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {Application programs},
  keywords  = {Formal languages;},
  language  = {English},
}

@InProceedings{20161202130232,
  author    = {Dieumegard, Arnaud and Pantel, Marc and Babin, Guillaume and Carton, Martin},
  title     = {Tool paper: A lightweight formal encoding of a constraint language for DSMLs},
  year      = {2015},
  volume    = {1512},
  pages     = {89 - 104},
  address   = {Ottawa, ON, Canada},
  note      = {Automated verification;Constraint language;Data flow language;Domain specific modeling languages;Formal verification tools;Model-driven Engineering;Safety critical systems;Standardized models;},
  abstract  = {Domain Specific Modeling Languages (DSMLS) plays a key role in the development of Safety Critical Systems to model system requirements and implementation. They often need to integrate property and query sub-languages. As a standardized modeling language, OCL can play a key role in their definition as they can rely both on its concepts and textual syntax which are well known in the Model Driven Engineering community. For example, most DSMLS are defined using MOF for their abstract syntax and OCL for their static semantics as a metamodeling DSML. OCLinEcore in the Eclipse platform is an example of such a metamodeling DSML integrating OCL as a language component in order to benefit from its property and query facilities. DSMLS for Safety Critical Systems usually provide formal model verification activities for checking models completeness or consistency, and implementation correctness with respect to requirements. This contribution describes a framework to ease the definition of such formal verification tools by relying on a common translation from a subset of OCL to the Why3 verification toolset. This subset was selected to ease efficient automated verification. This framework is illustrated using a block specification language for data flow languages where a subset of OCL is used as a component language.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {Modeling languages},
  keywords  = {Computational linguistics;Embedded systems;Formal methods;Formal verification;Safety engineering;Security systems;Semantics;Specification languages;Syntactics;Systems analysis;Visual languages;},
  language  = {English},
}

@InProceedings{20133816749570,
  author    = {Alvarez, Camilo and Casallas, Rubby},
  title     = {MTC Flow: A tool to design, develop and deploy model transformation chains},
  year      = {2013},
  pages     = {ACM Special Interest Group on Software Engineering (SIGSOFT); Centre National De La Recherche Scientifique (CNRS); ACM Special Interest Group on Programming Languages (SIGPLAN); University Montpellier 2 (UM2); Association Internationale pour les Technologies Objects (AITO) -},
  address   = {Montpellier, France},
  note      = {Abstraction layer;Development environment;Development process;Eclipse modeling framework;Graphical modeling frameworks;Model transformation;Model transformation chains;Technology support;},
  abstract  = {This paper presents a tool called MTC Flow, which allows model-driven developers to design, develop, test and deploy Model Transformation Chains (MTCs). The tool offers a graphical DSL for defining MTC workflow models independently of the technologies that support the transformations. Using basic concepts such as metamodels, models and transformations (M2M, M2T and T2M) the user defines, executes and tests his MTC easily in the same development environment. MTC Flow has an abstraction layer to implement technology support. It facilitates the interoperability of model transformation and validation using the existing technologies without changes. Additionally, once the MTC is finished, MTC Flow offers an option to deploy it in any environment that support JAVA technology. The tool supports modularity and alternative execution paths of the MTCs. It was built on top of the Eclipse Modeling Framework (EMF) and the Graphical Modeling Framework (GMF). The tool offers a development environment using the extending capabilities of the Eclipse platform. We illustrate how MTC Flow supports MTCs development process using an example. &copy; 2013 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ACadeMics Tooling with Eclipse, ACME 2013 - A Joint ECMFA/ECSA/ECOOP Workshop},
  key       = {Tools},
  keywords  = {Chains;Interoperability;Mathematical models;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2491279.2491286},
}

@InProceedings{20144600189214,
  author    = {Moreira, Rodrigo M.L.M. and Paiva, Ana C.R.},
  title     = {PBGT tool: An integrated modeling and testing environment for pattern-based GUI testing},
  year      = {2014},
  pages     = {863 - 866},
  address   = {Vasteras, Sweden},
  note      = {Eclipse modeling framework;Eclipse plugin;GUI testing;Integrated modeling;Test models;Test Pattern;Testing environment;},
  abstract  = {Pattern Based GUI Testing (PBGT) is a new methodology that aims at systematizing and automating the GUI testing process. It is supported by a Tool (PBGT Tool) which provides an integrated modeling and testing environment that supports the crafting of test models based on UI Test Patterns, using a GUI modeling DSL called PARADIGM. The tool is freely available as an Eclipse plugin, developed on top of the Eclipse Modeling Framework. This paper presents PBGT Tool, which has been successfully used in several projects, and more recently at industry level. &copy; 2014 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ASE 2014 - Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
  key       = {Graphical user interfaces},
  keywords  = {Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2642937.2648618},
}

@Article{20142017724647,
  author    = {Teruel, Miguel A. and Navarro, Elena and Lopez-Jaquero, Victor and Montero, Francisco and Gonzalez, Pascual},
  title     = {A CSCW Requirements Engineering CASE Tool: Development and usability evaluation},
  journal   = {Information and Software Technology},
  year      = {2014},
  volume    = {56},
  number    = {8},
  pages     = {922 - 949},
  note      = {Collaborative systems;Common industry formats;Computer science students;CSCW;CSRML;ISO/IEC;Requirements specifications;Usability evaluation;},
  abstract  = {Context CSRML Tool 2012 is a Requirements Engineering CASE Tool for the Goal-Oriented Collaborative Systems Requirements Modeling Language (CSRML). Objective This work aims at evaluating the usability of CSRML Tool 2012, thus identifying any possible usability flaw to be solved in the next releases of the application, as well as giving a general overview on how to develop a DSL tool similar to the one evaluated in this work by means of Visual Studio Modelling SDK. Method In this evaluation, which was reported by following the ISO/IEC 25062:2006 Common Industry Format for usability tests, 28 fourth-course Computer Science students took part. They were asked to carry out a series of modifications to an incomplete CSRML requirements specification. Usability was assessed by measuring the task's completion rate, the elapsed time, number of accesses to the help system of the tool and the instructor's verbal assistance. The participants' arousal and pleasantness were assessed by analyzing both facial expressions and a USE questionnaire. Results In spite of obtaining high usability levels, the test outcome revealed some usability flaws that should be addressed. Conclusion The important lessons learnt from this evaluation are also applicable to the success of other usability tests as well as to the development of new CASE tools. &copy; 2014 Elsevier B.V. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {09505849},
  key       = {Usability engineering},
  keywords  = {Computer aided software engineering;Requirements engineering;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.infsof.2014.02.009},
}

@Article{20150500472061,
  author    = {Hartel, Johannes and Hartel, Lukas and Lammel, Ralf},
  title     = {Test-data generation for xtext: Tool paper},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year      = {2014},
  volume    = {8706},
  pages     = {342 - 351},
  note      = {Context sensitivity;Grammar customization;Grammar transformation;Grammars;Test data;Test data generation;Xtend;Xtext;Xtextgen;},
  abstract  = {We describe a method and a corresponding tool for grammar-based test-data generation (GBTG). The basic generation principle is to enumerate test data based on grammatical choices. However, generation is broken down into two phases to deal with context-sensitive properties in an efficient and convenient manner. The first phase enumerates test data (i.e., parse trees) with placeholders. The second phase instantiates the placeholders through post-processors. A DSL for grammar transformation is used to customize a given grammar, meant for parsing, to be more suitable for test-data generation. Post-processors are derived from a corresponding object-oriented framework. The actual tool, XTEXTGEN, extends the XTEXT technology for language development. &copy; Springer International Publishing Switzerland 2014.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  key       = {Metadata},
  keywords  = {Data communication systems;Formal languages;Testing;Trees (mathematics);},
  language  = {English},
}


@inproceedings{20141717601264,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Kroki: A mockup-based tool for participatory development of business applications},
journal = {SoMeT 2013 - 12th IEEE International Conference on Intelligent Software Methodologies, Tools and Techniques, Proceedings},
author = {Milosavljevic, Gordana and Filipovic, Milorad and Marsenic, Vladan and Pejakovic, Darko and Dejanovic, Igor},
year = {2013},
pages = {235 - 242},
address = {Budapest, Hungary},
abstract = {This paper presents Kroki (fr. croquis - sketch), a tool for participatory development of business applications based on mockups. Kroki provides a graphical editor for visual creation of mockups and two engines (web and desktop) for mockup execution. Kroki is developed in order to foster development agility, communication and better understanding of end-user needs. The mockup editor and engines are based on our EUIS (Enterprise User Interface Specification) DSL for specifying user interfaces of business applications. &copy; 2013 IEEE.},
key = {Mockups},
keywords = {Engines;Tools;User interfaces;},
note = {Business applications;End users;Graphical editors;Interface specification;},
URL = {http://dx.doi.org/10.1109/SoMeT.2013.6645668},
} 

@InProceedings{20131516195114,
  author    = {Regnell, Bjorn},
  title     = {reqT.org - Towards a semi-formal, open and scalable requirements modeling tool},
  year      = {2013},
  volume    = {7830 LNCS},
  pages     = {112 - 118},
  address   = {Essen, Germany},
  note      = {Computer science students;Educational context;Executable codes;Free software;Natural languages;Requirements MetaModel;Requirements modeling;Student project;},
  abstract  = {[Context and motivation] This research preview presents ongoing work on a free software requirements modeling tool called reqT that is developed in an educational context. [Question/problem] The work aims to engage computer science students in Requirements Engineering (RE) through a tool that captures essential RE concepts in executable code. [Principal ideas] Requirements are modeled using an internal DSL in the Scala programming language that blends natural language strings with a graph-oriented formalism. [Contribution] The metamodel of reqT and its main features are presented and modeling examples are provided together with a discussion on initial experiences from student projects, limitations and directions of further research. &copy; 2013 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Requirements engineering},
  keywords  = {Computer aided software engineering;Computer programming languages;Computer software selection and evaluation;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-37422-7_8},
}

@InProceedings{20134116820056,
  author    = {Jindal, Nakul and Lotrich, Victor and Deumens, Erik and Sanders, Beverly A.},
  title     = {SIPMaP: A tool for modeling irregular parallel computations in the super instruction architecture},
  year      = {2013},
  pages     = {874 - 884},
  address   = {Boston, MA, United states},
  note      = {Assembly language;Domain specific languages;High performance computing;Instruction processors;Multidimensional arrays;Parallel application;Parallel Computation;Performance Model;},
  abstract  = {Performance modeling is becoming an increasingly important part of the parallel application development process, particulary for expensive computations that will be run on very high-end systems where resources are scarce. We describe a performance modeling tool SIP Map (Super Instruction Processor Modeling and Prediction) developed for the Super-Instruction Architecture(SIA). The SIA is designed for applications where the dominant data structures are large multi-dimensional arrays and it comprises a DSL, the Super-Instruction Assembly Language(SIAL) that supports expressing algorithms in terms of blocks(tiles), and its runtime system Super Instruction Processor (SIP)that manages distribution and disk storage of the arrays. SIPMaP generates performance models from the SIAL source code. In comparison with many applications where useful performance models have been developed and reported, these programs are irregular and have other difficult to model characteristics such as extensive overlapping of communication and computation. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings - IEEE 27th International Parallel and Distributed Processing Symposium, IPDPS 2013},
  key       = {Parallel processing systems},
  keywords  = {Application programs;Computer architecture;Distributed parameter networks;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/IPDPS.2013.35},
}

@InProceedings{20141217470916,
  author    = {Zhang, Maodi and Wang, Zili and Xu, Ping and Li, Yi},
  title     = {Research and implementation of a peripheral environment simulation tool with domain-specific languages},
  year      = {2014},
  volume    = {277 LNEE},
  pages     = {1217 - 1224},
  address   = {Shanghai, China},
  note      = {Domain specific languages;Environment simulation tools;Interface control;Program language;Simulation environment;Simulation model;Software requirement specification;System under test;},
  abstract  = {The importance to build relevant peripheral environment in the testing process for complex embedded software is becoming higher. This paper discussed the current design method of simulation test environment for the embedded software and then presented a modelling method which is used to build peripheral simulation environment for the SUT (system under test) through ICD (interface control data) documents and the software requirement specification. Using this method, the peripheral environment simulation tool which consisted of relevant database and simulation model was set up with Ruby program language. This tool could provide necessary control commands and data support just like in a real running environment for the SUT. Furthermore, a DSL (domain-specific languages) design method for this domain was researched on the basis of the model. The experiment result has demonstrated that it's feasible to set up a peripheral environment for embedded system with our simulation tool. &copy; 2014 Springer International Publishing Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {18761100},
  journal   = {Lecture Notes in Electrical Engineering},
  key       = {Tools},
  keywords  = {Complex networks;Computer simulation;Design;Embedded software;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-01766-2_138},
}

@InProceedings{20123415364594,
  author    = {Diaz, Oscar and Arellano, Cristobal},
  title     = {Sticklet: An end-user client-side augmentation-based mashup tool},
  year      = {2012},
  volume    = {7387 LNCS},
  pages     = {465 - 468},
  address   = {Berlin, Germany},
  note      = {End users;Javascript;Sticky notes;},
  abstract  = {A critical aspect of mashup tools for end users is to come up with an intuitive metaphor. Sticklet is an augmentation-based mashup tool that conceives websites as walls where you can fix HTML fragments (sticky notes) from other websites. Notes are contextualized to the hosting website, i.e. location, parameter passing and layout should be harmonized to those of the website. A set of declarative constructs are available to declaratively specify complex sticky notes. Sticklet is realized as an internal DSL in JavaScript that capitalizes on browser weavers (e.g. Greasemonkey (GM)). Being full-fledged GM scripts, Sticklet benefits from the sharing repositories (e.g. www.userscripts.org) or management utilities (e.g. activation, installation, edition) available for GM. &copy; 2012 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Websites},
  keywords  = {Artificial intelligence;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-31753-8_45},
}

@Article{20144900276692,
  author    = {Silva, Robson and Mota, Alexandre and Starr, Rodrigo Rizzi},
  title     = {Formal MDE-based tool development},
  journal   = {Advances in Intelligent Systems and Computing},
  year      = {2014},
  volume    = {263},
  pages     = {105 - 125},
  note      = {Domain specific languages;DSLs;Formal tools;GUI (graphical user interface);Human machine interaction;Mathematical representations;MDE;Model-driven Engineering;},
  abstract  = {Model-driven engineering (MDE) focuses on creating and exploiting (specific) domain models. It is common to use domain-specific languages (DSL) to describe the concrete elements of such models. MDE tools can easily build DSLs, although it is not clear how to capture dynamic semantics as well as formally verify properties. Formal methods are a well-known solution for providing correct software, but human-machine interaction is usually not addressed. Several industries, particularly the safety-critical industries, use mathematical representations to deal with their problem domains. Such DSLs are difficult to capture, using just MDE tools for instance, because they have specific semantics to provide the desired (core) expected behavior. Thus, we propose a rigorous methodology to create GUI (Graphical User Interface) based DSLs formal tools. We aim at providing a productive and trustworthy development methodology to safety critical industries. &copy; Springer International Publishing Switzerland 2014.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {21945357},
  key       = {Formal methods},
  keywords  = {Accident prevention;Computer programming languages;Graphical user interfaces;Problem oriented languages;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-04717-1_5},
}

@InProceedings{20161902365231,
  author    = {Kruck, Bastian and Lehmann, Stefan and Kecler, Christoph and Reschke, Jakob and Felgentreff, Tim and Lincke, Jens and Hirschfeld, Robert},
  title     = {Multi-level debugging for interpreter developers},
  year      = {2016},
  pages     = {91 - 93},
  address   = {Malaga, Spain},
  note      = {Context switch;Debugging tools;Language levels;Language workbenches;Levels of abstraction;Multiple levels;Squeak;System knowledge;},
  abstract  = {Conventional debuggers require programmers to work on multiple levels of abstraction at once when inspecting call stacks or data. This demands considerable cognitive overhead and deep system knowledge of all implementation technologies involved. When developing an interpreter, programmers often create a dedicated debugger to have a higher-level perspective on the client-language; the resulting use of multiple debuggers at once leads to mental context switches and needs an elaborated method. We present an integrated debugging tool in which interpreter developers define and select the levels of abstraction on which they focus. Our debugger provides them with an abstraction-specialized view. We consider both host-language and guest-language levels, since either may be levels of interest in a debugging session. We show how this separation into host-language levels can ease the debugging of applications through filtering call stacks and specializing call stack representation on levels. &copy; 2016 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {MODULARITY Companion 2016 - Companion Proceedings of the 15th International Conference on Modularity},
  key       = {Computational linguistics},
  keywords  = {Abstracting;DSL;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2892664.2892679},
}

@InProceedings{20160501861277,
  author    = {De Sousa Duarte, Paulo Artur and Barreto, Felipe Mota and De Almada Gomes, Francisco Anderson and De Carvalho, Windson Viana and Trinta, Fernando Antonio Mota},
  title     = {Towards context-aware behaviour generation},
  year      = {2015},
  volume    = {13-17-April-2015},
  pages     = {596 - 598},
  address   = {Salamanca, Spain},
  note      = {Adaptation mechanism;Android;Context-Aware;Contextual information;MDE;Middleware platforms;Model-driven Engineering;Self adaptation;},
  abstract  = {Development of Context-Aware and Mobile (CAM) applications requires software engineers to write complex code (e.g., adaptation mechanisms, context management) and deal with heterogeneity issues regarding devices and sensors. A promise to deal with this issue approach is the combination of MDE (ModelDriven Engineering) design principles and CAM middleware platforms. Following this approach, we present in this paper CRITiCAL, a ConfiguRation Tool for Context Aware and mobiLe applications. This tool enables visual modelling of contextual information and adaptive behaviour of a CAM application. From visual models, a code generation is performed and its result contains all methods required for communication between the application and a context management middleware. We aim at offering a simplified and visual way to define context acquisition mechanisms (e.g., get user location) and context rules in order to accelerate the development of CAM applications. Copyright 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the ACM Symposium on Applied Computing},
  key       = {Application programs},
  keywords  = {Cams;DSL;Middleware;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2695664.2696057},
}

@InProceedings{20140617289813,
  author    = {Farwick, Matthias and Trojer, Thomas and Breu, Michael and Ginther, Stefan and Kleinlercher, Johannes and Doblander, Andreas},
  title     = {A case study on textual enterprise architecture modeling},
  year      = {2013},
  pages     = {305 - 309},
  address   = {Vancouver, BC, Canada},
  note      = {Domain specific languages;Enterprise Architecture;Textual;Viewpoint;Xtext;},
  abstract  = {Today's Enterprise Architecture Management (EAM) tools are based on forms and graphical modeling capabilities via web-based applications or desktop clients. However, recent developments in textual modeling tools have not yet been considered for EA modeling in research and practice. In this paper we present a novel EAM-tool approach, called Txture, that consists of a textual modeling environment and a web-application to provide enterprise-wide architecture visualizations for different stakeholder groups. The tool is in production use at a major Austrian data center, where it proofed to be intuitive and provide efficient modeling capabilities compared to traditional approaches. In this paper we present lessons learned from the development of the tool as well as usage it and report on its benefits and drawbacks. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {15417719},
  journal   = {Proceedings - IEEE International Enterprise Distributed Object Computing Workshop, EDOC},
  key       = {Tools},
  keywords  = {DSL;Industry;Problem oriented languages;Research;System program documentation;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/EDOCW.2013.40},
}

@InProceedings{20154501507284,
  author    = {Schutzel, Johannes and Stieber, Sebastian and Haubelt, Christian and Uhrmacher, Adelinde M.},
  title     = {Targeted on-line data extraction with SystemXtract},
  year      = {2015},
  address   = {Athens, Greece},
  note      = {Computation time;Data extraction;Filter graph;Hybrid prototype;Large amounts of data;Processing architectures;Real time execution;System level simulation;},
  abstract  = {Complex system-level simulation can produce large amounts of data, of which only portions may be of interest. When experimenting with hybrid prototypes, consisting of physical and simulated components, data logs are generated and inspected in real-time. Storing full data logs would not only require much disk space, it would also require much effort to find special events and related system actions afterwards. Targeted on-line data extraction helps to instantly provide the data of interest. We present SystemXtract, a powerful specification language and tool for on-line data extraction, supporting origin-, value- and dynamic phase-based constrains on the data. The main contribution of this paper is to show how the language can be mapped to a graph-based processing architecture for executing data extraction as specified. Experiments show that the tool-induced overhead in computation time is insignificant and that the realtime execution of the hybrid prototype is not compromised, while the output is reduced to the interesting data. Copyright &copy; 2015 ICST.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {SIMUTOOLS 2015 - 8th EAI International Conference on Simulation Tools and Techniques},
  key       = {Data mining},
  keywords  = {Computational linguistics;Computer architecture;DSL;Extraction;Graphic methods;Information retrieval;Specification languages;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.4108/eai.24-8-2015.2260916},
}

@InProceedings{20151400701855,
  author    = {Yue, Jianan},
  title     = {Transition from EBNF to Xtext},
  year      = {2014},
  volume    = {1258},
  pages     = {75 - 80},
  address   = {Valencia, Spain},
  note      = {Domain specific languages;EBNF;Enabling tools;Fully automated;Meta model;Transformation;Transformation rules;Xtext;},
  abstract  = {Xtext is a framework for developing programming languages and domain specific languages (DSLs). Xtext contains a language in- frastructure including parsers, compiler and interpreter. In recent years, it has been applied to develop various DSLs. To benefit from Xtext, in certain cases, it is needed to transform an Extend Backus Naur Form (EBNF) based language to the Xtext grammar. For example, the well- known UML profile MARTE has a BNF-based Value Specification Lan- guage (VSL). It is needed to transform MARTE VSL in EBNF to a MARTE VSL Xtext grammar for the purpose of enabling tool integra- tion. In this paper, as the first step towards a fully automated trans- formation from EBNF to Xtext, a number of transformation rules are defined. The ultimate objective of the project is to provide developers a fully featured and customizable Eclipse-based IDE for developing DSLs using EBNF grammar or enabling tool integration by providing trans- formation from EBNF to Xtext.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {Computational linguistics},
  keywords  = {Computer programming languages;DSL;Problem oriented languages;},
  language  = {English},
}

@InProceedings{20162102413517,
  author    = {Cardoso, Bruno and Romao, Teresa},
  title     = {Avoiding "-too late! "-Expressing and Detecting Opportunity with EveWorks and EveXL},
  year      = {2015},
  pages     = {293 - 302},
  address   = {Brussels, Belgium},
  note      = {Context- awareness;Event detection;EveWorks;EveXL;Mobile application development;Time interval;},
  abstract  = {Adaptability is a desirable feature for context-aware applications to support the deployment of meaningful interactions on mobile devices. As such, flexible enough architectures are necessary to provide direct answers to applications requiring changes in their reactive behavior at runtime. To address this challenge, we present EveWorks, an Android application running on mobile devices, offering context-aware reactive services to other applications. Contrary to the norm found on the literature, EveWorks relies on definition of events of interest through expressions written in EveXL (EveWorks Expression Language), an original scripting language interpreted at runtime, thereby granting the desired adaptability to client context-aware applications. We evaluated the viability of EveWorks and EveXL and obtained evidence that EveXL is legible and straightforward, and is an adequate tool to express events. On the other hand, the results support EveWorks as a valid approach to facilitate development of reactive applications.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {13th International Conference on Advances in Mobile Computing and Multimedia, MoMM 2015 - Proceedings},
  key       = {Mobile devices},
  keywords  = {Computational linguistics;DSL;Mobile computing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2837126.2837139},
}


@article{20141617598357,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific languages for developing and deploying signature discovery workflows},
journal = {Computing in Science and Engineering},
author = {Jacob, Ferosh and Wynne, Adam and Liu, Yan and Gray, Jeff},
volume = {16},
number = {1},
year = {2014},
pages = {52 - 64},
issn = {15219615},
abstract = {Domain-agnostic signature discovery supports scientific investigation across domains through algorithm reuse. A new software tool defines two simple domain-specific languages that automate processes that support the reuse of existing algorithms in different workflow scenarios. The tool is demonstrated with a signature discovery workflow composed of services that wrap original scripts running high-performance computing tasks. &copy; 2014 IEEE.},
key = {Problem oriented languages},
keywords = {Algorithms;Automation;DSL;Natural sciences computing;},
note = {Automate process;Domain agnostics;Domain specific languages;High-performance computing;Scientific investigation;Signature discovery;Taverna;workflow;},
URL = {http://dx.doi.org/10.1109/MCSE.2013.97},
} 

@InProceedings{20144900295964,
  author    = {Louadah, Hassna and Champagne, Roger and Labiche, Yvan},
  title     = {Towards automating Interface Control Documents elaboration and management},
  year      = {2014},
  volume    = {1250},
  pages     = {26 - 33},
  address   = {Valencia, Spain},
  note      = {Avionic domains;Avionic systems;Federated architecture;Hardware and software;Integrated modular architectures;Integration process;Interface control documents;Production and consumption;},
  abstract  = {Avionic systems have been migrating from the legacy federated architecture towards an integrated modular architecture (IMA). The IMA architecture replaces the equipment principle by a set of interoperable components (hardware and software). The interoperability between the integrated components requires a detailed specification and description of their interfaces, which, in the avionic domain, is usually written in Interface Control Documents (ICD). However, ICD creation and usage during the integration process is challenging. In fact, the two main problems with the usage of ICDs are the lack of a commonly accepted language to define and use them on the one hand, and the lack of tool support in their production and consumption. In this paper, we present our approach and methodology to overcome these limitations.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {Embedded systems},
  keywords  = {Avionics;DSL;Interfaces (materials);Legacy systems;Models;},
  language  = {English},
}


@inproceedings{20132016334210,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {WikiWhirl: Wiki refactoring made easy},
journal = {WikiSym 2012 Conference Proceedings - 8th Annual International Symposium on Wikis and Open Collaboration},
author = {Puente, Gorka and Diaz, Oscar},
year = {2012},
pages = {Wikimedia Foundation; National Science Foundation; Google; Ars Electronic Center - },
address = {Linz, Austria},
abstract = {Wikis' organic growth inevitably leads to wiki degradation and the need for regular wiki refactoring. So far, wiki refactoring is a manual, time-consuming and error-prone activity since refactoring is conducted at the same level that editing: the article. This results in no performant wikis and the frequent abandon of wiki projects. We argue that refactoring requires a broader view of the wiki structure, where the impact of splitting, moving or merging extends beyond a single article. This demo shows WikiWhirl, a tool that visualizes and manipulates wikis via mind maps. Built on top of FreeMind, WikiWhirl (i) imports a wiki from MediaWiki, (ii) displays its structure as a mind map, (iii) supports refactoring operators as mind map node manipulation, and finally, (iv) saves those changes back to the wiki ensuring authorship and readership. &copy; 2012 Authors.},
key = {Websites},
keywords = {DSL;Schematic diagrams;},
note = {End users;Error prones;MediaWiki;Mind maps;Organic growth;Refactorings;wiki;},
URL = {http://dx.doi.org/10.1145/2462932.2462981},
} 

@InProceedings{20160101760933,
  author    = {Vieira, Nuno and Simoes, Alberto and Carvalho, Nuno Ramos},
  title     = {SplineAPI: A REST API for NLP services},
  year      = {2015},
  volume    = {563},
  pages     = {205 - 215},
  address   = {Madrid, Spain},
  note      = {Architectural solutions;Common operations;Dependency tracking;Modern applications;NAtural language processing;Programming interface;REST API;Third party application (Apps);},
  abstract  = {Modern applications often use Natural Language Processing (NLP) techniques and algorithms to provide sets of rich features. Researchers, who come up with these algorithms, often implement them for case studies, evaluation or as proof of concepts. These implementations are, in most cases, freely available for download and use. Nevertheless, these implementations do not comprise final software packages, with extensive installation instructions and detailed usage guides. Most lack a proper installation mechanism and library dependency tracking. The programming interfaces are, usually, limited to their usage through command line, or with just a few programming languages support. To overcome these shortcomings, this work aims to develop a new web platform to make available a set of common operations to third party applications that can be used to quickly access NLP based processes. Of course this platform still relies on the same tools mentioned before, as a base support to specific requests. Nevertheless, the end user will not need to install and learn their specific Application Programming Interfaces (API). For this to be possible, the architectural solution is to implement a RESTful API that hides all the tool details in a simple API that is common or, at least, coherent, across the different tools. &copy; Springer International Publishing Switzerland 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {18650929},
  journal   = {Communications in Computer and Information Science},
  key       = {Application programming interfaces (API)},
  keywords  = {Algorithms;Computational linguistics;Computer systems programming;DSL;Natural language processing systems;Slate;Web services;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-27653-3_20},
}

@InProceedings{20163302712423,
  author    = {Portugal, Ivens and Alencar, Paulo and Cowan, Donald},
  title     = {A Preliminary Survey on Domain-Specific Languages for Machine Learning in Big Data},
  year      = {2016},
  pages     = {108 - 110},
  address   = {Beer Sheva, Israel},
  note      = {Domain specific languages;Literature survey;Traditional approaches;},
  abstract  = {The proliferation of data often called Big Data has created problems with traditional approaches to data capture, storage, analysis and visualization, thus opening up new areas of research. Machine Learning algorithms are one area that has been used in Big Data for analysis. However, because of the challenges Big Data imposes, these algorithms need to be adapted and optimized to specific applications. One important decision made by software engineers is the choice of the language that is used in the implementation of these algorithms. This literature survey identifies and describes domain-specific languages and frameworks used for Machine Learning in Big Data with the intention of assisting software engineers in making more informed choices and providing beginners with an overview of the main languages used in this domain. This is the first survey that aims at better understanding how domain-specific languages for Machine Learning are used as a tool for research in Big Data. &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings - 2016 IEEE International Conference on Software Science, Technology and Engineering, SwSTE 2016},
  key       = {Big data},
  keywords  = {Artificial intelligence;Computational linguistics;Computer programming languages;Data visualization;Digital storage;DSL;Learning algorithms;Learning systems;Problem oriented languages;Surveys;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SWSTE.2016.23},
}

@Article{20144300123833,
  author    = {Erdweg, Sebastian and Fehrenbach, Stefan and Ostermann, Klaus},
  title     = {Evolution of software systems with extensible languages and DSLs},
  journal   = {IEEE Software},
  year      = {2014},
  volume    = {31},
  number    = {5},
  pages     = {68 - 75},
  note      = {Domain specific languages;Java;Language embedding;Legacy applications;Software Evolution;Software systems;SugarJ;},
  abstract  = {Domain-specific languages (DSLs) provide various advantages regarding the maintainability of software systems. Unfortunately, existing software systems don't exploit DSLs and their maintenance benefits. Based on the extensible programming language SugarJ, the authors present a process for gradually integrating DSLs into existing software systems, report on their experience in integrating three DSLs into two existing software systems, and outline a roadmap for the development of tool support for the integration of DSLs. &copy; 2014 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {07407459},
  key       = {Computer software maintenance},
  keywords  = {Application programs;Computer systems programming;DSL;Embedded systems;Java programming language;Legacy systems;Maintainability;Mathematical programming;Problem oriented languages;Software engineering;Syntactics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/MS.2014.99},
}


@inproceedings{20123315335654,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Wiki Scaffolding: Aligning wikis with the corporate strategy},
journal = {Information Systems},
author = {Diaz, Oscar and Puente, Gorka},
volume = {37},
number = {8},
year = {2012},
pages = {737 - 752},
issn = {03064379},
abstract = {Wikis are main exponents of collaborative development by user communities. This community may be created around the wiki itself (e.g., community of contributors in Wikipedia) or already exist (e.g., company employees in corporate wikis). In the latter case, the wiki is not created in a vacuum but as part of the information ecosystem of the hosting organization. As any other Information System resource, wiki success highly depends on the interplay of technology, work practice and the organization. Thus, wiki contributions should be framed along the concerns already in use in the hosting organization in terms of glossaries, schedules, policies, organigrams and the like. The question is then, how can corporate strategies permeate wiki construction while preserving wiki openness and accessibility? We advocate for the use of "Wiki Scaffoldings", i.e., a wiki installation that is provided at the onset to mimic these corporate concerns: categories, users, templates, articles initialized with boilerplate text, are all introduced in the wiki before any contribution is made. To retain wikis' friendliness and engage layman participation, we propose scaffoldings to be described as mind maps. Mind maps are next "exported" as wiki installations. We show the feasibility of the approach introducing a Wiki Scaffolding Language (WSL). WSL is realized as a plugin for FreeMind, a popular tool for mind mapping. Finally, we validate the expressiveness of WSL in four case studies. WSL is available for download. &copy; 2012 Elsevier Ltd. All rights reserved.},
key = {Websites},
keywords = {DSL;Scaffolds;Schematic diagrams;},
note = {Collaborative development;Corporate strategies;FreeMind;Information ecosystems;Mind maps;Mind-mapping;Plug-ins;User communities;Wiki;Wikipedia;Work practices;},
URL = {http://dx.doi.org/10.1016/j.is.2012.05.002},
} 

@InProceedings{20122715207937,
  author    = {Zimmermann, Olaf and Miksovic, Christoph and Kuster, Jochen M.},
  title     = {Reference architecture, metamodel, and modeling principles for architectural knowledge management in information technology services},
  year      = {2012},
  volume    = {85},
  number    = {9},
  pages     = {2014 - 2033},
  note      = {Architectural decision;Architectural principles;Model-driven Engineering;SOA;Workflow;},
  abstract  = {Capturing and sharing design knowledge such as architectural decisions is becoming increasingly important in firms providing professional Information Technology (IT) services such as enterprise application development and strategic outsourcing. Methods, models, and tools supporting explicit knowledge management strategies have been proposed in recent years; however, several challenges remain unaddressed. In this paper, we extend our previous work to overcome these challenges and to satisfy the requirements of an additional user group, presales architects that are responsible for IT service solution proposals. In strategic outsourcing, such solution proposals require complex, contractually relevant design decisions concerning many different resources such as IT infrastructures, people, and real estate. To support both presales and project architects, we define a common reference architecture and a decision process-oriented metamodel. We also present a tool implementation of these concepts and discuss their application to outsourcing proposals and application development projects. Finally, we establish twelve decision modeling principles and practices that capture the practical experience gained and lessons learned during the application of our decision modeling concepts to both proposal development and architecture design work on projects. &copy; 2012 Elsevier Inc. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {01641212},
  journal   = {Journal of Systems and Software},
  key       = {Information technology},
  keywords  = {Architecture;DSL;Knowledge management;Outsourcing;Software architecture;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.jss.2012.05.003},
}

@InProceedings{20140117164420,
  author    = {Fehrenbach, Stefan and Erdweg, Sebastian and Ostermann, Klaus},
  title     = {Software evolution to domain-specific languages},
  year      = {2013},
  volume    = {8225 LNCS},
  pages     = {96 - 116},
  address   = {Indianapolis, IN, United states},
  note      = {Domain specific;Domain specific languages;High-level abstraction;Software Evolution;Software maintainability;Syntactic sugars;Tool support;Two-dimension;},
  abstract  = {Domain-specific languages (DSLs) can improve software maintainability due to less verbose syntax, avoidance of boilerplate code, more accurate static analysis, and domain-specific tool support. However, most existing applications cannot capitalise on these benefits because they were not designed to use DSLs, and rewriting large existing applications from scratch is infeasible. We propose a process for evolving existing software to use embedded DSLs based on modular definitions and applications of syntactic sugar as provided by the extensible programming language SugarJ. Our process is incremental along two dimensions: A developer can add support for another DSL as library, and a developer can refactor more code to use the syntax, static analysis, and tooling of a DSL. Importantly, the application remains executable at all times and no complete rewrite is necessary. We evaluate our process by incrementally evolving the Java Pet Store and a deliberately small part of the Eclipse IDE to use language support for field-accessors, JPQL, XML, and XML Schema. To help maintainers to locate Java code that would benefit from using DSLs, we developed a tool that analyses the definition of a DSL to derive patterns of Java code that could be represented with a high-level abstraction of the DSL instead. &copy; 2013 Springer International Publishing.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Static analysis},
  keywords  = {Application programs;Computer programming languages;Natural language processing systems;Problem oriented languages;Syntactics;Tools;XML;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-02654-1_6},
}

@InProceedings{20143318061918,
  author    = {Krikava, Filip and Collet, Philippe and France, Robert B.},
  title     = {Manipulating models using internal domain-specific languages},
  year      = {2014},
  pages     = {1612 - 1614},
  address   = {Gyeongju, Korea, Republic of},
  note      = {Domain specific languages;Eclipse modeling framework;Execution performance;Model consistency checking;Model transformation;Model-driven Engineering;Scala;Tool support;},
  abstract  = {In Model-Driven Engineering, a number of external Domain-Specific Languages (DSL) for model manipulation have been proposed. However, they require users to learn new languages that, together with their execution performance, usability and tool support limitations, can significantly contribute to accidental complexities. In this paper, we present an alternative approach based on internal DSLs in Scala for model consistency checking and model transformations for the Eclipse Modeling Framework. Copyright 2014 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the ACM Symposium on Applied Computing},
  key       = {Model checking},
  keywords  = {Mathematical models;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2554850.2555127},
}

@InProceedings{20125015800776,
  author    = {Niazi, Moazzam Fareed and Seceleanu, Tiberiu and Tenhunen, Hannu},
  title     = {Towards reuse-based development for the on-chip distributed SoC architecture},
  year      = {2012},
  pages     = {278 - 283},
  address   = {Izmir, Turkey},
  note      = {Design Methodology;In-buildings;Modeling tool;Multi core;On chips;Plug-ins;Reusable library;Segmented bus platform;SoC architecture;},
  abstract  = {The development of a reusable library of components for a multi-core segmented bus platform, the SegBus, is presented. The library is based on a plug-in that we develop and deploy within a modeling tool which eventually used by the SegBus DSL while developing applications targeting the SegBus platform. The steps required in building the library and embed it into a plug-in are discussed together with the certain use of it in our design methodology. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {07303157},
  journal   = {Proceedings - International Computer Software and Applications Conference},
  key       = {Microprocessor chips},
  keywords  = {Computer software;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/COMPSACW.2012.58},
}


@inproceedings{20162202445786,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Comparative analysis of workbenches to support DSMLs: Discussion with non-trivial model-driven development needs},
journal = {MODELSWARD 2016 - Proceedings of the 4th International Conference on Model-Driven Engineering and Software Development},
author = {Ribeiro, Andre and De Sousa, Luis and Da Silva, Alberto Rodrigues},
year = {2016},
pages = {323 - 330},
address = {Rome, Italy},
abstract = {The development and use of Domain Specific Languages emerged as a way to cope with complex problems using concepts closer to the problem domain. By leveraging the principles proposed by Model-Driven Development (MDD), like the separation of concerns and the use of model transformations, this approach became popular and caused the emergence of a variety of languages, known as Domain Specific Modeling Languages (DSMLs). Moreover, the use of DSMLs with graphical notations abstracts even more the problem domain, either by using extensions of UML or directly using metamodeling languages. The definition and use of DSMLs is only possible through specific tools, known as languages workbenches. This paper discusses the analysis and comparison of three of these tools (namely Papyrus, Enterprise Architect and Sirius) that were used to create the XIS-Mobile language, a non-trivial DSML defined as a UML profile for modeling mobile applications in a platform-independent way. These tools were evaluated considering a set of key criteria (namely learnability, usability, graphical completeness, validation support, transformation support, evolvability and interoperability) which show their suitability to develop non-trivial languages. &copy; Copyright 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
key = {Software design},
keywords = {Computational linguistics;Computer programming languages;Embedded systems;Graphical user interfaces;Markup languages;Modeling languages;Problem oriented languages;Specification languages;},
note = {Domain specific languages;Domain specific modeling languages;Enterprise architects;Model driven development;Model transformation;Modeling tool;Platform independent;Separation of concerns;},
} 

@Article{20155101693056,
  author    = {Kos, Toma and Mernik, Marjan and Kosar, Toma},
  title     = {Test automation of a measurement system using a domain-specific modelling language},
  journal   = {Journal of Systems and Software},
  year      = {2016},
  volume    = {111},
  pages     = {74 - 88},
  note      = {Acquisition process;Data acquisition system;Domain-Specific Modelling Languages;High level specification;High-level abstraction;Test Automation;Testing infrastructure;Usage experience;},
  abstract  = {The construction of domain-specific modelling languages (DSMLs) is only the first step within the needed toolchain. Models need to be maintained, modified or functional errors searched for. Therefore, tool support is vital for the DSML end-user's efficiency. This paper presents SeTT, a simple but very useful tool for DSML end-users, a testing framework integrated within a DSML Sequencer. This Sequencer, part of the DEWESoft data acquisition system, supports the development of model-based tests using a high-level abstraction. The tests are used during the whole data acquisition process and able to test different systems' parts. This paper shows how high-level specifications can be extended to describe a testing infrastructure for a specific DSML. In this manner, the Sequencer and SeTT were combined at the metamodel level. The contribution of the paper is to show that one can leverage on the DSML to build a testing framework with relatively little effort, by implementing assertions to it. &copy; 2015 Elsevier Inc. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {01641212},
  key       = {Modeling languages},
  keywords  = {Computational linguistics;Data acquisition;Model checking;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.jss.2015.09.002},
}


@inproceedings{20155101699085,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {On lightweight metamodel extension to support modeling tools agility},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Bruneliere, Hugo and Garcia, Jokin and Desfray, Philippe and Khelladi, Djamel Eddine and Hebig, Regina and Bendraou, Reda and Cabot, Jordi},
volume = {9153},
year = {2015},
pages = {62 - 74},
issn = {03029743},
address = {L???Aquila, Italy},
abstract = {Modeling in real industrial projects implies dealing with different models, metamodels and supporting tools. They continuously have to be adapted to changing requirements, involving (often costly) problems in terms of traceability, coherence or interoperability. To this intent, solutions ensuring a better adaptability and flexibility of modeling tools are needed. As metamodels are cornerstones in such tools, metamodel extension capabilities are fundamental. However, current modeling frameworks are not flexible or dynamic enough. Thus, following the ongoing OMG MOF Extension Facility (MEF) RFP, this paper proposes a generic lightweight metamodel extension mechanism developed as part of the MoNoGe collaborative project. A base list of metamodel extension operators as well as a DSL for easily using them are introduced. Two different implementations of this extension mechanism (including a model-level support when (un)applying metamodel extensions) are also described, respectively based on Eclipse/EMF and the Modelio modeling environment. &copy; Springer International Publishing Switzerland 2015.},
key = {Application programs},
keywords = {Artificial intelligence;Computers;},
note = {Adaptability;Collaborative projects;Extension capabilities;Extension mechanisms;Flexibility;Meta model;Modeling environments;Modeling tool;},
URL = {http://dx.doi.org/10.1007/978-3-319-21151-0_5},
} 

@InProceedings{20142517846161,
  author    = {Pfister, Francois and Huchard, Marianne and Nebut, Clementine},
  title     = {A framework for concurrent design of metamodels and diagrams towards an agile method for the synthesis of domain specific graphical modeling languages},
  year      = {2014},
  volume    = {2},
  pages     = {298 - 306},
  address   = {Lisbon, Portugal},
  note      = {Concrete syntax;Domain specific languages;Graphical Syntax;Model driven architectures;Modeling formalisms;},
  abstract  = {DSML (Domain Specific Modeling Languages) are an alternative to general purpose modeling languages (e.g. UML or SysML) for describing models with concepts and relations specific to a domain. DSML design is often based on Ecore metamodels, which follow the class-relation paradigm and also require defining a concrete syntax which can be either graphical or textual. In this paper, we focus on graphical concrete syntax, and we introduce an approach and a tool (Diagraph) to assist the design of a graphical DSML. The main principles are: non-intrusive annotations of the metamodel to identify nodes, edges, nesting structures and other graphical information; immediate validation of metamodels by immediate generation of an EMF-GMF instance editor supporting multi-diagramming. We report a comparison experience between Diagraph and Obeo Designer (a commercial proprietary tool), which was conducted as part of a Model Driven Engineering Course. Copyright &copy; 2014 SCITEPRESS - Science and Technology Publications.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {ICEIS 2014 - Proceedings of the 16th International Conference on Enterprise Information Systems},
  key       = {Visual languages},
  keywords  = {Computer programming languages;Design;Embedded systems;Information systems;Syntactics;},
  language  = {English},
}

@InProceedings{20163102662324,
  author    = {ivkovi, Srdan and Karagiannis, Dimitris},
  title     = {Mixins and extenders for modular metamodel customisation},
  year      = {2016},
  volume    = {1},
  pages     = {259 - 270},
  address   = {Rome, Italy},
  note      = {Customisation;Development technique;Domain-Specific Modelling Languages;Enterprise modelling;Language engineering;Meta model;Meta-modelling;Overall efficiency;},
  abstract  = {Metamodelling is a practical yet rigorous formalism for modelling language definition with a metamodel being its pivotal engineering artifact. A multitude of domain-specific modelling languages (DSML) are engineered to cover various modelling domains. Metamodels of such languages evolve over time by introducing changes and extensions and are further customised to suite project-specific needs. While majority of DSML development techniques provide concepts for creating metamodels from scratch, composition concepts for metamodel customisation beyond class inheritance are sought towards more flexibility and reuse. In this paper, we introduce a modular approach for metamodel customisation based on the idea of mixins and extenders. While mixins allow for defining self-contained metamodel modules for reuse, extenders enable non-intrusive composition of such reusable modules on top of existing metamodels. We show how this approach can be applied in a metamodelling tool such as ADOxx and demonstrate its usefulness by customising the BPMN language. The benefit of the modular metamodel customisation is twofold. On the language engineering level, our approach significantly promotes reuse, flexibility and overall efficiency in language definition and customisation. On the modelling level, the approach leverages engineering flexibility to provide custom modelling languages that better suits enterprise modelling needs. ISBN: 978-989-758-187-8 Copyright &copy; 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ICEIS 2016 - Proceedings of the 18th International Conference on Enterprise Information Systems},
  key       = {Modeling languages},
  keywords  = {Computational linguistics;Enterprise resource planning;Information systems;},
  language  = {English},
}

@InProceedings{20134116837217,
  author    = {Izquierdo, Javier Luis Canovas and Cabot, Jordi and Lopez-Fernandez, Jesus J. and Cuadrado, Jesus Sanchez and Guerra, Esther and De Lara, Juan},
  title     = {Engaging end-users in the collaborative development of domain-specific modelling languages},
  year      = {2013},
  volume    = {8091 LNCS},
  pages     = {101 - 110},
  address   = {Alcudia, Mallorca, Spain},
  note      = {Collaborative construction;Collaborative development;Cooperative engineerings;Domain specific languages;Domain-Specific Modelling Languages;Language development;Language engineering;Model-driven Engineering;},
  abstract  = {Domain-Specific Modelling Languages (DSMLs) are high-level languages specially designed to perform tasks in a particular domain. When developing DSMLs, the participation of end-users is normally limited to providing domain knowledge and testing the resulting language prototypes. Language developers, which are perhaps not domain experts, are therefore in control of the language development and evolution. This may cause misinterpretations which hamper the development process and the quality of the DSML. Thus, it would be beneficial to promote a more active participation of end-users in the development process of DSMLs. While current DSML workbenches are mono-user and designed for technical experts, we present a process and tool support for the example-driven, collaborative construction of DSMLs in order to engage end-users in the creation of their own languages. &copy; 2013 Springer-Verlag Berlin Heidelberg.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Visualization},
  keywords  = {Computer programming languages;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-40840-3-16},
}


@inproceedings{20140517250456,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {On the way of bottom-up designing textual domain-specific modelling languages},
journal = {DSM 2013 - Proceedings of the 2013 ACM Workshop on Domain-Specific Modeling},
author = {Roth, Bastian and Jahn, Matthias and Jablonski, Stefan},
year = {2013},
pages = {51 - 55},
address = {Indianapolis, IN, United states},
abstract = {The development of domain-specific modelling languages (DSMLs) is not a trivial task. During recent years, a new approach has arisen which enables users to sketch example models that are used as basis for deriving an appropriate DSML. Until now, this bottom-up approach is merely applied to graphical DSMLs. However, the field of textual DSMLs is also very large and we believe that it can benefit from the bottom-up method as well. To really support users during this method it is necessary to equip them with an intuitively utilizable tool. In case of textual DSMLs, this needs to be an editor that allows for entering free text. Hence, in this paper we present the requirements for such an editor and how a basic solution may look like. Finally, we state some further challenges that need to be solved to achieve full support for developing textual DSMLs the bottom-up way. Copyright &copy; 2013 ACM.},
key = {Problem oriented languages},
note = {Basic solutions;Bottom up approach;Bottom up methods;Demonstration-based approach;Domain specific languages;Domain-Specific Modelling Languages;Free texts;New approaches;},
URL = {http://dx.doi.org/10.1145/2541928.2541938},
} 

@Article{20130616005382,
  author    = {Mtibaa, Sabri and Tagina, Moncef},
  title     = {A combined Petri nets and model-driven engineering for requirements specification approach for Service-Based Applications analysis},
  journal   = {International Review on Computers and Software},
  year      = {2012},
  volume    = {7},
  number    = {5},
  pages     = {2131 - 2138},
  note      = {Automatic verification;Business Process;Domain specific languages;Functional requirement;Model validity;Model-driven Engineering;Modeling phasis;Non-functional;Non-functional requirements;Overall quality;Prototype tools;Requirements specifications;Service-based;SOA;Workflow;},
  abstract  = {With the emergence of technologies such as workflow and web services supported by Service Oriented Architecture (SOA), blending of services provided by organizations become more and more instrumental. Organisations exert great efforts to not only fulfill functional requirements of their business processes but also satisfy their non-functional conditions by producing good overall Quality of Service (QoS). The purpose of this paper is to present an approach to accomplish verification in the early modeling phases of a Service-Based Application. This approach will allow verifying some userdefined Non-Functional Requirements (NFRs) easier. This work introduces our proposed prototype tool for NFRs specification using domain specific language. It ensures automatic verification chain for applications models based on Petri nets. Thanks to this chain, designers can check model validity without any prerequisite knowledge on how it actually was accomplished. &copy; 2012 Praise Worthy Prize S.r.l. - All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {18286003},
  key       = {Specifications},
  keywords  = {Blending;Information services;Petri nets;Quality of service;Service oriented architecture (SOA);Verification;Web services;},
  language  = {English},
}


@inproceedings{20153401198809,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Certified synthesis of efficient batch verifiers},
journal = {Proceedings of the Computer Security Foundations Workshop},
author = {Akinyele, Joseph A. and Barthe, Gilles and Gregoire, Benjamin and Schmidt, Benedikt and Strub, Pierre-Yves},
volume = {2014-January},
year = {2014},
pages = {153 - 165},
issn = {10636900},
address = {Vienna, Austria},
abstract = {Many algorithms admit very efficient batch versions that compute simultaneously the output of the algorithms on a set of inputs. Batch algorithms are widely used in cryptography, especially in the setting of pairing-based computations, where they deliver significant speed-ups. Auto Batch is an automated tool that computes highly optimized batch verification algorithms for pairing-based signature schemes. Thanks to finely tuned heuristics, Auto Batch is able to rediscover efficient batch verifiers for several signature schemes of interest, and in some cases to output batch verifiers that outperform the best known verifiers from the literature. However, Auto Batch only provides weak guarantees (in the form of a LaTeX proof) of the correctness of the batch algorithms it outputs. In this paper, we verify the correctness and security of these algorithms using the Easy Crypt framework. To achieve this goal, we define a domain-specific language to describe verification algorithms based on pairings and provide an efficient algorithm for checking (approximate) observational equivalence between expressions of this language. By translating the output of Auto Batch to this language and applying our verification procedure, we obtain machine-checked correctness proofs of the batch verifiers. Moreover, we formalize notions of security for batch verifiers and we provide a generic proof in Easy Crypt that batch verifiers satisfy a security property called screening, provided they are correct and the original signature is unforgeable against chosen-message attacks. We apply our techniques to several well-known pairing-based signature schemes from the literature, and to Groth-Sahai zero-knowledge proofs. &copy; 2014 IEEE.},
key = {Algorithms},
keywords = {Authentication;Computational linguistics;Computer programming languages;Cryptography;Problem oriented languages;Security of data;Security systems;},
note = {Certified proofs;Chosen message attacks;Domain specific languages;Observational equivalences;Security properties;Signature Scheme;Verification algorithms;Zero knowledge proof;},
URL = {http://dx.doi.org/10.1109/CSF.2014.19},
} 

@InProceedings{20151800807303,
  author    = {Ciraci, Selim and Fuller, Jason C. and Daily, Jeff and Makhmalbaf, Atefe and Callahan, David},
  title     = {A runtime verification framework for control system simulation},
  year      = {2014},
  pages     = {75 - 84},
  address   = {Vasteras, Sweden},
  note      = {Complex software systems;Control system simulations;Domain specific languages;Run-time verification;simulation;Specification process;System implementation;Timed Automata;},
  abstract  = {In a standard workflow for the validation of a control system, the control system is implemented as an extension to a simulator. Such simulators are complex software systems, and engineers may unknowingly violate constraints a simulator places on extensions. As such, errors may be introduced in the implementation of either the control system or the simulator leading to invalid simulation results. This paper presents a novel runtime verification approach for verifying control system implementations within simulators. The major contribution of the approach is the two-tier specification process. In the first tier, engineers model constraints using a domain-specific language tailored to modeling a controller's response to changes in its input. The language is high-level and effectively hides the implementation details of the simulator, allowing engineers to specify design-level constraints independent of low-level simulator interfaces. In the second tier, simulator developers provide mapping rules for mapping design-level constraints to the implementation of the simulator. Using the rules, an automated tool transforms the design-level specifications into simulator-specific runtime verification specifications and generates monitoring code which is injected into the implementation of the simulator. During simulation, these monitors observe the input and output variables of the control system and report changes to the verifier. The verifier checks whether these changes follow the constraints of the control system. We describe application of this approach to the verification of the constraints of an HVAC control system implemented with the power grid simulator Grid LAB-D. &copy; 2014 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {07303157},
  journal   = {Proceedings - International Computer Software and Applications Conference},
  key       = {Electric power system control},
  keywords  = {Application programs;Climate control;Computational linguistics;Computer control;Computer programming languages;Computer software;Control systems;Engineers;High level languages;Mapping;Modeling languages;Problem oriented languages;Simulators;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/COMPSAC.2014.14},
}

@InProceedings{20153001068527,
  author    = {Pramudianto, Ferry and Indra, Indra Rusmita and Jarke, Mathias},
  title     = {Model driven development for internet of things application prototyping},
  year      = {2013},
  volume    = {2013-January},
  number    = {January},
  pages     = {703 - 708},
  address   = {Boston, MA, United states},
  note      = {Architectural views;Code Generation;Component;Domain model;Domain specific languages;European research project;Model driven development;Prototype development;},
  abstract  = {We present an architectural view for the Internet of Things prototype development that emphasizes the separation of domain modeling from technological implementations. Using the provided model driven tool, domain experts are able to construct domain models by composing virtual objects and link them to the specific technologies. Having them linked, a Java prototype code can be generated by the tool. The developers may extend it into full applications simply by interfacing with the virtual objects without dealing with the communication to specific sensors and actuators. Subsequently, participants involved in the European research projects evaluated the architecture and the model driven tool using a software walk-through technique. The result shows that, for rapid prototyping, the participants are in favor of a simple domain specific language than a complex modeling language such as UML. Copyright &copy; 2013 by Knowledge Systems Institute Graduate School.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {23259000},
  journal   = {Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE},
  key       = {Software prototyping},
  keywords  = {Architecture;Computational linguistics;Computer programming languages;Information services;Internet;Internet of things;Knowledge engineering;Modeling languages;Problem oriented languages;Query languages;Service oriented architecture (SOA);Software engineering;},
  language  = {English},
}


@inproceedings{20150900591185,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Cloud MF: Applying MDE to tame the complexity of managing multi-cloud applications},
journal = {Proceedings - 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing, UCC 2014},
author = {Ferry, Nicolas and Song, Hui and Rossini, Alessandro and Chauvel, Franck and Solberg, Arnor},
year = {2014},
pages = {269 - 277},
address = {London, United kingdom},
abstract = {The market of cloud computing encompasses an ever-growing number of cloud providers offering a multitude of infrastructure-as-a-service (IaaS) and platform-as-a-service (PaaS) solutions. The heterogeneity of these solutions hinders the proper exploitation of cloud computing since it prevents interoperability and promotes vendor lock-in, which increases the complexity of executing and managing multi-cloud applications (i.e., Applications that can be deployed across multiple cloud infrastructures and platforms). Providers of multi-cloud applications seek to exploit the peculiarities of each cloud solution and to combine the delivery models of IaaS and PaaS in order to optimise performance, availability, and cost. In this paper, we show how the Cloud Modelling Framework leverages upon model-driven engineering to tame this complexity by providing: (i) a tool-supported domain-specific language for specifying the provisioning and deployment of multi-cloud applications, and (ii) a models@run-time environment for enacting the provisioning, deployment, and adaptation of these applications. &copy; 2014 IEEE.},
key = {Platform as a Service (PaaS)},
keywords = {Cloud computing;Computer programming languages;Embedded systems;Infrastructure as a service (IaaS);Modeling languages;Problem oriented languages;},
note = {Cloud infrastructures;Cloud providers;Delivery models;Domain specific languages;Model-driven Engineering;Modelling framework;Multi-clouds;Runtime environments;},
URL = {http://dx.doi.org/10.1109/UCC.2014.36},
} 

@InProceedings{20164202915729,
  author    = {Oliveira, Bruno and Belo, Orlando},
  title     = {An ontology for describing ETL patterns behavior},
  year      = {2016},
  pages     = {102 - 109},
  address   = {Lisbon, Portugal},
  note      = {Conceptual model;Data warehousing systems;Domain specific languages;ETL patterns;ETL skeletons;PL4ETL;},
  abstract  = {The use of software patterns is a common practice in software design, providing reusable solutions for recurring problems. Patterns represent a general skeleton used to solve common problems, providing a way to share regular practices and reduce the resources needed for implementing software systems. Data warehousing populating processes are a very particular type of software used to migrate data from one or more data sources to a specific data schema used to support decision support activities. The quality of such processes should be guarantee. Otherwise, the final system will deal with data inconsistencies and errors, compromising its suitability to support strategic business decisions. To minimize such problems, we propose a pattern-oriented approach to support ETL lifecycle, from conceptual representation to its execution primitives using a specific commercial tool. An ontology-based meta model it was designed and used for describing patterns internal specification and providing the means to support and enable its configuration and instantiation using a domain specific language. Copyright &copy; 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {DATA 2016 - Proceedings of the 5th International Conference on Data Management Technologies and Applications},
  key       = {Problem solving},
  keywords  = {Computer programming languages;Computer software reusability;Data warehouses;Decision support systems;Information management;Modeling languages;Musculoskeletal system;Ontology;Problem oriented languages;Software design;Warehouses;},
  language  = {English},
}

@InProceedings{20122515123427,
  author    = {Trancon Y Widemann, Baltasar and Lepper, Markus},
  title     = {Paisley: Pattern matching a la Carte},
  year      = {2012},
  volume    = {7307 LNCS},
  pages     = {240 - 247},
  address   = {Prague, Czech republic},
  note      = {Automated data;Complex model;Data abstraction;Domain specific;Domain specific languages;General-purpose programming language;Library codes;Light weight;Non-determinism;Object oriented;Object-oriented features;Professional development;Semantic foundation;Standard practices;Structured model;},
  abstract  = {Professional development of software dealing with structured models requires more systematic approach and semantic foundations than standard practice in general-purpose programming languages affords. One remedy is to move to domain-specific environments. Here, instead, we present a tool for the implementation of pattern matching as fundamental means of automated data extraction from complex models in a general-purpose programming language. The interface is simple but, thanks to elaborate and rigorous design, is also light-weight, portable, non-invasive, type-safe, modular and extensible. It is compatible with object-oriented data abstraction and has full support for nondeterminism by backtracking. The tool comes as a library consisting of two levels: elementary pattern constructs (generic, highly reusable) and pattern bindings for particular data models (specific, fairly reusable, user-definable). Applications use the library code in a small number of idiomatic ways, making pattern-matching code declarative in style (yet retaining richer host-language semantics), easily writable, readable and maintainable. Library and idiom together form a tightly embedded domain-specific language; no extension of the host language is required. The current implementation is in Java, but assumes only standard object-oriented features, and can hence be ported to other mainstream languages. &copy; 2012 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Java programming language},
  keywords  = {COBOL (programming language);Object oriented programming;Pattern matching;Problem oriented languages;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-30476-7_16},
}

@InProceedings{20154501519576,
  author    = {Opila, J.},
  title     = {Prototyping of visualization styles of 3D scalar fields using POV-Ray rendering engine},
  year      = {2015},
  pages     = {312 - 317},
  address   = {Opatija, Croatia},
  note      = {Pov rays;Pseudo-particles;Scalar field visualizations;ScPovPlot3D;Visual data analysis;},
  abstract  = {There is a persistent quest for novel methods of visualization in order to get insight into complex phenomena in scientific domains as various as physics, biomedicine or economics. Research teams involved achieved excellent results, however some problems with elaboration of novel visualization styles connected with flexibility of the software used and quality of the final images still persist. In the paper results of inspection of four visualization styles of 3D static scalar field employing POVRay ray-tracing engine are discussed, i.e. equipotential surface method using direct implementation of isosurface{} object, cellular trilinear interpolation approach, application of texture and eventually pseudo-particles design. All styles presented have been tested for hybrid visualizations and compared concerning computing time, informativeness and general appearance. It is shown in the work that Scene Description Language (SDL), domain specific language implemented in POV-Ray is flexible enough to use it as a tool for fast prototyping of novel visualization techniques. Visualizations discussed in the paper were computed using selected components of API of ScPovPlot3D, i.e. templates written in the SDL language. &copy; 2015 MIPRO.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {2015 38th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2015 - Proceedings},
  key       = {Three dimensional computer graphics},
  keywords  = {Computational linguistics;Computer programming languages;Data visualization;Engines;High energy physics;Microelectronics;Problem oriented languages;Ray tracing;Rendering (computer graphics);Visualization;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/MIPRO.2015.7160285},
}

@InProceedings{20153101098934,
  author    = {Nordmann, Arne and Wrede, Sebastian and Steil, Jochen},
  title     = {Modeling of movement control architectures based on motion primitives using domain-specific languages},
  year      = {2015},
  volume    = {2015-June},
  number    = {June},
  pages     = {5032 - 5039},
  address   = {Seattle, WA, United states},
  note      = {Automatically generated;Building blockes;Control architecture;Domain specific languages;Flexible control;Model driven approach;Motion primitives;Movement control;},
  abstract  = {This paper introduces a model-driven approach for engineering complex movement control architectures based on motion primitives, which in recent years have been a central development towards adaptive and flexible control of complex and compliant robots. We consider rich motor skills realized through the composition of motion primitives as our domain. In this domain we analyze the control architectures of representative example systems to identify common abstractions. It turns out that the introduced notion of motion primitives implemented as dynamical systems with machine learning capabilities, provide the computational building block for a large class of such control architectures. Building on the identified concepts, we introduce domain-specific languages that allow the compact specification of movement control architectures based on motion primitives and their coordination respectively. Using a proper tool chain, we show how to employ this model-driven approach in a case study for the real world example of automatic laundry grasping with the KUKA LWR-IV, where executable source-code is automatically generated from the domain-specific language specification. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {10504729},
  journal   = {Proceedings - IEEE International Conference on Robotics and Automation},
  key       = {Robotics},
  keywords  = {Artificial intelligence;Computational linguistics;Computer programming languages;Dynamical systems;Graphical user interfaces;Learning systems;Modeling languages;Problem oriented languages;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICRA.2015.7139899},
}

@InProceedings{20150700530237,
  author    = {Widemann, Baltasar Trancon and Lepper, Markus},
  title     = {Paisley: A pattern matching library for arbitrary object models},
  year      = {2013},
  volume    = {P-215},
  pages     = {171 - 186},
  address   = {Aachen, Germany},
  note      = {Embedded domain specific languages;General-purpose programming language;Object oriented data;Object-oriented features;Professional development;Programming paradigms;Semantic foundation;Standard practices;},
  abstract  = {Professional development of software dealing with structured models requires more systematic approach and semantic foundation than standard practice in general-purpose programming languages affords. One remedy is to integrate techniques from other programming paradigms, as seamless as possible and without forcing programmers to leave their comfort zone. Here we present a tool for the implementation of pattern matching as fundamental means of automated data extraction from models of arbitrary shape and complexity in a general-purpose programming language. The interface is simple but, thanks to elaborate and rigorous design, is also light-weight, portable, non-invasive, type-safe, modular and extensible. It is compatible with object-oriented data abstraction and has full support for nondeterminism by backtracking. The tool comes as a library consisting of two levels: elementary pattern algebra (generic, highly reusable) and pattern bindings for particular data models (specific, fairly reusable, user-definable). Applications use the library code in a small number of idiomatic ways, making pattern-matching code declarative in style, easily writable, readable and maintainable. Library and idiom together form a tightly embedded domain-specific language; no extension of the host language is required. The current implementation is in Java, but assumes only standard object-oriented features, and can hence be ported to other mainstream languages. &copy; Gesellschaft f&uuml;r Informatik, Bonn 2013.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16175468},
  journal   = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
  key       = {Object oriented programming},
  keywords  = {COBOL (programming language);Computational linguistics;Computer programming languages;Java programming language;Pattern matching;Problem oriented languages;Semantics;Software engineering;},
  language  = {English},
}

@InProceedings{20161702284244,
  author    = {Mori, Jones Y. and Llanos, Carlos H. and Huebner, Michael},
  title     = {A framework to the design and programming of many-core focal-plane vision processors},
  year      = {2015},
  pages     = {193 - 198},
  address   = {Porto, Portugal},
  note      = {Communication structures;Domain specific languages;Embedded computing;Flexible processing;Focal plane image;Many-core architecture;Micro architectures;Real time;},
  abstract  = {The Focal-Plane Image Processing area aims to bring processing elements as near as possible to the pixels and to the camera's focal-plane. Most of the works reported in the literature uses only simple processing elements, in general analog ones, with few flexibility. With the technology advances, a new generation of Vision Processors is emerging. It is expected that multi/many-core systems will be integrated to the pixel sensors, offering several opportunities for parallelism exploration, resulting in high performance and flexible processing systems. The programmability is one of the main problems in this area, since most programmers are not able to create parallel algorithms and applications. In this work, we propose a methodology to the design and programming of many-core focal-plane vision processors. The application is described using a Domain Specific Language, from which the parallelism characteristics are extracted. Afterwards, a new abstract model is derived using techniques such as Program Slicing (PS) and Task-Graph Clustering (TGC). The abstract model is then transformed in a SystemC/TLM2.0 description, in order to allow for different timing accuracy simulations. The results of the simulations are used together with an ASIP design tool in order to determine both the microarchitecture of processing elements and the communication structure of the new system. Finally, from the model derived before, a new source code is generated and programmed into the new platform. In this context, the main concepts and ideas are described in this work, as well as some partial results. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings - IEEE/IFIP 13th International Conference on Embedded and Ubiquitous Computing, EUC 2015},
  key       = {Computer architecture},
  keywords  = {Computer programming;Computer programming languages;Computer vision;Embedded systems;Focusing;Image processing;Integrated circuit design;Parallel processing systems;Pixels;Problem oriented languages;Program processors;Ubiquitous computing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/EUC.2015.24},
}

@InProceedings{20144700219317,
  author    = {Van Gijzel, Bas and Nilsson, Henrik},
  title     = {Towards a framework for the implementation and verification of translations between argumentation models},
  year      = {2013},
  pages     = {93 - 103},
  address   = {Nijmegen, Netherlands},
  note      = {Abstract argumentation;Argumentation;Argumentation frameworks;Argumentation model;Argumentation theory;Domain specific languages;Functional programming technique;Haskell;},
  abstract  = {Argumentation theory is concerned with studying the nature of arguments in the most general sense, including for example scientific, legal, or even completely informal arguments. There are two main approaches. Abstract argumentation is completely generic, making no specific assumptions about the structure of arguments. Structured argumentation, on the other hand, does adopt a predetermined structure pertaining to the domain of discourse. Structured argumentation models have seen a recent surge, with new developments in both general frameworks and more domain-specific approaches. Yet, in contrast to the abstract approach, there is a distinct lack of implementations of structured argumentation models. We believe a key reason for this is the lack of suitable implementation frameworks. Building on previous work, this paper attempts to tackle this problem by applying functional programming techniques. We show how to implement one structured argumentation framework (Carneades) and one abstract framework (Dung) in this way, and then proceed to show how to implement a translation from the former into the latter, one of the first such implementations. Ultimately, we hope our work will evolve into a domain-specific language for implementation of argumentation frameworks. But even at this stage, the paper demonstrates the benefits of functional programming as a tool for argumentation theory.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Functional programming},
  keywords  = {Computer programming languages;Problem oriented languages;Problem solving;Translation (languages);},
  language  = {English},
}


@inproceedings{20161502208015,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {CRITiCAL: A Configuration Tool for Context Aware and mobiLe Applications},
journal = {Proceedings - International Computer Software and Applications Conference},
author = {De Sousa Duarte, Paulo Artur and Barreto, Felipe Mota and De Almada Gomes, Francisco Anderson and Viana De Carvalho, Windson and Trinta, Fernando Antonio Mota},
volume = {2},
year = {2015},
pages = {159 - 168},
issn = {07303157},
address = {Taichung, Taiwan},
abstract = {This paper presents an approach for modelling and generating Context-Aware and Mobile (CAM) applications based on (i) Model-Driven Engineering and (ii) context acquisition middleware concepts. Our approach allows software engineers to build CAM applications by modelling contextual information and rule-based behaviour on a visual notation. These graphical models are transformed into an Android-based code, targeted for a context-aware middleware called LoCCAM, which encapsulates device sensors access. An initial user evaluation conducted with a group of fourteen computer science volunteers was implemented and indicates time reduction gains in the middleware configuration process and that the complexity in the writing of contextual behaviour of applications is also decreased. &copy; 2015 IEEE.},
key = {Application programs},
keywords = {Android (operating system);Cams;Computer software;DSL;Middleware;},
note = {Android;Context acquisition;Context aware middleware;Context-Aware;Contextual information;Middleware configurations;Model-driven Engineering;Self adaptation;},
URL = {http://dx.doi.org/10.1109/COMPSAC.2015.91},
} 

@InProceedings{20161402189536,
  author    = {Catmore, James and Cranshaw, Jack and Gillam, Thomas and Gramstad, Eirik and Laycock, Paul and Ozturk, Nurcan and Stewart, Graeme Andrew},
  title     = {A new petabyte-scale data derivation framework for ATLAS},
  year      = {2015},
  volume    = {664},
  number    = {7},
  address   = {Okinawa, Japan},
  note      = {Analysis models;Computing resource;Domain specific languages;Event selection;Logical operations;Physics analysis;Reconstruction software;Tool requirements;},
  abstract  = {During the Long Shutdown of the LHC, the ATLAS collaboration overhauled its analysis model based on experience gained during Run 1. A significant component of the model is a "Derivation Framework" that takes the petabyte-scale AOD output from ATLAS reconstruction and produces samples, typically terabytes in size, targeted at specific analyses. The framework incorporates all of the functionality of the core reconstruction software, while producing outputs that are simply configured. Event selections are specified via a concise domain-specific language, including support for logical operations. The output content can be highly optimised to minimise disk requirements, while maintaining the same C++ interface. The framework includes an interface to the late-stage physics analysis tools, ensuring that the final outputs are consistent with tool requirements. Finally, the framework allows several outputs to be produced for the same input, providing the possibility to optimise configurations to computing resources. &copy; Published under licence by IOP Publishing Ltd.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {17426588},
  journal   = {Journal of Physics: Conference Series},
  key       = {High energy physics},
  keywords  = {C++ (programming language);Computer programming languages;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1088/1742-6596/664/7/072007},
}


@inproceedings{20160501856929,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {3rd International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2015},
journal = {Communications in Computer and Information Science},
volume = {580},
year = {2015},
pages = {1 - 436},
issn = {18650929},
address = {Angers, France},
abstract = {The proceedings contain 25 papers. The special focus in this conference is on Modeling Languages, Tools and Architectures. The topics include: Realizing a conceptual framework to integrate model-driven engineering, software product line engineering, and software configuration management; composition of heterogeneous modeling languages; a model-driven approach for the generation of customizable model migrations; parallel application development using architecture view driven model transformations; runtime translation of model-level queries to persistence-level; integration of handwritten and generated object-oriented code; a framework for metamodel composition and adaptation with conformance-preserving model migration; a textual domain-specific language based on the UML testing profile; metamodel and model composition by integration of operational semantics; computability assurance for UML Template Binding; current limitations and proposed improvements; an approach to define and apply collaboration process patterns for software development; an ontology-based process editor for generating model mapping in tool integration; using model driven engineering to support multi-paradigms security analysis; designing safe and secure embedded and cyber-physical systems with sysML-sec; methodologies, processes and platforms architecture optimization with sysML modeling; capturing semantics to bridge the gap between complex data models and object models; the interface-modular method for global system behaviour specification; a textual domain-specific language based on the UML testing profile; metamodel and model composition by integration of operational semantics; an approach to define and apply collaboration process patterns for software development and an ontology-based process editor for generating model mapping in tool integration.},
} 

@Article{20124915756157,
  author    = {David, O. and Ascough, J.C. and Lloyd, W. and Green, T.R. and Rojas, K.W. and Leavesley, G.H. and Ahuja, L.R.},
  title     = {A software engineering perspective on environmental modeling framework design: The Object Modeling System},
  journal   = {Environmental Modelling and Software},
  year      = {2013},
  volume    = {39},
  pages     = {201 - 213},
  note      = {Code development;Code Generation;Component interaction;Component-based models;Computational scalability;Data transformation;Design goal;Domain specific languages;Engineering perspective;Environmental model;Environmental modeling;Environmental phenomena;Framework development;Functional units;High-performance computing;Implicit parallelisms;Model components;Model development;Modeling and simulation;Modeling process;Modeling tool;Multi-threading;Object modeling;Socio-economics;Software developer;Software frameworks;Spatial data;},
  abstract  = {The environmental modeling community has historically been concerned with the proliferation of models and the effort associated with collective model development tasks (e.g., code generation, data transformation, etc.). Environmental modeling frameworks (EMFs) have been developed to address this problem, but much work remains before EMFs are adopted as mainstream modeling tools. Environmental model development requires both scientific understanding of environmental phenomena and software developer proficiency. EMFs support the modeling process through streamlining model code development, allowing seamless access to data, and supporting data analysis and visualization. EMFs also support aggregation of model components into functional units, component interaction and communication, temporal-spatial stepping, scaling of spatial data, multi-threading/multi-processor support, and cross-language interoperability. Some EMFs additionally focus on high-performance computing and are tailored for particular modeling domains such as ecosystem, socio-economic, or climate change research. The Object Modeling System Version 3 (OMS3) EMF employs new advances in software framework design to better support the environmental model development process. This paper discusses key EMF design goals/constraints and addresses software engineering aspects that have made OMS3 framework development efficacious and its application practical, as demonstrated by leveraging software engineering efforts outside of the modeling community and lessons learned from over a decade of EMF development. Software engineering approaches employed in OMS3 are highlighted including a non-invasive lightweight framework design supporting component-based model development, use of implicit parallelism in system design, use of domain specific language design patterns, and cloud-based support for computational scalability. The key advancements in EMF design presented herein may be applicable and beneficial for other EMF developers seeking to better support environmental model development through improved framework design. &copy; 2012 Elsevier Ltd.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {13648152},
  key       = {Software engineering},
  keywords  = {Climate change;Computer programming;Computer simulation;Computer software selection and evaluation;Data visualization;Java programming language;Software design;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.envsoft.2012.03.006},
}

@InProceedings{20155201714503,
  author    = {Foster, Nate and Kozen, Dexter and Milano, Matthew and Silva, Alexandra and Thompson, Laure},
  title     = {A coalgebraic decision procedure for NetKAT},
  year      = {2015},
  volume    = {50},
  number    = {1},
  pages     = {343 - 355},
  note      = {Automata;Coalgebras;Domain specific languages;Implementation and optimization;Kleene algebra with tests;NetKAT;Soundness and completeness;Translation validation;},
  abstract  = {NetKAT is a domain-specific language and logic for specifying and verifying network packet-processing functions. It consists of Kleene algebra with tests (KAT) augmented with primitives for testing and modifying packet headers and encoding network topologies. Previous work developed the design of the language and its standard semantics, proved the soundness and completeness of the logic, defined a PSPACE algorithm for deciding equivalence, and presented several practical applications. This paper develops the coalgebraic theory of NetKAT, including a specialized version of the Brzozowski derivative, and presents a new efficient algorithm for deciding the equational theory using bisimulation. The coalgebraic structure admits an efficient sparse representation that results in a significant reduction in the size of the state space. We discuss the details of our implementation and optimizations that exploit NetKAT's equational axioms and coalgebraic structure to yield significantly improved performance. We present results from experiments demonstrating that our tool is competitive with state-of-the-art tools on several benchmarks including allpairs connectivity, loop-freedom, and translation validation. Copyright &copy; 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {15232867},
  journal   = {ACM SIGPLAN Notices},
  key       = {Optimization},
  keywords  = {Algebra;Algorithms;Computational linguistics;Computer programming languages;Packet networks;Problem oriented languages;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/10.1145/2676726.2677011},
}

@InProceedings{20155201716418,
  author    = {Kyle, David and Hansen, Jeffery and Chaki, Sagar},
  title     = {Statistical model checking of distributed adaptive real-time software},
  year      = {2015},
  volume    = {9333},
  pages     = {269 - 274},
  address   = {Vienna, Austria},
  note      = {Cyber physicals;Domain specific languages;Execution environments;Multirobots;Real-time software;Statistical model checking;Uncertain environments;Virtual machines;},
  abstract  = {The problem of estimating quantitative properties of distributed cyber-physical software that coordinate and adapt to uncertain environments is addressed. A domain-specific language, called dmpl, is developed to both describe such a system and a target property. Statistical model checking (SMC) is used to estimate the probability with which the property holds on the system. A distributed SMC tool is developed and described. Virtual machines are used to implement a realistic execution environment, and to isolate simulations from one another. Experimental results on a coordinated multi-robot example are presented. &copy; Springer International Publishing Switzerland 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Model checking},
  keywords  = {Computer programming languages;Problem oriented languages;Virtual reality;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-23820-3_17},
}

@InProceedings{20121514934007,
  author    = {Ubayashi, Naoyasu and Kamei, Yasutaka},
  title     = {An extensible aspect-oriented modeling environment for constructing domain-specific languages},
  year      = {2012},
  volume    = {E95-D},
  number    = {4},
  pages     = {942 - 958},
  note      = {Access protocols;Aspect oriented modeling;Domain specific languages;Extensible weaver;Meta model;Model weaving;Modeling construct;Structural reflection;Support tool;Tool support;},
  abstract  = {AspectM, an aspect oriented modeling (AOM) language, provides not only basic modeling constructs but also an extension mechanism called metamodel access protocol (MMAP) that allows a modeler to modify the metamodel. MMAP consists of metamodel extension points, extension operations, and primitive predicates for navigating the metamodel. Although the notion of MMAP is useful, it needs tool support. This paper proposes a method for implementing a MMAP based AspectM support tool. It consists of model editor, model weaver, and model verifier. We introduce the notion of edit-time structural reflection and extensible model weaving. Using these mechanisms, a modeler can easily construct domain-specific languages (DSLs). We show a case study using the AspectM support tool and discuss the effectiveness of the extension mechanism provided by MMAP. As a case study, we show a UML based DSL for describing the external contexts of embedded systems. Copyright &copy; 2012 The Institute of Electronics, Information and Communication Engineers.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {09168532},
  journal   = {IEICE Transactions on Information and Systems},
  key       = {Problem oriented languages},
  keywords  = {DSL;Information science;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1587/transinf.E95.D.942},
}

@InProceedings{20142817913737,
  author    = {Barthou, Denis and Brand-Foissac, Olivier and Pene, Olivier and Grosdidier, Gilbert and Dolbeau, Romain and Eisenbeis, Christina and Kruse, Michael and Petrov, Konstantin and Tadonki, Claude},
  title     = {Automated code generation for Lattice Quantum Chromodynamics and beyond},
  year      = {2014},
  volume    = {510},
  number    = {1},
  pages     = {DCOMP/APS; Department of Physical Sciences of Russian Academy of Sciences; EPS; IUPAP; RSC Group Company; Russian Foundation for Basic Research -},
  address   = {Moscow, Russia},
  note      = {Automated code generation;C codes;Domain specific languages;Implementation and optimization;Lattice quantum chromodynamics;Monte-Carlo simulations;Simulation software;},
  abstract  = {We present here our ongoing work on a Domain Specific Language which aims to simplify Monte-Carlo simulations and measurements in the domain of Lattice Quantum Chromodynamics. The tool-chain, called Qiral, is used to produce high-performance OpenMP C code from LaTeX sources. We discuss conceptual issues and details of implementation and optimization. The comparison of the performance of the generated code to the well-established simulation software is also made. &copy; Published under licence by IOP Publishing Ltd.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {17426588},
  journal   = {Journal of Physics: Conference Series},
  key       = {C (programming language)},
  keywords  = {Application programming interfaces (API);Computer programming languages;Computer software;Intelligent systems;Quantum theory;},
  language  = {English},
  url       = {http://dx.doi.org/10.1088/1742-6596/510/1/012005},
}

@InProceedings{20162202445762,
  author    = {Gamboa, Miguel Andres and Syriani, Eugene},
  title     = {Automating activities in MDE tools},
  year      = {2016},
  pages     = {123 - 133},
  address   = {Rome, Italy},
  note      = {Domain specific modeling;Enactment;Fitts Law;Model transformation;Workflow;},
  abstract  = {Model-Driven Engineering (MDE) is a victim of its own success: being able to quickly generate software tools, many modeling tools exist today, but their usability is far from efficient. Complex processes and repetitive tasks are often required to perform a modeling activity, such as creating a domain-specific language or creating a domain-specific model. The goal of this paper is to increase the productivity of modelers in their every day activities by automating the tasks they perform in current MDE tools. We propose an MDE-based solution where the user defines a workflow that can be parametrized at run-time and executed. Our solution works for frameworks that support two level metamodeling as well as deep metamodeling. We implemented our solution in the MDE tool AToMPM.We also performed a preliminary empirical evaluation of our approach and showed that we reduce both mechanical and cognitive efforts of the user. &copy; Copyright 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {MODELSWARD 2016 - Proceedings of the 4th International Conference on Model-Driven Engineering and Software Development},
  key       = {Software design},
  keywords  = {Computer aided software engineering;Computer programming languages;Embedded systems;Modeling languages;Problem oriented languages;},
  language  = {English},
}

@InProceedings{20143718153648,
  author    = {Tyugu, Enn and Harf, Mait and Grigorenko, Pavel},
  title     = {A case study of combining compositional and object-oriented software development},
  year      = {2014},
  pages     = {201 - 208},
  address   = {Lisbon, Portugal},
  note      = {Design of softwares;Domain specific languages;Domain specific modeling;General purpose software;Model-Driven Software Development;Object oriented software development;Software Specification;Structural synthesis;},
  abstract  = {We analyze an approach to software development where object-oriented and compositional software specifications are written in separate languages and are only loosely connected. It supports compositional design of software in a domain-specific language and automatic model-driven construction of code from classes written in Java. We justify our approach by giving examples of development of large simulation programs and services on large models. We present also an example of using our method in general purpose software development - this is bootstrapping the essential part of a software tool CoCoViLa, i.e. synthesizing CoCoViLa in CoCoViLa itself. Copyright &copy; 2014 SCITEPRESS - Science and Technology Publications. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {MODELSWARD 2014 - Proceedings of the 2nd International Conference on Model-Driven Engineering and Software Development},
  key       = {Software design},
  keywords  = {Computer aided software engineering;Computer software;Object oriented programming;Problem oriented languages;},
  language  = {English},
}

@InProceedings{20163002625913,
  title     = {ACM International Conference Proceeding Series},
  year      = {2016},
  volume    = {01-03-June-2016},
  address   = {Limerick, Ireland},
  abstract  = {The proceedings contain 44 papers. The topics discussed include: the impact of agile methods on the development of an agile culture - research proposal: the agile evolution; remedying knowledge loss in FLOSS (free/ libre open source software); integrating evidence from systematic reviews with software engineering practice through evidence briefings; personalised technical support for text-based interactions: a validation study; results from an ethnographically-informed study in the context of test driven development; the jinx on the NASA software defect data sets; benefits and limitations of job rotation in software organizations: a systematic literature review; evidence-based software portfolio management: a tool description and evaluation; a review-based comparative study of bad smell detection tools; do more inspectors guarantee higher accuracy of the capture-recapture estimates? an empirical study; an integrated tool environment for experimentation in domain specific language engineering; beyond the spreadsheet: reflections on tool support for literature studies; improving vulnerability detection measurement: test suites and software security assurance; what we have learnt adopting evidence-based software engineering for industrial practice; and an exploratory study on the effects of perceived value and stakeholder satisfaction on software projects.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {ACM International Conference Proceeding Series},
  language  = {English},
}


@inproceedings{20124415628135,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Using VIRMANEL and SILUMOD to study protocol for mobile multihop networks},
journal = {Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks workshops},
author = {Benchaib, Yacine and Chaudet, Claude},
volume = {1},
year = {2012},
pages = {76 - 78},
issn = {21555486},
address = {Seoul, Korea, Republic of},
abstract = {In this demonstration, we show how to use a couple of tools we developed, VIRMANEL and SIMULOD, to study how the true implementation of an ad hoc routing protocol behaves under various mobility scenarios. VIRMANEL is a tool that configure virtual machines connections with respect to mobility. It features a GUI to observe the behavior of mobile nodes. SILUMOD is a domain-specific language that allows to describe mobility models. It defines the positions of the trajectory of moving through the appropriate keywords. These tools, published under the LGPL license, are used here to study the Linux implementation of OLSR. &copy; 2012 IEEE.},
key = {MESH networking},
keywords = {Computer operating systems;Problem oriented languages;Sensors;},
note = {Ad hoc routing protocol;Domain specific languages;Linux implementation;Mobile multihop networks;Mobile nodes;Mobility model;Virtual machines;},
URL = {http://dx.doi.org/10.1109/SECON.2012.6275847},
} 

@InProceedings{20154501499710,
  author    = {Klarl, Annabelle},
  title     = {From HELENA ensemble specifications to PROMELA verification models},
  year      = {2015},
  volume    = {9232},
  pages     = {39 - 45},
  address   = {Stellenbosch, South africa},
  note      = {Asynchronous communication;Code generators;Distributed systems;Domain specific languages;Goal-directed behavior;Model approach;Promela models;Verification model;},
  abstract  = {With Helena, we introduced a modeling approach for distributed systems where components dynamically collaborate in ensembles. Conceptually, components participate in a goal-oriented collaboration by adopting certain roles in the ensemble. To verify the goal-directed behavior of ensembles, we propose to systematically translate Helena specifications to Promela and verify them with the model-checker Spin. In this paper, we report on tool support for an automated transition from Helena to Promela. Relying on the Xtext workbench of Eclipse, we provide a code generator from the domain-specific-language Helena- Text to Promela. The generated Promela model simulates the two layers, components and their adopted roles from Helena, and allows dynamic role creation as well as asynchronous communication of roles. &copy; Springer International Publishing Switzerland 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Model checking},
  keywords  = {Computer programming languages;Graphical user interfaces;Problem oriented languages;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-23404-5_4},
}

@InProceedings{20143418090621,
  author    = {Kuraj, Ivan and Kuncak, Viktor},
  title     = {SciFe: Scala framework for efficient enumeration of data structures with invariants},
  year      = {2014},
  pages     = {45 - 49},
  address   = {Uppsala, Sweden},
  note      = {Embedded Languages;Enumeration;Exhaustive search;Memoisation;Meta Programming;Property-based testing;Scala;Test generations;},
  abstract  = {We introduce SciFe, a tool for automated generation of complex structures, suitable for tasks such as automated testing and synthesis. SciFe is capable of exhaustive, memoized enumeration of values from finite or infinite domains. SciFe is based on the concept of an enumerator, defined as an efficiently computable bijection between natural numbers and values from a given set. SciFe introduces higher-order enumerators which define enumerators that depend on additional parameters. SciFe also includes combinators that can construct more complex enumerators from existing ones while preserving exhaustiveness and efficiency. SciFe is a Scala library that implements a domain-specific language. This tool demo presents an overview of SciFe as well as its use to generate complex structures such as search trees and models of class hierarchies. Our experiments demonstrate better performance and shorter specifications when compared to existing approaches.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {SCALA 2014 - Proceedings of the 5th Annual Scala Workshop, Co-located with ECOOP 2014},
  key       = {Problem oriented languages},
  keywords  = {Object oriented programming;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2637647.2637655},
}

@InProceedings{20162202436882,
  author    = {Abrantes, Joilson and Coelho, Roberta},
  title     = {Specifying and dynamically monitoring the exception handling policy},
  year      = {2015},
  volume    = {2015-January},
  pages     = {370 - 374},
  address   = {Pittsburgh, PA, United states},
  note      = {Contract languages;Domain specific languages;Exception handling;Monitoring tools;Runtime Monitoring;Source codes;System architects;Web-based system;},
  abstract  = {The exception handling policy of a system comprises the set of design rules that specify its exception handling behavior (how exceptions should be handled and thrown). Such policy is usually undocumented and implicitly defined by the system architect. For this reason, developers may think that by just including catch-blocks in the code they can deal with exception conditions. This lack of information may turn the exception handling into a generalized "goto" mechanism making the program more complex and less reliable. This work proposes a domain-specific language called ECL (Exception Contract Language) to specify the exception handling policy and a runtime monitoring tool which dynamically checks this policy. The monitoring tool is implemented in the form of an aspect library, which can be added to any Java system without the need to change the application source code. We applied this approach to a large-scale web-based system and to a set of versions of the well-known JUnit framework. The results indicate that this approach can be used to express and to automatically check the exception handling policy of a system, and consequently support the development of more robust Java systems.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {23259000},
  journal   = {Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE},
  key       = {Java programming language},
  keywords  = {Computational linguistics;Computer programming languages;Dynamic analysis;Knowledge engineering;Monitoring;Problem oriented languages;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.18293/SEKE2015-133},
}


@inproceedings{20162202445725,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Verification of atomicity preservation in model-to-code transformations using generic Java code},
journal = {MODELSWARD 2016 - Proceedings of the 4th International Conference on Model-Driven Engineering and Software Development},
author = {Zhang, Dan and Bosnacki, Dragan and Van Den Brand, Mark and Huizing, Cornelis and Kuiper, Ruurd and Jacobs, Bart and Wijs, Anton},
year = {2016},
pages = {578 - 588},
address = {Rome, Italy},
abstract = {A challenging aspect of model-to-code transformations is to ensure that the semantic behavior of the input model is preserved in the output code. When constructing concurrent systems, this is mainly difficult due to the non-deterministic potential interaction between threads. In this paper, we consider this issue for a framework that implements a transformation chain from models expressed in the state machine based domain specific language SLCO to Java. In particular, we provide a fine-grained generic solution to preserve atomicity of SLCO statements in the Java implementation. We give its generic specification based on separation logic and verify it using the verification tool VeriFast. The solution can be regarded as a reusable module to safely implement atomic operations in concurrent systems. &copy; Copyright 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
key = {Software design},
keywords = {Codes (symbols);Computer circuits;Computer programming languages;Cosine transforms;Formal logic;Formal verification;Java programming language;Problem oriented languages;Reconfigurable hardware;Semantics;},
note = {Atomicity;Code Generation;Concurrency;Model transformation;Separation logic;},
} 

@InProceedings{20162702569598,
  author    = {Lezos, Christakis and Dimitroulakos, Grigoris and Latifis, Ioannis and Masselos, Konstantinos},
  title     = {Automatic generation of code analysis tools: The CastQL approach},
  year      = {2016},
  volume    = {12-March-2016},
  pages     = {Rathlin Project -},
  address   = {Barcelona, Spain},
  note      = {Automatic generation of codes;Benchmark applications;Compiler generators;Domain specific languages;General-purpose programming language;Internal representation;Software development process;Source code analysis;},
  abstract  = {Source code analysis and manipulation tools have become an essential part of software development processes. Automating the development of such tools can heavily reduce development time, effort and cost. This paper proposes a framework for the efficient development of code analysis software. A tool for automatically generating the front end of analysis tools for a given language grammar is proposed. The proposed approach can be applied to any language that can be described using the BNF notation. The proposed framework also provides a domain specific language to concisely express queries on the internal representation generated by the front end. This language tackles the problem of writing complex code in a general purpose programming language in order to retrieve information from the internal representation. The approach has been evaluated through two different realistic usage scenarios applied to a number of different benchmark applications. The front end generator has also been tested for twenty input grammars. In all cases the software generated by the proposed framework functions according to the input grammar while the development time has been reduced on average down to 12% compared to equivalent handwritten implementations. The experimental results give evidence that the use of the proposed framework can heavily reduce the relevant design effort and cost.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Automatic programming},
  keywords  = {Benchmarking;Codes (symbols);Computational linguistics;Computer programming languages;Cost reduction;Graphical user interfaces;Problem oriented languages;Query languages;Software design;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2889420.2889422},
}

@Article{20124915745025,
  author    = {Obrenovic, Nikola and Popovic, Aleksandar and Aleksic, Slavica and Lukovic, Ivan},
  title     = {Transformations of check constraint pim specifications},
  journal   = {Computing and Informatics},
  year      = {2012},
  volume    = {31},
  number    = {5},
  pages     = {1045 - 1079},
  note      = {Check constraint;Model driven architectures;Model to model transformation;Model-to-code transformation;Platform independent model;SQL/DDL generation;},
  abstract  = {Platform independent modeling of information systems and generation of their prototypes play an important role in software development process. However, not all tasks in this process have been covered yet, i.e. not all pieces of an information system can be designed using platform independent artifacts that are later transformable into the executable code. One of the examples is modeling of database check constraints, for which there is a lack of appropriate mechanisms to formally specify them on a platform independent level. In order to provide formal specification of check constraints at platform independent level, we developed a domain specific language and embedded it into a tool for platform independent design and automated prototyping of information systems, named Integrated Information Systems CASE (IIS*Case). In this paper, we present algorithms for transformation of check constraints specified at the platform independent level into the relational data model, and further transformation into the executable SQL/DDL code for several standard and commercial platforms: ANSI SQL-2003, Oracle 9i and 10g, and MS SQL Server 2000 and 2008. We have also implemented these algorithms in IIS*Case as a part of the process of generation of relational database schema.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {13359150},
  key       = {Information systems},
  keywords  = {Algorithms;Cosine transforms;Software engineering;Specifications;},
  language  = {English},
}

@InProceedings{20154001337213,
  author    = {Just, Rene},
  title     = {The major mutation framework: Efficient and scalable mutation analysis for Java},
  year      = {2014},
  pages     = {433 - 436},
  address   = {San Jose, CA, United states},
  note      = {Compiler-integrated mutation;Domain specific languages;Large software systems;Mutation testing;Scalability problems;Strong mutation;Testing technique;Weak mutation;},
  abstract  = {Mutation analysis seeds artificial faults (mutants) into a program and evaluates testing techniques by measuring how well they detect those mutants. Mutation analysis is well-established in software engineering research but hardly used in practice due to inherent scalability problems and the lack of proper tool support. In response to those challenges, this paper presents Major, a framework for mutation analysis and fault seeding. Major provides a compiler-integrated mutator and a mutation analyzer for JUnit tests. Major implements a large set of optimizations to enable efficient and scalable mutation analysis of large software systems. It has already been applied to programs with more than 200,000 lines of code and 150,000 mutants. Moreover, Major features its own domain specific language and is designed to be highly configurable to support fundamental re- search in software engineering. Due to its efficiency and exibility, the Major mutation framework is suitable for the application of mutation analysis in research and practice. It is publicly available at http://mutation-testing.org. Copyright 2014 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {2014 International Symposium on Software Testing and Analysis, ISSTA 2014 - Proceedings},
  key       = {Software testing},
  keywords  = {Computer programming languages;Problem oriented languages;Program compilers;Software engineering;},
  language  = {English},
}


@inproceedings{20150800544746,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {UML/OCL based design and analysis of role-based access control policies},
journal = {CEUR Workshop Proceedings},
author = {Hofrichter, Oliver and Gogolla, Martin and Sohr, Karsten},
volume = {1102},
year = {2013},
pages = {33 - 42},
issn = {16130073},
address = {Miami, FL, United states},
abstract = {Access control plays an important part in IT systems these days. Specifically Role-Based Access Control (RBAC) has been widely adopted in practice. One of the major challenges within the introduction of RBAC into an organization is the policy definition. Modeling technologies provide support by allowing to design and to validate a policy. In this work we apply a UML and OCL based domain-specific language (DSL) to design and to analyze the access control of the conference management system EasyChair. For the first time EasyChair is formally described in connection with RBAC. Our activities are located on three levels: (a) the re-engineering of the system's access control policy is located at the policy level, (b) the framework level summarizes activities concerning the RBAC metamodel (e.g. enhancements), and (c) at the configuration level, we configure a concrete policy using the conference management system options. As a result, both a DSL developed in previous work is checked for the need of enhancements, and the re-enginered EasyChair access control policy is analyzed. For validation purposes a frequently used UML/OCL validation tool is utilized. Copyright &copy; 2013 for the individual papers by the papers' authors.},
key = {Access control},
keywords = {Computational linguistics;Computer programming languages;Design;Modeling languages;Problem oriented languages;},
note = {Meta model;OCL;Policy analysis;RBAC;UML;Validation;},
} 

@Article{20142217761509,
  author    = {Haitzer, Thomas and Zdun, Uwe},
  title     = {Semi-automated architectural abstraction specifications for supporting software evolution},
  journal   = {Science of Computer Programming},
  year      = {2014},
  volume    = {90},
  number    = {PART B},
  pages     = {135 - 160},
  note      = {Architectural abstraction;Architectural components;Model transformation;Software Evolution;UML;},
  abstract  = {In this paper we present an approach for supporting the semi-automated architectural abstraction of architectural models throughout the software life-cycle. It addresses the problem that the design and implementation of a software system often drift apart as software systems evolve, leading to architectural knowledge evaporation. Our approach provides concepts and tool support for the semi-automatic abstraction of architecture component and connector views from implemented systems and keeping the abstracted architecture models up-to-date during software evolution. In particular, we propose architecture abstraction concepts that are supported through a domain-specific language (DSL). Our main focus is on providing architectural abstraction specifications in the DSL that only need to be changed, if the architecture changes, but can tolerate non-architectural changes in the underlying source code. Once the software architect has defined an architectural abstraction in the DSL, we can automatically generate architectural component views from the source code using model-driven development (MDD) techniques and check whether architectural design constraints are fulfilled by these models. Our approach supports the automatic generation of traceability links between source code elements and architectural abstractions using MDD techniques to enable software architects to easily link between components and the source code elements that realize them. It enables software architects to compare different versions of the generated architectural component view with each other. We evaluate our research results by studying the evolution of architectural abstractions in different consecutive versions of five open source systems and by analyzing the performance of our approach in these cases. &copy; 2013 Elsevier B.V. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {01676423},
  key       = {Open systems},
  keywords  = {Abstracting;Automation;Computer programming languages;Life cycle;Open source software;Problem oriented languages;Software architecture;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.scico.2013.10.004},
}


@inproceedings{20144600193769,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Comprehension of spacecraft telemetry using hierarchical specifications of behavior},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Havelund, Klaus and Joshi, Rajeev},
volume = {8829},
year = {2014},
pages = {187 - 202},
issn = {03029743},
address = {Luxembourg, Luxembourg},
abstract = {A key challenge in operating remote spacecraft is that ground operators must rely on the limited visibility available through spacecraft telemetry in order to assess spacecraft health and operational status. We describe a tool for processing spacecraft telemetry that allows ground operators to impose structure on received telemetry in order to achieve a better comprehension of system state. A key element of our approach is the design of a domain-specific language that allows operators to express models of expected system behavior using partial specifications. The language allows behavior specifications with data fields, similar to other recent runtime verification systems. What is notable about our approach is the ability to develop hierarchical specifications of behavior. The language is implemented as an internal DSL in the Scala programming language that synthesizes rules from patterns of specification behavior. The rules are automatically applied to received telemetry and the inferred behaviors are available to ground operators using a visualization interface that makes it easier to understand and track spacecraft state. We describe initial results from applying our tool to telemetry received from the Curiosity rover currently roving the surface of Mars, where the visualizations are being used to trend subsystem behaviors, in order to identify potential problems before they happen. However, the technology is completely general and can be applied to any system that generates telemetry such as event logs. &copy; Springer International Publishing Switzerland 2014.},
key = {Spacecraft},
keywords = {Computer programming languages;Formal methods;Interface states;Problem oriented languages;Specifications;Telemetering equipment;Visualization;},
note = {Behavior specifications;Domain specific languages;Limited visibility;Partial specifications;Potential problems;Remote spacecraft;Run-time verification;System behaviors;},
} 

@InProceedings{20130616002373,
  author    = {Lu, Qiming and Biery, Kurt A. and Kowalkowski, James B.},
  title     = {Message correlation analysis tool for NONA},
  year      = {2012},
  volume    = {396},
  number    = {PART 1},
  pages     = {New York University; ACEOLE; Data Direct Networks; Dell; European Middleware Initiative; Nexsan -},
  address   = {New York, NY, United states},
  note      = {Correlation analysis;Correlation rule;Data corruption;Domain specific languages;Event identification;Initial design;On-line data acquisition;Plug-ins;Real-time correlations;Recognition patterns;Running systems;Runtimes;System failures;},
  abstract  = {A complex running system, such as the NO&nu;A online data acquisition, consists of a large number of distributed but closely interacting components. This paper describes a generic real-time correlation analysis and event identification engine, named Message Analyzer. Its purpose is to capture run time abnormalities and recognize system failures based on log messages from participating components. The initial design of analysis engine is driven by the data acquisition (DAQ) of the NO&nu;A experiment. The Message Analyzer performs filtering and pattern recognition on the log messages and reacts to system failures identified by associated triggering rules. The tool helps the system maintain a healthy running state and to minimize data corruption. This paper also describes a domain specific language that allows the recognition patterns and correlation rules to be specified in a clear and flexible way. In addition, the engine provides a plugin mechanism for users to implement specialized patterns or rules in generic languages such as C++.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {17426588},
  journal   = {Journal of Physics: Conference Series},
  key       = {Correlation methods},
  keywords  = {Data acquisition;Digital storage;Nuclear physics;Pattern recognition;Systems engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1088/1742-6596/396/1/012030},
}

@InProceedings{20140717317964,
  author    = {Schafer, Jorg and Klein, David},
  title     = {Implementing Situation Awareness for Car-to-X Applications using Domain Specific Languages},
  year      = {2013},
  address   = {Dresden, Germany},
  note      = {Application softwares;Domain specific languages;Model parameters;Radio technologies;Simulation environment;Situation awareness;Technology-based;Wireless communications;},
  abstract  = {Car-to-X i.e. Car-to-Anything communication based on standardized IEEE 802.11p radio technology is comprised with wireless communication between cars (Car-to-Car) and between vehicles and the environment (Car-to-Infrastructure). In order to develop Car-to-X applications based on this standard one needs to model parameters such as the vehicle's position, velocity, acceleration etc. and parameters of the vehicle's environment. Typically, the underlying domain models are designed in an ad-hoc manner and the domain rules become hard-coded into the source-code of the application software. In this paper we describe an alternative and more flexible approach. The model is described in almost plain English using a Domain Specific Language (DSL) and translated into target code via parser technology based on the ANTLR tool-chain. This provides more flexibility not only in creating and maintaining the domain rules, but also with regards to generating code for entirely different target languages and technology environments. For instance, we demonstrate to generate Java code for a simulation environment and C-code for the embedded device from the same rule definitions. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {15502252},
  journal   = {IEEE Vehicular Technology Conference},
  key       = {Vehicle to vehicle communications},
  keywords  = {Computer programming languages;Standards;Technology;Wireless telecommunication systems;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/VTCSpring.2013.6692589},
}


@article{20154401488568,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Concepts and evaluation of the extended entity-relationship approach to database design in a multi-paradigm information system modeling tool},
journal = {Computer Languages, Systems and Structures},
author = {Dimitrieski, Vladimir and elikovi, Milan and Aleksi, Slavica and Risti, Sonja and Alargt, Abdalla and Lukovi, Ivan},
volume = {44},
year = {2015},
pages = {299 - 318},
issn = {14778424},
abstract = {Different approaches to information system (IS) development are based on different data models. The selection of a data model for conceptual design, among other things, depends on the problem domain, the knowledge, and the personal preferences of an IS designer. In some situations, a simultaneous usage of different approaches to the conceptual database design and IS development may lead to the most appropriate solutions. In our previous research we have developed a tool that provides an evolutive and incremental approach to IS development, which is based on the form type data model. The approaches based on the Extended Entity-Relationship (EER) and class data models are broadly accepted throughout the community of IS designers. In order to support the simultaneous usage of approaches based on the form type, EER and class data models, we have developed the Multi-Paradigm Information System Modeling Tool (MIST). In this paper, we present a part of our MIST tool that supports EER approach to a database design. MIST components currently provide a formal specification of an EER database schema specification and its transformation into the relational data model, or the class model. Also, MIST allows generation of Structured Query Language code for a database creation and procedural code for implementing database constraints. In addition, Java code that stores and processes data from the database, may be generated from the class model. In this paper, we present the evaluation study of the MIST EER domain-specific language. Users' perceptions of language quality characteristics are used for the evaluation. &copy; 2015 Elsevier Ltd.},
key = {Quality control},
keywords = {Codes (symbols);Computational linguistics;Computer programming languages;Conceptual design;Data mining;Design;Formal specification;Information systems;Metadata;Problem oriented languages;Query languages;Query processing;Specifications;},
note = {Conceptual database design;Domain specific languages;Entity-relationship;Evaluation study;Information system model;Model transformation;Relational data models;Structured Query Language;},
URL = {http://dx.doi.org/10.1016/j.cl.2015.08.011},
} 

@InProceedings{20154301444277,
  author    = {Fox, Anthony},
  title     = {Improved tool support for machine-code decompilation in HOL4},
  year      = {2015},
  volume    = {9236},
  pages     = {187 - 202},
  address   = {Nanjing, China},
  note      = {Decompilation;Domain specific languages;Instruction set;Instruction set architecture;Interactive theorem prover;Machine code programs;Machine codes;Orders of magnitude;},
  abstract  = {The HOL4 interactive theorem prover provides a sound logical environment for reasoning about machine-code programs. The rigour of HOL&rsquo;s LCF-style kernel naturally guarantees very high levels of assurance, but it does present challenges when it comes implementing efficient proof tools. This paper presents improvements that have been made to our methodology for soundly decompiling machine-code programs to functions expressed in HOL logic. These advancements have been facilitated by the development of a domain specific language, called L3, for the specification of Instruction Set Architectures (ISAs). As a result of these improvements, decompilation is faster (on average by one to two orders of magnitude), the instruction set specifications are easier to write, and the proof tools are easier to maintain. &copy; Springer International Publishing Switzerland 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Theorem proving},
  keywords  = {Codes (symbols);Computer architecture;Computer programming languages;Problem oriented languages;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-22102-1_12},
}

@InProceedings{20153401193147,
  author    = {Bhat, Manoj and Reschenhofer, Thomas and Matthes, Florian},
  title     = {Tool support for analyzing the evolution of Enterprise Architecture metrics},
  year      = {2015},
  volume    = {3},
  pages     = {154 - 161},
  address   = {Barcelona, Spain},
  note      = {Domain specific languages;Enterprise Architecture;Enterprise architecture managements;Informed decision;Metrics;Model based approach;Retrospective analysis;Temporal aspects;},
  abstract  = {Managing the evolution of the Enterprise Architecture (EA) is a key challenge for modern enterprises. The EA metrics are instrumental in quantitatively measuring the progress of an enterprise towards its goals. Retrospective analysis of EA metrics empower business users to take informed decisions while planning and selecting efficient alternatives to achieve envisioned EA goals. Even though the current EA management tools support the definition and calculation of EA metrics, they do not capture the temporal aspects of EA metrics in their meta-model to enable retrospective analysis. In this paper, we first propose a model-based approach to capture the temporal aspects of EA metrics and then extend a domain specific language to compute EA metrics at any point of time in the past. This allows visualizing the evolution of EA metrics and as a consequence the evolution of the EA. Copyright &copy; 2015 SCITEPRESS Science and Technology Publications All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ICEIS 2015 - 17th International Conference on Enterprise Information Systems, Proceedings},
  key       = {Information systems},
  keywords  = {Computational linguistics;Computer programming languages;Problem oriented languages;},
  language  = {English},
}


@inproceedings{20143718153653,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Defining domain specific transformations in human-computer interfaces development},
journal = {MODELSWARD 2014 - Proceedings of the 2nd International Conference on Model-Driven Engineering and Software Development},
author = {Sottet, Jean-Sebastien and Vagner, Alain},
year = {2014},
pages = {246 - 253},
address = {Lisbon, Portugal},
abstract = {Early model-based approaches for Human-Computer Interaction (HCI) clearly depicted models and frameworks for generating User Interfaces (UI) but considered model transformations as black-boxes. In the 2000's, these approaches were criticized due to the poor quality of the produced UI. One of the main reasons of this poor quality can be easily observed in state of the art UI transformations: they are the heart of designers' know-how but are maintained by a minority of specialists. Meanwhile, mainstream UI design methods have shown a growing number of heterogeneous stakeholders that collaborate to produce modern and qualitative UI. We claim that these stakeholders must comprehend and interact with transformations and thus we need to make the transformation language affordable to these stakeholders. Indeed, such a simplification should hide transformations complexity and burden for any stakeholder, finally focusing on a specific part of the design domain: a Domain Specific Language (DSL) for transformations or Domain Specific Transformation Language (DSTL). We provide in this paper a method and a supporting tool for systematizing and finally executing DSTL for model-driven UI development. We depict that framework on a proof of concept implementation for an HCI-specific stakeholder: the usability expert. Copyright &copy; 2014 SCITEPRESS - Science and Technology Publications. All rights reserved.},
key = {Software design},
keywords = {Computer programming languages;Human computer interaction;Mathematical models;Technology transfer;User interfaces;},
note = {Domain specific languages;Human computer interaction (HCI);Human computer interfaces;Model based approach;Model driven development;Model transformation;Proof of concept;Transformation languages;},
} 

@InProceedings{20143118014661,
  author    = {Nabuco, Miguel and Paiva, Ana C. R.},
  title     = {Model-based test case generation for web applications},
  year      = {2014},
  volume    = {8584 LNCS},
  number    = {PART 6},
  pages     = {248 - 262},
  address   = {Guimaraes, Portugal},
  note      = {Capture-replay;Domain specific languages;Model based testing;Model-based test;Modeling tool;Test case generation;Test strategies;WEB application;},
  abstract  = {This paper presents a tool to filter/configure the test cases generated within the Model-Based Testing project PBGT. The models are written in a Domain Specific Language called PARADIGM and are composed by User Interface Test Patterns (UITP) describing the testing goals. To generate test cases, the tester has to provide test input data for each UITP in the model. After that, it is possible to generate test cases. However, without a filter/configuration of the test case generation algorithm, the number of test cases can be so huge that becomes unfeasible. So, this paper presents an approach to define parameters for the test case generation in order to generate a feasible number of test cases. The approach is evaluated by comparing the different test strategies and measuring the performance of the modeling tool against a capture-replay tool used for web testing. &copy; 2014 Springer International Publishing.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Testing},
  keywords  = {Computer programming languages;User interfaces;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-09153-2_19},
}

@InProceedings{20164202918668,
  author    = {Ramos-Cantor, Oscar D. and Lossow, Moritz and Droste, Heinz and Kadel, Gerhard and Pesavento, Marius},
  title     = {A network simulation tool for user traffic modeling and quality of experience analysis in a hybrid access architecture},
  year      = {2014},
  address   = {Berlin, Germany},
  note      = {Digital Subscriber Line (DSL);Hybrid-access;LTE Networks;Network simulation tools;Network users;Quality of experience (QoE);User experience;User traffics;},
  abstract  = {A Hybrid Access Architecture, where network users can be simultaneously served by different technologies, has been envisioned in order to increase the achievable data rates and enhance the user experience. This proposed access is promising to users where the costs of replacing existing technology are unmanageable and the complementary technology is underused. In order to understand the implications of a Hybrid Access between Digital Subscriber Line (DSL) and Long Term Evolution (LTE) in Downlink (DL) operation, a Network Simulation Tool has been developed, where the services demanded by the users are defined and modeled. Additionally, the Traffic and QoE Simulator (TQoES) establishes an algorithm to select the kind of access to be used by specific services, and reliably simulates the behavior of users within an LTE network based on 3GPP recommendations. &copy; VDE VERLAG GMBH &middot; Berlin &middot; Offenbach.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings of World Telecommunications Congress 2014, WTC 2014},
  key       = {Wireless telecommunication systems},
  keywords  = {Long Term Evolution (LTE);Mobile telecommunication systems;Modems;Network architecture;Office buildings;Quality of service;Telecommunication lines;Telephone lines;},
  language  = {English},
}

@InProceedings{20123315333260,
  author    = {Rabbi, Fazle and MacCaull, Wendy},
  title     = {Model driven workflow development with T},
  year      = {2012},
  volume    = {112 LNBIP},
  pages     = {265 - 279},
  address   = {Gdansk, Poland},
  note      = {Abstract process;Adaptive software systems;Domain specific languages;Model-driven;Model-driven Engineering;Tool support;Transformation methods;Workflow management systems;Workflow process;},
  abstract  = {Model Driven Engineering (MDE) refers to the systematic use of models as primary engineering artifacts throughout the engineering lifecycle. MDE has a lot of potential to make adaptive software systems, but it requires maturity and tool support. Here we present a domain specific language, called T <inf>&squ;</inf> (pronounced as T-Square) for writing workflow process specifications which allows us to write procedural statements for tasks and branch conditions, to query an ontology and to declare user interfaces. We apply transformation methods to generate executable software from the abstract process specifications. &copy; 2012 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {18651348},
  journal   = {Lecture Notes in Business Information Processing},
  key       = {Models},
  keywords  = {Adaptive systems;Information systems;Ontology;Specifications;Technical presentations;User interfaces;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-31069-0_23},
}

@InProceedings{20151300684113,
  author    = {Basso, Fabio P. and Werner, Claudia M.L. and Oliveira, Toacy C.},
  title     = {Towards facilities to introduce solutions for MDE in development environments with reusable assets},
  year      = {2014},
  pages     = {195 - 202},
  address   = {San Francisco, CA, United states},
  note      = {Development environment;Domain specific languages;Model-driven Engineering;Practical experience;Reusable assets;Reuse of tasks;Supporting tool;Technical solutions;},
  abstract  = {Model Driven Engineering (MDE) is a software development paradigm that promotes improvements in productivity through reuse of software model specifications. Although much effort has been dedicated for more than ten years, MDE has not achieved expressive use. In this paper we address the problem of a lack of a knowledge base about MDE-based solutions, a reason that hampers MDE in practice. To surpass it we propose a domain specific language named RAS++ that represents these solutions as reusable assets. Assets are composed by reuse structures and semantics for the execution of technical solutions for Automated Software Engineering, fostering the integration of tasks for MDE in development environments. Facilities are introduced through some supporting tools: one to design reusable assets and other to integrate them in target development environments. Practical experiences have proven to be promising, suggesting that reusable assets promote some benefits not allowed by other approaches, such as the possibility of a distributed base of knowledge for ASE solutions. &copy; 2014 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the 2014 IEEE 15th International Conference on Information Reuse and Integration, IEEE IRI 2014},
  key       = {Software design},
  keywords  = {Computer programming languages;Computer software reusability;Information use;Knowledge based systems;Problem oriented languages;Semantics;Software engineering;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/IRI.2014.7051890},
}

@Article{20152600982656,
  author    = {Blouin, Arnaud and Moha, Naouel and Baudry, Benoit and Sahraoui, Houari and Jezequel, Jean-Marc},
  title     = {Assessing the use of slicing-based visualizing techniques on the understanding of large metamodels},
  journal   = {Information and Software Technology},
  year      = {2015},
  volume    = {62},
  number    = {1},
  pages     = {124 - 142},
  note      = {Class diagrams;Domain specific languages;Interactive navigations;Interactive visualization tool;Interactive visualizations;Meta model;Model slicing;Model-driven Engineering;},
  abstract  = {Context: Metamodels are cornerstones of various metamodeling activities. Such activities consist of, for instance, transforming models into code or comparing metamodels. These activities thus require a good understanding of a metamodel and/or its parts. Current metamodel editing tools are based on standard interactive visualization features, such as physical zooms. Objective: However, as soon as metamodels become large, navigating through large metamodels becomes a tedious task that hinders their understanding. So, a real need to support metamodel comprehension appears. Method: In this work we promote the use of model slicing techniques to build interactive visualization tools for metamodels. Model slicing is a model comprehension technique inspired by program slicing. We show how the use of Kompren, a domain-specific language for defining model slicers, can ease the development of such interactive visualization features. Results: We specifically make four main contributions. First, the proposed interactive visualization techniques permit users to focus on metamodel elements of interest, which aims at improving the understandability. Second, these proposed techniques are developed based on model slicing, a model comprehension technique that involves extracting a subset of model elements of interest. Third, we develop a metamodel visualizer, called Explen, embedding the proposed interactive visualization techniques. Fourth, we conducted experiments. showing that Explen significantly outperforms EcoreTools, in terms of time, correctness, and navigation effort, on metamodeling tasks. Conclusion: The results of the experiments, in favor of Explen, show that improving metamodel understanding can be done using slicing-based interactive navigation features. &copy; 2015 Elsevier B.V. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {09505849},
  key       = {Visualization},
  keywords  = {Computer programming languages;Flow visualization;Human computer interaction;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.infsof.2015.02.007},
}

@InProceedings{20150900591783,
  author    = {Vallejo, Paola and Kerboeuf, Mickael and Babau, Jean-Philippe},
  title     = {Specification of a legacy tool by means of a dependency graph to improve its reusability},
  year      = {2013},
  volume    = {1090},
  pages     = {80 - 87},
  address   = {Miami, FL, United states},
  note      = {Co-evolution;Code Generation;Dependency graphs;DSML;Meta model;Meta-model transformations;Model migrations;Position papers;},
  abstract  = {This position paper, investigates a way to improve the reusability of legacy tools in specific contexts (defined by specific metamodels). The approach is based on a dedicated language for co-evolution, called Modif. Its associated process involves two model migrations. The first one (Migration), allows to put data under the scope of a legacy tool. The second one (Reverse Migration), allows to put the legacy tool's output back into the original specific context. The approach is generalized by introducing the notion of dependency graph. It specifies the relations between the legacy tool's input and the legacy tool's output. The dependency graph is then used to address some complexities of the Reverse Migration. The improvement is illustrated by the reuse of a attener tool defined on a specific metamodel of FSM (finite state machines). &copy; 2013 for the individual papers by the papers' authors.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {Reusability},
  keywords  = {Computational linguistics;Logic circuits;},
  language  = {English},
}


@inproceedings{20142317794126,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Verification of scheme plans using CSPB},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {James, Philip and Moller, Faron and Nguyen, Hoang Nga and Roggenbach, Markus and Schneider, Steve and Treharne, Helen and Trumble, Matthew and Williams, David},
volume = {8368 LNCS},
year = {2014},
pages = {189 - 204},
issn = {03029743},
address = {Madrid, Spain},
abstract = {The paper presents a tool-supported approach to graphically editing scheme plans and their safety verification. The graphical tool is based on a Domain Specific Language which is used as the basis for transformation to a CSP&par;B formal model of a scheme plan. The models produced utilise a variety of abstraction techniques that make the analysis of large scale plans feasible. The techniques are applicable to other modelling languages besides CSP&par;B. We use the ProB tool to ensure the safety properties of collision, derailment and run-through freedom. &copy; 2014 Springer International Publishing.},
key = {Formal methods},
keywords = {Computer programming languages;},
note = {Abstraction techniques;Domain specific languages;Formal model;Graphical tools;Modelling language;Safety property;Safety verification;},
URL = {http://dx.doi.org/10.1007/978-3-319-05032-4_15},
} 

@InProceedings{20133716736360,
  author    = {Batarseh Dr., Ola and McGinnis Dr., Leon and Lorenz, Jim},
  title     = {MBSE supports manufacturing system design},
  year      = {2012},
  volume    = {2},
  pages     = {920 - 944},
  address   = {Rome, Italy},
  note      = {Analysis tools;Design support tools;Domain specific languages;Electronics assembly;Manufacturing domains;Model-based systems engineering (MBSE);Product-design domain;System designers;},
  abstract  = {To date, Model Based Systems Engineering (MBSE) has been deployed primarily in the product design domain. However, manufacturing system design problems are equally challenging, but there are many fewer design support tools in the hands of system designers. This paper describes how MBSE principles and methods can be used to make a powerful analysis tool readily accessible to manufacturing systems engineers. The MagicDraw<sup>TM</sup> SysML tool was used to create a domain specific language for electronics assembly, and the tool itself was customized to present an interface that was relatively easy for the manufacturing domain experts to use to create descriptions of products, resources, and processes. The domain specific language was mapped to a metamodel of the Arena<sup>TM</sup> discrete event simulation language, and the ATL&copy; model transformation tool was used to automate the generation of the an instance of a simulation model from an instance of the electronics assembly system. The use of this kind of analysis automation can reduce by up to a factor of ten the time required to develop such simulation models. &copy; 2012 by Ola Batarseh, Leon McGinnis, and Jim Lorenz. Published and used by INCOSE with permission.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {22nd Annual International Symposium of the International Council on Systems Engineering, INCOSE 2012 and the 8th Biennial European Systems Engineering Conference 2012, EuSEC 2012},
  key       = {Systems engineering},
  keywords  = {Discrete event simulation;Manufacture;Product design;Systems analysis;Tools;},
  language  = {English},
}

@InProceedings{20140417237561,
  author    = {Unutulmaz, Ahmet and Dundar, Gunhan and Fernandez, Francisco V.},
  title     = {Template coding with LDS and applications of LDS in EDA},
  year      = {2014},
  volume    = {78},
  number    = {1},
  pages     = {137 - 151},
  note      = {Analog layout;Circuit synthesis;Hybrid template language;Layout description script;Layout templates;},
  abstract  = {This paper presents the layout description script (LDS), which is a domain specific language intended to code layout templates to be used for layout-aware circuit synthesis. LDS supports both sequential and constraint programming and is suitable for both manual coding and automatic code generation. LDS is compared with previous approaches related to layout description. Code samples are given for alignment, abutment, symmetry, and similar constraints. Also, implementation of the LDS compiler is discussed and a methodology for handling complex constraints is presented. Due to its support for constraint programming, it is possible to constrain topological representations and even combine them. It is also possible to combine and constrain placement and routing in an LDS template. Finally, a capture tool has been implemented. This tool is designed to extract a template from an expert-drawn layout. Capture converts a data structure extracted through a guided user interface into a template. This tool highlights the compatibility of LDS with electronic design automation. &copy; 2013 Springer Science+Business Media New York.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {09251030},
  journal   = {Analog Integrated Circuits and Signal Processing},
  key       = {Tools},
  keywords  = {Computer programming languages;Constraint theory;User interfaces;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s10470-013-0213-9},
}


@inproceedings{20160101744565,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {9th International Conference on Evaluation of Novel Approaches to Software Engineering, ENASE 2014},
journal = {Communications in Computer and Information Science},
volume = {551},
year = {2015},
pages = {1 - 168},
issn = {18650929},
address = {Lisbon, Portugal},
abstract = {The proceedings contain 11 papers. The special focus in this conference is on Evaluation of Novel Approaches to Software Engineering. The topics include: Reducing the level of complexity of working with model transformations; learning from the current status of agile adoption; using a domain specific language for lightweight model-driven development; a passive approach for protocols; experiences of use of a multi-domain tool for collaborative software engineering tasks; taking seriously software projects inception through games; natural language generation approach for automated generation of test cases from logical specification of requirements; visualization, simulation and validation for cyber-virtual systems and mobile application estimate the design phase.},
} 

@Article{20121514933149,
  author    = {Edge, Michael E. and Falcone Sampaio, Pedro R.},
  title     = {The design of FFML: A rule-based policy modelling language for proactive fraud management in financial data streams},
  journal   = {Expert Systems with Applications},
  year      = {2012},
  volume    = {39},
  number    = {11},
  pages     = {9966 - 9985},
  note      = {Active monitoring;Ad hoc security;Assistive tool;Bottom lines;Brand image;Conceptual levels;Customer services;Data stream;Domain specific languages;Executable codes;Financial data;Financial information systems;Financial institution;Financial loss;Financial service;Fraud detection;Fraud detection system;Fraudsters;Information models;Management policy;Modelling language;Multi-channel;New high;Policy mappings;Rule based;Rule-based expert system;Transaction execution;},
  abstract  = {Developing fraud management policies and fraud detection systems is a vital capability for financial institutions towards minimising the effect of fraud upon customer service delivery, bottom line financial losses and the adverse impact on the organisation's brand image reputation. Rapidly changing attacks in real-time financial service platforms continue to demonstrate fraudster's ability to actively re-engineer their methods in response to ad hoc security protocol deployments, and highlights the distinct gap between the speed of transaction execution within streaming financial data and corresponding fraud technology frameworks that safeguard the platform. This paper presents the design of FFML, a rule-based policy modelling language and encompassing architecture for facilitating the conceptual level expression and implementation of proactive fraud controls within multi-channel financial service platforms. It is demonstrated how a domain specific language can be used to abstract the financial platform into a data stream based information model to reduce policy modelling complexity and deployment latencies through an innovative policy mapping language usable by both expert and non-expert users. FFML is part of a comprehensive suite of assistive tools and knowledge-based systems developed to support fraud analysts' daily work of designing new high level fraud management policies, mapping into executable code of the underpinning application programming interface and deployment of active monitoring and compliance functionality within the financial platform. &copy; 2012 Elsevier Ltd. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {09574174},
  key       = {Information management},
  keywords  = {Application programming interfaces (API);Computer crime;Computer systems programming;Crime;Data communication systems;Expert systems;Finance;Information theory;Losses;Security of data;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.eswa.2012.01.143},
}

@InProceedings{20140717295378,
  author    = {Azevedo, Bruno M. and Almeida, Jose Joao},
  title     = {ABC with a UNIX flavor},
  year      = {2013},
  volume    = {29},
  pages     = {203 - 218},
  address   = {Porto, Portugal},
  note      = {ABC notation;Compiler architectures;Domain specific languages;Musical notation;Processing tools;Rule based;Scripting;Semantic transformation;},
  abstract  = {ABC is a simple, yet powerful, textual musical notation. This paper presents ABC::DT, a rule-based domain-specific language (Perl embedded), designed to simplify the creation of ABC processing tools. Inspired by the Unix philosophy, those tools intend to be simple and compositional in a Unix filters' way. From ABC::DT's rules we obtain an ABC processing tool whose main algorithm follows a traditional compiler architecture, thus consisting of three stages: 1) ABC parser (based on abcm2ps' parser), 2) ABC semantic transformation (associated with ABC attributes), 3) output generation (either a user defined or system provided ABC generator). &copy; Bruno M. Azevedo and Jose&acute; Joa&tilde;o Almeida.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {21906807},
  journal   = {OpenAccess Series in Informatics},
  key       = {UNIX},
  keywords  = {Problem oriented languages;Program compilers;Semantics;Slate;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.4230/OASIcs.SLATE.2013.203},
}

@InProceedings{20122315081050,
  author    = {Nilsson, Anders and Hedin, Gorel},
  title     = {Metacompiling OWL ontologies},
  year      = {2012},
  volume    = {6940 LNCS},
  pages     = {354 - 366},
  address   = {Braga, Portugal},
  note      = {Application programs;Attribute grammars;Domain specific languages;Industrial robotics;OWL ontologies;},
  abstract  = {Ontologies, formal knowledge representation, and reasoning are technologies that have begun to gain substantial interest in recent years. We present a high-level declarative approach to writing application programs for specific ontologies, based on viewing the ontology as a domain-specific language. Our approach is based on declarative meta-compilation techniques. We have implemented a tool using this approach that allows typed frontends to be generated for specific ontologies, and to which the desired functionality can be added as separate aspects. Our tool makes use of the JastAdd meta-compilation system which is based on reference attribute grammars. We describe the architecture of our tool and evaluate the approach on applications in industrial robotics. &copy; 2012 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Knowledge representation},
  keywords  = {Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-28830-2_20},
}

@InProceedings{20153401194762,
  author    = {Foster, Nate and Kozen, Dexter and Milano, Matthew and Silva, Alexandra and Thompson, Laure},
  title     = {A coalgebraic decision procedure for NetKAT},
  year      = {2015},
  volume    = {2015-January},
  pages     = {343 - 355},
  address   = {Mumbai, India},
  note      = {Automata;Coalgebraic structures;Coalgebras;Domain specific languages;Implementation and optimization;Kleene algebra with tests;NetKAT;Soundness and completeness;},
  abstract  = {NetKAT is a domain-specific language and logic for specifying and verifying network packet-processing functions. It consists of Kleene algebra with tests (KAT) augmented with primitives for testing and modifying packet headers and encoding network topologies. Previous work developed the design of the language and its standard semantics, proved the soundness and completeness of the logic, defined a PSPACE algorithm for deciding equivalence, and presented several practical applications. This paper develops the coalgebraic theory of NetKAT, including a specialized version of the Brzozowski derivative, and presents a new efficient algorithm for deciding the equational theory using bisimulation. The coalgebraic structure admits an efficient sparse representation that results in a significant reduction in the size of the state space. We discuss the details of our implementation and optimizations that exploit NetKAT's equational axioms and coalgebraic structure to yield significantly improved performance. We present results from experiments demonstrating that our tool is competitive with state-of-the-art tools on several benchmarks including allpairs connectivity, loop-freedom, and translation validation. Copyright &copy; 2015 by the Association for Computing Machinery, Inc. (ACM).},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {07308566},
  journal   = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
  key       = {Network coding},
  keywords  = {Algebra;Algorithms;Computational linguistics;Computer programming languages;Electric network topology;Packet networks;Problem oriented languages;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2676726.2677011},
}

@InProceedings{20161702310982,
  author    = {Jongmans, Sung-Shik T. Q. and Arbab, Farhad},
  title     = {PrDK: Protocol programming with automata},
  year      = {2016},
  volume    = {9636},
  pages     = {547 - 552},
  address   = {Eindhoven, Netherlands},
  note      = {Domain specific languages;General purpose languages;NAS parallel benchmarks;Theoretic semantics;},
  abstract  = {We present PrDK: a development kit for programming protocols. PrDK is based on syntactic separation of process code, presumably written in an existing general-purpose language, and protocol code, written in a domain-specific language with explicit, high-level elements of syntax for programming protocols. PrDK supports two complementary syntaxes (one graphical, one textual) with a common automata-theoretic semantics. As a tool for construction of systems, PrDK consists of syntax editors, a translator, a parser, an interpreter, and a compiler into Java. Performance in the NAS Parallel Benchmarks is promising. &copy; Springer-Verlag Berlin Heidelberg 2016.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Syntactics},
  keywords  = {Automata theory;Benchmarking;Computational linguistics;Computer programming languages;High level languages;Problem oriented languages;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-662-49674-9_33},
}

@InProceedings{20124715683512,
  author    = {Tesoriero, Ricardo and Gallud, Jose A. and Villanueva, Pedro G. and Sebastian, Gabriel},
  title     = {Interaction modeling on heterogeneous spaces},
  year      = {2012},
  pages     = {King Abdulaziz University (KAU); University of Castilla-La Mancha (UCLM) -},
  address   = {Elche, Alicante, Spain},
  note      = {Abstract syntax;Concrete syntax;Domain specific languages;Interaction modeling;Interactive spaces;Location-aware application;Meta model;Model based development;Model driven architectures;Model spaces;},
  abstract  = {This paper presents a metamodel that defines an abstract syntax to represent the interaction between entities and their environment through heterogeneous interactive spaces. It also presents a concrete syntax that defines a domain specific language supported by a case tool that allows developers to model space specific concerns independently from the rest of the application. Copyright 2012 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Syntactics},
  keywords  = {Human computer interaction;User interfaces;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2379636.2379672},
}


@inproceedings{20124915762776,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Business Process Model and Notation - 4th International Workshop, BPMN 2012, Proceedings},
journal = {Lecture Notes in Business Information Processing},
volume = {125 LNBIP},
year = {2012},
pages = {MID; Signavio; Sparx Systems; BPM and O, Akademie Enabling BPM. And People.; City of Vienna - },
issn = {18651348},
address = {Vienna, Austria},
abstract = {The proceedings contain 10 papers. The topics discussed include: a platform for research on process model collections; aspect oriented business process modeling with precedence; event-based gateways: open questions and inconsistencies; a BPMN extension for including data quality requirements in business process modeling; BPMN4TOSCA: a domain-specific language to model management plans for composite applications; extending BPMN 2.0 for modeling the combination of activities that involve data constraints; comparison of BPMN2 diagrams; a tool for animating BPMN token flow; and towards SecureBPMN - aligning BPMN with the information assurance and security domain.},
} 

@Article{20151300681984,
  author    = {Cunha, Jacome and Fernandes, Joao Paulo and Mendes, Jorge and Saraiva, Joao},
  title     = {Spreadsheet engineering},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year      = {2015},
  volume    = {8606},
  pages     = {246 - 299},
  note      = {Building blockes;Data refinements;Database technique;Domain specific languages;Empirical studies;Laboratory sessions;Spreadsheet development;Spreadsheet engineering;},
  abstract  = {These tutorial notes present a methodology for spreadsheet engineering. First, we present data mining and database techniques to reason about spreadsheet data. These techniques are used to compute relationships between spreadsheet elements (cells/columns/rows), which are later used to infer a model defining the business logic of the spreadsheet. Such a model of a spreadsheet data is a visual domain specific language that we embed in a well-known spreadsheet system. The embedded model is the building block to define techniques for model-driven spreadsheet development, where advanced techniques are used to guarantee the model-instance synchronization. In this modeldriven environment, any user data update has to follow the model-instance conformance relation, thus, guiding spreadsheet users to introduce correct data. Data refinement techniques are used to synchronize models and instances after users update/evolve the model. These notes briefly describe ourmodel-driven spreadsheet environment, the MDSheet environment, that implements the presented methodology. To evaluate both proposed techniques and the MDSheet tool, we have conducted, in laboratory sessions, an empirical study with the summer school participants. The results of this study are presented in these notes. &copy; Springer International Publishing Switzerland 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  key       = {Spreadsheets},
  keywords  = {Computer programming languages;Data mining;Problem oriented languages;Visual languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-15940-9_6},
}


@inproceedings{20162902597316,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {12th International Baltic Conference on Databases and Information Systems, DB and IS 2016},
journal = {Communications in Computer and Information Science},
volume = {615},
year = {2016},
pages = {1 - 380},
issn = {18650929},
address = {Riga, Latvia},
abstract = {The proceedings contain 25 papers. The special focus in this conference is on Ontology, Conceptual Modeling, Databases, Tools, Technologies, Decision Support Systems and Data Mining. The topics include: Towards self-explanatory ontology visualization with contextual verbalization; self-service ad-hoc querying using controlled natural language; database to ontology mapping patterns in RDB2OWL lite; models and model transformations within web applications; metamodel specialization for DSL tool building; DSML tool building platform in web; algorithms for extracting mental activity phases from heart beat rate streams; scheduling approach for enhancing quality of service in real-time DBMS; a comparative analysis of algorithms for mining frequent itemsets; a webGIS application for cloud storm monitoring; self-management of information systems; on the smart spaces approach to semantic-driven design of service-oriented information systems; conclusions from the evaluation of virtual machine based high resolution display wall system; the enterprise model frame for supporting security requirement elicitation from business processes; knowledge management performance measurement; a study on immediate automatic usability evaluation of web application user interfaces; model-based testing of real-time distributed systems; detection of multiple implicit features per sentence in consumer review data; web news sentence searching using linguistic graph similarity; heuristic method to improve systematic collection of terminology; the application of optimal topic sequence in adaptive e-learning systems and initial steps towards the development of formal method for evaluation of concept map complexity from the systems viewpoint.},
} 


@inproceedings{20154501511163,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Demo abstract: Reproducible deployment of pervasive applications},
journal = {2015 IEEE International Conference on Pervasive Computing and Communication Workshops, PerCom Workshops 2015},
author = {Gunalp, Ozan and Escoffier, Clement and Lalanda, Philippe},
year = {2015},
pages = {211 - 213},
address = {St. Louis, MO, United states},
abstract = {Pervasive systems present stringent requirements that make software deployment especially challenging. The unknown and fluctuating environment in which pervasive applications are executed discards traditional approaches. As a result, there is an increasing need for a reproducible and dynamic deployment process. In last years, we developed several industrial pervasive platforms and applications. Based on these experiences we propose Rondo, a tool suite for deploying pervasive applications. Rondo includes a domain-specific language for declaratively describing applications, a deployment manager that can dynamically apply these descriptions and development tools for helping the description of applications. In this paper we present this tool suite and a set of deployment scenarios in which we validated our approach, including a web framework and a home automation platform. &copy; 2015 IEEE.},
key = {Ubiquitous computing},
keywords = {Computer aided software engineering;Computer programming languages;Problem oriented languages;},
note = {Deployment scenarios;Domain specific languages;Dynamic deployment;Pervasive applications;Pervasive systems;Software deployment;Stringent requirement;Traditional approaches;},
URL = {http://dx.doi.org/10.1109/PERCOMW.2015.7134025},
} 

@InProceedings{20143017990613,
  author    = {Bache, Emily and Bache, Geoffrey},
  title     = {Specification by example with gui tests - how could that work?},
  year      = {2014},
  volume    = {179 LNBIP},
  pages     = {320 - 326},
  address   = {Rome, Italy},
  note      = {ATDD;Capture-replay;Crew management systems;Domain specific languages;Experience report;GUI testing;Record-replay;},
  abstract  = {Specification by Example is a collaborative method for developing software. It involves a workshop where people representing various roles and viewpoints discuss what is to be built, and come up with concrete example scenarios. These scenarios later form the basis for automated (functional) acceptance tests, and are sometimes called "Living Documentation", as they are written in a Domain Specific Language and can be read by non-programmers. GUI testing has traditionally used a record-replay paradigm that requires the user interface exists before the tests can be created, and hence have been considered incompatible with a Specification by Example approach. In this experience report we will discuss how we have overcome this apparent contradiction at Jeppesen, and relate an experience using the tool TextTest for GUI testing of Jeppesen's next-generation Crew Management System. &copy; Springer International Publishing Switzerland 2014.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {18651348},
  journal   = {Lecture Notes in Business Information Processing},
  key       = {Acceptance tests},
  keywords  = {Computer programming languages;Software engineering;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-06862-6},
}


@inproceedings{20123715418237,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Comprehensive two-level analysis of role-based delegation and revocation policies with UML and OCL},
journal = {Information and Software Technology},
author = {Sohr, Karsten and Kuhlmann, Mirco and Gogolla, Martin and Hu, Hongxin and Ahn, Gail-Joon},
volume = {54},
number = {12},
year = {2012},
pages = {1396 - 1417},
issn = {09505849},
abstract = {Context: Role-based access control (RBAC) has become the de facto standard for access management in various large-scale organizations. Often role-based policies must implement organizational rules to satisfy compliance or authorization requirements, e.g., the principle of separation of duty (SoD). To provide business continuity, organizations should also support the delegation of access rights and roles, respectively. This, however, makes access control more complex and error-prone, in particular, when delegation concepts interplay with SoD rules. Objective: A systematic way to specify and validate access control policies consisting of organizational rules such as SoD as well as delegation and revocation rules shall be developed. A domain-specific language for RBAC as well as delegation concepts shall be made available. Method: In this paper, we present an approach to the precise specification and validation of role-based policies based on UML and OCL. We significantly extend our earlier work, which proposed a UML-based domain-specific language for RBAC, by supporting delegation and revocation concepts. Result: We show the appropriateness of our approach by applying it to a banking application. In particular, we give three scenarios for validating the interplay between SoD rules and delegation/revocation. Conclusion: To the best of our knowledge, this is the first attempt to formalize advanced RBAC concepts, such as history-based SoD as well as various delegation and revocation schemes, with UML and OCL. With the rich tool support of UML, we believe our work can be employed to validate and implement real-world role-based policies. &copy; 2012 Elsevier B.V. All rights reserved.},
key = {Access control},
keywords = {Problem oriented languages;},
note = {Delegation;OCL;RBAC;Revocation;UML;},
URL = {http://dx.doi.org/10.1016/j.infsof.2012.06.008},
} 

@InProceedings{20134216854440,
  author    = {Sarimbekov, Aibek and Zheng, Yudi and Ansaloni, Danilo and Bulej, Lubomir and Marek, Luka and Binder, Walter and Tuma, Petr and Qi, Zhengwei},
  title     = {Productive development of dynamic program analysis tools with DiSL},
  year      = {2013},
  pages     = {11 - 19},
  address   = {Melbourne, VIC, Australia},
  note      = {Bytecode instrumentation;Controlled experiment;Development productivity;Domain specific languages;Dynamic program analysis;High-level abstraction;High-level programming;Program instrumentations;},
  abstract  = {Dynamic program analysis tools serve many important software engineering tasks such as profiling, debugging, testing, program comprehension, and reverse engineering. Many dynamic analysis tools rely on program instrumentation and are implemented using low-level instrumentation libraries, resulting in tedious and error-prone tool development. The recently released Domain-Specific Language for Instrumentation (DiSL) was designed to boost the productivity of tool developers targeting the Java Virtual Machine, without impairing the performance of the resulting tools. DiSL offers high-level programming abstractions especially designed for development of instrumentation-based dynamic analysis tools. In this paper, we present a controlled experiment aimed at quantifying the impact of the DiSL programming model and high-level abstractions on the development of dynamic program analysis instrumentations. The experiment results show that compared with a prevailing, state-of-the-art instrumentation library, the DiSL users were able to complete instrumentation development tasks faster, and with more correct results. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the Australian Software Engineering Conference, ASWEC},
  key       = {Instruments},
  keywords  = {Computer aided software engineering;Computer programming;Experiments;Problem oriented languages;Productivity;Reverse engineering;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ASWEC.2013.12},
}


@inproceedings{20124815732189,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Computer Applications for Software Engineering, Disaster Recovery, and Business Continuity - International Conferences, ASEA and DRBC 2012, Held in Conjunction with GST 2012, Proceedings},
journal = {Communications in Computer and Information Science},
volume = {340 CCIS},
year = {2012},
issn = {18650929},
address = {Jeju Island, Korea, Republic of},
abstract = {The proceedings contain 62 papers. The topics discussed include: impact on realistic mobility model for aircraft ad hoc networks; technology network model using bipartite social network analysis; mobile application development using component features and inheritance; view, level and fragment: commonalities in 'Architecture 101' and software modelling; highly analysable, reusable, and realisable architectural designs with XCD; ARSL: a domain specific language for aircraft separation minima determination; regression testing of object-oriented software: a technique based on use cases and associated tool; development of an instant meeting Android application using Wi-Fi direct APIs; developer support for understanding preprocessor macro expansions; towards building method level maintainability models based on expert evaluations; and a study on the improved stability of inverter through history management of semiconductor elements for power supply.},
} 

@InProceedings{20160101766113,
  author    = {Sakellariou, Ilias and Dranidis, Dimitris and Ntika, Marina and Kefalas, Petros},
  title     = {Stream X-machines for agent simulation test case generation},
  year      = {2015},
  volume    = {9494},
  pages     = {37 - 57},
  address   = {Lisbon, Portugal},
  note      = {Agent based simulation;Agent simulation platforms;Automated test case generation;Domain specific languages;Executable specifications;Multi agent simulation;NetLogo;Test case generation;},
  abstract  = {Applying the Stream X-Machine formal method in the development of multi-agent simulations has a number of significant advantages, since it combines the power of executable specifications and test case generation. The present work supports this argument by reporting on the combined use of two tools that involve Stream X-Machines (SXM): the first is a domain specific language for effortlessly encoding agent behaviour using SXMs in a well known agent simulation platform. The second tool, supports among other things, automated test case generation using SXMs. The main benefits of using the specific formal approach in such a practical setting is that it offers a clear intuitive way of specifying agent behaviour and the automated generation of &ldquo;agent simulation test scenarios&rdquo; that can be used for validation. &copy; Springer International Publishing Switzerland 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Formal methods},
  keywords  = {Artificial intelligence;Computer hardware description languages;Computer programming languages;Multi agent systems;Problem oriented languages;Testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-27947-3_3},
}

@InProceedings{20140317202765,
  author    = {Artho, Cyrille Valentin and Biere, Armin and Hagiya, Masami and Platon, Eric and Seidl, Martina and Tanabe, Yoshinori and Yamamoto, Mitsuharu},
  title     = {Modbat: A model-based API tester for event-driven systems},
  year      = {2013},
  volume    = {8244 LNCS},
  pages     = {112 - 128},
  address   = {Haifa, Israel},
  note      = {Abstract modeling;Domain specific languages;Event-driven system;Model based testing;Modeling features;Modeling notation;System under test;Test case derivations;},
  abstract  = {Model-based testing derives test executions from an abstract model that describes the system behavior. However, existing approaches are not tailored to event-driven or input/output-driven systems. In particular, there is a need to support non-blocking I/O operations, or operations throwing exceptions when communication is disrupted. Our new tool "Modbat" is specialized for testing systems where these issues are common. Modbat uses extended finite-state machines to model system behavior. Unlike most existing tools, Modbat offers a domain-specific language that supports state machines and exceptions as first-class constructs. Our model notation also handles non-determinism in the system under test, and supports alternative continuations of test cases depending on the outcome of non-deterministic operations. These features allow us to model a number of interesting libraries succinctly. Our experiments show the flexibility of Modbat and how language support for model features benefits their correct use. &copy; 2013 Springer International Publishing Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Software testing},
  keywords  = {Problem oriented languages;Tools;Verification;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-03077-7-8},
}

@InProceedings{20142517844422,
  author    = {Wu, Shaoqun and Fitzgerald, Alannah and Witten, Ian H.},
  title     = {Second language learning in the context of MOOCs},
  year      = {2014},
  volume    = {1},
  pages     = {354 - 359},
  address   = {Barcelona, Spain},
  note      = {English for academic purposes;Language learning;MOOCs;Open educational resources;Second language;},
  abstract  = {Massive Open Online Courses are becoming popular educational vehicles through which universities reach out to non-traditional audiences. Many enrolees hail from other countries and cultures, and struggle to cope with the English language in which these courses are invariably offered. Moreover, most such learners have a strong desire and motivation to extend their knowledge of academic English, particularly in the specific area addressed by the course. Online courses provide a compelling opportunity for domain-specific language learning. They supply a large corpus of interesting linguistic material relevant to a particular area, including supplementary images (slides), audio and video. We contend that this corpus can be automatically analysed, enriched, and transformed into a resource that learners can browse and query in order to extend their ability to understand the language used, and help them express themselves more fluently and eloquently in that domain. To illustrate this idea, an existing online corpus-based language learning tool (FLAX) is applied to a Coursera MOOC entitled Virology 1: How Viruses Work, offered by Columbia University.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {CSEDU 2014 - Proceedings of the 6th International Conference on Computer Supported Education},
  key       = {E-learning},
  keywords  = {Education;Flax;Linen;Precipitation (meteorology);Problem oriented languages;Yarn;},
  language  = {English},
}


@inproceedings{20123215325275,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Leveraging formal verification techniques for design-time animation of reactive control programs},
journal = {Proceedings of the IASTED International Conference on Human-Computer Interaction, HCI 2012},
author = {Prahofer, Herbert and Hurnaus, Dominik},
year = {2012},
pages = {293 - 300},
address = {Baltimore, MD, United states},
abstract = {In industrial automation, end users, who usually have no or only limited programming expertise, often need tochange and adapt the control program at hand. This results in high demands on end-user programminenvironments with respect to supporting, guiding, ansupervising end users. In the project MONACO, wdeveloped a domain-specific language and respectivetools for end-user programmers. In particular, wdeveloped a verification technique and semantic assistance tools for preventing end users from introducingsemantic errors that violate specified contracts andconstraints. In this paper, we present a further tool for supporting end users. The knowledge derived in the verification algorithm about states at particular codepositions is leveraged in a design-time animation toolwhich displays the possible states of the machine. Hencean end user can gain an intuitive understanding of thprogram and assess the consequences of program changesalready at design time and without conducting test run.},
key = {Human computer interaction},
keywords = {Animation;Computer programming;Design;Knowledge management;Model checking;Problem oriented languages;Semantics;Software testing;},
note = {Conducting tests;Control program;Design time;Domain specific languages;End user programmers;End user programming;End users;Formal verifications;High demand;Industrial automation;Intuitive understanding;Reactive control;Verification algorithms;Verification techniques;},
URL = {http://dx.doi.org/10.2316/P.2012.772-016},
} 

@InProceedings{20155201717727,
  author    = {Sergey, Ilya and Nanevski, Aleksandar and Banerjee, Anindya},
  title     = {Mechanized verification of fine-grained concurrent programs},
  year      = {2015},
  volume    = {50},
  number    = {6},
  pages     = {77 - 87},
  note      = {Concurrency;Dependent types;Mechanized proofs;Program Verification;Separation logic;},
  abstract  = {Efficient concurrent programs and data structures rarely employ coarse-grained synchronization mechanisms (i.e., locks); instead, they implement custom synchronization patterns via fine-grained primitives, such as compare-and-swap. Due to sophisticated interference scenarios between threads, reasoning about such programs is challenging and error-prone, and can benefit from mechanization. In this paper, we present the first completely formalized framework for mechanized verification of full functional correctness of fine-grained concurrent programs. Our tool is based on the recently proposed program logic FCSL. It is implemented as an embedded domain-specific language in the dependently-typed language of the Coq proof assistant, and is powerful enough to reason about programming features such as higher-order functions and local thread spawning. By incorporating a uniform concurrency model, based on state-transition systems and partial commutative monoids, FCSL makes it possible to build proofs about concurrent libraries in a thread-local, compositional way, thus facilitating scalability and reuse: libraries are verified just once, and their specifi-cations are used ubiquitously in client-side reasoning. We illustrate the proof layout in FCSL by example, and report on our experience of using FCSL to verify a number of concurrent programs. &copy; 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {15232867},
  journal   = {ACM SIGPLAN Notices},
  key       = {Concurrency control},
  keywords  = {Computational linguistics;Computer programming languages;Formal logic;Graphical user interfaces;Libraries;Machinery;Problem oriented languages;Theorem proving;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2737924.2737964},
}

@InProceedings{20155201732790,
  author    = {Sergey, Ilya and Nanevski, Aleksandar and Banerjee, Anindya},
  title     = {Mechanized verification of fine-grained concurrent programs},
  year      = {2015},
  volume    = {2015-June},
  pages     = {77 - 87},
  address   = {Portland, OR, United states},
  note      = {Concurrency;Dependent types;Mechanized proofs;Program Verification;Separation logic;},
  abstract  = {Efficient concurrent programs and data structures rarely employ coarse-grained synchronization mechanisms (i.e., locks); instead, they implement custom synchronization patterns via fine-grained primitives, such as compare-and-swap. Due to sophisticated interference scenarios between threads, reasoning about such programs is challenging and error-prone, and can benefit from mechanization. In this paper, we present the first completely formalized framework for mechanized verification of full functional correctness of fine-grained concurrent programs. Our tool is based on the recently proposed program logic FCSL. It is implemented as an embedded domain-specific language in the dependently-typed language of the Coq proof assistant, and is powerful enough to reason about programming features such as higher-order functions and local thread spawning. By incorporating a uniform concurrency model, based on state-transition systems and partial commutative monoids, FCSL makes it possible to build proofs about concurrent libraries in a thread-local, compositional way, thus facilitating scalability and reuse: libraries are verified just once, and their specifications are used ubiquitously in client-side reasoning. We illustrate the proof layout in FCSL by example, and report on our experience of using FCSL to verify a number of concurrent programs. &copy; 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
  key       = {Concurrency control},
  keywords  = {Computational linguistics;Computer programming languages;Formal logic;Graphical user interfaces;Libraries;Machinery;Problem oriented languages;Theorem proving;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2737924.2737964},
}

@InProceedings{20130515966438,
  author    = {Schivo, Stefano and Scholma, Jetse and Wanders, Brend and Camacho, Ricardo A. Urquidi and Van Der Vet, Paul E. and Karperien, Marcel and Langerak, Rom and Van De Pol, Jaco and Post, Janine N.},
  title     = {Modelling biological pathway dynamics with Timed Automata},
  year      = {2012},
  pages     = {447 - 453},
  address   = {Larnaca, Cyprus},
  note      = {Biological cells;Biological interactions;Biological networks;Biological pathways;Cell behaviours;Complex interaction;Discretizations;Domain specific languages;Dynamic behaviours;Event model;Executable model;Expressive power;Formal Semantics;Growth factor;Signalling molecules;Signalling network;Signalling pathways;Timed Automata;Uppaal model checkers;User friendly interface;},
  abstract  = {When analysing complex interaction networks occurring in biological cells, a biologist needs computational support in order to understand the effects of signalling molecules (e.g. growth factors, drugs). ANIMO (Analysis of Networks with Interactive MOdelling) is a tool that allows the user to create and explore executable models of biological networks, helping to derive hypotheses and to plan wet-lab experiments. The tool is based on the formalism of Timed Automata, which can be analysed via the UPPAAL model checker. Thanks to Timed Automata, we can provide a formal semantics for the domain-specific language used to represent signalling networks. This enforces precision and uniformity in the definition of signalling pathways, contributing to the integration of signalling event models into complex, crosstalk-driven networks. We propose an approach to discretization of reaction kinetics that allows us to efficiently use UPPAAL as the computational engine to explore the dynamic cell behaviour. A user friendly interface makes the use of Timed Automata completely transparent to the biologist, while keeping the expressive power intact. This allows to define relatively simple, yet faithful models of complex biological interactions. The resulting timed behaviour is displayed graphically, allowing for an intuitive and interactive modelling experience. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {IEEE 12th International Conference on BioInformatics and BioEngineering, BIBE 2012},
  key       = {Automata theory},
  keywords  = {Behavioral research;Bioinformatics;Model checking;Models;Problem oriented languages;Reaction kinetics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/BIBE.2012.6399719},
}

@InProceedings{20161402189735,
  author    = {Bautista, Efrain and La Serna, Nora},
  title     = {An MDE-based graphical tool for the validation of MySQL replication models},
  year      = {2015},
  address   = {Arequipa, Peru},
  note      = {Automatic validation;Error prones;Errors correction;GraphicaL model;Graphical tools;MicroSoft;MySQL Replication;Replication models;},
  abstract  = {At modeling level, diagramming tools such as Microsoft Visio are used to design MySQL replication models. However, this type of tools do not allow validating if the MySQL replication model is free of errors, showing errors if exists. Thus, we can have erroneous documentation of the MySQL replication models. Due to the lack of this feature, this is done manually, which becomes a tedious task, time consuming and error prone. This paper proposes a MDE-based graphical modeling tool under the Eclipse platform for the automatic validation of MySQL replication models. In addition, once a model has been validated, the tool is capable of generating the mysqlreplicate commands of configuration. The results of the experiments for the errors correction of MySQL replication models with 25 servers demonstrate that by using the proposed tool the time is reduced in more than 87% compared with the tool Microsoft Visio 2013. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings - 2015 41st Latin American Computing Conference, CLEI 2015},
  key       = {Errors},
  keywords  = {DSL;Windows operating system;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/CLEI.2015.7360009},
}

@Article{20122115055821,
  author    = {Garcia-Diaz, V. and G-Bustelo, B.C. Pelayo and Sanjuan-Martinez, O. and Valdez, E.R. Nunez and Lovelle, J.M. Cueva},
  title     = {MCTest: Towards an improvement of match algorithms for models},
  journal   = {IET Software},
  year      = {2012},
  volume    = {6},
  number    = {2},
  pages     = {127 - 139},
  note      = {Domain specific languages;Eclipse modelling frameworks;Meta model;Model-driven Engineering;Modeling project;Software systems;},
  abstract  = {Owing to the increasing importance of model-driven engineering (MDE) and the changes experienced by software systems over their life cycle, the calculation, representation and visualisation of matches and differences between two different versions of the same model are becoming more necessary and useful. This study shows the need for improvement in the algorithms for calculating the relationships between models and presents a tool to test different implementations, thus reducing the effort required to measure, compare or create new algorithms. To demonstrate the need for improvement and the framework developed, the authors have created different models that conform to the metamodel of a domain-specific language. Subsequently, the authors compared these models using the algorithms of the eclipse modelling framework (EMF) Compare tool, part of the eclipse modeling project, which is the framework of reference for MDE. Thus, in the case study, the authors tool is used to measure the quality of the comparisons performed by EMF Compare. &copy; 2012 The Institution of Engineering and Technology.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {17518806},
  key       = {Mathematical models},
  keywords  = {Algorithms;Java programming language;Problem oriented languages;Visualization;},
  language  = {English},
  url       = {http://dx.doi.org/10.1049/iet-sen.2011.0040},
}


@inproceedings{20160601908447,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Generating the blueprints of the Java ecosystem},
journal = {IEEE International Working Conference on Mining Software Repositories},
author = {Karakoidas, Vassilios and Mitropoulos, Dimitrios and Louridas, Panos and Gousios, Georgios and Spinellis, Diomidis},
volume = {2015-August},
year = {2015},
pages = {510 - 513},
issn = {21601852},
address = {Florence, Italy},
abstract = {Examining a large number of software artifacts can provide the research community with data regarding quality and design. We present a dataset obtained by statically analyzing 22730 jar files taken from the Maven central archive, which is the de-facto application library repository for the Java ecosystem. For our analysis we used three popular static analysis tools that calculate metrics regarding object-oriented design, program size, and package design. The dataset contains the metrics results that every tool reports for every selected jar of the ecosystem. Our dataset can be used to produce interesting research results, such as measure the domain-specific language usage. &copy; 2015 IEEE.},
key = {Object oriented programming},
keywords = {Computer programming languages;Computer software;Ecology;Ecosystems;Java programming language;Problem oriented languages;Static analysis;},
note = {Chidamber and Kemerer;Domain specific languages;Java;Maven;Object oriented design;Research communities;Software artifacts;Software metrics;},
URL = {http://dx.doi.org/10.1109/MSR.2015.76},
} 

@InProceedings{20142817930685,
  author    = {Ecker, Wolfgang and Velten, Michael and Zafari, Leily and Goyal, Ajay},
  title     = {The metamodeling approach to system level synthesis},
  year      = {2014},
  pages     = {ACM-SIGDA; ECSI; EDA Consortium (EDAC); European Design and Automation Association (EDAA); IEEE Council on Electronic Design Automation (CEDA); Russian Academy of Sciences (RAS) -},
  address   = {Dresden, Germany},
  note      = {Code Generation;Design consistency;Document structure;Domain specific languages;Meta-modeling technique;Metamodeling;Specific languages;System level synthesis;},
  abstract  = {This paper presents an industry proven Metamodeling based approach to System-Level-Synthesis which is seen as generic design automation strategy above today's implementation levels RTL (for digital) and Schematic Entry (for analog). The approach follows a new synthesis paradigm: The designer develops a simple domain and/or design specific language and a smart tool synthesizing implementation level models according to its needs. The overhead of making both a tool and a model pays off since the tool building is automated by code generation and reuse, both based on Metamodeling techniques. Also the focus on owns demand keeps development costs low. Finally, specification data is utilized. I.e. the domain specific language simplifies to a document structure as a table. This keeps also modeling effort low since specification content is used and no model need to be built. Furthermore, increases design consistency and thus decreases debug time. Using these concepts, single design steps have been speed up to a factor of 20x and implementations of chips (specification-to-tapeout) have been speed up to a factor of 3x. &copy; 2014 EDAA.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {15301591},
  journal   = {Proceedings -Design, Automation and Test in Europe, DATE},
  key       = {Structural design},
  keywords  = {Automation;Computer aided design;Computer programming languages;Multiprocessing systems;Network components;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.7873/DATE2014.324},
}

@Article{20143600042103,
  author    = {Puente, Gorka and Diaz, Oscar and Azanza, Maider},
  title     = {Refactoring affordances in corporate wikis: a case for the use of mind maps},
  journal   = {Enterprise Information Systems},
  year      = {2015},
  volume    = {9},
  number    = {8},
  pages     = {785 - 834},
  note      = {Affordances;Corporate wikis;FreeMind;MediaWiki;Mind maps;Refactorings;},
  abstract  = {The organisation of corporate wikis tends to deteriorate as time goes by. Rearranging categories, structuring articles and even moving sections among articles are cumbersome tasks in current wiki engines. This discourages the layman. But, it is the layman who writes the articles, knows the wiki content and detects refactoring opportunities. Our goal is to improve the refactoring affordances of current wiki engines by providing an alternative front-end tuned to refactoring. This is achieved by (1) surfacing the structure of the wiki corpus as a mind map, and (2) conducting refactoring as mind map reshaping. To this end, we introduce WikiWhirl, a domain-specific language for wiki refactoring. WikiWhirl is supported as an extension of FreeMind, a popular mind mapping tool. In this way, refactoring operations are intuitively conducted as actions upon mind map nodes. In a refactoring session a user imports the wiki structure as a FreeMind map; next, conducts the refactoring operations on the map, and finally, the effects are saved in the wiki database. The operational semantics of the WikiWhirl operations follow refactoring good practices (e.g., authorship preservation). Results from a controlled experiment suggest that WikiWhirl outperforms MediaWiki in three main affordance enablers: understandability, productivity and fulfillment of refactoring good practices. &copy; 2013, &copy; 2013 Taylor & Francis.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {17517575},
  key       = {Schematic diagrams},
  keywords  = {Computer aided software engineering;Computer programming languages;Computer software;Engines;Problem oriented languages;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1080/17517575.2013.830343},
}

@Article{20142117749949,
  author    = {Schivo, Stefano and Scholma, Jetse and Wanders, Brend and Camacho, Ricardo A.Urquidi and Van Der Vet, Paul E. and Karperien, Marcel and Langerak, Rom and Van De Pol, Jaco and Post, Janine N.},
  title     = {Modeling biological pathway dynamics with timed automata},
  journal   = {IEEE Journal of Biomedical and Health Informatics},
  year      = {2014},
  volume    = {18},
  number    = {3},
  pages     = {832 - 839},
  note      = {Complex network models;Construction of models;Domain specific languages;Dynamic behaviors;Interconnected network;Signaling pathways;Timed Automata;User friendly interface;},
  abstract  = {Living cells are constantly subjected to a plethora of environmental stimuli that require integration into an appropriate cellular response. This integration takes place through signal transduction events that form tightly interconnected networks. The understanding of these networks requires capturing their dynamics through computational support and models. ANIMO (analysis of Networks with Interactive Modeling) is a tool that enables the construction and exploration of executable models of biological networks, helping to derive hypotheses and to plan wet-lab experiments. The tool is based on the formalism of Timed Automata, which can be analyzed via the UPPAAL model checker. Thanks to Timed Automata, we can provide a formal semantics for the domain-specific language used to represent signaling networks. This enforces precision and uniformity in the definition of signaling pathways, contributing to the integration of isolated signaling events into complex network models. We propose an approach to discretization of reaction kinetics that allows us to efficiently use UPPAAL as the computational engine to explore the dynamic behavior of the network of interest. A user-friendly interface hides the use of Timed Automata from the user, while keeping the expressive power intact. Abstraction to single-parameter kinetics speeds up construction of models that remain faithful enough to provide meaningful insight. The resulting dynamic behavior of the network components is displayed graphically, allowing for an intuitive and interactive modeling experience. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {21682194},
  key       = {Automata theory},
  keywords  = {Integration;Model checking;Models;Pigments;Problem oriented languages;Reaction kinetics;Signal transduction;Signaling;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/JBHI.2013.2292880},
}

@InProceedings{20120814792304,
  author    = {Klein, Casey and Clements, John and Dimoulas, Christos and Eastlund, Carl and Felleisen, Matthias and Flatt, Matthew and McCarthy, Jay A. and Rafkind, Jon and Sam, Tobin-Hochstadt and Findler, Robert Bruce},
  title     = {Run your research: On the effectiveness of lightweight mechanization},
  year      = {2012},
  volume    = {47},
  number    = {1},
  pages     = {285 - 296},
  note      = {Domain specific languages;Formal model;Language design;Language tools;Program analysis;Programming language;Semantic Model;Work-flows;},
  abstract  = {Formal models serve in many roles in the programming language community. In its primary role, a model communicates the idea of a language design; the architecture of a language tool; or the essence of a program analysis. No matter which role it plays, however, a faulty model doesn't serve its purpose. One way to eliminate flaws from a model is to write it down in a mechanized formal language. It is then possible to state theorems about the model, to prove them, and to check the proofs. Over the past nine years, PLT has developed and explored a lightweight version of this approach, dubbed Redex. In a nutshell, Redex is a domain-specific language for semantic models that is embedded in the Racket programming language. The effort of creating a model in Redex is often no more burdensome than typesetting it with LaTeX; the difference is that Redex comes with tools for the semantics engineering life cycle. In this paper we report on a validation of this form of lightweight mechanization. The largest part of this validation concerns the formalization and exploration of nine ICFP 2009 papers in Redex, an effort that uncovered mistakes in all nine papers. The results suggest that Redex-based lightweight modeling is effective and easy to integrate into the work flow of a semantics engineer. This experience also suggests lessons for the developers of other mechanization tools. &copy; 2012 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {15232867},
  journal   = {ACM SIGPLAN Notices},
  key       = {Machinery},
  keywords  = {Computer programming languages;Formal languages;Mechanization;Problem oriented languages;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2103621.2103691},
}

@InProceedings{20121114843704,
  author    = {Klein, Casey and Clements, John and Dimoulas, Christos and Eastlund, Carl and Felleisen, Matthias and Flatt, Matthew and McCarthy, Jay A. and Rafkind, Jon and Tobin-Hochstadt, Sam and Findler, Robert Bruce},
  title     = {Run your research: On the effectiveness of lightweight mechanization},
  year      = {2012},
  pages     = {285 - 296},
  address   = {Philadelphia, PA, United states},
  note      = {Domain specific languages;Formal model;Language design;Language tools;Program analysis;Semantic Model;Work-flows;},
  abstract  = {Formal models serve in many roles in the programming language community. In its primary role, a model communicates the idea of a language design; the architecture of a language tool; or the essence of a program analysis. No matter which role it plays, however, a faulty model doesn't serve its purpose. One way to eliminate flaws from a model is to write it down in a mechanized formal language. It is then possible to state theorems about the model, to prove them, and to check the proofs. Over the past nine years, PLT has developed and explored a lightweight version of this approach, dubbed Redex. In a nutshell, Redex is a domain-specific language for semantic models that is embedded in the Racket programming language. The effort of creating a model in Redex is often no more burdensome than typesetting it with LaTeX; the difference is that Redex comes with tools for the semantics engineering life cycle. In this paper we report on a validation of this form of lightweight mechanization. The largest part of this validation concerns the formalization and exploration of nine ICFP 2009 papers in Redex, an effort that uncovered mistakes in all nine papers. The results suggest that Redex-based lightweight modeling is effective and easy to integrate into the work flow of a semantics engineer. This experience also suggests lessons for the developers of other mechanization tools. Copyright &copy; 2012 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {07308566},
  journal   = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
  key       = {Machinery},
  keywords  = {Computer programming languages;Formal languages;Mechanization;Problem oriented languages;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2103656.2103691},
}

@Article{20122215059602,
  author    = {Iglberger, Klaus and Hager, Georg and Treibig, Jan and Rude, Ulrich},
  title     = {Expression templates revisited: A performance analysis of current methodologies},
  journal   = {SIAM Journal on Scientific Computing},
  year      = {2012},
  volume    = {34},
  number    = {2},
  pages     = {C42 - C69},
  note      = {Blaze;Blitz++;Boost;Eigen3;Expression templates;High performance programming;MTL4;Performance optimizations;UBLAS;},
  abstract  = {In the last decade, expression templates (ETs) have gained a reputation as an efficient performance optimization tool for C++ codes. This reputation builds on several ET-based linear algebra frameworks focused on combining both elegant and high-performance C++ code. However, on closer examination the assumption that ETs are a performance optimization technique cannot be maintained. In this paper we compare the performance of several generations of ET-based frameworks. We analyze different ET methodologies and explain the inability of some ET implementations to deliver high performance for dense and sparse linear algebra operations. Additionally, we introduce the notion of "smart" ETs, which truly allow for a combination of high performance code with the elegance and maintainability of a domain-specific language. &copy; 2012 Society for Industrial and Applied Mathematics.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {10648275},
  key       = {Object oriented programming},
  keywords  = {Linear algebra;Maintainability;Optimization;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1137/110830125},
}

@Article{20150600497288,
  author    = {Skersys, Tomas and Pavalkis, Saulius and Lagzdinyte-Budnike, Ingrida},
  title     = {Model-driven approach and implementation of partial model-to-model transformations in a CASE tool},
  journal   = {Communications in Computer and Information Science},
  year      = {2014},
  volume    = {465},
  pages     = {260 - 271},
  note      = {Capability requirements;Development process;Drag and drop;MDA;Model driven approach;Model driven architectures;Model to model transformation;Uml profiles;},
  abstract  = {One of the main features of Model Driven Architecture is a model-to-model (M2M) transformations, which improve the overall model-driven systems development process by speeding up the development process itself and also enabling the reusability of the existing models within a single or even multiple projects. However, CASE tool-supported M2M transformations quite often lack so needed flexibility and customization options. The main goal of this paper is to present a practical model-driven approach to improve the usability of partial model-to-model transformations in a CASE tool environment. The approach is currently implemented in the CASE tool MagicDraw; however, it can be adopted by any other CASE tool that meets certain capability requirements. &copy; Springer International Publishing Switzerland 2014.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {18650929},
  key       = {Software architecture},
  keywords  = {Computer aided software engineering;DSL;Reusability;Software design;},
  language  = {English},
}

@InProceedings{20160501875959,
  author    = {Silvestre, Luis},
  title     = {Automatic generation of transformations for software process tailoring},
  year      = {2015},
  volume    = {1503},
  pages     = {46 - 51},
  address   = {Ottawa, ON, Canada},
  note      = {Automatic Generation;Current transformation;Domain specific languages;Model-driven Engineering;Small software enterprise;Software company;Software industry;Software process tailoring;},
  abstract  = {Tailoring software processes is an activity that allows process engineers to adapt organizational software processes to the needs of particular projects. Model-driven engineering (MDE) has been used for tailoring software processes using models and transformations. Even though there are some proposals for automatically generating part of the transformations, they are not easily applicable in the software industry because there are still factors that jeopardize its usage in small software enterprises. First, the potential users-process engineers-do not usually have the required knowledge for writing transformations. Second, current transformation languages and tools are not simple for defining and applying tailoring transformations. Trying to deal with these challenges, this research proposes a tool-set that balances the formality required by MDE and the usability needed by the users. We define a domain-specific language for defining tailoring rules. These rules are the input for a higher-order transformation that automatically generates tailoring transformations with no direct user interaction with the code. The tool-set reduces the complexity of defining tailoring rules and allows for the automatic generation of tailoring transformations. We illustrate the application of our approach in a small Chilean software company.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {Application programs},
  keywords  = {Computational linguistics;Computer programming languages;Graphical user interfaces;Problem oriented languages;Software design;Software engineering;},
  language  = {English},
}

@InProceedings{20161002077055,
  author    = {Sun, Wei-Tsun and Girault, Alain and Delaval, Gwenael},
  title     = {A formal approach for the synthesis and implementation of fault-tolerant industrial embedded systems},
  year      = {2015},
  pages     = {264 - 273},
  address   = {Siegen, Germany},
  note      = {Correct-by-construction;Discrete controller synthesis;Distributed embedded system;Distributed systems;Domain specific languages;Fault tolerant systems;Integrated circuit modeling;Processor failures;},
  abstract  = {We demonstrate the feasibility of a complete workflow to synthesize and implement correct-by-construction fault tolerant distributed embedded systems consisting of real-time periodic tasks. Correct-by-construction is provided by the use of discrete controller synthesis (DCS), a formal method thanks to which we are able to guarantee that the synthesized controlled system guarantees the functionality of its tasks even in the presence of processor failures. For this step, our workflow uses the Heptagon domain specific language and the Sigali DCS tool. The correct implementation of the resulting distributed system is a challenge, all the more since the controller itself must be tolerant to the processor failures. We achieve this step thanks to the libDGALS realtime library (1) to generate the glue code that will migrate the tasks upon processor failures, maintaining their internal state through migration, and (2) to make the synthesized controller itself fault-tolerant. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {2015 10th IEEE International Symposium on Industrial Embedded Systems, SIES 2015 - Proceedings},
  key       = {Embedded systems},
  keywords  = {Computer programming languages;Contracts;Control systems;Controllers;Digital libraries;Energy utilization;Fault tolerance;Fault tolerant computer systems;Formal methods;Problem oriented languages;Process control;Real time systems;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SIES.2015.7185068},
}

@InProceedings{20163802810636,
  author    = {Dziwok, Stefan and Gerking, Christopher and Becker, Steffen and Thiele, Sebastian and Heinzemann, Christian and Pohlmann, Uwe},
  title     = {A tool suite for the model-driven software engineering of cyber-physical systems},
  year      = {2014},
  volume    = {16-21-November-2014},
  pages     = {715 - 718},
  address   = {Hong Kong, China},
  note      = {Cyber physical systems (CPSs);Mechatronic systems;Real time coordination;System simulations;Timed model checking;},
  abstract  = {Cyber-physical systems, e.g., autonomous cars or trains, interact with their physical environment. As a consequence, they commonly have to coordinate with other systems via complex message communication while realizing safety-critical and real-time tasks. As a result, those systems should be correct by construction. Software architects can achieve this by using the MECHATRONICUML process and language. This paper presents the MECHATRONICUML TOOL SUITE that offers unique features to support the MECHATRONICUML modeling and analyses tasks. Copyright 2014 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
  key       = {Real time systems},
  keywords  = {DSL;Embedded systems;Model checking;Safety engineering;Software architecture;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2635868.2661665},
}

@InProceedings{20163502761133,
  author    = {Opila, J.},
  title     = {Prototyping of visualization designs of 3D vector fields using POVRay rendering engine},
  year      = {2016},
  pages     = {343 - 348},
  address   = {Opatija, Croatia},
  note      = {Domain specific languages;Exploratory visualizations;Pov rays;Scene description languages;ScPovPlot3D;Vector field visualizations;Visual data analysis;Visualization designs;},
  abstract  = {There is a persistent quest for novel methods of visualization in order to get insight into complex phenomena in variety of scientific domains. Researchers, ex. VTK team, achieved excellent results; however, some problems connected with implementation of new techniques and quality of the final images still persist. Results of inspection of number of visualization styles of 3D vector field employing POVRay ray-tracing engine are discussed, i.e. hedgehogs, oriented glyphs, streamlines, isosurface component approach and texturing design. All styles presented have been tested using water molecule model and compared concerning computing time, informativeness and general appearance. It is shown in the work that Scene Description Language (SDL), domain specific language implemented in POVRay is flexible enough to use it as a tool for fast prototyping of novel and exploratory visualization techniques. Visualizations discussed in the paper were computed using selected components of API of ScPovPlot3D, i.e. templates written in the SDL language. Results are compared to designs already implemented in VTK. &copy; 2016 Croatian Society MIPRO.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {2016 39th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2016 - Proceedings},
  key       = {Three dimensional computer graphics},
  keywords  = {Computational linguistics;Computer programming languages;Data visualization;Engines;Microelectronics;Molecules;Problem oriented languages;Ray tracing;Rendering (computer graphics);Visualization;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/MIPRO.2016.7522164},
}

@InProceedings{20133716731528,
  author    = {Ogunshile, E. and Saaj, C. and Chhaniyara, S. and Wang, X. and Langef, C. and Findlay, R.},
  title     = {Application of model based systems engineering for an asteroid lander},
  year      = {2012},
  volume    = {10},
  pages     = {8445 - 8453},
  address   = {Naples, Italy},
  note      = {Domain specific languages;Functional modelling;Integrated development;Levels of abstraction;Model-based systems engineering;Model-based systems engineering (MBSE);Platform independent;Rapid transformations;},
  abstract  = {Surface exploration of asteroids is scientifically important for understanding of the origin and history of our solar system. Space agencies all over the world have started to launch exploration missions to asteroids. Low cost, small - sized landers with some capability to move on the surface of an asteroid would be highly suitable for in-situ observations. This paper primarily proposes on Model Based Systems Engineering (MBSE) tool to handle the functional modelling of a class of small-scaled asteroid lander that would have requirements similar to the Mobile Asteroid Surface Scout (MASCOT) mission from the German Aerospace Centre (DLR). The latter aims at developing a landing package for the Hayabusa-2 mission. In this paper, System Modelling Language (SysML) is selected as the domain-specific language, and the lander system context is developed in the integrated development environmental (IDE) of IBM Rational Rhapsody. The proposed unified functional modelling tool is platform independent. It covers a wide range of features for the lander system under consideration and proposes a clear decomposition of its functionalities. This MBSE approach can be easily adapted for other asteroid landers. Through this approach, systems engineers would make a rapid transformation from stakeholders' requirements to a functional model. To this end, the proposed MBSE approach allows systems engineers and associated stakeholders at varying levels to define a number of common and basic lander scenarios derived from different levels of abstractions of the model system under test (i.e. the MASCOT lander). Furthermore, this proposed MBSE technique offers a structured and well-formed set of script templates for the lander model execution. Thus, allowing system engineers and stakeholders the privilege to verify, test and validate all functional, systems and interfacing requirements in a timely and efficient manner at varying stages in the project lifecycle. Further, the use of the animation feature of the Rational Rhapsody IDE to engineer the acquisition of visualised levels of detail for all SysML model elements and their respective executions will be presented. Finally, to further show that the theoretical purity of the proposed MBSE approach does not mitigate against practical concerns, this approach is exemplified in a SysML model implementation of a shadow mission scenario the MASCOT lander.&copy;2012 by the International Astronautical Federation.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {00741795},
  journal   = {Proceedings of the International Astronautical Congress, IAC},
  key       = {Asteroids},
  keywords  = {Animation;Engineers;Integrodifferential equations;Problem oriented languages;Systems engineering;Tools;},
  language  = {English},
}


@inproceedings{20124515646759,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Leveraging formal verification tools for DSML users: A process modeling case study},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Zalila, Faiez and Cregut, Xavier and Pantel, Marc},
volume = {7610 LNCS},
number = {PART 2},
year = {2012},
pages = {329 - 343},
issn = {03029743},
address = {Heraklion, Crete, Greece},
abstract = {In the last decade, Model Driven Engineering (MDE) has been used to improve the development of safety critical systems by providing early Validation and Verification (V&amp;V) tools for Domain Specific Modeling Languages (DSML). Verification of behavioral models is mainly addressed by translating domain specific models to formal verification dedicated languages in order to use the sophisticated associated tools such as model-checkers. This approach has been successfully applied in many different contexts, but it has a major drawback: the user has to interact with the formal tools. In this paper, we present an illustrated approach that allows the designer to formally express the expected behavioral properties using a user oriented language - a temporal extension of OCL -, that is automatically translated into the formal language; and then to get feedback from the assessment of these properties using its domain language without having to deal with the formal verification language nor with the underlying translational semantics. This work is based on the metamodeling pattern for executable DSML that extends the DSML metamodel to integrate concerns related to execution and behavior. &copy; 2012 Springer-Verlag.},
key = {Translation (languages)},
keywords = {Computer aided software engineering;Embedded systems;Formal languages;Model checking;Semantics;},
note = {Associated tool;Behavioral model;Behavioral properties;Domain language;Domain specific;Domain specific modeling languages;Formal tools;Formal verification tools;Formal verifications;Meta model;Metamodeling patterns;Model-driven Engineering;Process Modeling;Safety critical systems;Temporal extensions;User oriented;Validation and verification;},
URL = {http://dx.doi.org/10.1007/978-3-642-34032-1_34},
} 

@Article{20154101365722,
  author    = {Tafazzoli, Nima},
  title     = {Methods, Computational Platform, Verification, and Application of Earthquake-Soil-Structure-Interaction Modeling and Simulation},
  journal   = {ProQuest Dissertations and Theses Global},
  year      = {2012},
  note      = {Computational platforms;Domain specific languages;Energy dissipation mechanism;Foundation embedments;Full three-dimensional;Soil structure system;Structural excitation;Verification-and-validation;},
  abstract  = {Seismic response of soil-structure systems has attracted significant attention for a long time. This is quite understandable with the size and the complexity of soil-structure systems. The focus of three important aspects of ESSI modeling could be on consistent following of input seismic energy and a number of energy dissipation mechanisms within the system, numerical techniques used to simulate dynamics of ESSI, and influence of uncertainty of ESSI simulations. This dissertation is a contribution to development of one such tool called ESSI Simulator. The work is being done on extensive verified and validated suite for ESSI Simulator. Verification and validation are important for high fidelity numerical predictions of behavior of complex systems. This simulator uses finite element method as a numerical tool to obtain solutions for large class of engineering problems such as liquefaction, earthquake-soil-structure-interaction, site effect, piles, pile group, probabilistic plasticity, stochastic elastic-plastic FEM, and detailed large scale parallel models. Response of full three-dimensional soil-structure-interaction simulation of complex structures is evaluated under the 3D wave propagation. Domain-Reduction-Method is used for applying the forces as a two-step procedure for dynamic analysis with the goal of reducing the large size computational domain. The issue of damping of the waves at the boundary of the finite element models is studied using different damping patterns. This is used at the layer of elements outside of the Domain-Reduction-Method zone in order to absorb the residual waves coming out of the boundary layer due to structural excitation. Extensive parametric study is done on dynamic soil-structure-interaction of a complex system and results of different cases in terms of soil strength and foundation embedment are compared. High efficiency set of constitutive models in terms of computational time are developed and implemented in ESSI Simulator. Efficiency is done based on simplifying the elastic-plastic stiffness tensor of the constitutive models. Almost in all the soil-structure systems, there are interface zones in contact with each other. These zones can get detached during the loading or can slip on each other. In this dissertation the frictional contact element is implemented in ESSI Simulator. Extended verification has been done on the implemented element. The interest here is the effect of slipping and gap opening at the interface of soil and concrete foundation on the soil-structure system behavior. In fact transferring the loads to structure is defined based on the contact areas which will affect the response of the system. The effect of gap openings and sliding at the interfaces are shown through application examples. In addition, dissipation of the seismic energy due to frictional sliding of the interface zones are studied. Application Programming Interface (API) and Domain Specific Language (DSL) are being developed to increase developer's and user's modeling and simulation capabilities. API describes software services developed by developers that are used by users. A domain-specific language (DSL) is a small language which usually focuses on a particular problem domain in software. In general DSL programs are translated to a common function or library which can be viewed as a tool to hide the details of the programming, and make it easier for the user to deal with the commands. ProQuest Subject Headings: Civil engineering, Geophysics.  &copy; Citation reproduced with permission of ProQuest LLC.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  key       = {Finite element method},
  keywords  = {Application programming interfaces (API);Boundary layers;Computational linguistics;Computer programming languages;Constitutive models;Damping;Earthquakes;Elastoplasticity;Energy dissipation;Friction;Geophysics;Large scale systems;Modeling languages;Numerical methods;Piles;Problem oriented languages;Seismology;Simulators;Soil liquefaction;Soil structure interactions;Soils;Stochastic models;Stochastic systems;Structural geology;Uncertainty analysis;Wave propagation;},
  language  = {English},
}

@InProceedings{20143918179801,
  author    = {Aram, Michael and Neumann, Gustaf},
  title     = {Exploring collective DSL integration in a large situated IS: Towards comprehensive language integration in information systems},
  year      = {2014},
  pages     = {University of Vienna -},
  address   = {Vienna, Austria},
  note      = {Domain specific languages;Enterprise wiki;Language integration;Shared understanding;Via technologies;},
  abstract  = {In large situated information system instances, a great variety of stakeholders interact with each other via technology, constantly shaping and refining the information system. In the course of such a system's history, a range of domain-specific languages may have been incorporated. These language means are often not sufficiently integrated on an ontological level leading to syntactical and conceptual redundancies and impeding a shared understanding of the systems' functionalities. In this paper, we present our ambitions towards a language integration approach that aims at mitigating this problem. We exemplify it in the context of an existing educational information system instance. &copy; 2014 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Integration},
  keywords  = {DSL;Information systems;Problem oriented languages;Semantics;Software architecture;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2642803.2642823},
}


@inproceedings{20143918179802,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Dicto: A unified DSL for testing architectural rules},
journal = {ACM International Conference Proceeding Series},
author = {Caracciolo, Andrea and Lungu, Mircea Filip and Nierstrasz, Oscar},
year = {2014},
pages = {University of Vienna - },
address = {Vienna, Austria},
abstract = {Software architecture consists of a set of design choices that can be partially expressed in form of rules that the implementation must conform to. Architectural rules are intended to ensure properties that fulfill fundamental non-functional requirements. Verifying architectural rules is often a non-trivial activity: available tools are often not very usable and support only a narrow subset of the rules that are commonly specified by practitioners. In this paper we present a new highly-readable declarative language for specifying architectural rules. With our approach, users can specify a wide variety of rules using a single uniform notation. Rules can get tested by third-party tools by conforming to pre-defined specification templates. Practitioners can take advantage of the capabilities of a growing number of testing tools without dealing with them directly. &copy; 2014 ACM.},
key = {Software architecture},
keywords = {Computer applications;Computer programming;DSL;},
note = {Architectural rules;Declarative Languages;Non-functional requirements;Non-trivial;Testing tools;Third-party tools;Validation;},
URL = {http://dx.doi.org/10.1145/2642803.2642824},
} 

@InProceedings{20162902597339,
  author    = {Kalnins, Audris and Barzdins, Janis},
  title     = {Metamodel specialization for DSL tool building},
  year      = {2016},
  volume    = {615},
  pages     = {68 - 82},
  address   = {Riga, Latvia},
  note      = {Abstract syntax;Diagram editors;Domain specific;Meta model;Metamodeling;New approaches;Transformation languages;UML class diagrams;},
  abstract  = {Most of domain-specific tool building and especially diagram editor building nowadays involves some usage of metamodels. However normally the metamodel alone is not sufficient to define an editor. Frequently the metamodel just defines the abstract syntax of the domain, mappings or transformations are required to define the editor. Another approach [8] is based on a fixed type metamodel, there an editor definition consists of an instance of this metamodel to be executed by an engine. However there typically a number of functionality extensions in a transformation language is required. The paper offers a new approach based on metamodel specialization. First the metamodel specialization based on UML class diagrams and OCL is defined. A universal metamodel and an associated universal engine is described, then it is shown how a specific editor definition can be obtained by specializing this metamodel. Examples of a flowchart editor and UML class diagram editor are given. &copy; Springer International Publishing Switzerland 2016.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {18650929},
  journal   = {Communications in Computer and Information Science},
  key       = {Information systems},
  keywords  = {Encoding (symbols);Engines;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-40180-5_5},
}

@InProceedings{20133516658120,
  author    = {Kouhen, Amine El and Dumoulin, Cedric and Gerard, Sebastien and Boulet, Pierre},
  title     = {A component-based approach for specifying dsml's concrete syntax},
  year      = {2013},
  pages     = {3 - 11},
  address   = {Montpellier, France},
  note      = {Component based approach;Concrete syntax;Development process;Meta-CASE;Metamodeling;Model-driven development;Model-driven Engineering;Reusable components;},
  abstract  = {Model-Driven Engineering (MDE) encourages the use of graphical modeling tools, which facilitate the development process from modeling to coding. Such tools can be designed using the MDE approach into meta-modeling environments called metaCASE tools. It turned out that current metaCASE tools still require, in most cases, manual programming to build full tool support for the modeling language, especially for users' native methodologies and representational elements and propose limited possibilities in terms of reusability. In this context, we propose MID, a set of meta-models supporting the easy specification of modeling editors by means of reusable components and explain how representational meta-modeling is carried out with it. Copyright 2013 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings of the 2nd Workshop on Graphical Modeling Language Development, GMLD 2013 - In Conjunction with European Conference on Modelling Foundations and Applications, ECMFA 2013},
  key       = {Visual languages},
  keywords  = {Graphic methods;Reusability;Syntactics;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2489820.2489822},
}


@inproceedings{20130716009027,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {On the use of an internal DSL for enriching EMF models},
journal = {Proceedings of the 12th Workshop on OCL and Textual Modelling, OCL 2012 - Being Part of the ACM/IEEE 15th International Conference on Model Driven Engineering Languages and Systems, MODELS 2012},
author = {Krikava, Filip and Collet, Philippe},
year = {2012},
pages = {25 - 30},
address = {Innsbruck, Austria},
abstract = {The Object Constraint Language (OCL) is widely used to enrich modeling languages with structural constraints, side effect free query operations implementation and contracts. OCL was designed to be small and compact language with appealing short "to-the-point" expressions. When trying to apply it to larger EMF models some shortcomings appear in the language expressions, the invariant constructs as well as in the supporting tools. In this paper we argue that some of these shortcomings are mainly related to the scalability of the OCL language and its trade-offs between domain-specificity and general-purpose. We present an alternative approach based on an internal DSL in Scala. By using this modern multi-paradigm programing language we can realize an internal DSL with similar features found in OCL while taking full advantage of the host language including state-of-the-art tool support. In particular, we discuss the mapping between the OCL and Scala concepts together with some additional constructs for better scalability in both expressiveness and reusability of the expressions. &copy; 2012 ACM.},
key = {Models},
keywords = {Object oriented programming;Reusability;Scalability;},
note = {Alternative approach;Language constructs and features;Modeling languages;Multi-paradigm;Object Constraint Language;Object oriented design methods;Query operations;Side effect;Structural constraints;Supporting tool;Tool support;},
URL = {http://dx.doi.org/10.1145/2428516.2428521},
} 

@InProceedings{20151100647526,
  author    = {Georg, Geri and Troup, Lucy},
  title     = {Experiences developing a requirements language based on the psychological framework activity theory},
  year      = {2013},
  volume    = {1092},
  pages     = {63 - 72},
  address   = {Miami, FL, United states},
  note      = {Activity Theory;Domain specific languages;Initial system designs;Interactive system;Requirements elicitation;Social behavior;Social constraints;Structural constraints;},
  abstract  = {We have developed a Domain Specific Language (DSL) for requirements elicitation that is based on the psychological framework of Activity Theory (AT). AT emphasizes the social context in which human activity takes place, and thus is useful to systematically develop models of social contexts, validate these contexts with stakeholders, and identify potential sources of system evolution based on identified changing social constraints. AT holds potential as a requirements elicitation tool for complex human interactive systems with a diverse set of stakeholders that do not have common goals. Our adaptation of AT for use in software engineering has evolved over time as we have used it in a case study and developed limited tools that can support designers both during initial system design and during system evolution. Here we describe how the USE tool was applied to develop the DSL and how we have used this tool to create instances of AT models and analyze them for structural constraint inconsistencies. We identify some of the issues encountered in this process and some of the remaining open issues regarding a USE model as an implementation of our DSL.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {Computational linguistics},
  keywords  = {Activity coefficients;Computer programming languages;DSL;Economic and social effects;Problem oriented languages;Requirements engineering;Software engineering;Systems analysis;},
  language  = {English},
}


@inproceedings{20133716719198,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Distal: A framework for implementing fault-tolerant distributed algorithms},
journal = {Proceedings of the International Conference on Dependable Systems and Networks},
author = {Biely, Martin and Delgado, Pamela and Milosevic, Zarko and Schiper, Andre},
year = {2013},
pages = {IEEE; ifip - },
address = {Budapest, Hungary},
abstract = {We introduce Distal, a new framework that simplifies turning pseudocode of fault tolerant distributed algorithms into efficient executable code. Without proper tool support, even small amounts of pseudocode normally ends up in several thousands of non-trivial lines of Java or C++. Distal is implemented as a library in Scala and consists of two main parts: a domain specific language (DSL) in which algorithms are expressed and an efficient messaging layer that deals with low level issues such as connection management, threading and (de)serialization. The DSL is designed such that implementations of distributed algorithms highly resemble the pseudocode found in research papers. By writing code that is close to the protocol description, one can be more convinced that the implemented system really reflects the protocol specification on paper. Distal does not only make it simple and intuitive to implement distributed algorithms but it also leads to efficient implementations. &copy; 2013 IEEE.},
key = {Algorithms},
keywords = {Computer networks;DSL;Information systems;},
note = {Connection managements;Domain specific languages;Efficient implementation;Fault-tolerant;Paxos;Protocol description;Protocol specifications;SMR;},
URL = {http://dx.doi.org/10.1109/DSN.2013.6575306},
} 

@Article{20132916502334,
  author    = {Molina, Ana I. and Gallardo, Jesus and Redondo, Miguel A. and Ortega, Manuel and Giraldo, William J.},
  title     = {Metamodel-driven definition of a visual modeling language for specifying interactive groupware applications: An empirical study},
  journal   = {Journal of Systems and Software},
  year      = {2013},
  volume    = {86},
  number    = {7},
  pages     = {1772 - 1789},
  note      = {Domain specific languages;Groupware design;Interaction design;Interactive applications;MDE;Meta model;Model-driven Engineering;Visual modeling languages;},
  abstract  = {This work is framed in the area of software development for Computer Supported Cooperative Work (CSCW). These software systems are called groupware systems. The development of groupware systems is a complex task, a problem that can be addressed applying the Model Driven Engineering (MDE) principles and techniques, where the use of models is essential. However, there are no proposals to address all issues to model in this kind of application (group work, shared context, coordination, etc.) and, in particular, there are no proposals that consider the modeling of both interactive and collaborative issues. To solve this deficiency, a domain-specific language (DSL) called Collaborative Interactive Application Notation (CIAN) has been proposed. To define this DSL a metamodel has been created describing the universe of discourse of the applications supporting interactive group work. We have defined the syntax and semantics of this language. We have also implemented a tool (called CIAT) for supporting the edition and validation of models created with CIAN. This tool has been implemented using the metamodeling facilities provided by the Eclipse platform. Finally, an empirical study was conducted with the aim of verifying the suitability of this approach and the perception of software engineers about its usefulness. The results obtained show that our proposal can facilitate the development process of groupware systems. &copy; 2012 Elsevier Inc. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {01641212},
  key       = {Groupware},
  keywords  = {Computer supported cooperative work;DSL;Models;Problem oriented languages;Semantics;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.jss.2012.07.049},
}

@InProceedings{20135017083196,
  author    = {Sujeeth, Arvind K. and Gibbons, Austin and Brown, Kevin J. and Lee, HyoukJoong and Rompf, Tiark and Odersky, Martin and Olukotun, Kunle},
  title     = {Forge: Generating a high performance DSL implementation from a declarative specification},
  year      = {2013},
  pages     = {145 - 154},
  address   = {Indianapolis, IN, United states},
  note      = {Code Generation;Distributed hardware;Distributed programming;Domain specific languages;High level specification;High-level abstraction;Multi-stage programming;Software expertise;},
  abstract  = {Domain-specific languages provide a promising path to automatically compile high-level code to parallel, heterogeneous, and distributed hardware. However, in practice high performance DSLs still require considerable software expertise to develop and force users into tool-chains that hinder prototyping and debugging. To address these problems, we present Forge, a new meta DSL for declaratively specifying high performance embedded DSLs. Forge provides DSL authors with high-level abstractions (e.g., data structures, parallel patterns, effects) for specifying their DSL in a way that permits high performance. From this high-level specification, Forge automatically generates both a nave Scala library implementation of the DSL and a high performance version using the Delite DSL framework. Users of a Forge-generated DSL can prototype their application using the library version, and then switch to the Delite version to run on multicore CPUs, GPUs, and clusters without changing the application code. Forge-generated Delite DSLs perform within 2x of hand-optimized C++ and up to 40x better than Spark, an alternative high-level distributed programming environment. Compared to a manually implemented Delite DSL, Forge provides a factor of 3-6x reduction in lines of code and does not sacrifice any performance. Furthermore, Forge specifications can be generated from existing Scala libraries, are easy to maintain, shield DSL developers from changes in the Delite framework, and enable DSLs to be retargeted to other frameworks transparently. &copy; 2013 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {SPLASH Indianapolis 2013; GPCE 2013 - Proceedings of the 12th International Conference on Generative Programming: Concepts and Experiences},
  key       = {Program debugging},
  keywords  = {Automatic programming;Parallel programming;Problem oriented languages;Program processors;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2517208.2517220},
}


@inproceedings{20155201723341,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Ontology-based integration of software artefacts for DSL development},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Haav, Hele-Mai and Ojamaa, Andres and Grigorenko, Pavel and Kotkas, Vahur},
volume = {9416},
year = {2015},
pages = {309 - 318},
issn = {03029743},
address = {Rhodes, Greece},
abstract = {This paper addresses a high level semantic integration of software artefacts for the development of Domain Specific Languages (DSL). The solution presented in the paper utilizes a concept of DSL meta-model ontology that is defined in the paper as consisting of a system ontology linked to one or more domain ontologies. It enables dynamic semantic integration of software artefacts for the composition of a DSL meta-model. The approach is prototypically implemented in Java as an extension to the DSL development tool CoCoViLa. &copy; Springer International Publishing Switzerland 2015.},
key = {Ontology},
keywords = {Computer programming languages;High level languages;Integration;Internet;Problem oriented languages;Semantics;},
note = {Domain specific languages;High level semantics;Meta model;Ontology based modeling;Ontology-based integrations;Semantic integration;Semantic interoperability;Software artefacts;},
URL = {http://dx.doi.org/10.1007/978-3-319-26138-6_34},
} 


@inproceedings{20164002874907,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {DSL-Maps: From requirements to design of domain-specific languages},
journal = {ASE 2016 - Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
author = {Pescador, Ana and De Lara, Juan},
year = {2016},
pages = {438 - 443},
address = {Singapore, Singapore},
abstract = {Domain-Specific Languages (DSLs) are central to ModelDriven Engineering, where they are used for creating models for particular domains. However, current research and tools for building DSLs focus on the design and implementation aspects of the DSL, while the requirements analysis phase, and its automated transition to design is largely neglected. In order to alleviate this situation, we propose DSL-maps, a notation inspired by mind-maps, to represent requirements for DSLs. The notation is supported by a tool, which helps in the automated transition into an initial meta-model design, using a customizable transformation and recommendations from a catalogue of meta-model design patterns. &copy; 2016 ACM.},
key = {Software engineering},
keywords = {Automation;Computer programming languages;Modeling languages;Problem oriented languages;},
note = {Customizable;Design and implementations;Domain specific languages;Meta model;Meta-modelling;Model-driven Engineering;Requirements analysis;Requirements to designs;},
URL = {http://dx.doi.org/10.1145/2970276.2970328},
} 

@InProceedings{20163202680453,
  author    = {Barreiro, Fabian A. and Vazquez, Diana},
  title     = {Expanding and integrating L2 software systems using a new cooperative DSL language},
  year      = {2016},
  volume    = {3},
  pages     = {3161 - 3168},
  address   = {Pittsburgh, PA, United states},
  note      = {Domain specific languages;Industrial software;New plants;Software industry;Software systems;Tubular products;},
  abstract  = {Finding a clear method of expressing an objective in a particular domain is one of the most challenging problems that the software industry faces. A lot of time and effort have been spent on searching for a way to deal with this issue. Domain Specific Languages (DSL) are well known for increasing the developers' productivity and improving the communication between the experts of the domain. This paper demonstrates the implementation of a new, expansible DSL language, which was designed as a cooperative tool in the integration of different vendors' industrial software systems and that took place in a new plant of tubular products. &copy; 2016 by AIST.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {15516997},
  journal   = {AISTech - Iron and Steel Technology Conference Proceedings},
  key       = {Computational linguistics},
  keywords  = {Computer programming languages;Computer software;Problem oriented languages;Software engineering;},
  language  = {English},
}

@InProceedings{20150900588948,
  author    = {Wider, Arif},
  title     = {Implementing a bidirectional model transformation language as an internal DSL in scala},
  year      = {2014},
  volume    = {1133},
  pages     = {63 - 70},
  address   = {Athens, Greece},
  note      = {Bidirectional model transformation;Bidirectional transformation;Domain specific languages;Eclipse modeling framework;General-purpose programming language;Java platforms;Software technology;Transformation languages;},
  abstract  = {Despite advantages in terms of comprehensibility, verification, and maintainability, bidirectional transformation (bx) languages lack wide-spread adoption. Possible reasons are that tool support for bx languages is sometimes weak or outdated, that many bx languages are hard to integrate with existing software technologies, or that bx languages often cannot be mixed with unidirectional transformation languages and general-purpose programming languages. We present an approach to implement existing bx languages as internal domain-specific languages (iDSLs) in the Scala programming language and demonstrate the approach by implementing state-based tree lenses as a statically typed iDSL in Scala. We show that this approach allows for rich tool-support based on static analysis and for achieving technological integration with the Java platform in general and with the Eclipse Modeling Framework (EMF) in particular. At the same time, the iDSL is independent from DSL-specific tool-support and can be mixed with Scala, Java, or unidirectional transformation languages.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {Java programming language},
  keywords  = {Computational linguistics;Computer programming languages;Problem oriented languages;Static analysis;},
  language  = {English},
}


@inproceedings{20163002629449,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Using timed automata to check space mission feasibility in the early design phases},
journal = {IEEE Aerospace Conference Proceedings},
author = {Akhundov, Jafar and Werner, Matthias and Schaus, Volker and Gerndt, Andreas},
volume = {2016-June},
year = {2016},
issn = {1095323X},
address = {Big Sky, MT, United states},
abstract = {According to the model-based systems engineering paradigm, all engineers contribute to a single centralized data model of the system. The German Aerospace Center (DLR) develops a software tool Virtual Satellite which enables the engineers to store, exchange and alter their corresponding subsystem data on base of a distributed system model and thus contribute to the overall mission design during concurrent engineering (CE) sessions. Each engineer has their own scope of responsibilities, e.g. satellite trajectory, communication, or thermal analysis. Tracking implications of design changes on the whole system and feasibility aspects of the design is not trivial. Having an automated feasibility checking mechanism as a part of CE which would run iteratively after each design change provides a useful feedback mechanism for engineers and for the spacecraft client. For the purpose of mission feasibility checking a domain specific language (DSL) has been implemented using the Xtext Java framework. The extended parametric data model defined in the DSL serves as an executable representation of the spacecraft mission. The idea to use such an executable model to create a preliminary mission plan and hence confirm missions feasibility during conceptual study has already been introduced by Schaus et al. at the DLR. However, the vector of values of system variables was assumed to be equivalent with the currently active component, implying that component activities are mutually exclusive. This led to over-constraining of the execution model. Our work argues that concurrency considerations are critical from the earliest design phases. Since satellite is coupled with its environment and concurrency is an intrinsic property of the physical nature, considering concurrency allows for more realistic mission plans. The contributions of this paper are the introduction of concurrency considerations at the early space mission design phases and the use of timed automata tool (UPPAAL) for the mission feasibility check during concurrent engineering sessions. As a result, with almost no overhead, the planned mission can be analyzed in a more realistic way. Furthermore, the run-times of the feasibility check amount to 10-100 milliseconds or less, which is also a significant improvement with respect to the previous work. This allows for more precision and fine granular modeling, and is a promising basis for model refinements in the consecutive mission design phases. &copy; 2016 IEEE.},
key = {Design},
keywords = {Automata theory;Computer aided software engineering;Computer programming languages;Concurrent engineering;Engineers;Java programming language;Problem oriented languages;Satellites;Space flight;Spacecraft;Thermoanalysis;},
note = {Component activities;Distributed systems;Domain specific languages;German aerospace centers;Model-based systems engineering;Satellite trajectories;Space mission design;Spacecraft missions;},
URL = {http://dx.doi.org/10.1109/AERO.2016.7500572},
} 


@inproceedings{20152701007159,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {On the industrial applicability of TextTest: An empirical case study},
journal = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation, ICST 2015 - Proceedings},
author = {Alegroth, Emil and Bache, Geoffrey and Bache, Emily},
year = {2015},
pages = {Graz University of Technology (TU Graz); IEEE Computer Society - },
address = {Graz, Austria},
abstract = {Software systems are becoming more complex, not least in their Graphical User Interfaces (GUIs), which presents challenges for existing testing practices. Pressure to reduce time to market leaves less time for manual testing and increases the importance of test automation. Previous research has identified several generations of automated GUI-based test approaches with different cost-benefit tradeoffs. Whilst test automation provides fast quality feedback it can be associated with high costs and inability to identify defects not explicitly anticipated by the test designer. TextTest is a capture-replay tool for GUI-based testing with a novel approach that overcomes several of the challenges experienced with previous approaches. Firstly the tool supports Approval Testing, an approach where ASCII-art representations of the GUI's visual state are used to verify correct application behavior at the system level. Secondly it records and replays test scripts in a user defined domain specific language (DSL) that is readable by all stakeholders. In this paper we present a three phase industrial case study that aims to identify TextTest's applicability in industrial practice. The paper reports that the tool is associated with (1) low script development costs due to recording functionality, (2) low maintenance costs, on average 7 minutes per test case, (3) better defect finding ability than manual system testing, (4) high test case execution performance (In this case 500 test cases in 20 minutes), (5) high script readability due to DSL defined scripts, and (6) test suites that are robust to change (In this case 93 percent per iteration). However, the tool requires a higher degree of technical skill for customization work, test maintainers need skills in designing regular expressions and the tool's applicability is currently restricted to Java and Python based applications. &copy; 2015 IEEE.},
key = {Software testing},
keywords = {Ability testing;Automation;Commerce;Computer programming languages;Cost effectiveness;Costs;Defects;Graphical user interfaces;Java programming language;Problem oriented languages;System theory;User interfaces;Verification;},
note = {Cost-benefit tradeoffs;Domain specific languages;Empirical case studies;Graphical user interface (GUIs);Industrial case study;Industrial Study;System testing;TextTest;},
URL = {http://dx.doi.org/10.1109/ICST.2015.7102598},
} 

@Article{20152400940949,
  author    = {Qamar, Ahsan and Wikander, Jan and During, Carl},
  title     = {Managing dependencies in mechatronic design: a case study on dependency management between mechanical design and system design},
  journal   = {Engineering with Computers},
  year      = {2015},
  volume    = {31},
  number    = {3},
  pages     = {631 - 646},
  note      = {Automated model transformations;Domain specific modeling languages;DSML;General purpose modeling languages;Machine learning techniques;Mechatronic design;Model transformation;SysML;},
  abstract  = {In this paper, we have investigated the role of dependencies in the design process of mechatronic products. Since explicit modeling of dependencies is largely considered unnecessary today, current languages do not support dependency modeling due to lack of sufficiently expressive language constructs. However, this paper argues that modeling dependencies is important in managing the overall design process. The paper highlights dependencies between two important viewpoints: system design and mechanical design. We have looked closely at how mechanical design (supported by CAD tools) establishes a backbone for the overall design concept. Mechanical design cannot be isolated from other design activities, and the mismanagement of dependencies there leads to problems in other domains too. To illustrate the process, the paper presents an example of modeling dependencies between system hierarchy in OMG SysML&trade; and the CAD assembly in Solid Edge for a mechatronic design example. The paper presents two different approaches to capturing dependencies&mdash;using a general purpose modeling language such as SysML and using a domain specific modeling language (DSML). We argue for using a DSML instead of a general purpose language and provide a DSML called the dependency modeling language (DML). An example DML model for a two degree of freedom robot use case is discussed. The paper also illustrates the complete process of capturing dependencies in a general purpose modeling language like SysML, which served as a good exercise on how to fetch data from a CAD tool and how to represent dependencies inside a significantly different modeling language. Lessons learned from doing this were applied to the construction of DML. Our aim for the future is to reduce the human effort required to build dependency models. Machine learning techniques and automated model transformations are valuable techniques to support this cause. &copy; 2014, Springer-Verlag London.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {01770667},
  key       = {Computer aided design},
  keywords  = {Artificial intelligence;Computational linguistics;Degrees of freedom (mechanics);Design;High level languages;Learning systems;Modeling languages;Product design;Specification languages;Systems analysis;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s00366-014-0366-x},
}

@InProceedings{20162502508926,
  author    = {Ratiu, Daniel and Voelter, Markus},
  title     = {Automated testing of DSL implementations: Experiences from building mbeddr},
  year      = {2016},
  pages     = {15 - 21},
  address   = {Austin, TX, United states},
  note      = {Associated tool;Automated testing;Development environment;Domain specific languages;Language engineering;Language testing;Language workbenches;Quality of softwares;},
  abstract  = {Domain specific languages promise to improve productivity and quality of software by providing problem-adequate abstractions to developers. Projectional language workbenches like JetBrains MPS allow the definition of modular and extensible domain specific languages, generators and development environments. While recent advances in language engineering have enabled the definition of DSLs and tooling in a modular and cost-effective manner, the quality assurance of their implementation is still challenging. In this paper we present our work on testing the implementation of domain specific languages and associated tools, and discuss different approaches to increase the automation of language testing. We illustrate this based on MPS and our experience with testing mbeddr, a set of domain specific languages and tools on top of C tailored to embedded software development. &copy; 2016 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings - 11th International Workshop on Automation of Software Test, AST 2016},
  key       = {C (programming language)},
  keywords  = {Automation;Computational linguistics;Computer programming languages;Cost effectiveness;Cost engineering;Problem oriented languages;Productivity;Quality assurance;Software design;Software engineering;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2896921.2896922},
}

@InProceedings{20133716718173,
  author    = {Torsel, Arne-Michael},
  title     = {A testing tool for web applications using a domain-specific modelling language and the NuSMV model checker},
  year      = {2013},
  pages     = {383 - 390},
  address   = {Luxembourg, Luxembourg},
  note      = {Domain specific languages;Domain-Specific Modelling Languages;Model based testing;Model checking software;Model-based testing approaches;Test Automation;Test automation tool;WEB application;},
  abstract  = {Test case generation from formal models using model checking software is an established method. This paper presents a model-based testing approach for web applications based on a domain-specific language model. It is shown how the domain-specific language is transformed into the input language of the NuSMV model checker and how the resulting traces are converted into executable test scripts for various test automation tools. The presented approach has been implemented with comprehensive automation in a research tool which architecture is outlined. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings - IEEE 6th International Conference on Software Testing, Verification and Validation, ICST 2013},
  key       = {Software testing},
  keywords  = {Applications;Automation;Computational linguistics;Model checking;Problem oriented languages;Tools;World Wide Web;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICST.2013.54},
}

@InProceedings{20160801960773,
  author    = {Bonaki, Dragan and van den Brand, Mark and Gabriels, Joost and Jacobs, Bart and Kuiper, Ruurd and Roede, Sybren and Wijs, Anton and Zhang, Dan},
  title     = {Towards modular verification of threaded concurrent executable code generated from DSL models},
  year      = {2016},
  volume    = {9539},
  pages     = {141 - 160},
  address   = {Niteroi, Brazil},
  note      = {Fine-grained concurrency;Model transformation;Model-driven Engineering;Modular verification;Object orientation;Parameterized verifications;Traditional techniques;Transformation chains;},
  abstract  = {An important problem in Model Driven Engineering is maintaining the correctness of a specification under model transformations. We consider this issue for a framework that implements the transformation chain from the modeling language SLCO to Java. In particular, we verify the generic part of the last transformation step to Java code, involving change in granularity, focusing on the implementation of SLCO communication channels. To this end we use a parameterized modular approach; we apply a novel proof schema that supports fine grained concurrency and procedure-modularity, and use the separation logic based tool VeriFast. Our results show that such tool-assisted formal verification can be a viable addition to traditional techniques, supporting object orientation, concurrency via threads, and parameterized verification. &copy; Springer International Publishing Switzerland 2016.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Formal verification},
  keywords  = {Computer software;Embedded systems;Java programming language;Modeling languages;Software design;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-28934-2_8},
}

@Article{20124815714622,
  author    = {Jacob, Ferosh and Gray, Jeff and Carver, Jeffrey C. and Mernik, Marjan and Bangalore, Purushotham},
  title     = {PPModel: A modeling tool for source code maintenance and optimization of parallel programs},
  journal   = {Journal of Supercomputing},
  year      = {2012},
  volume    = {62},
  number    = {3},
  pages     = {1560 - 1582},
  note      = {Benchmark programs;Computation power;CUDA;Domain specific languages;Graphical modeling;Modeling tool;OpenMP;Optimum version;Parallel code;Parallel program;Parallel programming paradigms;Performance Gain;PPModel;Problem size;Re-execution;Software engineers;Source codes;TPPModel;},
  abstract  = {As the computation power in desktops advances, parallel programming has emerged as one of the essential skills needed by next generation software engineers. However, programs written in popular parallel programming paradigms have a substantial amount of sequential code mixed with the parallel code. Several such versions supporting different platforms are necessary to find the optimum version of the program for the available resources and problem size. As revealed by our study on benchmark programs, sequential code is often duplicated in these versions. This can affect code comprehensibility and re-usability of the software. In this paper, we discuss a framework named PPModel, which is designed and implemented to free programmers from these scenarios. Using PPModel, a programmer can separate parallel blocks in a program, map these blocks to various platforms, and re-execute the entire program.We provide a graphical modeling tool (PPModel) intended for Eclipse users and a Domain-Specific Language (tPPModel) for non-Eclipse users to facilitate the separation, the mapping, and the re-execution. This is illustrated with a case study from a benchmark program, which involves re-targeting a parallel block to CUDA and another parallel block to OpenMP. The modified program gave almost 5&times; performance gain compared to the sequential counterpart, and 1.5&times; gain compared to the existing OpenMP version. &copy; Springer Science+Business Media, LLC 2012.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {09208542},
  key       = {Computer software reusability},
  keywords  = {Application programming interfaces (API);DSL;Multiprocessing systems;Parallel architectures;Parallel programming;Problem oriented languages;Separation;Signal encoding;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s11227-012-0821-7},
}


@article{20160701936941,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Design pattern detection using a DSL-driven graph matching approach},
journal = {Journal of Software: Evolution and Process},
author = {Bernardi, Mario Luca and Cimitile, Marta and Di Lucca, Giuseppe},
volume = {26},
number = {12},
year = {2014},
pages = {1233 - 1266},
issn = {20477481},
abstract = {Knowledge about design pattern (DP) instances improves program comprehension and reengineering of object-oriented systems. Effectively, it helps to discover developer design decisions and trade-offs that often are not documented. This work describes an approach to automatically detect DPs in existing object-oriented systems by tracing systems' source code components with the roles they play in the patterns. In the proposed approach, DPs are modeled based on their high-level structural properties (e.g., inheritance, dependency, invocation, delegation, type nesting, and membership relationships) that are checked, by source code parsing, against the system structure and components. Moreover, the approach can also detect pattern variants, defined by overriding the pattern properties. This paper presents a description of the approach, provides a brief description of the supporting tool, and discusses the results from the experiments carried out to validate it. The approach was validated on seven systems of an open benchmark that contains systems of increasing sizes. For five additional systems, the results have been compared with the ones from a similar approach existing in the literature. The obtained results, the identified DP variants, and the effectiveness of the approach are thoroughly presented and discussed. Copyright &copy; 2014 John Wiley & Sons, Ltd.},
key = {Pattern recognition},
keywords = {Computer programming languages;Design;Economic and social effects;Object oriented programming;Problem oriented languages;Structural properties;},
note = {Design pattern detections;Domain specific languages;Graph matchings;Model driven development;Object-oriented system;},
URL = {http://dx.doi.org/10.1002/smr.1674},
} 


@inproceedings{20153401191825,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Cube v4: From performance report explorer to performance analysis tool},
journal = {Procedia Computer Science},
author = {Saviankou, Pavel and Knobloch, Michael and Visser, Anke and Mohr, Bernd},
volume = {51},
year = {2015},
pages = {1343 - 1352},
issn = {18770509},
address = {Reykjavik, Iceland},
abstract = {Cube v3 has been a powerful tool to examine reports of the parallel performance tool Scalasca, but was basically unable to perform analyses on its own. With Cube v4, we addressed several shortcomings of Cube v3. We generalized the Cube data model, extended the list of supported data types, and allow operations with nontrivial algebras, e.g. for performance models or statistical data. Additionally, we introduced two major new features that greatly enhance the performance analysis features of Cube: Derived metrics and GUI plugins. Derived metrics can be used to create and manipulate metrics directly within the GUI, using a powerful domain-specific language called CubePL. Cube GUI plugins allow the development of novel performance analysis techniques and visualizations based on Cube data without changing the source code of the Cube GUI. &copy; The Authors. Published by Elsevier B.V.},
key = {Geometry},
keywords = {Computer programming languages;DSL;Graphical user interfaces;Problem oriented languages;},
note = {Call-tree profile;Derived metrics;Domain specific languages;Parallel performance tools;Performance analysis;Performance analysis techniques;Performance reports;Plug-ins;},
URL = {http://dx.doi.org/10.1016/j.procs.2015.05.320},
} 

@InProceedings{20123415364568,
  author    = {Biehl, Matthias and Gu, Wenqing and Loiret, Frederic},
  title     = {Model-based service discovery and orchestration for OSLC services in tool chains},
  year      = {2012},
  volume    = {7387 LNCS},
  pages     = {283 - 290},
  address   = {Berlin, Germany},
  note      = {Development tools;Distributed development;Domain specific modeling languages;High level of abstraction;Model driven development;Model-driven;Open services;Platform independent;Service discovery;Service orchestration;Service Oriented;Tool integration;},
  abstract  = {Globally distributed development of complex systems relies on the use of sophisticated development tools but today the tools provide only limited possibilities for integration into seamless tool chains. If development tools could be integrated, development data could be exchanged and tracing across remotely located tools would be possible and would increase the efficiency of globally distributed development. We use a domain specific modeling language to describe tool chains as models on a high level of abstraction. We use model-driven technology to synthesize the implementation of a service-oriented wrapper for each development tool based on OSLC (Open Services for Lifecyle Collaboration) and the orchestration of the services exposed by development tools. The wrapper exposes both tool data and functionality as web services, enabling platform independent tool integration. The orchestration allows us to discover remote tools via their service wrapper, integrate them and check the correctness of the orchestration. &copy; 2012 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Integration},
  keywords  = {Web services;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-31753-8_21},
}

@InProceedings{20143418079291,
  author    = {Miao, Yongwu and Ally, Mohamed and Samaka, Mohammed and Tsinakos, Avgoustos A.},
  title     = {Towards pedagogy-driven learning design: A case study of problem-based learning design},
  year      = {2014},
  volume    = {8613 LNCS},
  pages     = {179 - 189},
  address   = {Tallinn, Estonia},
  note      = {Authoring tool;Course plans;Design languages;Domain specific languages;IMS-LD;Learning designs;PBL;Problem based learning;},
  abstract  = {Existing learning design languages are pedagogy-neutral. They provide insufficient support to explicitly represent pedagogy-specific approaches such as problem-based learning (PBL). As the first step towards pedagogy-driven learning design, we developed a PBL design language and an associated authoring tool by adopting a domain-specific language (DSL) approach. The language and the tool provide means for teachers to think and represent their own PBL designs in vocabularies that the teacher daily uses to describe their PBL approaches. This paper presents a case study to investigate whether the language and the tool can facilitate the design of a PBL course plan. Although participants had minimal knowledge of PBL and were not skilled in process modeling, after a short training they were able to prepare their own PBL course plans using the PBL authoring tool. They reported that the vocabularies in the PBL design language were easy to understand. Some thought that the tool provides flexibility and others did not think so. Nevertheless, some found the process somewhat difficult to represent the narrative into a course plan. In addition, most participants found that the tool is user-friendly and easy to learn. &copy; 2014 Springer International Publishing.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Curricula},
  keywords  = {Computer aided instruction;Design;DSL;E-learning;Personnel training;Problem oriented languages;Teaching;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-09635-3_20},
}


@inproceedings{20144700227689,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Domain specific languages for managing feature models: Advances and challenges},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Collet, Philippe},
volume = {8802},
year = {2014},
pages = {273 - 288},
issn = {03029743},
address = {Imperial, Corfu, Greece},
abstract = {Managing multiple and complex feature models is a tedious and error-prone activity in software product line engineering. Despite many advances in formal methods and analysis techniques, the supporting tools and APIs are not easily usable together, nor unified. In this paper, we report on the development and evolution of the Familiar Domain-Specific Language (DSL). Its toolset is dedicated to the large scale management of feature models through a good support for separating concerns, composing feature models and scripting manipulations. We overview various applications of Familiar and discuss both advantages and identified drawbacks. We then devise salient challenges to improve such DSL support in the near future.},
key = {Software design},
keywords = {Computer programming languages;DSL;Formal methods;Problem oriented languages;},
note = {Analysis techniques;Domain specific languages;Error prones;Feature models;Scale management;Software product line engineerings;Supporting tool;Toolsets;},
} 


@inproceedings{20140117155357,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Customizing the visualization and interaction for embedded domain-specific languages in a structured editor},
journal = {Proceedings of IEEE Symposium on Visual Languages and Human-Centric Computing, VL/HCC},
author = {Asenov, Dimitar and Muller, Peter},
year = {2013},
pages = {127 - 130},
issn = {19436092},
address = {San Jose, CA, United states},
abstract = {Large software projects are often based on libraries that provide abstractions for a particular domain such as writing database queries, staging, or constraint solving. The API provided by such a library can be considered a domain-specific language within the implementation language of the library, a so-called internal or embedded domain-specific language (eDSL). Embedding a DSL leverages the tool infrastructure of the host language, but also restricts the syntax and IDE support to that of the host language. This restriction prevents programmers from using convenient specialized notations and, thus, has a negative effect on their productivity. To address this problem, we outline concepts for a structured code editor that enable developers of eDSLs to customize how eDSL code is rendered and what interactions are available. We demonstrate the benefits of our approach by customizing a structured editor for the.NET Code Contracts API. Our prototype shows in particular that we can customize many aspects of visualization and interaction with little effort. &copy; 2013 IEEE.},
key = {Problem oriented languages},
keywords = {Computer programming;Graphical user interfaces;Human computer interaction;Visual languages;Visualization;},
note = {editor customization;Embedded domain-specific languages;Programming environment;Structured editors;Visual programming;},
URL = {http://dx.doi.org/10.1109/VLHCC.2013.6645255},
} 


@inproceedings{20163102662262,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Constraints-based URDAD Model verification},
journal = {ENASE 2016 - Proceedings of the 11th International Conference on Evaluation of Novel Software Approaches to Software Engineering},
author = {Solms, Fritz and Hammond, Priscilla Naa Dedei and Marshall, Linda},
year = {2016},
pages = {148 - 155},
address = {Rome, Italy},
abstract = {In Model-Driven Engineering the primary artifact is a technology and architecture neutral model called a Platform Independent Model (PIM). The Use-Case, Responsibility Driven Analysis and Design (URDAD) is a service-oriented method which is used to construct a PIM commonly specified in the URDAD Domain-Specific Language (DSL). In this paper we show that model quality can be verified by specifying a set of quality constraints at metamodel level which are used to verify certain consistency, completeness, traceability and simplicity qualities of URDAD models. The set of constraints has been mapped onto the Object Constraint Language (OCL) and a tool used to verify these constraints has been developed. The set of constraints is also used by an URDAD model editor to verify aspects of model quality as it is being developed. Copyright &copy; 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
key = {Software engineering},
keywords = {Computational linguistics;Computer aided software engineering;Computer programming languages;Problem oriented languages;},
note = {Domain specific languages;Meta model;Model validation;Model-driven Engineering;Object Constraint Language;URDAD;},
} 

@InProceedings{20161602265338,
  author    = {Adam, Sorin and Schultz, Ulrik Pagh},
  title     = {Towards tool support for spreadsheet-based domain-specific languages},
  year      = {2015},
  pages     = {95 - 98},
  address   = {Pittsburgh, PA, United states},
  note      = {Automatic Generation;Domain specific languages;Parser;Safety specifications;Structured data;Tool support;Two-dimensional grammars;},
  abstract  = {Spreadsheets are commonly used by non-programmers to store data in a structured form, this data can in some cases be considered to be a program in a domain-specific language (DSL). Unlike ordinary text-based domain-specific languages, there is however currently no formalism for expressing the syntax of such spreadsheet-based DSLs (SDSLs), and there is no tool support for automatically generating language infrastructure such as parsers and IDE support. In this paper we define a simple notion of two-dimensional grammars for SDSLs, and show how such grammars can be used for automatically generating parsers that extract structured data from a spreadsheet in the form of an AST. We demonstrate automatic generation of parsers for a number of examples, including the questionnaire DSL from LWC2014 and a DSL for writing safety specifications. &copy; 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {GPCE 2015 - Proceedings of the 2015 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
  key       = {Computational linguistics},
  keywords  = {Computer programming languages;Graphical user interfaces;Problem oriented languages;Spreadsheets;Syntactics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2814204.2814215},
}

@InProceedings{20124615674225,
  author    = {Jia, Xiaoping and Jones, Chris},
  title     = {AXIOM: A model-driven approach to cross-platform application development},
  year      = {2012},
  pages     = {24 - 33},
  address   = {Rome, Italy},
  note      = {Application development;Cross-platform;Customizable;Development costs;Development productivity;Domain specific languages;Mobile application development;Mobile applications;Mobile platform;Model driven approach;Model-driven Engineering;Multiple platforms;Platform-independent model;Product quality;Prototype tools;Transformation process;},
  abstract  = {The development and maintenance of mobile applications for multiple platforms is expensive. One approach to reducing this cost is model-driven engineering (MDE). In this paper, we present AXIOM, a model-driven approach for developing cross-platform mobile applications. Our approach uses a domain specific language (DSL) for defining platform-independent models (PIM) of mobile applications. It also defines a multi-phase, customizable transformation process to convert platform-independent models into native applications for target mobile platforms. Our approach could significantly reduce the development cost and increase the product quality of mobile applications. A prototype tool has been developed to demonstrate the feasibility of the approach. The preliminary findings are promising and show significant gains in development productivity.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {ICSOFT 2012 - Proceedings of the 7th International Conference on Software Paradigm Trends},
  key       = {Problem oriented languages},
  keywords  = {Mobile computing;},
  language  = {English},
}


@inproceedings{20154201406352,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Building a forensic computing language},
journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
author = {Roussev, Vassil},
volume = {2015-March},
year = {2015},
pages = {5228 - 5233},
issn = {15301605},
address = {Kauai, HI, United states},
abstract = {The primary goal of this discussion is to motivate the need for the development of a domain-specific language (DSL) focused on the requirements of forensic and security analysis. We argue that, at present, there is no adequate mechanism that a) allows analysts to specify the forensic computation as a tool-agnostic, logical sequence of steps, b) provides a formal specification for tool developers, and c) seamlessly integrates different available tools to provides a complete and extensible solution. We present an initial design sketch for a forensic DSL called nugget, and use it to illustrate the ideas behind our approach. &copy; 2015 IEEE.},
key = {Computer crime},
keywords = {Computational linguistics;Computer programming languages;DSL;Modems;Problem oriented languages;},
note = {Digital forensic;Domain specific languages;Forensic computing;Initial design;Logical sequences;Security analysis;},
URL = {http://dx.doi.org/10.1109/HICSS.2015.617},
} 


@inproceedings{20140417233206,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {CRISTAL: Collection of resource-centric supporting tools and languages},
journal = {CEUR Workshop Proceedings},
author = {Cabanillas, Cristina and Del-Rio-ortega, Adela and Resinas, Manuel and Ruiz-Cortes, Antonio},
volume = {936},
year = {2012},
pages = {51 - 56},
issn = {16130073},
address = {Tallinn, Estonia},
abstract = {In this demo, we introduce CRISTAL (Collection of ResourcecentrIc Supporting Tools And Languages), a tool suite aimed at improving the human resource management capabilities of current Business Process Management Systems (BPMSs), covering the design and enactment phases of the business process (BP) life cycle. The central element is Resource Assignment Language (RAL), a Domain Specific Language (DSL) for specifying resource assignments in process models. RAL's strong analysis capabilities enable the automated resolution of resource assignment expressions both (i) at design time, serving for post-design analysis to find and correct potential problems prior to execution, and (ii) at run time, in order to execute the BP in an existing BPMS considering the RAL assignments for resource allocation. The resource assignments can be directly modelled in a Business Process Modelling Notation (BPMN) diagram, or specified by means of a RACI matrix. In the latter case, CRISTAL can take all the RACI information automatically and introduce it into a resource-unaware BPMN model at any moment, resulting in a RACI-aware BP model (and, thus, a resource-aware BP model).},
key = {Tools},
keywords = {Administrative data processing;Computer programming languages;Design;Human resource management;},
note = {Analysis capabilities;Automated resolution;Business process management systems;Business process modelling notations;Domain specific languages;Potential problems;Resource assignment;Resource management;},
} 


@inproceedings{20150600504786,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Decomposing scheme plans to manage verification complexity},
journal = {FORMS/FORMAT 2014 - 10th Symposium on Formal Methods for Automation and Safety in Railway and Automotive Systems},
author = {James, Phillip and Moller, Faron and Nguyen, Hoang Nga and Roggenbach, Markus and Treharne, Helen},
year = {2014},
pages = {210 - 220},
address = {Braunschweig, Germany},
abstract = {Several formal methods have been proposed for the specification and safety verification of railway applications. In order to be successful they need industrial strength tools to support the animation, proof, model checking and simulation of such systems. The complexity of railway systems means that capabilities of the analysis tools have consistently been improving. In our approach we propose that the complexity of analysis of railway interlocking systems can also be managed through incremental addition of system detail and decomposition of system specifications themselves. We propose a domain specific language (DSL) which describes the core aspects of a railway interlocking system and demonstrate how one can identify suitable decompositions in terms of the DSL. The DSL informs our system engineering approach which uses a graphical editor to input railway scheme plans, supports the automatic generation of CSP jj B specifications of the plans and uses the ProB tool for their animation and model checking.},
key = {Interlocking signals},
keywords = {Animation;Boron;Computer programming languages;Decomposition;Formal methods;Formal specification;Formal verification;Model checking;Problem oriented languages;Railroad transportation;Railroads;Safety devices;Safety engineering;Specifications;Transportation;},
note = {Automatic Generation;CSP;Domain specific languages;Railway applications;Railway interlocking system;Safety verification;System specification;Verification complexity;},
} 

@Article{20162202431329,
  author    = {Patwari, Puneet and Chaudhuri, Subhrojyoti Roy and Natarajan, Swaminathan and Muralikrishna, G.},
  title     = {MC ML: A modeling language for monitoring and control systems},
  journal   = {Fusion Engineering and Design},
  year      = {2016},
  note      = {C-systems;Domain specific languages;Interface control documents;International thermonuclear experimental reactor;Model-driven Engineering;Monitoring and control;Monitoring and control systems;Square kilometer arrays;},
  abstract  = {The use of System Engineering (SE) language such as SysML [1,20] is common within the community of control system designers. However the design handoff to the subsequent phases of the control system development is carried out manually in most cases without much tool support. The approach to agreeing on the control interface between components is a good example where engineers still rely on either manually created Interface Control Documents (ICD) or one off tools implemented by individual projects. Square Kilometer Array (SKA) [2] and International Thermonuclear Experimental Reactor (ITER) [3] are two good examples of such large projects adopting these approaches. This results in non-uniformity in the overall system design since individual groups invent their own vocabulary while using a language like SysML which leads to inconsistencies across the design, interface and realized code. To mitigate this, we propose the development of a Monitoring and Control Modeling Language (M&amp;CML), a domain specific language (DSL) [4,22] for specifying M&amp;C solutions. M&amp;C ML starts with defining a vocabulary borrowing concepts from standard practices used in the control domain and incorporates a language which ensures uniformity and consistency across the M&amp;C design, interfaces and implementation artifacts. In this paper we discuss this language with an analysis of its usage to point out its benefits. &copy; 2016 Elsevier B.V.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {09203796},
  key       = {C (programming language)},
  keywords  = {Computational linguistics;Computer programming languages;Control systems;Design;Experimental reactors;Modeling languages;Monitoring;Nuclear reactors;Problem oriented languages;Systems analysis;Systems engineering;Tokamak devices;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.fusengdes.2016.05.024},
}

@InProceedings{20133816750972,
  author    = {Cencetti, M. and Pasquinelli, M. and Maggiore, P.},
  title     = {System modeling framework and MDO tool integration: MBSE methodologies applied to design and analysis of space system},
  year      = {2013},
  address   = {Boston, MA, United states},
  note      = {Design and analysis;Design approaches;Design optimization;Domain specific languages;Model-based system engineerings;Multidisciplinary design optimization;System characteristics;Tool integration;},
  abstract  = {This paper presents the results of a research study related to the integration of a Design Optimization Framework in a Model Based System Engineering (MBSE) environment. The main aim of this work concerns the feasibility of such connection in order to assess actual advantages and possible drawbacks. The objective is to show how the Multidisciplinary Design Optimization (MDO) methods may be managed in the context of a MBSE environment with respect to the traditional design approach. Basically this analysis is addressed to the demonstration of the benefits of MBSE methodology in the field of aerospace engineering. The state of the art of the considered methodology is briefly introduced in the first part of the paper. The following part concerns the description of the modeling activities that have been used to define system characteristics. System data model is defined through a Domain Specific Language (DSL) on the basis of MBSE paradigm and managed through a web application tool. Design optimization functionalities are also integrated within this framework to assess if possible advantages can be obtained. A test case is presented in the following section, reporting the results reached and discussing their meaning. A comparison between the MBSE approach and the traditional one is then proposed in the final section.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {AIAA Modeling and Simulation Technologies (MST) Conference},
  key       = {Tools},
  keywords  = {Aerospace engineering;Computer simulation;Design aids;Optimization;},
  language  = {English},
}

@InProceedings{20135017066944,
  author    = {Di Ruscio, Davide and Iovino, Ludovico and Pierantonio, Alfonso},
  title     = {Managing the coupled evolution of metamodels and textual concrete syntax specifications},
  year      = {2013},
  pages     = {114 - 121},
  address   = {Santander, Spain},
  note      = {Concrete syntax;Coupled evolution;Difference models;Domain specific modeling languages;MDE;Metamodeling;Model to model transformation;Model-driven Engineering;},
  abstract  = {In the context of Model Driven Engineering (MDE) the definition of a Domain Specific Modeling Language (DSML) consists of a set of coordinated artifacts specifying the abstract and concrete syntax of the language, and possibly further aspects related to semantics. Concerning the specification of concrete syntaxes a number of tools are available. They typically permit to associate syntactic elements to metamodel (abstract syntax) of the modeling language being developed and to generate a number of supporting tools (e.g., parsers, pretty printers, and editors). Currently, tools for the specification of textual concrete syntaxes lack support for propagating metamodel changes to the corresponding concrete syntax specifications. In this paper, we analyze such a co-evolution problem, and provide an approach able to automate the propagation of metamodel changes to textual concrete specifications given by means of the TCS tool. The approach relies on model-to-model transformations which are applied according to difference models which represent the occurred metamodel changes. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings - 39th Euromicro Conference Series on Software Engineering and Advanced Applications, SEAA 2013},
  key       = {Visual languages},
  keywords  = {Embedded systems;Semantics;Software engineering;Specifications;Syntactics;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SEAA.2013.22},
}

@InProceedings{20132216381532,
  author    = {Rose, Louis M. and Kolovos, Dimitrios S. and Paige, Richard F.},
  title     = {EuGENia live: A flexible graphical modelling tool},
  year      = {2012},
  pages     = {15 - 20},
  address   = {Innsbruck, Austria},
  note      = {Design and implementations;Domain specific languages;Eclipse modeling framework;Graphical modelling;Incremental process;Model-driven Engineering;Potential benefits;Technical expertise;},
  abstract  = {Designing a domain-specific language (DSL) is a collaborative, iterative and incremental process between domain experts and software engineers. Existing tools for implementing DSLs produce powerful and interoperable domain-specific editors, but are resistant to language change and require considerable technical expertise to use. We present EuGENia Live, a tool for designing (graphical) DSLs. EuGENia Live runs in a web browser, supports on-the-fly meta-model editing, and produces DSLs that can be exported and used with the Eclipse Modeling Framework. As well as presenting the design and implementation of EuGENia Live, we discuss potential benefits to our underlying approach, and challenges for future work on flexible modelling tools. &copy; 2012 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {2012 Extreme Modeling Workshop, XM 2012 - Post-Proceedings, Satellite Event of the IEEE/ACM 15th International Conference on Model Driven Engineering Languages and Systems, MODELS 2012},
  key       = {Embedded systems},
  keywords  = {Graphical user interfaces;Models;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2467307.2467311},
}

@InProceedings{20133616695135,
  author    = {Ben Maissa, Yann and Kordon, Fabrice and Mouline, Salma and Thierry-Mieg, Yann},
  title     = {Modeling and analyzing wireless sensor networks with VeriSensor: An integrated workflow},
  year      = {2013},
  volume    = {8100 LNCS},
  pages     = {24 - 47},
  address   = {Hamburg, Germany},
  note      = {Domain specific modeling languages;Environmental conditions;Formal Specification;Formal verifications;Integrated workflow;Life-critical applications;Model-driven Engineering;Quality requirements;},
  abstract  = {A Wireless Sensor Network (WSN), made of distributed autonomous nodes, is designed to monitor physical or environmental conditions. WSNs have many application domains such as environment or health monitoring. Their design must consider energy constraints, concurrency issues, node heterogeneity, while still meeting the quality requirements of life-critical applications. Formal verification helps to obtain WSN reliability, but usually requires a high expertise, which limits its adoption in industry. This paper presents VeriSensor, a domain specific modeling language (DSML) for WSNs offering support for formal verification. VeriSensor is designed to be used by WSN experts. It can be automatically translated into a formal specification for model checking. We present the language and its translation into a formal model (we use Instantiable Transition Systems - ITS). A tool has been implemented. We used it to work on a case study, illustrating how several metrics and properties relevant to the domain can be evaluated. &copy; 2013 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Sensor nodes},
  keywords  = {Embedded systems;Model checking;Petri nets;Wireless sensor networks;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-40465-8_2},
}

@InProceedings{20134416912606,
  author    = {Edwards, Craig and Gruner, Stefan},
  title     = {A new tool for URDAD to Java EE EJB transformations'},
  year      = {2013},
  pages     = {144 - 153},
  address   = {East London, South africa},
  note      = {EJB;JaMoPP;MDA;Model transformation;MOF;QVT;URDAD;},
  abstract  = {Following the Object Management Group's (OMG) Model-Driven Architecture (MDA) approach, the semi-formal, service-orientated "Use Case, Responsibility Driven Analysis and Design" (URDAD) method is used by requirements engineers to specify a software system's functional properties in a Platform Independent Model (PIM). PIMs are represented using the URDAD Domain Specific Language (DSL), and thus conform to the URDAD MOF meta model. As a result, they can be transformed into Platform-Specific Models (PSM) for frameworks such as Java Platform Enterprise Edition (JEE) Enterprise Java Beans (EJB). This paper describes the semi-automatic transformation of a URDAD PIM into a EJB PSM, which is the basis for the further generation of EJB program code. For this purpose, a new prototype CASE tool<sup>1</sup>was implemented to facilitate such transformations. The tool was evaluated using a non-trivial example project, with results indicating that it produces the PSM and template code that constitutes the static Java EE EJB structural representation of the example PIM. Copyright 2013 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Software architecture},
  keywords  = {Computer aided software engineering;Computer science;Engineers;Information technology;Java programming language;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2513456.2513459},
}

@InProceedings{20131616208286,
  author    = {Yamashita, Kazuhiro},
  title     = {Modular construction of an analysis tool for mining software repositories},
  year      = {2013},
  pages     = {37 - 38},
  address   = {Fukuoka, Japan},
  note      = {Analysis tools;Domain specific languages;Feature oriented domain analysis;Mining software repositories;Mining software repository (MSR);Software Evolution;},
  abstract  = {In this paper, we propose an analysis tool for mining software repository (MSR) called E-CUBE, which corresponds to three types of evolution in MSR (i.e., Platform Evolution, Target Evolution and Scale Evolution). To encapsulate the essence of these types of evolution, we introduce modular construction for MSR studies to E-CUBE. We make a choice of features (i.e., modules) in the field of MSR using Feature Oriented Domain Analysis (FODA) and implement those modules using an internal Domain specific language (DSL). Copyright &copy; 2013 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {AOSD 2013 Companion - Proceedings of the 2013 ACM on Aspect-Oriented Software Development},
  key       = {Modular construction},
  keywords  = {Computer systems programming;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2457392.2457409},
}


@inproceedings{20163102672840,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {High-level modeling and application validation for SDN},
journal = {Proceedings of the NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium},
author = {Lopes, Felipe A. and Lima, Leonidas and Santos, Marcelo and Fidalgo, Robson and Fernandes, Stenio},
year = {2016},
pages = {197 - 205},
address = {Istanbul, Turkey},
abstract = {Software-Defined Networking (SDN) enables applications running on its control plane. The Northbound API allows programmers to develop SDN applications for a number of policy-based network management tasks. However, there is still a clear need for supporting the development of controller-agnostic modeled applications. In this paper, we show how the Model-Driven Networking (MDN), a framework composed of CASE tool and Domain-Specific Modeling Language (DSML), can be a feasible solution to create applications independent from controllers and to enable proper verification of SDN applications. Our evaluation demonstrates that MDN framework is viable for using in real scenarios and independent from SDN controllers. Moreover, our performance tests show that: (i) MDN's code generation is two times faster than other approaches; and (ii) it can validate several constraints and complex topologies at millisecond-timescale. &copy; 2016 IEEE.},
key = {Application programs},
keywords = {Applications;Complex networks;Computational linguistics;Computer aided software engineering;Controllers;Embedded systems;Modeling languages;Network management;Software defined networking;Specification languages;},
note = {Complex topology;Domain specific modeling languages;Feasible solution;framework;High-level modeling;Performance tests;Policy based network management;Software defined networking (SDN);},
URL = {http://dx.doi.org/10.1109/NOMS.2016.7502813},
} 

@InProceedings{20143918179818,
  title     = {Proceedings of the ECSA 2014 Workshops and Tool Demos Track - European Conference on Software Architecture, ECSAW 2014},
  year      = {2014},
  pages     = {University of Vienna -},
  address   = {Vienna, Austria},
  abstract  = {The proceedings contain 33 papers. The topics discussed include: adaptive risk management with ontology linked evidential statistics and SDN; a tool for security metrics modeling and visualization; the merits of a meritocracy in open source software ecosystems; the reality of an associate model - comparing partner activity in the eclipse ecosystem; scientific research software ecosystems; governance mechanisms for healthcare apps; towards faster method search through static ecosystem analysis; a quantitative analysis of developer information needs in software ecosystems; supporting architects in mastering the complexity of open software ecosystems; flexibility in ecosystem architectures; domain specific language for deployment of parallel applications on parallel computing platforms; hierarchical combination of internal and external domain-specific languages for scientific computing; and supporting software evolution by integrating DSL-based architectural abstraction and understandability related metrics.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ACM International Conference Proceeding Series},
  language  = {English},
}

@Article{20143800066660,
  author    = {Bachtarzi, Faycal and Chaoui, Allaoua},
  title     = {A modelling language and a tool for web services composition},
  journal   = {International Journal of Communication Networks and Distributed Systems},
  year      = {2014},
  volume    = {13},
  number    = {2},
  pages     = {221 - 240},
  note      = {Business Process Execution Language;Domain specific languages;Extensible Mark-Up language (XML);Model-driven Engineering;Software development process;Web services composition;Web services description languages;Web Services technologies;},
  abstract  = {Web services technology is the most common implementation of service oriented architecture. Web services are based on open technologies such as eXtensible Markup Language (XML) and offer a distributed approach for the integration of heterogeneous applications across the internet. The process of combining web services functionalities into one composite service is called web services composition. To perform this task, several languages such as Business Process Execution Language (BPEL), Web Services Flow Language (WSFL) and Web Service Choreography Interface (WSCI) have emerged. These languages are based on programming concepts and neglect the specification step which is very important in any software development process. In this paper, we address the formal specification of web services descriptions and the modelling of their composition using the model driven engineering principles. To this end, we propose a domain specific language (DSL) called S-GNet. The proposed DSL introduces new modelling elements which make it well adapted to the web services characteristics. We also propose a graph grammar which transforms Web Services Description Language (WSDL) descriptions into their equivalent S-GNet specifications. This grammar is integrated within an S-GNet modelling tool. &copy; 2014 Inderscience Enterprises Ltd.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {17543916},
  key       = {Web services},
  keywords  = {Computer programming languages;Formal languages;Hypertext systems;Information services;Problem oriented languages;Service oriented architecture (SOA);Social networking (online);Software design;Specifications;XML;},
  language  = {English},
  url       = {http://dx.doi.org/10.1504/IJCNDS.2014.064168},
}

@InProceedings{20140117164424,
  title     = {Software Language Engineering - 6th International Conference, SLE 2013, Proceedings},
  year      = {2013},
  volume    = {8225 LNCS},
  address   = {Indianapolis, IN, United states},
  abstract  = {The proceedings contain 20 papers. The topics discussed include: developing a domain-specific language for scheduling in the European energy sector; micro-machinations: a DSL for game economies; xMOF: executable DSMLs based on fUML; variability support in domain-specific language development; software evolution to domain-specific languages; safe specification of operator precedence rules; detecting ambiguity in programming language grammars; a pretty good formatting pipeline; the state of the art in language workbenches: conclusions from the language workbench challenge; a model-driven approach to enhance tool interoperability using the theory of models of computation; method and tool support for classifying software languages with Wikipedia; a language independent task engine for incremental name and type analysis; a generic framework for symbolic execution; mapping-aware megamodeling: design patterns and laws; and reifying concurrency for executable metamodeling.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  language  = {English},
}

@InProceedings{20122215073689,
  author    = {Tariq, Muhammad Umer and Nasir, Hasan Arshad and Muhammad, Abubakr and Wolf, Marilyn},
  title     = {Model-driven performance analysis of large scale irrigation networks},
  year      = {2012},
  pages     = {151 - 160},
  address   = {Beijing, China},
  note      = {Cyber physical systems (CPSs);Domain specific modeling languages;Model transformation;Model-Driven Software Development;Modeling and simulation;},
  abstract  = {Irrigation networks play a fundamental part in the agriculture system of various countries. In the wake of global environmental challenges and economic competition, efficient use of water resources has become extremely important. This can only be achieved by developing smarter control infrastructures for irrigation networks, via the incorporation of communication and computation technologies. Thus, future irrigation networks represent a prime example of cyber physical systems. Effective operation of these complex cyber physical systems is not possible with conventional methods and requires unprecedented levels of automation and decision-support tools. We argue that these cyber physical systems will require a complete model-driven toolset for effective operation. As a first step towards that tool flow, we have developed a model-driven simulation infrastructure for irrigation networks. In the future, we propose to complete the toolset by developing a model-driven configuration infrastructure. Our contributions in this paper include the development of a domain-specific modeling language (DSML) for irrigation networks, implementation of this DSML in Generic Modeling Environment (GME), and automatic simulator M-file generation capability from the DSML-based case diagram of an arbitrary irrigation network. Moreover, we present case studies of water distribution and flood management to show the utility as well as the effectiveness of our approach. We also present the performance of our toolset for the realistic scenario of irrigation networks in Pakistan. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings - 2012 IEEE/ACM 3rd International Conference on Cyber-Physical Systems, ICCPS 2012},
  key       = {Computer simulation},
  keywords  = {Decision support systems;Embedded systems;Flood control;Irrigation;Specification languages;Water resources;Water supply systems;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICCPS.2012.23},
}


@inproceedings{20123315330517,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Let's make refactoring tools user-extensible!},
journal = {ACM International Conference Proceeding Series},
author = {Li, Huiqing and Thompson, Simon},
year = {2012},
pages = {32 - 39},
address = {Rapperswil, Switzerland},
abstract = {We present a framework for making a refactoring tool extensible, allowing users to define refactorings from scratch using the concrete syntax of the language, as well as to describe complex refactorings in a domain-specific language for scripting. We demonstrate the approach in practice through a series of examples. The extension framework is built into Wrangler, a tool for refactoring Erlang programs, but we argue that the approach is equally applicable to tools for other languages. &copy; 2012 ACM.},
key = {Syntactics},
keywords = {DSL;Problem oriented languages;},
note = {analysis;API;Concrete syntax;Erlang;extensible;Program transformations;Refactorings;Wrangler;},
URL = {http://dx.doi.org/10.1145/2328876.2328881},
} 

@InProceedings{20144900279144,
  author    = {Li, Kaituo and Joshi, Pallavi and Gupta, Aarti and Ganai, Malay K.},
  title     = {ReproLite: A lightweight tool to quickly reproduce hard system bugs},
  year      = {2014},
  pages     = {ACM Special Interest Group on Management of Data (SIGMOD); ACM Special Interest Group on Operating Systems (SIGOPS) -},
  address   = {Seattle, WA, United states},
  note      = {Automatically generated;Cloud systems;Domain specific languages;Execution logs;Hard system bug;Internet users;Lightweight;Non-determinism;},
  abstract  = {Cloud systems have become ubiquitous today - they are used to store and process the tremendous amounts of data being generated by Internet users. These systems run on hundreds of commodity machines, and have a huge amount of non-determinism (thousands of threads and hundreds of processes) in their execution. Therefore, bugs that occur in cloud systems are hard to understand, reproduce, and fix. The state-of-the-art of debugging in the industry is to log messages during execution, and refer to those messages later in case of errors. In ReproLite, we augment the already widespread process of debugging using logs by enabling testers to quickly and easily specify the conjectures that they form regarding the cause of an error (or bug) from execution logs, and to also automatically validate those conjectures. ReproLite includes a Domain Specific Language (DSL) that allows testers to specify all aspects of a potential scenario (e.g., specific workloads, execution operations and their orders, environment non-determinism) that causes a given bug. Given such a scenario, ReproLite can enforce the conditions in the scenario during system execution. Potential buggy scenarios can also be automatically generated from a sequence of log messages that a tester believes indicates the cause of the bug. We have experimented ReproLite with 11 bugs from two popular cloud systems, Cassandra and HBase. We were able to reproduce all of the bugs using ReproLite. We report on our experience with using ReproLite on those bugs.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the 5th ACM Symposium on Cloud Computing, SOCC 2014},
  key       = {Program debugging},
  keywords  = {Cloud computing;Computer debugging;Computer programming languages;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2670979.2671004},
}

@InProceedings{20133716724973,
  author    = {Thillainathan, Niroshan and Hoffmann, Holger and Hirdes, Eike M. and Leimeister, Jan Marco},
  title     = {Enabling educators to design serious games - A serious game logic and structure modeling language},
  year      = {2013},
  volume    = {8095 LNCS},
  pages     = {643 - 644},
  address   = {Paphos, Cyprus},
  note      = {Didactical experts;Domain specific modeling languages;Educational contents;Educational context;Learning objectives;Model driven development;Programming knowledge;Structure modeling;},
  abstract  = {Serious games are applications combining educational content with gameplay by integrating learning objectives into a game-like environment to keep up the player's motivation to continue playing, and hence learning. This characteristic is highly sought after in educational contexts, making serious games a big asset for didactics [1]. Offering new learning contents through a game not only induces higher motivation, employing serious games can also yield higher learning success than presenting material in a classical, non-computer based, way [2]. Only few people having the proper didactical background to tailor the learning objectives to the students' need also have the programming knowledge and game design skills allowing them to develop didactically and technically sound serious games [3, 4]. In this paper, we argue for an approach to enable didactical experts, i.e. educators, to develop serious games adapted to their own learning content. To address this problem we develop a tool allowing educators to visually design their serious games, which is based on model driven development techniques that allow the generation of software from visual models. We describe the first step towards this tool, the development of the underlying domain specific modeling language (DSML). &copy; 2013 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Learning systems},
  keywords  = {Motivation;Students;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-40814-4_92},
}

@InProceedings{20132816491630,
  author    = {Kurpick, Thomas and Pinkernell, Claas and Look, Markus and Rumpe, Bernhard},
  title     = {Modeling cyber-physical systems: Model-driven specification of energy efficient buildings},
  year      = {2012},
  pages     = {ACM Special Interest Group on Software Engineering (SIGSOFT); IEEE CS -},
  address   = {Innsbruck, Austria},
  note      = {CPS;Cyber physical systems (CPSs);Domain specific languages;energy;Model-driven;Specification of energy;Technical facility;UML;},
  abstract  = {A lot of current buildings are operated energy inefficient and offer a great potential to reduce the overall energy consumption and CO<inf>2</inf> emission. Detecting these inefficiencies is a complicated task and needs domain experts that are able to identify them. Most approaches try to support detection by focussing on monitoring the building's operation and visualizing data. Instead our approach focuses on using techniques taken from the cyber-physical systems' modeling domain. We create a model of the building and show how we constrain the model by OCL-like rules to support a sound specification which can be matched against monitoring results afterwards. The paper presents our domain-specific language for modeling buildings and technical facilities that is implemented in a software-based tool used by domain experts and thus hopefully providing a suitable contribution to modeling the cyber-physical world. &copy; 2012 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the Modelling of the Physical World Workshop, MOTPW 2012},
  key       = {Models},
  keywords  = {Carbon dioxide;DSL;Embedded systems;Energy efficiency;Energy utilization;Problem oriented languages;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2491617.2491619},
}


@inproceedings{20153401202673,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Generating milling tool paths for prismatic parts using genetic programming},
journal = {Procedia CIRP},
author = {Barclay, Jack and Dhokia, Vimal and Nassehi, Aydin},
volume = {33},
year = {2015},
pages = {490 - 495},
issn = {22128271},
address = {Capri, Italy},
abstract = {The automatic generation of milling tool paths traditionally relies on applying complex tool path generation algorithms to a geometric model of the desired part. For parts with unusual geometries or intricate intersections between sculpted surfaces, manual intervention is often required when normal tool path generation methods fail to produce efficient tool paths. In this paper, a simplified model of the machining process is used to create a domain-specific language that enables tool paths to be generated and optimised through an evolutionary process -formulated, in this case, as a genetic programming system. The driving force behind the optimisation is a fitness function that promotes tool paths whose result matches the desired part geometry and favours those that reach their goal in fewer steps. Consequently, the system is not reliant on tool path generation algorithms, but instead requires a description of the desired characteristics of a good solution, which can then be used to measure and evaluate the relative performance of the candidate solutions that are generated. The performance of the system is less sensitive to different geometries of the desired part and doesn't require any additional rules to deal with changes to the initial stock (e.g. when rest roughing). The method is initially demonstrated on a number of simple test components and the genetic programming process is shown to positively influence the outcome. Further tests and extensions to the work are presented. &copy; 2014 The Authors. Published by Elsevier B.V.},
key = {Genetic programming},
keywords = {Algorithms;Computer control systems;Computer programming;Computer programming languages;Genetic algorithms;Geometry;Manufacture;Milling (machining);Problem oriented languages;},
note = {Automatic Generation;Computer numerical control;Domain specific languages;Evolutionary process;Genetic programming system;Manual intervention;Relative performance;Tool path generation;},
URL = {http://dx.doi.org/10.1016/j.procir.2015.06.060},
} 


@inproceedings{20143618129747,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Behavior modeling and reasoning for ambient support: HCM-L modeler},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Machot, Fadi Al and Mayr, Heinrich C. and Michael, Judith},
volume = {8482 LNAI},
number = {PART 2},
year = {2014},
pages = {388 - 397},
issn = {03029743},
address = {Kaohsiung, Taiwan},
abstract = {This paper introduces the architecture and the features of the HCM-L Modeler, a modeling tool supporting the Human Cognitive Modeling Language HCM-L and a comprehensive reasoning approach for Human Cognitive Models based on Answer Set Programming. The HCM-L tool has been developed using the ADOxx&reg; meta modeling platform and following the principles of the Open Modeling Initiative: to provide open models that are formulated in an arbitrary, domain specific modeling language, which however is grounded in a common ontological framework, and therefore easily to translate in another language depending of the given purpose. &copy; 2014 Springer International Publishing Switzerland.},
key = {Cognitive systems},
keywords = {Intelligent systems;Knowledge based systems;Logic programming;Ontology;},
note = {Ambient Assistance;Answer set programming;Behavior model;Knowledge base;Model languages;Model mappings;Modeling tool;Reasoning;},
URL = {http://dx.doi.org/10.1007/978-3-319-07467-2_41},
} 


@article{20164302941951,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {WESSBAS: extraction of probabilistic workload specifications for load testing and performance predictiona model-driven approach for session-based application systems},
journal = {Software and Systems Modeling},
author = {Vogele, Christian and van Hoorn, Andre and Schulz, Eike and Hasselbring, Wilhelm and Krcmar, Helmut},
year = {2016},
pages = {1 - 35},
issn = {16191366},
abstract = {The specification of workloads is required in order to evaluate performance characteristics of application systems using load testing and model-based performance prediction. Defining workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in both areas. To overcome this challenge, this paper presents an approach that aims to automate the extraction and transformation of workload specifications for load testing and model-based performance prediction of session-based application systems. The approach (WESSBAS) comprises three main components. First, a system- and tool-agnostic domain-specific language (DSL) allows the layered modeling of workload specifications of session-based systems. Second, instances of this DSL are automatically extracted from recorded session logs of production systems. Third, these instances are transformed into executable workload specifications of load generation tools and model-based performance evaluation tools. We present transformations to the common load testing tool Apache JMeter and to the Palladio Component Model. Our approach is evaluated using the industry-standard benchmark SPECjEnterprise2010 and the World Cup 1998 access logs. Workload-specific characteristics (e.g., session lengths and arrival rates) and performance characteristics (e.g., response times and CPU utilizations) show that the extracted workloads match the measured workloads with high accuracy. &copy; 2016 The Author(s)},
key = {Load testing},
keywords = {Computer programming languages;Extraction;Forecasting;Modeling languages;Problem oriented languages;Specifications;},
note = {Domain specific languages;Industry-standard benchmarks;Model driven approach;Performance characteristics;Performance evaluation tools;Performance Model;Performance prediction;Testing and modeling;},
URL = {http://dx.doi.org/10.1007/s10270-016-0566-5},
} 

@InProceedings{20160101752174,
  author    = {Aerts, Arend and Mousavi, Mohammad Reza and Reniers, Michel},
  title     = {A tool prototype for model-based testing of cyber-physical systems},
  year      = {2015},
  volume    = {9399},
  pages     = {563 - 572},
  address   = {Cali, Colombia},
  note      = {Acumen;Conformance testing;Cyber physical systems (CPSs);DC-DC boost converters;Domain specific languages;Hybrid system models;Model based testing;Test case generation;},
  abstract  = {We report on a tool prototype for model-based testing of cyber-physical systems. Our starting point is a hybrid-system model specified in a domain-specific language called Acumen. Our prototype tool is implemented in Matlab and covers three stages of model-based testing, namely, test-case generation, test-case execution, and conformance analysis. We have applied our implementation to a number of typical examples of cyber-physical systems in order to analyze its applicability. In this paper, we report on the result of applying the prototype tool on a DC-DC boost converter. &copy; Springer International Publishing Switzerland 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Embedded systems},
  keywords  = {Computer programming languages;DC-DC converters;Hybrid systems;MATLAB;Model checking;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-25150-9_32},
}

@InProceedings{20143718153646,
  author    = {Tatibouet, Jeremie and Cuccuru, Arnaud and Gerard, Sebastien and Terrier, Francois},
  title     = {Towards a systematic, tool-independent methodology for defining the execution semantics of UML profiles with fUML},
  year      = {2014},
  pages     = {182 - 192},
  address   = {Lisbon, Portugal},
  note      = {Alf;DSML;Execution;FUML;MoC;Profile;Turing;},
  abstract  = {The purpose of UML profile mechanism is to design domain specific languages (DSL) based on UML. It exists a wide range of UML profiles: MARTE, ROOM, SysML. Current profile design methodology only considers the syntactic part of the language and keeps informal the execution semantics description. This impairs Model Driven Engineering (MDE) promises which advocates for executable models. This paper presents a systematic approach to formalize the execution semantics of UML profiles using foundational UML (normative specification) which defines a precise semantics for a subset of UML. This approach is integrated into the reference profile design methodology. It is illustrated on a small profile to support Turing machines. It demonstrates capability to execute resulting profiled models through the defined semantics. Copyright &copy; 2014 SCITEPRESS - Science and Technology Publications. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {MODELSWARD 2014 - Proceedings of the 2nd International Conference on Model-Driven Engineering and Software Development},
  key       = {Unified Modeling Language},
  keywords  = {Computer programming languages;Design;Markup languages;Semantics;Software design;Turing machines;},
  language  = {English},
}


@inproceedings{20123915476603,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Virmanel: A mobile multihop network virtualization tool},
journal = {Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM},
author = {Benchaib, Yacine and Chaudet, Claude},
year = {2012},
pages = {67 - 74},
address = {Istanbul, Turkey},
abstract = {This paper describes VIRMANEL, a new, open source (LGPL) tool that we developed to run experiments and evaluate protocols and algorithms on mobile multihop networks using real software and real operating systems. VIRMANEL comprises an integrated domain-specific language to define new mobility models, a Graphical User Interface to study the behavior of mobiles nodes and a controller engine that emulates a multihop mobile network by setting firewall rules between virtual machines to define network connectivity. Designed to work with OpenVZ1, an eficient operating system-level virtualization tool, VIRMANEL combines ease of use and ef- ficiency by enabling the study of large networks distributed over multiple physical machines. Copyright &copy; 2012 ACM.},
key = {Wireless networks},
keywords = {Carrier mobility;Computer system firewalls;Graphical user interfaces;Open systems;Problem oriented languages;Testbeds;Virtual reality;},
note = {Domain specific languages;Ease-of-use;Firewall rules;Large networks;Mobile multihop networks;Mobility model;Multihop mobile networks;Network connectivity;Open sources;Real softwares;System levels;Virtual machines;Virtualization tools;Virtualizations;Wireless multi-hop network;},
URL = {http://dx.doi.org/10.1145/2348688.2348703},
} 

@InProceedings{20141817636840,
  title     = {ESM 2012 - 2012 European Simulation and Modelling Conference: Modelling and Simulation 2012},
  year      = {2012},
  pages     = {The European Simulation Society (EUROSIS); FOM University of Applied Sciences; Ghent University; The University of Skovde; The Higher Technology Institute -},
  address   = {Essen, Germany},
  abstract  = {The proceedings contain 61 papers. The topics discussed include: Markov chain Monte Carlo methods to analyze the steady-state flux solution space of metabolic network models; nonparametric estimation of a survival function using refined descriptive sampling; COASTGEN: a new agent based modeling tool for invasive spartina species; vine model design using a domain specific modeling language: prototype &amp; proof of concept; a distributed simulation tool on windows phone 7; a CFD approach for CANDU6 fuel bundle subcooled boiling flow; development of CANDU 6 moderator models for simulating the flow circulation and predicting temperature distribution inside the Calandria vessel; providing a graphical user interface for the modeling of network simulator 3 scenarios; and influence of relative traffic distribution in nodes with blocking: an analytical model.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ESM 2012 - 2012 European Simulation and Modelling Conference: Modelling and Simulation 2012},
  language  = {English},
}

@InProceedings{20160401841687,
  author    = {Van Broeckhoven, Frederik and Vlieghe, Joachim and De Troyer, Olga},
  title     = {Mapping between Pedagogical Design Strategies and Serious Game Narratives},
  year      = {2015},
  pages     = {University of Skovde -},
  address   = {Skovde, Sweden},
  note      = {Annotation systems;Cyber bullying;Domain specific modeling languages;Intervention methods;Multi-disciplinary collaborations;Multi-disciplinary groups;Pedagogical designs;Pedagogical experts;},
  abstract  = {Successful serious games include a compelling narrative context and empirically validated pedagogical intervention methods. In order to create such games, design teams must consist of a multidisciplinary group of technical and pedagogical experts. In this paper, the authors show how the domain specific modeling language ATTAC-L facilitates communication between designers with different expertise, thus enabling and stimulating multidisciplinary collaboration. As a serious game design tool, ATTAC-L creates a link between the processes of pedagogical design and narrative modeling through its elaborate annotation system. As such, this modeling language enables designers to concentrate on aspects related to their field of expertise without losing oversight of the serious game as a whole. To support these tentative claims, the author present illustrations of how ATTAC-L is used in combination with a specific pedagogical design strategy (i.e. the Intervention Mapping Protocol) for the development of a serious game against cyber-bullying. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {VS-Games 2015 - 7th International Conference on Games and Virtual Worlds for Serious Applications},
  key       = {Design},
  keywords  = {Computational linguistics;Education;Mapping;Modeling languages;Specification languages;Virtual reality;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/VS-GAMES.2015.7295780},
}

@InProceedings{20161602247485,
  author    = {Geyer, Fabien and Schneele, Stefan and Carle, Georg},
  title     = {PETFEN: A performance evaluation tool for flow-level network modeling of ethernet networks},
  year      = {2014},
  pages     = {25 - 30},
  address   = {Bratislava, Slovakia},
  note      = {Discrete-event simulators;Effective domains;Ethernet networks;Link utilization;Network modeling;Network traffic modeling;Performance evaluation;Performance evaluation tools;},
  abstract  = {We present in this paper PETFEN, a Performance Evaluation Tool for Flow-level network modeling of Ethernet Networks. Flow-level network models are a useful tool to dimension and predict various performances of networks with TCP and UDP flows, providing information such as mean flow bandwidths, link utilizations or queue sizes. While the literature on flow-level network models is extensive, there is still a lack of tools for numerical evaluations on user provided topologies. In this paper, we describe the three components of PETFEN: (i) an effective domain specific language used for algorithmically describing topologies, (ii) a mathematical toolbox for the numerical evaluation of flow-level network models on the provided topologies, (iii) modules for the evaluation of the topologies with external tools. Via various numerical evaluations, we compare the results of PETFEN with results of SimGrid, another tool based on flow-level network models, as well as results of the discrete event simulator OMNeT++. &copy; Copyright 2015 ICST.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the 8th International Conference on Performance Evaluation Methodologies and Tools, VALUETOOLS 2014},
  key       = {Internet protocols},
  keywords  = {Computer programming languages;Discrete event simulation;Ethernet;Numerical models;Problem oriented languages;Topology;},
  language  = {English},
  url       = {http://dx.doi.org/10.4108/icst.valuetools.2014.258166},
}

@InProceedings{20161302149612,
  author    = {Boube, Erwan and Corley, Jonathan and Combemale, Benoit and Gray, Jeff and Baudry, Benoit},
  title     = {Supporting efficient and advanced omniscient debugging for xDSMLs},
  year      = {2015},
  pages     = {137 - 148},
  address   = {Pittsburgh, PA, United states},
  note      = {Debuggers;Domain specific modeling languages;Error prone tasks;Execution trace;General purpose languages;Generic solutions;Omniscient debugging;XDSML;},
  abstract  = {Omniscient debugging is a promising technique that relies on execution traces to enable free traversal of the states reached by a system during an execution. While some General-Purpose Languages (GPLs) already have support for omniscient debugging, developing such a complex tool for any executable Domain-Specific Modeling Language (xDSML) remains a challenging and error prone task. A solution to this problem is to define a generic omniscient debugger for all xDSMLs. However, generically supporting any xDSML both compromises the efficiency and the usability of such an approach. Our contribution relies on a partly generic omniscient debugger supported by generated domain-specific trace management facilities. Being domain-specific, these facilities are tuned to the considered xDSML for better efficiency. Usability is strengthened by providing multidimensional omniscient debugging. Results show that our approach is on average 3.0 times more efficient in memory and 5.03 more efficient in time when compared to a generic solution that copies the model at each step. &copy; 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {SLE 2015 - Proceedings of the 2015 ACM SIGPLAN International Conference on Software Language Engineering},
  key       = {Program debugging},
  keywords  = {Computational linguistics;Computer programming languages;Efficiency;Modeling languages;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2814251.2814262},
}

@InProceedings{20160902036908,
  author    = {Groce, Alex and Pinto, Jervis and Azimi, Pooria and Mittal, Pranjal},
  title     = {TSTL: A language and tool for testing (demo)},
  year      = {2015},
  pages     = {414 - 417},
  address   = {Baltimore, MD, United states},
  note      = {Automated testing;Delta debugging;Domain specific languages;Programming tasks;Python;Source language;Support testing;Testing tools;},
  abstract  = {Writing a test harness is a difficult and repetitive programming task, and the lack of tool support for customized automated testing is an obstacle to the adoption of more sophisticated testing in industry. This paper presents TSTL, the Template Scripting Testing Language, which allows users to specify the general form of valid tests for a system in a simple but expressive language, and tools to support testing based on a TSTL definition. TSTL is a minimalist template- based domain-specific language, using the source language of the Software Under Test (SUT) to support most operations, but adding declarative idioms for testing. TSTL compiles to a common testing interface that hides the details of the SUT and provides support for logging, code coverage, delta debugging, and other core testing functionality, making it easy to write universal testing tools such as random testers or model checkers that apply to all TSTL-defined harnesses. TSTL is currently available for Python, but easily adapted to other languages as well. &copy; 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings},
  key       = {Software testing},
  keywords  = {Computational linguistics;Computer programming;Computer programming languages;Graphical user interfaces;High level languages;Model checking;Natural language processing systems;Problem oriented languages;XML;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2771783.2784769},
}

@InProceedings{20160201784907,
  author    = {Gunalp, Ozan and Escoffier, Clement and Lalanda, Philippe},
  title     = {Rondo: A Tool Suite for Continuous Deployment in Dynamic Environments},
  year      = {2015},
  pages     = {720 - 727},
  address   = {New York, NY, United states},
  note      = {Computing environments;Continuous Deployment;Domain specific languages;Dynamic environments;Dynamism;Heterogeneous environments;Service oriented application;Service oriented computing;},
  abstract  = {Driven by the emergence of new computing environments, dynamically evolving software systems makes it impossible for developers to deploy software with human-centric processes. Instead, there is an increasing need for automation tools that continuously deploy software into execution, in order to push updates or adapt existing software regarding contextual and business changes. Existing solutions fall short on providing fault-tolerant, reproducible deployments that can scale on heterogeneous environments. In this paper we present Rondo, a tool suite that enables continuous deployment for dynamic, service-oriented applications. At the center of these tools, we propose a deterministic and idem potent deployment process. We provide with Rondo a deployment manager that implements this process and capable of conducting deployments and continuously adapting applications according to the changes in the current target platform. The tool suite also includes a domain-specific language for describing deployment requests. We validate our approach in multiple projects, for provisioning the platform as well as for installing applications and continuous reconfigurations. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings - 2015 IEEE International Conference on Services Computing, SCC 2015},
  key       = {Computer aided software engineering},
  keywords  = {Computer programming languages;Distributed computer systems;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SCC.2015.102},
}

@Article{20143600043933,
  author    = {Selim, Gehan M. K. and Wang, Shige and Cordy, James R. and Dingel, Juergen},
  title     = {Model transformations for migrating legacy deployment models in the automotive industry},
  journal   = {Software and Systems Modeling},
  year      = {2013},
  volume    = {14},
  number    = {1},
  pages     = {365 - 381},
  note      = {Automotive control softwares;AutoSAR;Model transformation;Model-driven development;Transformation languages;},
  abstract  = {Many companies in the automotive industry have adopted model-driven development in their vehicle software development. As a major automotive company, General Motors (GM) has been using a custom-built, domain-specific modeling language, implemented as an internal proprietary metamodel, to meet the modeling needs in its control software development. Since AUTomotive Open System ARchitecture (AUTOSAR) has been developed as a standard to ease the process of integrating components provided by different suppliers and manufacturers, there has been a growing demand to migrate these GM-specific, legacy models to AUTOSAR models. Given that AUTOSAR defines its own metamodel for various system artifacts in automotive software development, we explore applying model transformations to address the challenges in migrating GM-specific, legacy models to their AUTOSAR equivalents. As a case study, we have built and validated a model transformation using the MDWorkbench tool, the Atlas Transformation Language, and the Metamodel Coverage Checker tool. This paper reports on the case study, makes observations based on our experience to assist in the development of similar types of transformations, and provides recommendations for further research. &copy; 2013, Springer-Verlag Berlin Heidelberg.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16191366},
  key       = {Software design},
  keywords  = {Automobile manufacture;Automotive industry;Black-box testing;Computational linguistics;Embedded systems;Model checking;Modeling languages;Open systems;Software testing;Specification languages;Supply chains;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s10270-013-0365-1},
}

@InProceedings{20123015267169,
  author    = {Simic, Hrvoje},
  title     = {Predicate trees: A tool for descriptive subgraph extraction},
  year      = {2012},
  pages     = {Vestlandsforsking; Sitech; DataArt; Eau de Web; PlanetData Network of Excellence -},
  address   = {Craiova, Romania},
  note      = {Linked datum;RDF data;Scala;SPARQL;Subgraph extraction;},
  abstract  = {Extracting a subgraph descriptive of a single resource from a given RDF graph is an issue relevant to the Linked Data initiative, RDF triple stores and Semantic Web in general. Existing methods of subgraph extraction tend to be either simple and inexpressive, or else powerful and complex. This paper introduces a novel method of descriptive subgraph extraction as a new expression language and as a domain-specific language library in Scala, which aims to be more expressive than the former and easier to write and use than the latter methods. These expressions can then be translated into SPARQL, used directly on triple pattern matching interfaces for RDF graphs, or as DESCRIBE handlers in SPARQL engines. A comparison highlighting advantages and limitations of the new method is also given. Copyright 2012 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Semantic Web},
  keywords  = {Data handling;Pattern matching;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2254129.2254160},
}

@InProceedings{20155201735059,
  author    = {Peralta, Alvaro Jose and Le, Nguyen Tuan Thanh and Stinckwich, Serge and Hanachi, Chihab and Bergel, Alexandre and Ho, Tuong Vinh},
  title     = {A tool for assessing quality of rescue plans by combining visualizations of different business process perspectives},
  year      = {2015},
  volume    = {233},
  pages     = {155 - 166},
  address   = {Tunis, Tunisia},
  note      = {Allocation strategy;BPMN;Business process model;Crisis situations;Domain specific languages;Formal structures;Rescue plans;Static and dynamic analysis;},
  abstract  = {Rescue plans for crisis situations such as natural or made disasters are mostly presented in a textual format to the relevant authority. Assessing the quality of a rescue plan requires analyzing different perspectives, such as plan complexity, resources costs, service time, allocation strategy and organization efficiency. Unfortunately, textual rescue plans lack a formal structure to ease the reading and navigation through the document. To address this problem we are composing tailored visualizations, each visualization representing a particular perspective. We provide a domain specific language to describe domain specific visualizations of processes. We validate our approach using static and dynamic analysis of the Ho Chi Minh city rescue plan in case of a tsunami. Our approach provides recommendations that are useful for the authority to improve the original rescue plan. &copy; Springer International Publishing Switzerland 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {18651348},
  journal   = {Lecture Notes in Business Information Processing},
  key       = {Information management},
  keywords  = {Computer programming languages;Flow visualization;Information systems;Problem oriented languages;Systems engineering;Visualization;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-24399-3_14},
}

@InProceedings{20144800250273,
  author    = {Karnitis, Girts and Bicevska, Zane and Cerina-Berzina, Jana and Bicevskis, Janis},
  title     = {Practitioners approach to business processes modeling},
  year      = {2014},
  volume    = {Databases and Information Systems VIII -Selected Papers from the Eleventh International Baltic Conference,DB\&IS 2014},
  pages     = {343 - 356},
  address   = {Tallinn, Estonia},
  note      = {Business modeling;Business Process;Business process model;Domain specific languages;Executable model;Modeling type;Public institution;Support tool;},
  abstract  = {This paper describes experience in business process modeling using Domain Specific Language (DSL) in several public institutions in Latvia. Authors identified five types of business model use: (1) informal model to enhance comprehension of business processes, (2) manually or semi-automatically executable model to define business processes, (3) model to specify requirements for information system (IS), (4) executable model as component of IS and (5) model to verify correctness of business processes. Authors analyze special requirements dictated by each type of use towards DSL and its support tools. Authors demonstrate ude-cases for each model type. &copy; 2014 The authors and IOS Press.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {09226389},
  journal   = {Frontiers in Artificial Intelligence and Applications},
  key       = {Process engineering},
  keywords  = {Computer programming languages;Information systems;Problem oriented languages;Systems engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.3233/978-1-61499-458-9-343},
}

@Article{20153201109246,
  author    = {Semerath, Oszkar and Barta, agnes and Horvath, akos and Szatmari, Zoltan and Varro, Daniel},
  title     = {Formal validation of domain-specific languages with derived features and well-formedness constraints},
  journal   = {Software and Systems Modeling},
  year      = {2015},
  note      = {Derived features;Design environment;Domain specific languages;Language validation;Partial snapshots;Performance experiment;Smt solvers;Transitive closure;},
  abstract  = {Despite the wide range of existing tool support, constructing a design environment for a complex domain-specific language (DSL) is still a tedious task as the large number of derived features and well-formedness constraints complementing the domain metamodel necessitate special handling. Such derived features and constraints are frequently defined by declarative techniques (such graph patterns or OCL invariants). However, for complex domains, derived features and constraints can easily be formalized incorrectly resulting in inconsistent, incomplete or ambiguous DSL specifications. To detect such issues, we propose an automated mapping of EMF metamodels enriched with derived features and well-formedness constraints captured as graph queries in EMF-IncQuery or (a subset of) OCL invariants into an effectively propositional fragment of first-order logic which can be efficiently analyzed by back-end reasoners. On the conceptual level, the main added value of our encoding is (1) to transform graph patterns of the EMF-IncQuery framework into FOL and (2) to introduce approximations for complex language features (e.g., transitive closure or multiplicities) which are not expressible in FOL. On the practical level, we identify and address relevant challenges and scenarios for systematically validating DSL specifications. Our approach is supported by a tool, and it will be illustrated on analyzing a DSL in the avionics domain. We also present initial performance experiments for the validation using Z3 and Alloy as back-end reasoners. &copy; 2015 Springer-Verlag Berlin Heidelberg},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16191366},
  key       = {Computational linguistics},
  keywords  = {Computer programming languages;Formal logic;Graphical user interfaces;Problem oriented languages;Specifications;XML;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s10270-015-0485-x},
}

@Article{20150500483596,
  author    = {Moline, Eric and Morette, Nicolas and Novales, Cyril and Vieyres, Pierre},
  title     = {Robotic engineers specifications for a well-fitted model-driven control architecture for robots},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year      = {2014},
  volume    = {8810},
  pages     = {170 - 181},
  note      = {Associated tool;Component-based models;Domain specific languages;Model driven architectures;Model driven control;Robot architecture;Robotic architectures;Software model;},
  abstract  = {This paper gives an overview of reflections about more generic robotic architectures models and their associated tools. The objective of our work is not to define a new robot software but rather to specify common robotic requirements for future component-based models. These models could be used as a common-base by the robotic sub-communities whatever the purpose their different robots have been designed for, whatever the targeted hardware, the chosen frameworks or the host operating systems. Even if we are not yet strongly familiar with the specificities of the Model-Driven Architecture (MDA) and with the Domain-Specific Language (DSL), we are self-convinced by the powerful benefits that these two fields could bring to robotics and to robotic architecture models. In this paper, we discuss about the characteristics a robotic architecture model should own to be efficiently designed by software model engineers and easily but efficiently used by robot engineers. &copy; Springer International Publishing Switzerland 2014.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  key       = {Robotics},
  keywords  = {Computer programming languages;Engineers;Problem oriented languages;Robots;Software architecture;Software design;},
  language  = {English},
}


@inproceedings{20134516952780,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Validation of derived features and well-formedness constraints in DSLs: By mapping graph queries to an SMT-solver},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Semerath, Oszkar and Horvath, Akos and Varro, Daniel},
volume = {8107 LNCS},
year = {2013},
pages = {538 - 554},
issn = {03029743},
address = {Miami, FL, United states},
abstract = {Despite the wide range of existing generative tool support, constructing a design environment for a complex domain-specific language (DSL) is still a tedious task as the large number of derived features and well-formedness constraints complementing the domain metamodel necessitate special handling. Incremental model queries as provided by the EMF-IncQuery framework can (i) uniformly specify derived features and well-formedness constraints and (ii) automatically refresh their result set upon model changes. However, for complex domains, derived features and constraints can be formalized incorrectly resulting in incomplete, ambiguous or inconsistent DSL specifications. To detect such issues, we propose an automated mapping of EMF metamodels enriched with derived features and well-formedness constraints captured as graph queries in EMF-IncQuery into an effectively propositional fragment of first-order logic which can be efficiently analyzed by the Z3 SMT-solver. Moreover, overapproximations are proposed for complex query features (like transitive closure and recursive calls). Our approach will be illustrated on analyzing a DSL being developed for the avionics domain. &copy; 2013 Springer-Verlag.},
key = {Models},
keywords = {Problem oriented languages;},
note = {Automated mapping;Design environment;Domain specific languages;First order logic;Incremental modeling;Model validation;SMT-solvers;Transitive closure;},
URL = {http://dx.doi.org/10.1007/978-3-642-41533-3_33},
} 


@inproceedings{20125015782922,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {LDS based tools to ease template construction},
journal = {2012 International Conference on Synthesis, Modeling, Analysis and Simulation Methods and Applications to Circuit Design, SMACD 2012},
author = {Unutulmaz, A. and Dundar, G. and Fernandez, F.V.},
year = {2012},
pages = {61 - 64},
address = {Seville, Spain},
abstract = {Layout Description Script (LDS) is a domain specific language (DSL) intended to describe analog layouts. This paper introduces an LDS based tool, Capture, and an add-on, LDS Analyzer, for LDS. Capture aims to convert layout images into layout templates. Components of a layout are extracted with this tool and a template is synthesized from the extracted data. LDS Analyzer is an enhanced LDS parser. Analyzer investigates an LDS statement and conducts either simple parsing or enhanced parsing which make use of symbolic variables. &copy; 2012 IEEE.},
key = {Software engineering},
keywords = {Chemistry;Circuit simulation;Speech synthesis;},
note = {Analog layout;Domain specific languages;Layout templates;},
URL = {http://dx.doi.org/10.1109/SMACD.2012.6339417},
} 


@inproceedings{20144800255625,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Next generation (Meta)modeling: Web- and cloud-based collaborative tool infrastructure},
journal = {CEUR Workshop Proceedings},
author = {Maroti, Miklos and Kecskes, Tamas and Kereskenyi, Robert and Broll, Brian and Volgyesi, Peter and Juracz, Laszlo and Levendoszky, Tihamer and Ledeczi, Akos},
volume = {1237},
year = {2014},
pages = {41 - 60},
issn = {16130073},
address = {Valencia, Spain},
abstract = {The paper presents WebGME, a novel, web- and cloud-based, collaborative, scalable (meta)modeling tool that supports the design of Domain Specific Modeling Languages (DSML) and the creation of corresponding domain models. The unique prototypical inheritance, originally introduced by GME, is extended in WebGME to fuse metamodeling with modeling. The tool also introduces novel ways to model cross-cutting concerns. These concepts are especially useful for multi-paradigm modeling. The main design drivers for WebGME have been scalability, extensibility and version control. The web-based architecture and the constraints the browser-based environment introduces provided significant challenges that WebGME has overcome with balanced trade-offs. The paper describes the architecture of WebGME, argues why the major design decisions were taken and presents the novel features of the tool.},
key = {Social networking (online)},
keywords = {Design;Economic and social effects;Embedded systems;Specification languages;Web browsers;},
note = {Collaboration;Collaborative tools;Cross-cutting concerns;Domain specific modeling languages;DSML;Meta model;Multi paradigm modeling;Web-based architecture;},
} 

@InProceedings{20140917372806,
  author    = {Ozik, Jonathan and Collier, Nicholson T. and Murphy, John T. and North, Michael J.},
  title     = {The ReLogo agent-based modeling language},
  year      = {2013},
  pages     = {1560 - 1568},
  address   = {Washington, DC, United states},
  note      = {Agent-based model;Code libraries;Domain specific languages;Dynamically typed languages;High performance computing;Integrated development environment;Open sources;Programming idioms;},
  abstract  = {ReLogo is a new agent-based modeling (ABM) domain specific language (DSL) for developing agent-based models in the free and open source Repast Suite of ABM tools; the Java based Repast Simphony ABM toolkit and the C++ high performance computing Repast HPC toolkit both incorporate ReLogo. The language is geared towards a wide range of modeling and programming expertise, combining the sophisticated and powerful ABM infrastructure and capabilities in the Repast Suite with the ease of use of the Logo programming language and its associated programming idioms. This paper will present how ReLogo combines a number of concepts, including object-oriented programming, simple integration of existing code libraries, statically and dynamically typed languages, domain specific languages, and the use of integrated development environments, to create an ABM tool that is easy to learn yet is also capable of creating large scale ABMs of real world complex systems. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the 2013 Winter Simulation Conference - Simulation: Making Decisions in a Complex World, WSC 2013},
  key       = {Open systems},
  keywords  = {Computational methods;Computer programming languages;Decision making;Object oriented programming;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/WSC.2013.6721539},
}


@inproceedings{20150500483149,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Clooca : Web based tool for domain specific modeling},
journal = {CEUR Workshop Proceedings},
author = {Hiya, Shuhei and Hisazumi, Kenji and Fukuda, Akira and Nakanishi, Tsuneo},
volume = {1115},
year = {2013},
pages = {31 - 35},
issn = {16130073},
address = {Miami, FL, United states},
abstract = {Clooca is a development environment that allows us to build up domain-specific modeling languages, or DSMLs, and their code gen- erators. DSMLs are widely used to improve productivity and quality of developing software to raise the level of abstraction and to generate a fully functional software codes. Currently some tools to develop software are provided as web services. We can use the tool without installing any software and without professional knowledge of software development. Even domain specialists who do not know how to develop software can use it. Therefore, we tackle with developing software-as-a-service(SaaS) type of DSML tools to bring benefits of both DSML and SaaS type of development tools. We chose to use clooca in an education setting, because this tool solves some problems in that field. The youtube link is http://www.youtube.com/watch?v=VS5VNB0YA-o. The youtube link is http://www.youtube.com/watch?v=VS5VNB0YA-o.},
key = {Software as a service (SaaS)},
keywords = {Codes (symbols);Computational linguistics;Education computing;Embedded systems;Modeling languages;Productivity;Social networking (online);Software design;Software engineering;Specification languages;Technology transfer;Web services;Websites;World Wide Web;},
note = {Code generators;Development environment;Domain specific modeling;Domain specific modeling languages;DSML;Level of abstraction;Professional knowledge;SaaS;},
} 

@InProceedings{20122915249390,
  author    = {Hlaoui, Yousra Bendaly and Ben Ayed, Leila Jemni and Ben Fradj, Imen},
  title     = {A model driven approach to compose and develop Grid service workflow applications},
  year      = {2012},
  address   = {Sousse, Tunisia},
  note      = {Activity diagram;BPEL4WS;BPEL4WS language;Domain specific languages;Grid service workflow;Grid services;Meta model;Model driven approach;UML activity diagrams;Workflow models;},
  abstract  = {We use a Domain Specific Language (DSL) based on UML activity diagrams (UML-AD) to specify and compose systematically workflow models from Grid services. To be executed, workflow activity diagram models should be translated into BPEL4WS models which will be executed by the BPEL4WS engine. To reach this objective, we propose a meta-model based transformation from UML activity diagrams to BPEL4WS language. To ensure the correctness and the completion of the transformation, we propose a graph homomorphic mapping between the activity diagram and BPEL4WS language elements. To execute the BPEL4WS provided model, we propose in this paper an execution infrastructure based on The Globus Tool Kit. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {2012 International Conference on Information Technology and e-Services, ICITeS 2012},
  key       = {Telecommunication services},
  keywords  = {Grid computing;Information technology;Systems analysis;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICITeS.2012.6216638},
}

@InProceedings{20134416925186,
  author    = {Iliasov, Alexei and Lopatkin, Ilya and Romanovsky, Alexander},
  title     = {The SafeCap platform for modelling railway safety and capacity},
  year      = {2013},
  volume    = {8153 LNCS},
  pages     = {130 - 137},
  address   = {Toulouse, France},
  note      = {capacity-improving patterns;Domain specific languages;Eclipse;Event-B;GMF;Model transformation;ProB;Smt solvers;},
  abstract  = {This paper describes a tooling platform that supports reasoning about railway capacity while ensuring system safety. It uses a Domain Specific Language (DSL) that allows signalling engineers to design stations and junctions, to check their safety and to evaluate the potential improvements of capacity while applying various alteration patterns that change the railway schemas. The platform uses a combination of model checking and SMT solving to verify system safety in the most efficient and user-friendly way. It includes several plug-ins that evaluate various capacity parameters. The tool uses the Eclipse technology, including its EMF and GMF frameworks. It has been developed in close cooperation with the Invensys Rail engineers and applied in a variety of mediumscale projects, which has demonstrated its ability to help understand the effects that changes in the plans and schemas can potentially have on capacity. &copy; 2013 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Security of data},
  keywords  = {Electric potential;Model checking;Problem oriented languages;Railroad transportation;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-40793-2_12},
}

@InProceedings{20140917370419,
  author    = {George, Nithin and Novo, David and Rompf, Tiark and Odersky, Martin and Ienne, Paolo},
  title     = {Making domain-specific hardware synthesis tools cost-efficient},
  year      = {2013},
  pages     = {120 - 127},
  address   = {Kyoto, Japan},
  note      = {Cost-effective approach;Domain specific languages;Efficient implementation;Hardware implementations;Hardware synthesis;High level of abstraction;High level specification;High-level synthesis;},
  abstract  = {Tools to design hardware at a high level of abstraction promise software-like productivity for hardware designs. Among them, tools like Spiral, HDL Coder, Optimus and MMAlpha target specific application domains and produce highly efficient implementations from high-level input specifications in a Domain Specific Language (DSL). But, developing similar domain-specific High-Level Synthesis (HLS) tools need enormous effort, which might offset their many advantages. In this paper, we propose a novel, cost-effective approach to develop domain-specific HLS tools. We develop the HLS tool by embedding its input DSL in Scala and using Lightweight Modular Staging (LMS), a compiler framework written in Scala, to perform optimizations at different abstraction levels. For example, to optimize computation on matrices, some optimizations are more effective when the program is represented at the level of matrices while others are better applied at the level of individual matrix elements. To illustrate the proposed approach, we create an HLS flow to automatically generate efficient hardware implementations of matrix expressions described in our own high-level specification language. Although a simple example, it shows how easy it is to reuse modules across different HLS flows and to integrate our flow with existing tools like LegUp, a C-to-RTL compiler, and FloPoCo, an arithmetic core generator. The results reveal that our approach can simultaneously achieve high productivity and design quality with a very reasonable tool development effort. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {FPT 2013 - Proceedings of the 2013 International Conference on Field Programmable Technology},
  key       = {Tools},
  keywords  = {Computer programming languages;Hardware;Optimization;Productivity;Program compilers;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/FPT.2013.6718341},
}

@Article{20143017980323,
  author    = {Satyanarayan, Arvind and Heer, Jeffrey},
  title     = {Authoring narrative visualizations with Ellipsis},
  journal   = {Computer Graphics Forum},
  year      = {2014},
  volume    = {33},
  number    = {3},
  pages     = {361 - 370},
  note      = {Descriptors;Domain specific languages;Graphical interface;Information interfaces;Interactive narrative;Prototyping tools;Technical expertise;Visualization tools;},
  abstract  = {Data visualization is now a popular medium for journalistic storytelling. However, current visualization tools either lack support for storytelling or require significant technical expertise. Informed by interviews with journalists, we introduce a model of storytelling abstractions that includes state-based scene structure, dynamic annotations and decoupled coordination of multiple visualization components. We instantiate our model in Ellipsis: a system that combines a domain-specific language (DSL) for storytelling with a graphical interface for story authoring. User interactions are automatically translated into statements in the Ellipsis DSL. By enabling storytelling without programming, the Ellipsis interface lowers the threshold for authoring narrative visualizations. We evaluate Ellipsis through example applications and user studies with award-winning journalists. Study participants find Ellipsis to be a valuable prototyping tool that can empower journalists in the creation of interactive narratives. &copy; 2014 The Eurographics Association and John Wiley &amp; Sons Ltd. Published by John Wiley &amp; Sons Ltd.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {01677055},
  key       = {Visualization},
  keywords  = {Data visualization;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1111/cgf.12392},
}

@Article{20133016525276,
  author    = {Kuhlmann, Mirco and Sohr, Karsten and Gogolla, Martin},
  title     = {Employing UML and OCL for designing and analysing role-based access control},
  journal   = {Mathematical Structures in Computer Science},
  year      = {2013},
  volume    = {23},
  number    = {4},
  pages     = {796 - 833},
  note      = {Domain specific languages;Mathematical structure;New approaches;Role-based Access Control;Security policy;Security requirements;Validation tools;Visual representations;},
  abstract  = {The stringent security requirements of organisations like banks or hospitals frequently adopt role-based access control (RBAC) principles to represent and simplify their internal permission management. While representing a fundamental advanced RBAC concept enabling precise restrictions on access rights, authorisation constraints increase the complexity of the resulting security policies so that tool support for convenient creation and adequate validation is required. A particular contribution of our work is a new approach to developing and analysing RBAC policies using a UML-based domain-specific language (DSL), which allows the hiding of the mathematical structures of the underlying authorisation constraints implemented in OCL. The DSL we present is highly configurable and extensible with respect to new concepts and classes of authorisation constraints, and allows the developer to validate RBAC policies in an effective way. The handling of dynamic (that is, time-dependent) constraints, their visual representation through the RBAC DSL and their analysis all form another part of our contribution. The approach is supported by a UML and OCL validation tool. &copy; 2013 University Press.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {09601295},
  key       = {Tools},
  keywords  = {Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1017/S0960129512000266},
}

@Article{20144800253988,
  author    = {Hernandez, Guillermo Infante and Perez, Benjamin Lopez and Fuente, Aquilino Adolfo Juan},
  title     = {Specific modeling for procedures in eGovernment domain},
  journal   = {RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao},
  year      = {2012},
  volume    = {2012},
  number    = {9},
  pages     = {736 -},
  note      = {Domain specific languages;e-Government;eGovernment domain;GraphicaL model;Management platforms;Meta model;Procedure managements;},
  abstract  = {Due to the complexity involved in E-Government domain applications, the developed ones should be able to interoperate with the growing number of emerging management platforms. The impact of this integration has among its main goals to improve the procedure management task, which suffers an important lack of technological proposals. This work proposes a graphical domain specific language (DSL) for procedure management in E-Government domain. This language came from the definition of a metamodel that states the principle EGovernment elements and defines its relations. A further graphical modeling tool was developed to implement the DSL and was tested with two actual case studies.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16469895},
  key       = {Government data processing},
  keywords  = {Computer programming languages;Problem oriented languages;},
  language  = {English},
}

@InProceedings{20133816763530,
  author    = {Bajaj, Manas and Scott, Andrew and Deming, Douglas and Wickstrom, Gregory and De Spain, Mark and Zwemer, Dirk and Peak, Russell},
  title     = {Maestro-a model-based systems engineering environment for complex electronic systems},
  year      = {2012},
  volume    = {4},
  pages     = {2651 - 2667},
  address   = {Rome, Italy},
  note      = {Complex electronic systems;Design and simulation;Domain specific languages;Model-based systems engineering;Model-based systems engineering (MBSE);Sandia National Laboratories;System architectures;Systems engineering process;},
  abstract  = {In this paper we present Maestro, a model-based systems engineering (MBSE) environment for design and simulation of complex electronic systems using Orchestra-a simulation tool developed at Sandia National Laboratories. Maestro is deployed as a plugin for MagicDraw and uses Orchestra domain-specific language (DSL) which is based on SysML. Maestro enables a model-based design and analysis approach that replaces the traditional document-based systems engineering process. It provides a unified graphical modeling environment to domain experts who have had to depend on drawing tools for defining system architecture and manual transcription of system topology in creating complex simulation models.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {22nd Annual International Symposium of the International Council on Systems Engineering, INCOSE 2012 and the 8th Biennial European Systems Engineering Conference 2012, EuSEC 2012},
  key       = {Systems engineering},
  keywords  = {Computer simulation;Electronics engineering;Problem oriented languages;},
  language  = {English},
}


@inproceedings{20143118006559,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Cross-Platform Application Development Using AXIOM as an Agile Model-Driven Approach},
journal = {Communications in Computer and Information Science},
author = {Jia, Xiaoping and Jones, Chris},
volume = {411 CCIS},
year = {2013},
pages = {36 - 51},
issn = {18650929},
address = {Rome, Italy},
abstract = {The development and maintenance of cross-platform mobile applications is expensive. Two approaches for reducing this cost are model-driven engineering (MDE) and Agile development. In this paper, we present AXIOM, a model-driven approach for developing cross-platform mobile applications in ways that also support Agile principles. Our approach uses a domain specific language (DSL) for defining platform-independent models (PIM) of mobile applications. AXIOM defines a multi-phase, customizable transformation process to convert platform-independent models into native applications for target mobile platforms. Our approach could significantly reduce development time and cost while increasing the quality of mobile applications. A prototype tool has been developed to demonstrate the feasibility of the approach. The preliminary findings are promising and show significant gains in development productivity. &copy; Springer-Verlag Berlin Heidelberg 2013.},
key = {Cost reduction},
keywords = {Computer programming languages;Mobile computing;},
note = {Application development;Development productivity;Domain specific languages;Mobile applications;Model driven approach;Model-driven Engineering;Platform-independent model;Transformation process;},
URL = {http://dx.doi.org/10.1007/978-3-642-45404-2_3},
} 

@InProceedings{20161602247501,
  author    = {Van Hoorn, Andre and Vogele, Christian and Schulz, Eike and Hasselbring, Wilhelm and Krcmar, Helmut},
  title     = {Automatic extraction of probabilistic workload specifications for load testing session-based application systems},
  year      = {2014},
  pages     = {139 - 146},
  address   = {Bratislava, Slovakia},
  note      = {Application systems;Clustering;Clustering techniques;Controlled conditions;Domain specific languages;Industry-standard benchmarks;Navigational patterns;Performance properties;},
  abstract  = {Workload generation is essential to systematically evaluate performance properties of application systems under controlled conditions, e.g., in load tests or benchmarks. The definition of workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in this area. This paper presents our approach for the modeling and automatic extraction of probabilistic workload specifications for load testing session-based application systems. The approach, called Wessbas, comprises (i.) a domain-specific language (DSL) enabling layered modeling of workload specifications as well as support for (ii.) automatically extracting instances of the DSL from recorded sessions logs and (iii.) transforming instances of the DSL to workload specifications of existing load testing tools. During the extraction process, different groups of customers with similar navigational patterns are identified using clustering techniques. We developed corresponding tool support including a transformation to probabilistic test scripts for the Apache JMeter load testing tool. The evaluation of the proposed approach using the industry standard benchmark SPECjEnterprise2010 demonstrates its applicability and the representativeness of the extracted workloads. &copy; Copyright 2015 ICST.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings of the 8th International Conference on Performance Evaluation Methodologies and Tools, VALUETOOLS 2014},
  key       = {Load testing},
  keywords  = {Benchmarking;Computer programming languages;Extraction;Modeling languages;Problem oriented languages;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.4108/icst.valuetools.2014.258171},
}


@inproceedings{20155201733196,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Bootstrapping Mobile App Development},
journal = {Proceedings - International Conference on Software Engineering},
author = {Barnett, Scott and Vasa, Rajesh and Grundy, John},
volume = {2},
year = {2015},
pages = {657 - 660},
issn = {02705257},
address = {Florence, Italy},
abstract = {Modern IDEs provide limited support for developers when starting a new data-driven mobile app. App developers are currently required to write copious amounts of boilerplate code, scripts, organise complex directories, and author actual functionality. Although this scenario is ripe for automation, current tools are yet to address it adequately. In this paper we present RAPPT, a tool that generates the scaffolding of a mobile app based on a high level description specified in a Domain Specific Language (DSL). We demonstrate the feasibility of our approach by an example case study and feedback from a professional development team. Demo at: https://www.youtube.com/watch?v=ffquVgBYpLM. &copy; 2015 IEEE.},
key = {Software engineering},
keywords = {Computer programming languages;High level languages;Problem oriented languages;Scaffolds;},
note = {Code Generation;Data driven;Domain specific languages;High level description;Mobile app;Model driven development;Professional development;},
URL = {http://dx.doi.org/10.1109/ICSE.2015.216},
} 


@article{20140817345285,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {DropsBox: The Dresden Open Software Toolbox: Domain-specific modelling tools beyond metamodels and transformations},
journal = {Software and Systems Modeling},
author = {Acmann, Uwe and Bartho, Andreas and Burger, Christoff and Cech, Sebastian and Demuth, Birgit and Heidenreich, Florian and Johannes, Jendrik and Karol, Sven and Polowinski, Jan and Reimann, Jan and Schroeter, Julia and Seifert, Mirko and Thiele, Michael and Wende, Christian and Wilke, Claas},
volume = {13},
number = {1},
year = {2014},
pages = {133 - 169},
issn = {16191366},
abstract = {The Dresden Open Software Toolbox (DropsBox) is a software modelling toolbox consisting of a set of open source tools developed by the Software Technology Group at TU Dresden. The DropsBox is built on top of the Eclipse Platform and the Eclipse Modeling Framework. The DropsBox contributes to the development and application of domain-specific language changes (DSLs) in model-driven software development. It can be customised by tool and language developers to support various activities of a DSL's life cycle ranging from language design to language application and evolution. In this paper, we provide an overview of the DSL life cycle, the DropsBox tools, and their interaction on a common example. Furthermore, we discuss our experiences in developing and integrating tools for DropsBox in an academic environment. &copy; 2012 Springer-Verlag.},
key = {Tools},
keywords = {Computer aided software engineering;Electric potential;Life cycle;Open systems;Problem oriented languages;},
note = {Academic environment;Development and applications;Domain specific languages;Domain-specific modelling;Eclipse modeling framework;MDSD;Model-Driven Software Development;Modelling tools;},
URL = {http://dx.doi.org/10.1007/s10270-012-0284-6},
} 


@article{20143600026227,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Dynamic program analysis - Reconciling developer productivity and tool performance},
journal = {Science of Computer Programming},
author = {Sarimbekov, Aibek and Zheng, Yudi and Ansaloni, Danilo and Bulej, Lubomir and Marek, Luka and Binder, Walter and Tma, Petr and Qi, Zhengwei},
volume = {95},
number = {P3},
year = {2014},
pages = {344 - 358},
issn = {01676423},
abstract = {Dynamic program analysis tools serve many important software engineering tasks such as profiling, debugging, testing, program comprehension, and reverse engineering. Many dynamic analysis tools rely on program instrumentation and are implemented using low-level instrumentation libraries, resulting in tedious and error-prone tool development. Targeting this issue, we have created the Domain-Specific Language for Instrumentation (DiSL), which offers high-level programming abstractions especially designed for instrumentation-based dynamic analysis. When designing DiSL, our goal was to boost the productivity of tool developers targeting the Java Virtual Machine, without impairing the performance of the resulting tools. In this paper we assess whether DiSL meets this goal. First, we perform a controlled experiment to measure tool development time and correctness of the developed tools, comparing DiSL with a prevailing, state-of-the-art instrumentation library. Second, we recast 10 open-source software engineering tools in DiSL and compare source code metrics and performance with the original implementations. Our studies show that DiSL significantly improves developer productivity, enables concise tool implementations, and does not have any negative impact on tool performance. &copy; 2014 Elsevier B.V. All rights reserved.},
key = {Program debugging},
keywords = {Computer aided software engineering;Experiments;Java programming language;Open source software;Open systems;Problem oriented languages;Productivity;Reverse engineering;Software testing;},
note = {Bytecode instrumentation;Controlled experiment;Development productivity;Domain specific languages;Dynamic analysis tools;Dynamic program analysis;High-level programming;Program instrumentations;},
URL = {http://dx.doi.org/10.1016/j.scico.2014.03.014},
} 


@article{20161302152236,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {DAEH: A tool for specifying and monitoring the exception handling policy},
journal = {International Journal of Software Engineering and Knowledge Engineering},
author = {Abrantes, Joilson and Coelho, Roberta and Bonifacio, Rodrigo},
volume = {25},
number = {9-10},
year = {2015},
pages = {1515 - 1530},
issn = {02181940},
abstract = {The exception handling policy of a system comprises the set of design rules that specify its exception handling behavior (how exceptions should be handled and thrown). Such policy is usually undocumented and implicitly defined by the system architect. For this reason, developers often consider that by just including catch-blocks in the code they are dealing with exceptional conditions. This lack of information may turn the exception handling into a generalized "goto" mechanism making the program more complex and less reliable. This work presents a domain-specific language called ECL (Exception Contract Language) to specify the exception handling policy and a runtime monitoring tool which dynamically checks this policy. The monitoring tool is implemented in the form of an aspect library, which can be added to any Java system without the need to change the application source code. We applied this approach to two large-scale web-based systems and to a set of versions of the well-known JUnit framework. The results indicate that this approach can be used to express and to automatically check the exception handling policy of a system, and consequently support the development of more robust Java systems. &copy; 2015 World Scientific Publishing Company.},
key = {Java programming language},
keywords = {Computational linguistics;Computer programming languages;Dynamic analysis;Problem oriented languages;},
note = {Contract languages;Domain specific languages;Exception handling;Monitoring tools;Runtime Monitoring;Source codes;System architects;Web-based system;},
URL = {http://dx.doi.org/10.1142/S0218194015400306},
} 

@InProceedings{20162902610890,
  author    = {Morales, Zuriel and Magaa, Cristina and Aguilar, Jose Alfonso and Zaldivar-Colado, Anibal and Tripp-Barba, Carolina and Misra, Sanjay and Garcia, Omar and Zurita, Eduardo},
  title     = {A baseline domain specific language proposal for model-driven web engineering code generation},
  year      = {2016},
  volume    = {9790},
  pages     = {50 - 59},
  address   = {Beijing, China},
  note      = {Domain specific languages;MDA(model driven architecture);MDWE;Meta model;Model-driven web engineerings;Non-functional requirements;Platform independent model;Web application development;},
  abstract  = {It is well-known that Model-Driven Web Engineering requires the development of code-generation tools in order to be adopted outside research field as a complete solution in Web application development industry. Regrettably, a fully-guided methodology supported by a complete code-generation tool that considers a complete development process based on MDA (Model-Driven Architecture) is missing. The idea behind MDA is that requirements are considered (functional and nonfunctional requirements) from the Computational Independent Model (CIM), to the Platform Specific Model (PSM) passing for the Platform Independent Model (PIM) to generate the source code for the Web application. In our work is presented a baseline DSL (Domain Specific Language) for Web application code-generation considering the basic language used in a small software factory in Mexico. This is an ongoing work which is part of a institutional project in order to build a suite of tools for code-generation for Web application development. &copy; Springer International Publishing Switzerland 2016.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Software architecture},
  keywords  = {Application programs;Codes (symbols);Computational linguistics;Computer aided software engineering;Computer programming languages;Problem oriented languages;Software design;World Wide Web;XML;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-42092-9_5},
}


@inproceedings{20142417819040,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {DEVS-Ruby: A domain specific language for DEVS modeling and simulation (WIP)},
journal = {Simulation Series},
author = {Franceschini, Romain and Bisgambiglia, Paul-Antoine and Bisgambglia, Paul and Hill, David},
volume = {46},
number = {4},
year = {2014},
pages = {103 - 108},
issn = {07359276},
address = {Tampa, FL, United states},
abstract = {This paper introduces a new Discrete EVent system Specification (DEVS) modeling and simulation library implemented in Ruby. Its syntactic sugar and features such as monkey patching, lexical closures, custom dispatch behavior and native plug-in API provides strong support to grow a Domain Specific Language (DSL). The library, by providing an internal DSL, allows formal specifications of DEVS models. The greatest strength of DEVS-Ruby lies in the extensibility of the DSL, allowing to meet each modeler's domain specific vocabulary and thus, to evolve from a general modeling and simulation formalism to a specialized tool.},
key = {Computer programming languages},
keywords = {Discrete event simulation;DSL;Ruby;Specifications;},
note = {DEVS;Discrete event system specification;Domain specific;Domain specific languages;Formal Specification;Model and simulation;Specialized tools;Syntactic sugars;},
} 


@inproceedings{20123315339317,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Defining and verifying behaviour of domain specific language with fUML},
journal = {ACM International Conference Proceeding Series},
author = {Lai, Qinan and Carpenter, Andy},
year = {2012},
pages = {Eur. Conf. Model. Found. Appl. (ECMFA) - },
address = {Kgs. Lyngby, Denmark},
abstract = {The behavioural semantics of a Domain Specific Language (DSL) are the instructions on how to execute the language. In practice, such semantics are often documented by text, which leads to ambiguity and tool generation problems. Although some formal frameworks have been proposed to address these drawbacks, they only allow the correctness of a specification to be tested at a later stage, usually when the semantics are implemented. This paper presents a new framework for implementing the behavioural semantics of meta-model based DSLs and tools. The framework uses the foundational subset of executable UML (fUML) as its semantic base, and uses the fUML meta-model for modelling the abstract syntax and operational semantics of a DSL. The semantics specification can be verified at design time without the need to execute behaviour models. Thus, it can provide useful feedback to the DSL designer. The framework is demonstrated in a Petri-net example. &copy; 2012 ACM.},
key = {Semantics},
keywords = {Abstracting;Computer programming languages;Specifications;Visual languages;},
note = {Abstract syntax;Behaviour models;Design time;Domain specific languages;Executable UML;Formal framework;fUML;Meta model;Modeling languages;Operational semantics;Tool generation;},
URL = {http://dx.doi.org/10.1145/2325276.2325277},
} 


@inproceedings{20130115856658,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {QORAL: An external domain-specific language for mining software repositories},
journal = {Proceedings - 2012 4th International Workshop on Empirical Software Engineering in Practice, IWESEP 2012},
author = {Nakamura, Hiroki and Nagano, Rina and Hisazumi, Kenji and Kamei, Yasutaka and Ubayashi, Naoyasu and Fukuda, Akira},
year = {2012},
pages = {23 - 29},
address = {Osaka, Japan},
abstract = {The mining software repositories (MSR) field integrates and analyzes data stored in repositories such as source control and bug repositories to provide support to practitioners. In order to provide useful information to practitioners, MSR researchers need to perform tasks iteratively, these tasks include extracting data from repositories, transforming them into specific data formats, and loading them into the statistical analysis tool. These tasks require a significant amount of man hours to implement and execute according to the requirements of the researchers. This paper proposes an external domain-specific language (DSL) called QORAL to facilitate the performance of multiple iterations and environment development. The results from a questionnaire used to evaluate QORAL indicate that it is easy to understand and modify source code. &copy; 2012 IEEE.},
key = {Loading},
keywords = {DSL;Metadata;Problem oriented languages;Software engineering;},
note = {Domain specific languages;Man hours;Mining software repositories;MSR;Multiple iterations;QORAL;Source codes;Source control;Statistical analysis tools;},
URL = {http://dx.doi.org/10.1109/IWESEP.2012.20},
} 

@InProceedings{20151700774781,
  author    = {Moser, Michael and Pfeiffer, Michael and Pichler, Josef},
  title     = {A novel domain-specific language for the robot welding automation domain},
  year      = {2014},
  pages     = {IEEE Industrial Electronics Society (IES); Technical University of Catalonia - BarcelonaTech (UPC) -},
  address   = {Barcelona, Spain},
  note      = {Development approach;Domain specific languages;General-purpose programming language;Industrial automation;Professional software;Programming skills;Visual notations;Welding automation;},
  abstract  = {Implementation, fault analysis, and maintenance of robot welding automation solutions are traditionally restricted to professional software developers only. Program code is written in a general purpose programming language and, hence, unmanageable by other stakeholders with limited or no programming skills. To tackle this problem we have implemented a domain-specific language (DSL) specifically designed to the domain of robot welding automation and to be intuitively manageable by all stakeholders. The created DSL supports a textual and visual notation and is embedded within a full featured tool chain which let our customer fully replace the creation and maintenance of welding automation solutions by our DSL-based development approach. &copy; 2014 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {19th IEEE International Conference on Emerging Technologies and Factory Automation, ETFA 2014},
  key       = {Automation},
  keywords  = {Computational linguistics;Computer programming languages;Factory automation;Maintenance;Problem oriented languages;Robots;Welding;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ETFA.2014.7005348},
}


@article{20120514732894,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Domain Specific Language for the generation of Learning Management Systems modules},
journal = {Journal of Web Engineering},
author = {Montenegro-Marin, Carlos Enrique and Cueva-Lovelle, Juan Manuel and Sanjuan-Martinez, Oscar and Garcia-Diaz, Vicente},
volume = {11},
number = {1},
year = {2012},
pages = {23 - 50},
issn = {15409589},
abstract = {Nowadays there are many research projects conducted in the areas of Learning Management Systems (LMS) and Model-Driven Engineering (MDE). These research projects have shown that there are LMS platforms with different architectures and inoperative to each other. The most significant contribution of MDE has been the creation of a common meta-metamodel. This meta-metamodel allows transformations between different models. This research work presents a LMS metamodel. The metamodel created is based on the study of five LMS platforms. The LMS metamodel is a global model that makes a bridge for the transformation of modules between the model and different LMS platforms, and it also presents the development of a Domain Specific Language (DSL) tool to validate the metamodel, the transformation process of the model with our DSL Tool to modules deployed in Moodle, Claroline and Atutor, and finally testing and validation of creating modules with LMS platforms VS creating modules with our DSL Tool. &copy; Rinton Press.},
key = {Software architecture},
keywords = {Engineering research;Project management;Software design;},
note = {Domain specific languages;Meta model;Model transformation;Model-driven architecture;Platform independent model;},
} 

@InProceedings{20155201723318,
  author    = {Vukovi, eljko and Milanovi, Nikola and Vaderna, Renata and Dejanovi, Igor and Milosavljevi, Gordana},
  title     = {Sail: A domain-specific language for semantic-aided automation of interface mapping in enterprise integration},
  year      = {2015},
  volume    = {9416},
  pages     = {97 - 106},
  address   = {Rhodes, Greece},
  note      = {Domain specific languages;Enterprise Integration;ESB;Model-based OPC;Semantic conflict;},
  abstract  = {Mapping elements of various interfaces is one of the most complex tasks in enterprise integration. Differences in the ways that these interfaces represent data in lead to the need of conflict detection and resolving. We present an approach where a structural model of the interfaces can be annotated with a semantic model and used together to (semi-)automate this process. A domain-specific language (DSL) is proposed that can be used to specify criteria for interface element mapping, define conflicts with steps for their resolution if possible, and how the resulting mappings will be translated into expressions needed for code generation. This DSL is intended to give the user the possibility to customise a prototype tool (which we have presented earlier) enabling us to practically test our approach and yield a real-world runnable implementation. Code generated by this tool is deployable to an enterprise service bus (ESB). &copy; Springer International Publishing Switzerland 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Mapping},
  keywords  = {Chemical detection;Computational linguistics;Computer programming languages;Integration;Internet;Ontology;Problem oriented languages;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-26138-6_13},
}

@Article{20163402734138,
  author    = {Bocanegra Garcia, Jose and Pavlich-Mariscal, Jaime and Carillo-Ramos, Angela},
  title     = {Towards a domain-specific language to design adaptive software: The DMLAS approach},
  journal   = {Ingenieria y Universidad},
  year      = {2016},
  volume    = {20},
  number    = {2},
  pages     = {277 - 296},
  note      = {Adaptation;Adaptive software;Context;Domain specific languages;Model-driven Engineering;Notation;},
  abstract  = {An adaptive software has the ability to modify its own behavior at runtime due to changes in the users and their context in the system, requirements, or environment in which the system is deployed, and thus, give the users a better experience. However, the development of this kind of systems is not a simple task. There are two main issues: (1) there is a lack of languages to specify, unambiguously, the elements related to the design phase. As a consequence, these systems are often developed in an ad-hoc manner, without the required formalism, augmenting the complexity in the process of derivation of design models to the next phases in the development cycle. (2) Design decisions and the adaptation model tend to be directly implemented into the source code and not thoroughly specified at the design level. Since the adaptation models become tangled with the code, system evolution becomes more difficult. To address the above issues, this paper proposes DMLAS, a Domain-Specific Language (DSL) to design adaptive systems. As proof of concept, this paper also provides a functional prototype based on the Sirius plugin for Eclipse. This prototype is a tool to model, in several layers of abstraction, the main components of an adaptive system. The notation used both in the models and the tool was validated against the nine principles for designing cognitively effective visual notations presented by Moody. &copy; 2016, Pontificia Universidad Javeriana. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {01232126},
  key       = {Design},
  keywords  = {Adaptive systems;Computational linguistics;Computer programming languages;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.11144/Javeriana.iyu20-2.tdsl},
}

@InProceedings{20161102111846,
  author    = {Li, Huiqing and Thompson, Simon},
  title     = {A domain-specific language for scripting refactorings in erlang},
  year      = {2012},
  volume    = {7212},
  pages     = {501 - 515},
  address   = {Tallinn, Estonia},
  note      = {Analysis;Erlang;Refactorings;Transformation;Wrangler;},
  abstract  = {Refactoring is the process of changing the design of a program without changing its behaviour. Many refactoring tools have been developed for various programming languages; however, their support for composite refactorings &ndash; refactorings that are composed from a number of primitive refactorings &ndash; is limited. In particular, there is a lack of powerful and easy-to-use frameworks that allow users to script their own large-scale refactorings efficiently and effectively. This paper introduces the domain-specific language framework of Wrangler &ndash; a refactoring and code inspection tool for Erlang programs &ndash; that allows users to script composite refactorings, test them and apply them on the fly. The composite refactorings are fully integrated into Wrangler and so can be previewed, applied and &lsquo;undone&rsquo; interactively. &copy; Springer-Verlag Berlin Heidelberg 2012.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Software engineering},
  keywords  = {Computational linguistics;Computer programming languages;Computer systems programming;DSL;Problem oriented languages;},
  language  = {English},
}

@InProceedings{20121414921418,
  author    = {Li, Huiqing and Thompson, Simon},
  title     = {A domain-specific language for scripting refactorings in Erlang},
  year      = {2012},
  volume    = {7212 LNCS},
  pages     = {501 - 515},
  address   = {Tallinn, Estonia},
  note      = {analysis;API;Erlang;Refactorings;transformation;Wrangler;},
  abstract  = {Refactoring is the process of changing the design of a program without changing its behaviour. Many refactoring tools have been developed for various programming languages; however, their support for composite refactorings - refactorings that are composed from a number of primitive refactorings - is limited. In particular, there is a lack of powerful and easy-to-use frameworks that allow users to script their own large-scale refactorings efficiently and effectively. This paper introduces the domain-specific language framework of Wrangler - a refactoring and code inspection tool for Erlang programs -that allows users to script composite refactorings, test them and apply them on the fly. The composite refactorings are fully integrated into Wrangler and so can be previewed, applied and 'undone' interactively. &copy; 2012 Springer-Verlag Berlin Heidelberg.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Software engineering},
  keywords  = {Computer systems programming;DSL;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-28872-2_34},
}

@InProceedings{20162002384839,
  author    = {Hadiwijaya, Ryan Ignatius and Inggriani Liem, M.M.},
  title     = {A domain-specific language for automatic generation of checkers},
  year      = {2015},
  pages     = {7 - 12},
  address   = {Yogyakarta, Indonesia},
  note      = {Automatic Generation;Automatic programs;Competition environments;Domain specific languages;Generator tool;Programming class;Programming learning;property checker;},
  abstract  = {One of the important modules of a black-box automatic program grader is a "checker". In programming competition environment, a checker is a program written for the purpose to check the output of the contestant's program for a task that has many solutions. Usually, a checker is written manually as needed. In this paper, the idea of the output checker in the programming competition environment is extended to input checker and source code checker as a part of the automatic grader in our programming learning environment. Input checker validates the input coverage. The source code checker is used to validate a set of properties from a source code against the given coding specification. A Domain-Specific Language (DSL) grammar is designed and developed as a specification for the automatic generation of the output, input, and source code checkers. The DSL grammar and the checker generator tool set are used to evaluate source codes in our programming class. By writing the checkers specification in DSL, the specification is automatically documented and can be reused for similar properties. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings of 2015 International Conference on Data and Software Engineering, ICODSE 2015},
  key       = {Automatic programming},
  keywords  = {Codes (symbols);Computational linguistics;Computer aided instruction;Computer programming languages;Grading;Natural language processing systems;Problem oriented languages;Software engineering;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICODSE.2015.7436963},
}

@Article{20133816764250,
  author    = {Hoyos, Jose R. and Garcia-Molina, Jesus and Botia, Juan A.},
  title     = {A domain-specific language for context modeling in context-aware systems},
  journal   = {Journal of Systems and Software},
  year      = {2013},
  volume    = {86},
  number    = {11},
  pages     = {2890 - 2905},
  note      = {Context information;Context modeling;Context-Aware;Context-aware systems;Domain specific languages;High-level abstraction;Middleware platforms;Model driven development;},
  abstract  = {Context-awareness refers to systems that can both sense and react based on their environment. One of the main difficulties that developers of context-aware systems must tackle is how to manage the needed context information. In this paper we present MLContext, a textual Domain-Specific Language (DSL) which is specially tailored for modeling context information. It has been implemented by applying Model-Driven Development (MDD) techniques to automatically generate software artifacts from context models. The MLContext abstract syntax has been defined as a metamodel, and model-to text transformations have been written to generate the desired software artifacts. The concrete syntax has been defined with the EMFText tool, which generates an editor and model injector. MLContext has been designed to provide a high-level abstraction, to be easy to learn, and to promote reuse of context models. A domain analysis has been applied to elicit the requirements and design choices to be taken into account in creating the DSL. As a proof of concept of the proposal, the generative approach has been applied to two different middleware platforms for context management. &copy; 2013 Elsevier Inc.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {01641212},
  key       = {Abstracting},
  keywords  = {Middleware;Problem oriented languages;Semantics;Syntactics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.jss.2013.07.008},
}


@inproceedings{20125015800408,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Kutulu: A domain-specific language for feature-driven product derivation},
journal = {Proceedings - International Computer Software and Applications Conference},
author = {Dayba, Orcun and Oguztuzun, Halit},
year = {2012},
pages = {105 - 110},
issn = {07303157},
address = {Izmir, Turkey},
abstract = {Software Product Line Engineering (SPLE) defines processes to facilitate the development of a family of products in a pre-defined market more effectively. Its success depends on implementation of these processes utilizing best practices with proper tool support. This paper describes how to enhance domain design and variation management processes of SPLE with a domain-specific language (DSL), namely "Kutulu". It also introduces novel modeling tools and dependency injection-based realization approach that are well-suited for product derivation in SPL. Our DSL definition, developed tools and their position in the product line context are put forth in this paper. &copy; 2012 IEEE.},
key = {Problem oriented languages},
keywords = {Software design;},
note = {Component;Dependency injection;Domain specific languages;Feature-component binding;Software Product Line;Variability management;},
URL = {http://dx.doi.org/10.1109/COMPSAC.2012.20},
} 


@inproceedings{20144900294543,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Generation of presentation slides on web browser using a domain-specific language},
journal = {23rd International Conference on Software Engineering and Data Engineering, SEDE 2014},
author = {Maeda, Kazuaki},
year = {2014},
pages = {173 - 177},
address = {New Orleans, LA, United states},
abstract = {This paper describes how to create presentation slides using a DSL (Domain-Specific Language), generate HTML documents on a modern web browser, Chrome, and run an impressive slide show on the web browser. Current desktop presentation tools are not fully integrated to the World Wide Web. On the other hand, we can create impressive presentation slides using the modern web browser. To bridge the gap, an internal DSL based on Ruby for creating presentation slides was designed by the author. A tool to generate HTML documents on Chrome was implemented using Native Client SDK. In the author's preliminary experience, productivity was improved while creating presentation slides for the web browser.},
key = {World Wide Web},
keywords = {Bridges;Computer programming languages;HTML;Problem oriented languages;Social networking (online);Software engineering;Web browsers;},
note = {Desktop presentations;Domain specific languages;Fully integrated;HTML documents;On chrome;Presentation slides;Slide shows;},
} 

@InProceedings{20143918179799,
  author    = {Schefer-Wenzl, Sigrid and Feiertag, Katharina},
  title     = {A domain-specific language for XML security standards},
  year      = {2014},
  pages     = {University of Vienna -},
  address   = {Vienna, Austria},
  note      = {Concepts and features;Domain specific languages;Problem domain;Security domains;XML encryption;XML security;XML signature;XML standards;},
  abstract  = {A domain-specific language (DSL) is designed for a certain problem domain. Its notation is tailored to the relevant concepts and features of that domain. In this paper, we present a basis for a DSL for XML security standards. In particular, we focus on three prominent examples, i.e. XML Signature, XML Encryption, and SAML that are integrated into a common DSL. The main goals of our DSL are to make it easily comprehensible for security domain experts, easily applicable for people being familiar with at least one GPL, and easily extensible for further XML standards. &copy; 2014 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {ACM International Conference Proceeding Series},
  key       = {XML},
  keywords  = {Problem oriented languages;Software architecture;Standards;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2642803.2642821},
}

@InProceedings{20131516185172,
  author    = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert B.},
  title     = {FAMILIAR: A domain-specific language for large scale management of feature models},
  year      = {2013},
  volume    = {78},
  number    = {6},
  pages     = {657 - 681},
  note      = {Domain specific languages;Feature models;Model management;Software Product Line;Variability;},
  abstract  = {The feature model formalism has become the de facto standard for managing variability in software product lines (SPLs). In practice, developing an SPL can involve modeling a large number of features representing different viewpoints, sub-systems or concerns of the software system. This activity is generally tedious and error-prone. In this article, we present FAMILIAR a Domain-Specific Language (DSL) that is dedicated to the large scale management of feature models and that complements existing tool support. The language provides a powerful support for separating concerns in feature modeling, through the provision of composition and decomposition operators, reasoning facilities and scripting capabilities with modularization mechanisms. We illustrate how an SPL consisting of medical imaging services can be practically managed using reusable FAMILIAR scripts that implement reasoning mechanisms. We also report on various usages and applications of FAMILIAR and its operators, to demonstrate their applicability to different domains and use for different purposes. &copy; 2012 Elsevier B.V. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {01676423},
  journal   = {Science of Computer Programming},
  key       = {Software design},
  keywords  = {Computer software;Medical imaging;Modular construction;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.scico.2012.12.004},
}

@InProceedings{20131616212929,
  author    = {Adolf, Diego and Ferranti, Ettore and Koch, Stephan},
  title     = {SmartScript - A domain-specific language for appliance control in Smart Grids},
  year      = {2012},
  pages     = {465 - 470},
  address   = {Tainan, Taiwan},
  note      = {Active components;Appliance controls;Building automation;Building automation systems;Domain specific languages;Energy-aware algorithms;Software systems;Voice-controlled;},
  abstract  = {This paper describes an auto-configuring agent based software architecture connecting appliances, smart meters, solar panels, and a KNX building automation system, resulting in a complete demand-side smart grid. The agents are responsible for providing access to all datapoints in the system as well as sending commands to the active components. To control the system, a domain-specific language (DSL) called SmartScript was developed, whose benefits are twofold. The first one is to provide users, experts in electrical engineering and/or building automation but not in software systems, with a high level tool which they can use to control a demand-side smart grid. The second benefit is to provide a layer to implement and test quickly and effectively energy-aware algorithms without having to deal with all the underlying connections. Finally, some demo applications created using SmartScript (i.e., smartphone interface, voice-controlled building automation system) are presented in this work, in order to give an example of how SmartScript can be used. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {2012 IEEE 3rd International Conference on Smart Grid Communications, SmartGridComm 2012},
  key       = {Smart power grids},
  keywords  = {Electrical engineering;Intelligent buildings;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SmartGridComm.2012.6486028},
}


@inproceedings{20143918179797,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Domain specific language for deployment of parallel applications on parallel computing platforms},
journal = {ACM International Conference Proceeding Series},
author = {Arkin, Ethem and Tekinerdogan, Bedir},
year = {2014},
pages = {University of Vienna - },
address = {Vienna, Austria},
abstract = {To increase the computing performance the current trend is towards applying parallel computing in which parallel tasks are executed on multiple nodes. The deployment of tasks on the computing platform usually impacts the overall performance and as such needs to be modelled carefully. In the architecture design community the deployment viewpoint is an important viewpoint to support this mapping process. In general the derived deployment views are visual notations that are not amenable for run-time processing, and do not scale well for deployment of large scale parallel applications. In this paper we propose a domain specific language (DSL) for modeling the deployment of parallel applications and for providing automated support for the deployment process. The DSL is based on a metamodel that is derived after a domain analysis on parallel computing. We illustrate the application of the DSL for a traffic simulation system and provide a set of important scenarios for using the DSL. &copy; 2014 ACM.},
key = {Parallel architectures},
keywords = {Computer programming languages;Parallel processing systems;Software architecture;},
note = {Architecture designs;Computing performance;Deployment;Domain specific languages;Parallel application;Parallel computing platform;Software languages;Traffic simulations;},
URL = {http://dx.doi.org/10.1145/2642803.2642819},
} 

@InProceedings{20160501861478,
  author    = {De Sousa, Luis and Da Silva, Alberto Rodrigues},
  title     = {A domain specific language for spatial simulation scenarios(DSL3S): Introduction and tool support},
  year      = {2015},
  volume    = {13-17-April-2015},
  pages     = {1854 - 1856},
  address   = {Salamanca, Spain},
  note      = {Agent-based modelling;Design of simulations;Domain specific languages;Graphical elements;Model driven development;Programming skills;Spatial simulation;Uml profiles;},
  abstract  = {Cellular automata and agent-based modelling techniques have long been used for spatial simulation in the Geographic Information Systems field. However, they largely rely on code libraries and pre-compiled models, either requiring advanced programming skills or imposing scope constraints. Several domain specific languages have been proposed in this context, but mostly resulting in new textual programming languages. DSL3S is a domain specific language for spatial simulation, synthesising concepts in a UML profile, permitting the design of simulation models through graphical elements. MDD3S is an implementation of this language relying on model-driven development (MDD) tools built around the Eclipse IDE; it produces ready to run simulations from DSL3S models, supported by theMASON simulation tool-kit. These assets have proved sufficient to developed classic models in different GIS application fields. Copyright 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings of the ACM Symposium on Applied Computing},
  key       = {Computational linguistics},
  keywords  = {Autonomous agents;Computational methods;Computer programming languages;Geographic information systems;Graphical user interfaces;Markup languages;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2695664.2695972},
}

@InProceedings{20163002625887,
  author    = {Haser, Florian and Felderer, Michael and Breu, Ruth},
  title     = {An integrated tool environment for experimentation in domain specific language engineering},
  year      = {2016},
  volume    = {01-03-June-2016},
  address   = {Limerick, Ireland},
  note      = {Controlled experiment;Domain specific languages;Empirical evaluations;Experimentation;Language engineering;Meta Programming;Tool support;},
  abstract  = {Domain specific languages (DSLs) are widely used in practice and investigated in software engineering research. But so far, language workbenches do not provide sufficient builtin decision support for language design and improvement. Controlled experiments have the potential to provide appropriate, data-driven decision support for language engineers and researchers to compare different language features with evidence-based feedback. This paper provides an integrated end-to-end tool environment to perform controlled experiments in DSL engineering. The experiment environment is built on the basis and integrated into the language workbench Meta Programming System (MPS). The environment not only supports language design but also all steps of experimentation, i.e., planning, operation, analysis &amp; interpretation, as well as presentation &amp; package. The tool environment is presented by means of a running example experiment comparing the time taken to create system acceptance tests for web applications in two different DSLs. &copy; 2016 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Computational linguistics},
  keywords  = {Acceptance tests;Computer programming languages;Decision support systems;Graphical user interfaces;Problem oriented languages;Software engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2915970.2916010},
}

@InProceedings{20153101086285,
  author    = {Visic, Niksa and Fill, Hans-Georg and Buchmann, Robert Andrei and Karagiannis, Dimitris},
  title     = {A domain-specific language for modeling method definition: From requirements to grammar},
  year      = {2015},
  volume    = {2015-June},
  number    = {June},
  pages     = {286 - 297},
  address   = {Athens, Greece},
  note      = {Domain specific languages;Domain specificity;Level of abstraction;Meta model;Model method;Modeling tool;Platform independent;Research questions;},
  abstract  = {The core process a modeling method engineer needs to accomplish starts with the acquisition of domain knowledge and requirements, and ends with the deployment of a usable modeling tool. In between, a key intermediate deliverable of this process is the modeling method specification which, ideally, should be platform independent. On one hand, it takes input from a structured understanding of the application domain and scenarios; on the other hand, it provides sufficiently structured input to support the implementation of tool support for modeling activities. It is quite common that such modeling methods are domain-specific, in the sense that they provide concepts from the domain as 'first-class modeling citizens'. However, for the purposes of this paper, we raise the level of abstraction for 'domain specificity' and consider 'modeling method engineering' as the application domain. Consequently, we raise several research questions - whether a domain-specific language can support this domain, and what would be its requirements, properties, constructs and grammar. We propose an initial draft of such a language - one that abstracts away from meta-modeling platforms by establishing a meta&lt;sup&gt;2&lt;/sup&gt; layer of abstraction where a modeling method can be defined in a declarative manner, then the final modeling tool is generated by automated compilation of the method definition for the meta-modeling environment of choice. &copy; 2015 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {21511349},
  journal   = {Proceedings - International Conference on Research Challenges in Information Science},
  key       = {Modeling languages},
  keywords  = {Abstracting;Computational linguistics;Computer programming languages;Information science;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/RCIS.2015.7128889},
}

@InProceedings{20131116119224,
  author    = {Hover, Kai Michael and Borgert, Stephan and Muhlhauser, Max},
  title     = {A domain specific language for describing S-BPM processes},
  year      = {2013},
  volume    = {360 CCIS},
  pages     = {72 - 90},
  address   = {Deggendorf, Germany},
  note      = {Business Process;Business process modeling;Domain specific languages;ePASS;Graph-based tool;Language elements;Natural languages;Process engines;Subject-oriented modeling;},
  abstract  = {Natural language is the first choice for most stakeholders for describing business processes. S-BPM addresses this by taking basic natural language structure into consideration. However, so far S-BPM processes can only be modeled with graph-based tools. Although graph-based tools provide a good overview of processes they have also their disadvantages, because changing or adding language elements is costly, and graphical symbols cannot be written like natural sentences. In this paper, we present a Domain Specific Language to specify S-BPM processes and a process engine kernel for executing these modeled processes. &copy; 2013 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {18650929},
  journal   = {Communications in Computer and Information Science},
  key       = {Systems engineering},
  keywords  = {Enterprise resource management;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-36754-0_5},
}

@InProceedings{20151200662902,
  author    = {Jaroslav, Poruban and Dominik, Lakato},
  title     = {Iterative domain-specific language development with YAJCo parser generator},
  year      = {2015},
  volume    = {1648},
  pages     = {Santilli Foundation -},
  address   = {Rhodes, Greece},
  abstract  = {Tool support for iterative language development is crucial when we treat a domain-specific language as a dynamic element in the software development lifecycle. We present YAJCo language processor generator and its approach to iterative development of DSLs on the case study of the Karel the Robot language. YAJCo is built upon existing parsing technologies and it reuses programmer experience in the field of object- and aspect-oriented programming paradigms and existing tooling infrastructure widely used for system development (e.g. IDE). &copy; 2015 AIP Publishing LLC.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {0094243X},
  journal   = {AIP Conference Proceedings},
  language  = {English},
  url       = {http://dx.doi.org/10.1063/1.4912558},
}


@inproceedings{20154501506285,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Using a domain-specific language to enrich ETL schemas},
journal = {Communications in Computer and Information Science},
author = {Belo, Orlando and Gomes, Claudia and Oliveira, Bruno and Marques, Ricardo and Santos, Vasco},
volume = {539},
year = {2015},
pages = {28 - 35},
issn = {18650929},
address = {Poitiers, France},
abstract = {Today it is easy to find a lot of tools to define data migration schemas among different types of information systems. Data migration processes use to be implemented on a very diverse range of applications, ranging from conventional operational systems to data warehousing platforms. The implementation of a data migration process often involves a serious planning, considering the development of conceptual migration schemas at early stages. Such schemas help architects and engineers to plan and discuss the most adequate way to migrate data between two different systems. In this paper we present and discuss a way for enriching data migration conceptual schemas in BPMN using a domain-specific language, demonstrating how to convert such enriched schemas to a first correspondent physical representation (a skeleton) in a conventional ETL implementation tool like Kettle. &copy; Springer International Publishing Switzerland 2015.},
key = {Modeling languages},
keywords = {Administrative data processing;Computational linguistics;Computer programming languages;Data warehouses;Information systems;Musculoskeletal system;Problem oriented languages;Warehouses;},
note = {Conceptual model;Data migration;Data warehousing systems;Domain specific languages;ETL skeletons;Kettle;Specification models;},
URL = {http://dx.doi.org/10.1007/978-3-319-23201-0_4},
} 


@inproceedings{20121914991981,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {DiSL: A domain-specific language for bytecode instrumentation},
journal = {AOSD'12 - Proceedings of the 11th Annual International Conference on Aspect Oriented Software Development},
author = {Marek, Luka and Villazon, Alex and Zheng, Yudi and Ansaloni, Danilo and Binder, Walter and Qi, Zhengwei},
year = {2012},
pages = {239 - 250},
address = {Potsdam, Germany},
abstract = {Many dynamic analysis tools for programs written in managed languages such as Java rely on bytecode instrumentation. Tool development is often tedious because of the use of low-level bytecode manipulation libraries. While aspect-oriented programming (AOP) offers high-level abstractions to concisely express certain dynamic analyses, the join point model of mainstream AOP languages such as AspectJ is not well suited for many analysis tasks and the code generated by weavers in support of certain language features incurs high overhead. In this paper we introduce DiSL (domain-specific language for instrumentation), a new language especially designed for dynamic program analysis. DiSL offers an open join point model where any region of byte-codes can be a shadow, synthetic local variables for efficient data passing, efficient access to comprehensive static and dynamic context information, and weave-time execution of user-defined static analysis code. We demonstrate the benefits of DiSL with a case study, recasting an existing dynamic analysis tool originally implemented in AspectJ. We show that the DiSL version offers better code coverage, incurs significantly less overhead, and eases the integration of new analysis features that could not be expressed in AspectJ. &copy; 2012 ACM.},
key = {Java programming language},
keywords = {Aspect oriented programming;Computer software;Computer systems programming;Dynamic analysis;Problem oriented languages;Static analysis;},
note = {Aspect-J;Aspect-oriented;Bytecode instrumentation;Bytecode manipulation;Bytecodes;Code coverage;Domain specific languages;Dynamic analysis tools;Dynamic program analysis;High-level abstraction;Join point;JVM;Language features;Local variables;Static and dynamic;Tool development;},
URL = {http://dx.doi.org/10.1145/2162049.2162077},
} 

@InProceedings{20124315601071,
  author    = {Rabbi, Fazle and MacCaull, Wendy},
  title     = {T: A domain specific language for rapid workflow development},
  year      = {2012},
  volume    = {7590 LNCS},
  pages     = {36 - 52},
  address   = {Innsbruck, Austria},
  note      = {Access control policies;Domain specific languages;Health services;Model-driven Engineering;Requirement specification;Scheduling tasks;Software systems;Task specifications;Tool support;Transformation methods;Workflow management systems;},
  abstract  = {In MDE, software systems are always synchronized with their models since changes are made first to the model whenever there are changes in the requirement specifications. While MDE has a lot of potential, it requires maturity and tool support. In this research we present a framework for a workflow management system based on the MDE approach. We propose a domain specific language, T <inf>&squ;</inf> (T-Square) for rapidly specifying details of (workflow) tasks and their associated user interfaces which may be used with the NOVA Workflow, an executable workflow management system. T <inf>&squ;</inf> includes syntax for writing procedural statements, for querying an ontology, for declaring user interfaces, for applying access control policy, and for scheduling tasks, using Xtext to write the grammar. We apply transformation methods, based on Xtend, to generate executable software from the abstract task specifications. A running example from health services delivery illustrates the usefulness of this approach. &copy; 2012 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Models},
  keywords  = {Access control;Ontology;User interfaces;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-33666-9_4},
}

@InProceedings{20124815732185,
  author    = {Kaewchinporn, Chinnapat and Limpiyakorn, Yachai},
  title     = {Semantic approach to verifying activity diagrams with a domain specific language},
  year      = {2012},
  volume    = {340 CCIS},
  pages     = {466 - 473},
  address   = {Jeju Island, Korea, Republic of},
  note      = {Action description languages;Activity diagram;Design tool;Domain specific languages;Process Improvement;Quality of design;Quality software;Semantic approach;Software systems;Static and dynamic;UML activity diagrams;UML specifications;},
  abstract  = {The Unified Modeling Language is widely used as a design tool for modeling a software system via a set of diagrams providing both static and dynamic views of the system. However, the applications of UML have many problems, namely model inconsistent behaviors, model misconception, and mistake interpretation. The notations are used in different definitions that may not conform to the UML specification. This paper thus present a semantic approach to verifying UML activity diagrams with a domain specific language called Action Description Language (ADL). The method would facilitate the inspection of activity diagrams for the conformance to UML specification, resulting in better quality of design blueprints that would lead to quality software systems. &copy; 2012 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {18650929},
  journal   = {Communications in Computer and Information Science},
  key       = {Unified Modeling Language},
  keywords  = {Computer applications;Computer software;Semantics;Specifications;Systems analysis;Verification;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-35267-6_62},
}


@inproceedings{20140117164419,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Variability support in domain-specific language development},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Vacchi, Edoardo and Cazzola, Walter and Pillay, Suresh and Combemale, Benoit},
volume = {8225 LNCS},
year = {2013},
pages = {76 - 95},
issn = {03029743},
address = {Indianapolis, IN, United states},
abstract = {Domain Specific Languages (DSLs) are widely adopted to capitalize on business domain experiences. Consequently, DSL development is becoming a recurring activity. Unfortunately, even though it has its benefits, language development is a complex and time-consuming task. Languages are commonly realized from scratch, even when they share some concepts and even though they could share bits of tool support. This cost can be reduced by employing modern modular programming techniques that foster code reuse. However, selecting and composing these modules is often only within the reach of a skilled DSL developer. In this paper we propose to combine modular language development and variability management, with the objective of capitalizing on existing assets. This approach explicitly models the dependencies between language components, thereby allowing a domain expert to configure a desired DSL, and automatically derive its implementation. The approach is tool supported, using Neverlang to implement language components, and the Common Variability Language (CVL) for managing the variability and automating the configuration. We will further illustrate our approach with the help of a case study, where we will implement a family of DSLs to describe state machines. &copy; 2013 Springer International Publishing.},
key = {Graphical user interfaces},
keywords = {Computer programming languages;Problem oriented languages;Tools;},
note = {CVL and Neverlang;Domain specific languages;Language component;Language design;Language development;Modular programming;Time-consuming tasks;Variability management;},
URL = {http://dx.doi.org/10.1007/978-3-319-02654-1_5},
} 

@InProceedings{20154501493335,
  author    = {Oliveira, Bruno and Belo, Orlando},
  title     = {A domain-specific language for ETL patterns specification in data warehousing systems},
  year      = {2015},
  volume    = {9273},
  pages     = {597 - 602},
  address   = {Coimbra, Portugal},
  note      = {Conceptual modelling;Data warehousing systems;Domain specific languages;ETL patterns;Specification models;},
  abstract  = {During the last few years many research efforts have been done to improve the design of ETL (Extract-Transform-Load) systems. ETL systems are considered very time-consuming, error-prone and complex involving several participants from different knowledge domains. ETL processes are one of the most important components of a data warehousing system that are strongly influenced by the complexity of business requirements, their changing and evolution. These aspects influence not only the structure of a data warehouse but also the structures of the data sources involved with. To minimize the negative impact of such variables, we propose the use of ETL patterns to build specific ETL packages. In this paper, we formalize this approach using BPMN (Business Process Modelling Language) for modelling more conceptual ETL workflows, mapping them to real execution primitives through the use of a domain- specific language that allows for the generation of specific instances that can be executed in an ETL commercial tool. &copy; Springer International Publishing Switzerland 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Data warehouses},
  keywords  = {Administrative data processing;Artificial intelligence;Computational linguistics;Computer programming languages;Graphical user interfaces;Modeling languages;Problem oriented languages;Specifications;Structural design;Systems engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-23485-4_60},
}


@inproceedings{20123315344373,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {QDSL - Quality domain specific language for cloud composite applications: Short research paper},
journal = {CLOSER 2012 - Proceedings of the 2nd International Conference on Cloud Computing and Services Science},
author = {Hadar, Ethan and Hadar, Irit and Ferguson, Donald F.},
year = {2012},
pages = {228 - 233},
address = {Porto, Portugal},
abstract = {Quality Domain Specific Language (QDSL) is a model-driven approach providing a taxonomy, model, and visual editing tool for evaluating and benchmarking the quality of composite applications in cloud environments. Our language and associated modeling tool provide visual and textual means for constructing mathematical algorithms needed for computing aggregated quality assessment of cloud services. QDSL enables the illustration and definition of metrics, measurements and indicators, relationships for computation, and transformation functions that normalize the measurements into relative quality scoring. As a result, QDSL provides a structure that guides overall quality assessments. The computation algorithm is structured in a visual manner and associates the quality assessments graph with the structure of the cloud composite application in a hybrid environment. QDSL supports transformation from physical measurements into scoring comparative assessments of benchmarked provided IT solutions. This paper presents a basic model for QDSL and examples of usage. A prototypical eclipse EMF modeling tool of QDSL is used for communication, whereas commercial monitoring tools implement the instantiated models for evaluating service qualities.},
key = {Benchmarking},
keywords = {Algorithms;Cloud computing;Distributed database systems;Quality of service;Visual languages;},
note = {Cloud modeling;Cloud services;Domain specific languages;Quality assessment;Service Level Agreements;},
} 


@article{20163802818799,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {On the specification of extract, transform, and load patterns behavior: A domain-specific language approach},
journal = {Expert Systems},
author = {Oliveira, Bruno and Belo, Orlando},
year = {2016},
issn = {02664720},
abstract = {During the last few years, many research efforts have been done to improve the design of extract, transform, and load (ETL) models systems. Still, ETL systems are considered very time-consuming, error-prone, and complex involving several participants from different knowledge domains. The ETL processes are one of the most important components of a data warehousing system that are strongly influenced by the complexity of business requirements, their changing and evolution. These aspects influence not only the structure of the data warehouse itself but also the structures of the data sources involved with. To minimize the negative impact of such variables, we propose the use of ETL patterns to build specific ETL packages. In this paper, we formalize this approach using the BPMN for modeling more conceptual ETL workflows, mapping them to real execution primitives through the use of a domain-specific language that allows for the generation of specific instances that can be executed in an ETL commercial tool. &copy; 2016 Wiley Publishing Ltd.},
key = {Structural design},
keywords = {Administrative data processing;Computer programming languages;Data warehouses;Modeling languages;Problem oriented languages;Specifications;},
note = {Conceptual model;Data warehousing systems;Domain specific languages;ETL patterns;ETL skeletons;Specification models;},
URL = {http://dx.doi.org/10.1111/exsy.12168},
} 

@InProceedings{20161802338293,
  author    = {Cuenca, Fredy and Van Den Bergh, Jan and Luyten, Kris and Coninx, Karin},
  title     = {A user study for comparing the programming efficiency of modifying executable multimodal interaction descriptions: A domain-specific language versus equivalent event-callback code},
  year      = {2015},
  pages     = {31 - 38},
  address   = {Pittsburgh, PA, United states},
  note      = {Composite event;Declarative Languages;Domain specific languages;Multi-Modal Interactions;Multimodal system;Perceived difficulties;Perceived usability;Programming tasks;},
  abstract  = {The present paper describes an empirical user study intended to compare the programming efficiency of our proposed domain-specific language versus a mainstream event language when it comes to modify multimodal interactions. By concerted use of observations, interviews, and standardized questionnaires, we managed to measure the completion rates, completion time, code testing effort, and perceived difficulty of the programming tasks along with the perceived usability and perceived learnability of the tool supporting our proposed language. Based on this experience, we propose some guidelines for designing comparative user studies of programming languages. The paper also discusses the considerations we took into account when designing a multimodal interaction description language that intends to be well regarded by its users. &copy; 2015 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {PLATEAU 2015 - Proceedings of the 6th Workshop on Evaluation and Usability of Programming Languages and Tools},
  key       = {Computational linguistics},
  keywords  = {Computer programming languages;Efficiency;Graphical user interfaces;Interactive computer systems;Problem oriented languages;Surveys;User interfaces;XML;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2846680.2846686},
}


@inproceedings{20160101743305,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Globalized domain specific language engineering},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Bryant, Barrett and Jezequel, Jean-Marc and Lammel, Ralf and Mernik, Marjan and Schindler, Martin and Steinmann, Friedrich and Tolvanen, Juha-Pekka and Vallecillo, Antonio and Volter, Markus},
volume = {9400},
year = {2015},
pages = {43 - 69},
issn = {03029743},
address = {Dagstuhl Castle, Germany},
abstract = {This chapter is dedicated to discussing the engineering aspects involved in the integration of modeling languages, as an essential part of the globalization process. It covers the foundations of language integration, the definition of the relationships between the languages to be integrated, and the various dimensions of language and tool integration. Language variants, evolution, refactoring and retirement are also discussed, as key issues involved in the globalization of modeling languages. &copy; Springer International Publishing Switzerland 2015.},
key = {Modeling languages},
keywords = {Computational linguistics;Computer programming languages;Graphical user interfaces;Integration;Problem oriented languages;},
note = {Domain specific languages;Engineering aspects;Globalized DSLs;Key Issues;Language engineering;Language integration;Refactorings;Tool integration;},
URL = {http://dx.doi.org/10.1007/978-3-319-26172-0_4},
} 

@Article{20154301433503,
  author    = {Moreira de Sousa, Luis and Rodrigues da Silva, Alberto},
  title     = {A domain specific language for spatial simulation scenarios},
  journal   = {GeoInformatica},
  year      = {2016},
  volume    = {20},
  number    = {1},
  pages     = {117 - 149},
  note      = {Agent-based modelling;Design of simulations;Domain specific languages;Domain-Specific Modelling Languages;Model driven development;Spatial informations;Spatial simulation;Uml profiles;},
  abstract  = {This article describes DSL3S, a domain specific modelling language for Spatial Simulation in the field of Geographic Information Systems (GIS). Techniques such as cellular automata and agent-based modelling have long been used to capture and simulate the temporal dynamics of spatial information. Tools commonly employed to implement spatial simulation models include code libraries and pre-compiled models; the former require advanced programming skills while the latter impose relevant constraints on application scope. Previous attempts to produce domain specific languages in the field have invariably resulted in new textual programming languages (e.g. SELES, NetLogo, Ocelet) that are platform specific and in some cases with weak GIS support and interoperability. DSL3S synthesises relevant concepts of spatial simulation in a UML profile, that allows the design of simulation models through the arrangement of graphical elements. An implementation of this language is also presented, that relies on Model Driven Development (MDD) tools distributed with the Eclipse IDE. This includes a code generation infrastructure, that produces ready to run simulations from DSL3S models, supported by the MASON simulation tool-kit. Finally, DSL3S models for three simple and classical simulations allows to better illustrate and discuss the usage of the language. &copy; 2015, Springer Science+Business Media New York.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {13846175},
  key       = {Modeling languages},
  keywords  = {Autonomous agents;Computational linguistics;Computational methods;Computer programming languages;Geographic information systems;Graphical user interfaces;Markup languages;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s10707-015-0233-y},
}

@InProceedings{20142117741499,
  author    = {Vendrov, Ivan and Dutchyn, Christopher and Osgood, Nathaniel D.},
  title     = {Frabjous: A declarative domain-specific language for agent-based modeling},
  year      = {2014},
  volume    = {8393 LNCS},
  pages     = {385 - 392},
  address   = {Washington, DC, United states},
  note      = {Agent based simulation;Agent-based model;Domain specific languages;functional reactive;simulation;},
  abstract  = {Agent-based modeling (ABM) is a powerful tool for the study of complex systems; but agent-based models are notoriously difficult to create, modify, and reason about, especially in contrast to system dynamics models. We argue that these difficulties are strongly related to the choice of specification language, and that they can be mitigated by using functional reactive programming (FRP), a paradigm for describing dynamic systems. We describe Frabjous, a new language for agent-based modeling based on FRP, and discuss its software engineering benefits and their broader implications for language choice in ABM. &copy; 2014 Springer International Publishing Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Computational methods},
  keywords  = {Dynamic models;Functional programming;Problem oriented languages;Software engineering;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-05579-4_47},
}


@inproceedings{20124315587616,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Declaratively Defining Domain-Specific Language Debuggers},
journal = {ACM SIGPLAN Notices},
author = {Lindeman, Ricky T. and Kats, Lennart C.L. and Visser, Eelco},
volume = {47},
number = {3},
year = {2012},
pages = {127 - 136},
issn = {15232867},
abstract = {Tool support is vital to the effectiveness of domain-specific languages. With language workbenches, domain-specific languages and their tool support can be generated from a combined, high-level specification. This paper shows how such a specification can be extended to describe a debugger for a language. To realize this, we introduce a meta-language for coordinating the debugger that abstracts over the complexity of writing a debugger by hand. We describe the implementation of a language-parametric infrastructure for debuggers that can be instantiated based on this specification. The approach is implemented in the Spoofax language workbench and validated through realistic case studies with the Stratego transformation language and the WebDSL web programming language. &copy; 2011 ACM.},
key = {Problem oriented languages},
keywords = {Computer debugging;Graphical user interfaces;Specifications;},
note = {Debuggers;Domain specific languages;High level specification;Language workbenches;Meta language;Spoofax;Stratego;Tool support;},
URL = {http://dx.doi.org/10.1145/2189751.2047885},
} 


@inproceedings{20124915762770,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {BPMN4TOSCA: A domain-specific language to model management plans for composite applications},
journal = {Lecture Notes in Business Information Processing},
author = {Kopp, Oliver and Binz, Tobias and Breitenbucher, Uwe and Leymann, Frank},
volume = {125 LNBIP},
year = {2012},
pages = {38 - 52},
issn = {18651348},
address = {Vienna, Austria},
abstract = {TOSCA is an upcoming standard to capture cloud application topologies and their management in a portable way. Management aspects include provisioning, operation and deprovisioning of an application. Management plans capture these aspects in workflows. BPMN 2.0 as general-purpose language can be used to model these workflows. There is, however, no tailored support for management plans in BPMN. This paper analyzes TOSCA with the focus on requirements on workflow modeling languages to come up with a strong link to the application topology with the goal to improve modeling support. To simplify the modeling of management plans, we introduce BPMN4TOSCA, which extends BPMN with four TOSCA-specific elements: TOSCA Topology Management Task, TOSCA Node Management Task, TOSCA Script Task, and TOSCA Data Object. Portability is ensured by a transformation of BPMN4TOSCA to plain BPMN. A prototypical modeling tool supports the strong link between the management plan and the TOSCA topology. &copy; 2012 Springer-Verlag.},
key = {Management science},
keywords = {Cloud computing;Problem oriented languages;Topology;},
note = {BPMN Extension;Composite applications;Data objects;Domain specific languages;Management plans;Model management;Modeling tool;Node management;Service management;Strong link;Topology management;Work-flows;Workflow modeling;},
URL = {http://dx.doi.org/10.1007/978-3-642-33155-8_4},
} 

@Article{20163102654764,
  author    = {Cordoba-Sanchez, Irene and de Lara, Juan},
  title     = {Ann: A domain-specific language for the effective design and validation of Java annotations},
  journal   = {Computer Languages, Systems and Structures},
  year      = {2016},
  volume    = {45},
  pages     = {164 - 190},
  note      = {Code Generation;Conceptual model;Domain specific languages;Domain-Specific Modelling Languages;Integrity constraints;Java annotations;Model-driven Engineering;Software project;},
  abstract  = {This paper describes a new modelling language for the effective design and validation of Java annotations. Since their inclusion in the 5th edition of Java, annotations have grown from a useful tool for the addition of meta-data to play a central role in many popular software projects. Usually they are not conceived in isolation, but in groups, with dependency and integrity constraints between them. However, the native support provided by Java for expressing this design is very limited. To overcome its deficiencies and make explicit the rich conceptual model which lies behind a set of annotations, we propose a domain-specific modelling language. The proposal has been implemented as an Eclipse plug-in, including an editor and an integrated code generator that synthesises annotation processors. The environment also integrates a model finder, able to detect unsatisfiable constraints between different annotations, and to provide examples of correct annotation usages for validation. The language has been tested using a real set of annotations from the Java Persistence API (JPA). Within this subset we have found enough rich semantics expressible with Ann and omitted nowadays by the Java language, which shows the benefits of Ann in a relevant field of application. &copy; 2016 Elsevier Ltd},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {14778424},
  key       = {Java programming language},
  keywords  = {Automatic programming;Computational linguistics;Computer programming languages;Computer software;Graphical user interfaces;Modeling languages;Problem oriented languages;Program compilers;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.cl.2016.02.002},
}

@InProceedings{20124315605706,
  author    = {Lace, Lelde and Liepin, Renars and Rencis, Edgars},
  title     = {Architecture and language for semantic reduction of domain-specific models in BPMS},
  year      = {2012},
  volume    = {128 LNBIP},
  pages     = {70 - 84},
  address   = {Nizhny Novgorod, Russia},
  note      = {BPMS;Business process management systems;Domain specific;Domain specific languages;Domain-specific modeling language;Industry standards;Model transformation;Modeling languages;Semantic reductions;Specific languages;Tool-building Platforms;},
  abstract  = {Nowadays each business process management system (BPMS) supports either an industry standard or its own specific modeling language. But no BPMS supports a specific language for each organization. We propose an architecture for building BPMS that allows creating a domain-specific modeling language for every client easily. The main problem is to bridge the gap between the domain-specific language and the executable language. We show that we can look at this problem as a classification of the domain-specific language constructs in the terms of the executable language. To solve this problem we present a novel model transformation language, with which this type of problem can be solved more naturally than with existing transformation languages. &copy; 2012 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {18651348},
  journal   = {Lecture Notes in Business Information Processing},
  key       = {Problem solving},
  keywords  = {DSL;Enterprise resource management;Information science;Mathematical models;Problem oriented languages;Semantics;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-33281-4_6},
}

@InProceedings{20131716225025,
  author    = {Zalila, Faiez and Cregut, Xavier and Pantel, Marc},
  title     = {Towards a generic approach for DSML v v},
  year      = {2012},
  pages     = {IEEE CS; ACM Special Interest Group on Software Engineering (SIGSOFT) -},
  address   = {Obergurgl, Austria},
  note      = {Business languages;Domain-specific modeling language;Formal verifications;Generic approach;Safety-critical embedded systems;Traceability;Verification feedbacks;Verification results;},
  abstract  = {Model checking has produced very good results for the verfication of safety critical embedded systems. However, au-tomated verifcation tool-chains that allow users to rely on their usual business languages while enjoying the benefits of model checking powerful methods show different barriers: 1) the semantic gap between these languages is a very seri- ous barrier in the specification and implementation of this translational definition of the semantics of business models in the formal level, 2) expressing behavioral requirements in the business level and mapping them on the formal level and 3) the interpretation of verification results from the formal level by the end users in the business world. We propose a tooled approach which allows to resolve these cited barriers.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Modeling Wizards: 2nd International Master Class on Model-Driven Engineering, MW 2012 - Satellite Event of MODELS 2012},
  key       = {Semantics},
  keywords  = {Model checking;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2448076.2448081},
}


@article{20141917704254,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {On the modeling and generation of service-oriented tool chains},
journal = {Software and Systems Modeling},
author = {Biehl, Matthias and El-Khoury, Jad and Loiret, Frederic and Torngren, Martin},
volume = {13},
number = {2},
year = {2014},
pages = {461 - 480},
issn = {16191366},
abstract = {Tool chains have grown from ad-hoc solutions to complex software systems, which often have a service-oriented architecture. With service-oriented tool integration, development tools are made available as services, which can be orchestrated to form tool chains. Due to the increasing sophistication and size of tool chains, there is a need for a systematic development approach for service-oriented tool chains. We propose a domain-specific modeling language (DSML) that allows us to describe the tool chain on an appropriate level of abstraction. We present how this language supports three activities when developing service-oriented tool chains: communication, design and realization. A generative approach supports the realization of the tool chain using the service component architecture. We present experiences from an industrial case study, which applies the DSML to support the creation of a service-oriented tool chain. We evaluate the approach both qualitatively and quantitatively by comparing it with a traditional development approach. &copy; 2012 Springer-Verlag.},
key = {Tools},
keywords = {Chains;Industrial applications;Information services;Service oriented architecture (SOA);Specification languages;},
note = {Complex software systems;Domain specific modeling languages;Domain-specific modeling language;Generative approach;Industrial case study;Level of abstraction;Service component architecture;Tool integration;},
URL = {http://dx.doi.org/10.1007/s10270-012-0275-7},
} 

@InProceedings{20142017730457,
  author    = {Viana, Matheus and Penteado, Rosangela and Do Prado, Antonio and Durelli, Rafael},
  title     = {F3T: From features to frameworks tool},
  year      = {2013},
  pages     = {89 - 98},
  address   = {Brasilia, DF, Brazil},
  note      = {Adaptive natures;Development process;Domain model;Domain-specific modeling language;Framework development;Model application;},
  abstract  = {Frameworks are used to enhance the quality of applications and the productivity of development process, since applications can be designed and implemented by reusing framework classes. However, frameworks are hard to develop, learn and reuse, due to their adaptive nature. In this paper we present the From Features to Framework Tool (F3T), which supports framework development in two steps: Domain Modeling, in which the features of the framework domain are modeled, and Framework Construction, in which the source-code and the Domain-Specific Modeling Language (DSML) of the framework are generated from the features. In addition, the F3T also supports the use of the framework DSML to model applications and generate their source-code. The F3T has been evaluated in a experiment that is also presented in this paper. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings - 2013 27th Brazilian Symposium on Software Engineering, SBES 2013},
  key       = {Tools},
  keywords  = {Software engineering;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SBES.2013.15},
}


@inproceedings{20162902597573,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Verification support for a state-transition-DSL defined with Xtext},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Baar, Thomas},
volume = {9609},
year = {2016},
pages = {50 - 60},
issn = {03029743},
address = {Kazan and Innopolis, Russia},
abstract = {A Domain-Specific Language (DSL) allows the succinct modeling of phenomena in a problem domain. Modern DSL-tools make it easy for a language designer to define the syntax of a new DSL, to specify code generators or to build a new DSL on top of existing DSLs. Based on the language specification, the DSL-tool then generates rich editors. Often, these editors support features such as syntax highlighting, code completion or automatic refactoring. In this paper, we describe an approach of adding verification support for DSLs defined within the Eclipse-framework Xtext. Xtext provides good support for checking the well-formedness rules of the DSL&rsquo;s syntax. In contrast, support for specifying the language&rsquo;s semantics as well as verification support have been rather neglected so far. Our approach of incorporating semantic verification techniques is illustrated by a very simple State-Transition-DSL, which has been fully implemented in Xtext. The DSL&rsquo;s editor verifies on the fly that the current model holds some semantic properties such as deterministic execution and invariant preservation. The verification services for this DSL are based on the theorem prover PRINCESS. &copy; Springer International Publishing Switzerland 2016.},
key = {Modeling languages},
keywords = {Computational linguistics;Computer programming languages;DSL;Information science;Problem oriented languages;Semantics;Syntactics;},
note = {Automatic refactoring;Deterministic execution;Domain specific languages;Language specification;Model verification;Proof obligations;Semantic verification;State machine;},
URL = {http://dx.doi.org/10.1007/978-3-319-41579-6_5},
} 

@InProceedings{20124315601060,
  author    = {Noyrit, Florian and Gerard, Sebastien and Selic, Bran},
  title     = {FacadeMetamodel: Masking UML},
  year      = {2012},
  volume    = {7590 LNCS},
  pages     = {20 - 35},
  address   = {Innsbruck, Austria},
  note      = {Abstract syntax;Alternative approach;Domain-specific modeling language;Meta model;Uml profiles;UML tools;},
  abstract  = {UML profiling is pragmatic choice that lets language designers define a Domain-Specific Modeling Language (DSML) by tuning UML to meet specific domain. An alternative approach is to define a pure-DSML. Each approach has its own benefits and drawbacks. We propose an approach and a tool that helps get the best from both approaches; maximizing reuse while retaining a focused and adapted DSML. We guide the language designer in the definition of a metamodel based on one or more UML profiles. Language designers then recast UML so that only what they need will appear in this metamodel. From that, the tool automatically generates the pure-DSML and the transformations between it and UML. However, the new pure-DSML is only a facade; models can be manipulated using the pure-DSML abstract syntax but they are actually stored in fully-compliant UML abstract syntax and therefore remain compatible with UML tools. &copy; 2012 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Unified Modeling Language},
  keywords  = {Design;Markup languages;Models;Syntactics;Visual languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-33666-9_3},
}

@Article{20141917704267,
  author    = {Levendovszky, Tihamer and Balasubramanian, Daniel and Narayanan, Anantha and Shi, Feng and van Buskirk, Chris and Karsai, Gabor},
  title     = {A semi-formal description of migrating domain-specific models with evolving domains},
  journal   = {Software and Systems Modeling},
  year      = {2014},
  volume    = {13},
  number    = {2},
  pages     = {807 - 823},
  note      = {Domain specific;Domain specific modeling;Domain-specific modeling language;Language evolution;Model change;Model languages;Model migrations;},
  abstract  = {One of the main advantages of defining a domain-specific modeling language (DSML) is the flexibility to adjust the language definition to changing requirements or in response to a deeper understanding of the domain. With the industrial applications of domain-specific modeling environments, models are valuable investments. If the modeling language evolves, these models must be seamlessly migrated to the evolved DSML. Although the changes stemming from the language evolution are not abrupt in nature, migrating existing models to a new language is still a challenging task. Our solution is the Model Change Language (MCL) tool set, which defines a DSML to describe the migration rules and then performs the model migration automatically. In this paper, we describe the precise semantics of MCL and its execution, along with the confluence of the migration. &copy; 2013 Springer-Verlag Berlin Heidelberg.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {16191366},
  key       = {Natural language processing systems},
  keywords  = {Industrial applications;Semantics;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s10270-012-0313-5},
}

@InProceedings{20142217769078,
  author    = {He, Lei and Yao, Jian and Lei, Yong Lin},
  title     = {Air-combat decision modeling method based on DSM},
  year      = {2014},
  volume    = {536-537},
  pages     = {416 - 420},
  address   = {Zhuhai, China},
  note      = {Decision modeling;Domain specific modeling;Domain-specific modeling language;Generic modeling;Important features;Metamodeling;Model generation;Open source tools;},
  abstract  = {Air-combat decision modeling in effectiveness simulation has to be concerned with the important feature of decision making, such as complexity, diversity, flexibility. So Several challenges have to be mastered, including: improving the abstract level of modeling, providing friendly modeling language, validating concept model and generated code (or executive model) automatically. In this paper, domain-specific modeling (DSM) method is applied in air-combat decision simulation modeling to cope with those challenges. A graphical and textual domain-specific modeling language (DSML) of air-combat decision is designed through metamodel based on an open source tool, Generic Modeling Environment (GME). A code generator is developed to implement users' decision model based on python script. &copy; (2014) Trans Tech Publications, Switzerland.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {16609336},
  journal   = {Applied Mechanics and Materials},
  key       = {Robotics},
  keywords  = {Computer simulation;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.4028/www.scientific.net/AMM.536-537.416},
}

@InProceedings{20144700225488,
  author    = {Bordeleau, Francis},
  title     = {Model-Based Engineering: A new era based on papyrus and open source tooling},
  year      = {2014},
  volume    = {1290},
  pages     = {2 - 8},
  address   = {Valencia, Spain},
  note      = {Domain-specific modeling language;Eclipse;Integrated development environment;Model-based engineering;Open sources;Papyrus;Research communities;Software organization;},
  abstract  = {Model-Based Engineering (MBE) has proven to be highly successful in many different contexts in large software organizations such as Ericsson over the last decades. However, the broad adoption of MBE has been significantly limited by the fact that existing tools have failed to provide for better customizability and support for Domain-Specific Modeling Language (DSML) and to deliver capabilities to cover for the broad range of development aspects that are considered critical by end-users. Moreover, the lack of evolution of commercial modeling tools in the recent years has led several development units to seriously re-consider the use of modeling tools. We believe that the emergence of Papyrus as an industrial-grade open source modeling UML tool has the potential to be a real game changer and provide the required cornerstone of a new MBE era that will enable collaboration between industry and the research community to develop a complete MBE Integrated Development Environment (IDE) that will provide support for the broad set of capabilities required by the end-users.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {Open systems},
  keywords  = {Industrial research;Open source software;Software engineering;Specification languages;Web services;},
  language  = {English},
}

@InProceedings{20154001333217,
  author    = {Groce, Alex and Pinto, Jervis},
  title     = {A little language for testing},
  year      = {2015},
  volume    = {9058},
  pages     = {204 - 218},
  address   = {Pasadena, CA, United states},
  note      = {Automated testing;Domain specific languages;Test harness;Testing algorithm;},
  abstract  = {The difficulty of writing test harnesses is a major obstacle to the adoption of automated testing and model checking. Languages designed for harness definition are usually tied to a particular tool and unfamiliar to programmers; moreover, such languages can limit expressiveness. Writing a harness directly in the language of the software under test (SUT) makes it hard to change testing algorithms, offers no support for the common testing idioms, and tends to produce repetitive, hard to- read code. This makes harness generation a natural fit for the use of an unusual kind of domain-specific language (DSL). This paper defines a template scripting testing language, TSTL, and shows how it can be used to produce succinct, readable definitions of state spaces. The concepts underlying TSTL are demonstrated in Python but are not tied to it. &copy; Springer International Publishing Switzerland 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Software testing},
  keywords  = {Computational linguistics;Computer programming languages;Formal methods;Model checking;NASA;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-17524-9_15},
}


@inproceedings{20130315904612,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Domain specific modeling for operations research simulation in a large industrial context},
journal = {SPLASH 2012: DSM 2012 - Proceedings of the 2012 ACM Workshop on Domain-Specific Modeling},
author = {Lugato, David and Palyart, Marc and Engelvin, Christophe},
year = {2012},
pages = {19 - 24},
abstract = {In order to conduct operations research studies on complex systems, CEA/CESTA<sup>1</sup> has been using and developing a new generation of simulator. The inherent complexity of such simulations ensues from the large spectrum of physical phenomena involved. As a consequence the description of a scenario and the analysis of parametric studies are time-consuming tasks. In this paper, we illustrate how the use of modeling techniques can help users construct and interpret simulation scenarios, especially users who are not computer scientists. To that end, we present a domain-specific modeling language for operations research. Moreover its associated tool, which is deployed in a large industrial context, is introduced along with model examples. Copyright &copy; 2012 ACM.},
key = {Research},
keywords = {Models;Operations research;Problem oriented languages;Specification languages;},
note = {Associated tool;Computer scientists;Domain specific languages;Domain specific modeling;Domain-specific modeling language;Industrial context;Inherent complexity;Model-driven Engineering;Modeling technique;Parametric study;Physical phenomena;Time-consuming tasks;},
URL = {http://dx.doi.org/10.1145/2420918.2420924},
} 

@InProceedings{20161502237471,
  author    = {Yue, Songqing and Gray, Jeff},
  title     = {A DSL for reducing the accidental complexities of using program transformation engines},
  year      = {2015},
  pages     = {195 - 200},
  address   = {San Diego, CA, United states},
  note      = {Abstraction level;Code Generation;Code modifications;Domain specific languages;Language tools;Program transformation techniques;Program transformations;Software evolution and maintenances;},
  abstract  = {Many software evolution and maintenance problems can be addressed through techniques of program transformation. To facilitate development of language tools assisting software evolution and maintenance, we created a Domain-Specific Language (DSL), named SPOT (Specifying PrOgram Transformation), which can be used to raise the abstraction level of code modification. The design goal is to automate source-tosource program transformations through techniques of code generation, so that developers only need to specify desired transformations using constructs provided by the DSL while being oblivious to the details about how the transformations are performed. The paper provides a general motivation for using program transformation techniques and explains the design details of SPOT. In addition, we present a case study to illustrate how SPOT can be used to build a code coverage tool for applications implemented in different programming languages.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {24th International Conference on Software Engineering and Data Engineering, SEDE 2015},
  key       = {Computer software maintenance},
  keywords  = {Codes (symbols);Computational linguistics;Computer programming languages;Problem oriented languages;Program compilers;Software engineering;},
  language  = {English},
}

@InProceedings{20150900589366,
  author    = {elikovi, Milan and Dimitrieski, Vladimir and Aleksic, Slavica and Ristic, Sonja and Lukovic, Ivan},
  title     = {A DSL for EER data model specification},
  year      = {2014},
  pages     = {290 - 297},
  address   = {Varazdin, Croatia},
  note      = {Domain specific languages;Ecore;Entity-relationship;Graphical notation;Information system model;Model specifications;Object Constraint Language;Relational data models;},
  abstract  = {In this paper we present a domain specific language (DSL) for Extended Entity-Relationship (EER) data model approach, named EERDSL. EERDSL is a part of our Multi-Paradigm Information System Modeling Tool (MIST) that provides EER database schema specification at the conceptual level and its transformation into a relational data model, or a class model. EERDSL modeling concepts are specified by Ecore, one of the commonly used approaches to create meta-models. In the paper we present both textual and graphical notations of EERDSL. Since only few modeling constraints may be described at the level of abstract syntax, we use Object Constraint Language (OCL) to specify complex validation rules for EER models.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Information Systems Development: Transforming Organisations and Society Through Information Systems - Proceedings of the 23rd International Conference on Information Systems Development, ISD 2014},
  key       = {Modeling languages},
  keywords  = {Computational linguistics;Computer programming languages;Data mining;Database systems;Information systems;Metadata;Problem oriented languages;Specifications;},
  language  = {English},
}

@InProceedings{20144600188474,
  author    = {Rahman, Anisur and Amyot, Daniel},
  title     = {A DSL for importing models in a requirements management system},
  year      = {2014},
  pages     = {37 - 46},
  address   = {Karlskrona, Sweden},
  note      = {Automatic Generation;Domain specific languages;evolution;Proprietary solutions;Requirements management;Requirements management systems;traceability;Traceability links;},
  abstract  = {Requirements are artefacts often described with text and models. It is important to manage traceability between requirements and other software artefacts, including designs and test cases, also often captured with specialized models. Some Requirements Management Systems (RMS) support traceability relationships, between (textual) requirements artefacts in the RMS and model artefacts created outside the RMS, through complex standards or proprietary solutions. This paper proposes a new Domain-Specific Language (DSL) for describing the concepts of a modeling language intended to be traced using an RMS, with tool support handling the import and re-import of models and of their traceability links. The Model Import DSL (MI-DSL) is supported by an Xtext-based editor and the automatic generation of an import library targeting a leading RMS, namely IBM Rational DOORS. The language and the tools are demonstrated for model import and evolution scenarios with two different modeling languages. This work contributes a simple yet reliable mechanism to define and support traceability between requirements and models from different tools. &copy; 2014 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {2014 IEEE 4th International Model-Driven Requirements Engineering Workshop, MoDRE 2014 - Proceedings},
  key       = {Requirements engineering},
  keywords  = {Computer programming languages;Doors;DSL;Models;Outsourcing;Problem oriented languages;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/MoDRE.2014.6890824},
}

@Article{20133516666866,
  author    = {Lukman, Tomaz and Godena, Giovanni and Gray, Jeff and Hericko, Marjan and Strmcnik, Stanko},
  title     = {Model-driven engineering of process control software - beyond device-centric abstractions},
  journal   = {Control Engineering Practice},
  year      = {2013},
  volume    = {21},
  number    = {8},
  pages     = {1078 - 1096},
  note      = {Application engineering;Automatic code generations;Domain-specific modeling language;Industrial process control;Model languages;Model transformation;Model-driven Engineering;Process control software;},
  abstract  = {This paper presents a new, two-level, model-driven engineering approach to industrial process control software. The first level (infrastructure engineering) is concerned with the following: the definition of the development process and guidelines, the definition of a domain-specific modeling language, the specification of the model transformations, and the development of a tool suite. This tool suite enables modeling of the process control software and the automatic code generation for programmable logic controllers. In the second level (application engineering), the process control software is engineered using the results of the infrastructure level. The approach is demonstrated on excerpts from an industrial project. &copy; 2013 Elsevier Ltd.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {09670661},
  key       = {Application programs},
  keywords  = {Controllers;Process control;Programmable logic controllers;Programmed control systems;Specification languages;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.conengprac.2013.03.013},
}

@InProceedings{20123015276546,
  author    = {Selim, Gehan M. K. and Wang, Shige and Cordy, James R. and Dingel, Juergen},
  title     = {Model transformations for migrating legacy models: An industrial case study},
  year      = {2012},
  volume    = {7349 LNCS},
  pages     = {90 - 101},
  address   = {Kgs. Lyngby, Denmark},
  note      = {Atlas transformation languages;Automotive companies;Automotive control;AutoSAR;Domain-specific modeling language;General motors;Growing demand;Industrial case study;Meta model;Model transformation;Model-driven development;Open system architecture;Vehicle control software;},
  abstract  = {Many companies in the automotive industry have adopted MDD in their vehicle control software development. As a major automotive company, General Motors has been using a custom-built, domain-specific modeling language, implemented as an internal proprietary metamodel, to meet the modeling needs in its control software development. As AUTOSAR (AUTomotive Open System ARchitecture) is being developed as a standard to ease the process of integrating components provided by different suppliers and manufacturers, there is a growing demand to migrate these GM-specific, legacy models to AUTOSAR models. Given that AUTOSAR defines its own metamodel for various system artifacts in automotive software development, we explore using model transformations to address the challenges in migrating GM legacy models to their AUTOSAR equivalents. As a case study, we have built a model transformation using the MDWorkbench tool and the Atlas Transformation Language (ATL). This paper reports on the case study, makes observations based on our experience to assist in the development of similar types of transformations, and provides recommendations for further research. &copy; 2012 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Mathematical models},
  keywords  = {Automotive industry;Control system synthesis;Industrial applications;Open systems;Research;Software design;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-31491-9_9},
}

@InProceedings{20144800255627,
  author    = {Balasubramanian, Daniel and Levendovszky, Tihamer and Dubey, Abhishek and Karsai, Gabor},
  title     = {Taming multi-paradigm integration in a software architecture description language},
  year      = {2014},
  volume    = {1237},
  pages     = {67 - 76},
  address   = {Valencia, Spain},
  note      = {Architecture description languages;Automated analysis;Distributed real time system;Domain-specific modeling language;High-level structure;Software architecture description languages;Software community;Software systems;},
  abstract  = {Software architecture description languages offer a convenient way of describing the high-level structure of a software system. Such descriptions facilitate rapid prototyping, code generation and automated analysis. One of the big challenges facing the software community is the design of architecture description languages that are general enough to describe a wide-range of systems, yet detailed enough to capture domain-specific properties and provide a high level of tool automation. This paper presents the multi-paradigm challenges we faced and solutions we built when creating a domain-specific modeling language for software architectures of distributed real-time systems.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {High level languages},
  keywords  = {Embedded systems;Interactive computer systems;Real time systems;Software architecture;Specification languages;Systems analysis;},
  language  = {English},
}

@InProceedings{20142817910406,
  author    = {Thiery, Adrien and Cerqueus, Thomas and Thorpe, Christina and Sunye, Gerson and Murphy, John},
  title     = {A DSL for deployment and testing in the cloud},
  year      = {2014},
  pages     = {376 - 382},
  address   = {Cleveland, OH, United states},
  note      = {Application deployment;Cloud applications;Deployment;Generation process;High-level domain;Production environments;Resource requirements;Software-as-a-Service;},
  abstract  = {Cloud computing is becoming increasingly prevalent, more and more software providers are offering their applications as Software-as-a-Service solutions rather than traditional on-premises installations. In order to ensure the efficacy of the testing phase, it is critical to create a test environment that sufficiently emulates the production environment. Thus, Cloud applications should be tested in the Cloud. Cloud providers offer command-line tools for interacting with their platforms. However, writing custom low-level scripts using the provider's tool can become very complex to maintain and manage when variability (in terms of providers and platforms) is introduced. The contributions in this paper include: the development of a high level Domain Specific Language for the abstract definition of the application deployment process, and resource requirements, and a generation process that transforms these definitions to automatically produce deployment and instantiation scripts for a variety of providers and platforms. These contributions significantly simplify and accelerate the testing process for Cloud applications. &copy; 2014 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings - IEEE 7th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2014},
  key       = {Application programs},
  keywords  = {Clouds;Computer programming languages;DSL;Software testing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICSTW.2014.43},
}


@inproceedings{20143118008948,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {OpenMETA: A model- and component-based design tool chain for cyber-physical systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Sztipanovits, Janos and Bapty, Ted and Neema, Sandeep and Howard, Larry and Jackson, Ethan},
volume = {8415 LNCS},
year = {2014},
pages = {235 - 248},
issn = {03029743},
address = {Grenoble, France},
abstract = {Model- and component-based design have yielded dramatic increase in design productivity in several narrowly focused homogeneous domains, such as signal processing, control and aspects of electronic design. However, significant impact on the design and manufacturing of complex cyber-physical systems (CPS) such as vehicles has not yet been achieved. This paper describes challenges of and solution approaches to building a comprehensive design tool suite for complex CPS. The primary driver for the OpenMETA tool chain was to push the boundaries of the "correct-by-construction" principle to decrease significantly the costly design-build-test-redesign cycles in design flows. In the discussions we will focus on the impact of heterogeneity in modeling CPS. This challenge is compounded by the need for rapidly evolving the design flow by changing/updating the selection of modeling languages, analysis and verification tools and synthesis methods. Based on our experience with the development of OpenMETA and with the evaluation of its performance in a complex CPS design challenge we argue that the current vertically integrated, discipline-specific tool chains for CPS design need to be complemented with horizontal integration layers that support model integration, tool integration and design process integration. This paper will examine the OpenMETA technical approach to construct the new integration layers, provides and overview of the technical framework we established for their implementation and summarize our experience with their application. &copy; 2014 Springer-Verlag Berlin Heidelberg.},
key = {Chains},
keywords = {Computer aided design;Embedded systems;Signal processing;Specification languages;},
note = {Component based design;Cyber physical systems (CPSs);Design automations;Domain-specific modeling language;Model integrated computing;Model integration;Model-based design;},
URL = {http://dx.doi.org/10.1007/978-3-642-54848-2_16},
} 


@article{20122915259411,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {NCSWT: An integrated modeling and simulation tool for networked control systems},
journal = {Simulation Modelling Practice and Theory},
author = {Eyisi, Emeka and Bai, Jia and Riley, Derek and Weng, Jiannian and Yan, Wei and Xue, Yuan and Koutsoukos, Xenofon and Sztipanovits, Janos},
volume = {27},
year = {2012},
pages = {90 - 111},
issn = {1569190X},
abstract = {Networked Control Systems (NCS) are becoming increasingly ubiquitous in a growing number of applications, such as groups of unmanned aerial vehicles and industrial control systems. The evaluation of NCS properties such as stability and performance is very important given that these systems are typically deployed in critical settings. This paper presents the Networked Control Systems Wind Tunnel (NCSWT), an integrated modeling and simulation tool for the evaluation of Networked Control Systems (NCS). NCSWT integrates Matlab/Simulink and ns-2 for modeling and simulation of NCS using the High Level Architecture (HLA) standard. The tool is composed of two parts, the design-time models and the run-time components. The design-time models use Model Integrated Computing (MIC) to define HLA-based model constructs such as federates representing the simulators and interactions representing the communication between the simulators. MIC techniques facilitate the modeling and design of complex systems by using abstractions defined in domain-specific modeling languages (DSMLs) to describe the systems. The design-time models represent the control system dynamics and networking system behaviors in order to facilitate the run-time simulation of a NCS. The run-time components represent the main software components and interfaces for the actual realization of a NCS simulation using the HLA framework. Our implementation of the NCSWT based on HLA guarantees accurate time synchronization and data communication. Two case studies are presented to demonstrate the capabilities of the tool as well as evaluate the impact of network effects on NCS. &copy; 2012 Elsevier B.V. All rights reserved.},
key = {Networked control systems},
keywords = {Computer simulation;Design;Integration;Models;Specification languages;Tools;},
note = {Control system dynamics;Data-communication;Domain-specific modeling language;High level architecture standards;HLA;Industrial control systems;Integrated modeling;MATLAB /simulink;Modeling and simulation;Network effects;Networking systems;Runtimes;Simulation;Software component;Time synchronization;Use-model;},
URL = {http://dx.doi.org/10.1016/j.simpat.2012.05.004},
} 


@inproceedings{20123415350878,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Creating visual domain-specific modeling languages from end-user demonstration},
journal = {2012 4th International Workshop on Modeling in Software Engineering, MiSE 2012 - Proceedings},
author = {Cho, Hyun and Gray, Jeff and Syriani, Eugene},
year = {2012},
pages = {22 - 28},
address = {Zurich, Switzerland},
abstract = {Domain-Specific Modeling Languages (DSMLs) have received recent interest due to their conciseness and rich expressiveness for modeling a specific domain. However, DSML adoption has several challenges because development of a new DSML requires both domain knowledge and language development expertise (e.g., defining abstract/concrete syntax and specifying semantics). Abstract syntax is generally defined in the form of a metamodel, with semantics associated to the metamodel. Thus, designing a metamodel is a core DSML development activity. Furthermore, DSMLs are often developed incrementally by iterating across complex language development tasks. An iterative and incremental approach is often preferred because the approach encourages end-user involvement to assist with verifying the DSML correctness and feedback on new requirements. However, if there is no tool support, iterative and incremental DSML development can be mundane and error-prone work. To resolve issues related to DSML development, we introduce a new approach to create DSMLs from a set of domain model examples provided by an end-user. The approach focuses on (1) the identification of concrete syntax, (2) inducing abstract syntax in the form of a metamodel, and (3) inferring static semantics from a set of domain model examples. In order to generate a DSML from user-supplied examples, our approach uses graph theory and metamodel design patterns. &copy; 2012 IEEE.},
key = {Visual languages},
keywords = {Graph theory;Semantics;Software engineering;Specification languages;Syntactics;},
note = {Abstract syntax;Concrete syntax;Design Patterns;Development activity;Domain knowledge;Domain model;Domain-specific modeling language;End users;End-user involvements;Error prones;Incremental approach;Language development;Meta model;Semantic inference;Static semantics;Tool support;},
URL = {http://dx.doi.org/10.1109/MISE.2012.6226010},
} 


@article{20122715215998,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Weaving variability into domain metamodels},
journal = {Software and Systems Modeling},
author = {Perrouin, Gilles and Vanwormhoudt, Gilles and Morin, Brice and Lahire, Philippe and Barais, Olivier and Jezequel, Jean-Marc},
volume = {11},
number = {3},
year = {2012},
pages = {361 - 383},
issn = {16191366},
abstract = {Domain-specific modeling languages (DSMLs) are the essence of MDE. A DSML describes the concepts of a particular domain in a metamodel, as well as their relationships. Using a DSML, it is possible to describe a wide range of different models that often share a common base and vary on some parts. On the one hand, some current approaches tend to distinguish the variability language from the DSMLs themselves, implying greater learning curve for DSMLs stakeholders and a significant overhead in product line engineering. On the other hand, approaches integrating variability in DSMLs lack generality and tool support. We argue that aspect-oriented modeling techniques enabling flexible metamodel composition and results obtained by the software product line community to manage and resolve variability form the pillars for a solution for integrating variability into DSMLs. In this article, we consider variability as an independent and generic aspect to be woven into the DSML. In particular, we detail how variability is woven and how to perform product line derivation. We validate our approach through the weaving of variability into two different metamodels: Ecore-widely used for DSML definition-and SmartAdapters, our aspect model weaver. These results emphasize how new abilities of the language can be provided by this means. &copy; 2010 Springer-Verlag.},
key = {Weaving},
keywords = {Network architecture;Production engineering;Software design;Specification languages;},
note = {Aspect model;Aspect oriented modeling;Common-base;Domain metamodels;Domain specific languages;Domain-specific modeling language;Learning curves;Meta model;Model weaving;Product line engineering;Product-lines;Software Product Line;Tool support;},
URL = {http://dx.doi.org/10.1007/s10270-010-0186-4},
} 

@InProceedings{20160101760945,
  author    = {de la Vega, Alfonso and Garcia-Saiz, Diego and Zorrilla, Marta and Sanchez, Pablo},
  title     = {Towards a DSL for educational data mining},
  year      = {2015},
  volume    = {563},
  pages     = {79 - 90},
  address   = {Madrid, Spain},
  note      = {Data analysis tool;Domain specific languages;Educational data mining;Work process;},
  abstract  = {Nowadays, most companies and organizations rely on computer systems to run their work processes. Therefore, the analysis of how these systems are used can be an important source of information to improve these work processes. In the era of Big Data, this is perfectly feasible with current state-of-art data analysis tools. Nevertheless, these data analysis tools cannot be used by general users, as they require a deep and sound knowledge of the algorithms and techniques they implement. In other areas of computer science, domain-specific languages have been created to abstract users from low level details of complex technologies. Therefore, we believe the same solution could be applied for data analysis tools. This article explores this hypothesis by creating a Domain-Specific Language (DSL) for the educational domain. &copy; Springer International Publishing Switzerland 2015.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {18650929},
  journal   = {Communications in Computer and Information Science},
  key       = {Big data},
  keywords  = {Abstracting;Computational linguistics;Computer programming languages;Data handling;Data mining;Graphical user interfaces;Information analysis;Problem oriented languages;Slate;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-27653-3_8},
}

@InProceedings{20123315339751,
  author    = {Sulzmann, Martin and Zechner, Axel},
  title     = {Model checking DSL-generated C source code},
  year      = {2012},
  volume    = {7385 LNCS},
  pages     = {241 - 247},
  address   = {Oxford, United kingdom},
  note      = {Domain specific languages;Mission critical applications;Source codes;Temporal specification;},
  abstract  = {We report on the application of SPIN for model-checking C source code which is generated out of a textual domain-specific language (DSL). We have built a tool which automatically generates the necessary SPIN wrapper code using (meta-)information available at the DSL level. The approach is part of a larger tool-chain for developing mission critical applications. The main purpose of SPIN is for bug-finding where error traces resulting from SPIN can be automatically replayed at the DSL level and yield concise explanations in terms of a temporal specification DSL. The tool-chain is applied in some large scale industrial applications. &copy; 2012 Springer-Verlag Berlin Heidelberg.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Model checking},
  keywords  = {Industrial applications;Problem oriented languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-31759-0_18},
}


@inproceedings{20144700211884,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Developing conceptual modeling tools using a DSL},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Visic, Niksa and Karagiannis, Dimitris},
volume = {8793},
year = {2014},
pages = {162 - 173},
issn = {03029743},
address = {Sibiu, Romania},
abstract = {There are multiple ways one can pursue when developing conceptual modeling tools. The most common are the ones where modeling tool engineers implement by using multiple graphical editors and various programming languages to realize the requirements of a modeling method. In this case, implementing artifacts such as abstract and concrete syntax or algorithms is linked to a specific technological platform. This motivated us to develop a DSL for this area, which entailed designing, specifying and implementing it. In this paper we propose a domain-specific language (MM-DSL) based on a metamodeling approach, which gives us the ability to be technology independent. With MMDSL a specification for a conceptual modeling tool is programmed on an abstract level. The code can be compiled and executed on different metamodeling platforms. We tested the MM-DSL 1.0 using a prototype-based evaluation. &copy; Springer International Publishing Switzerland 2014.},
key = {Data mining},
keywords = {Computer programming languages;Problem oriented languages;},
note = {Abstract levels;Conceptual model;Concrete syntax;Domain specific languages;Graphical editors;Metamodeling;Technological platform;Technology independent;},
} 

@Article{20142717895849,
  author    = {Frank, Ulrich},
  title     = {Multi-perspective enterprise modeling: Foundational concepts, prospects and future research challenges},
  journal   = {Software and Systems Modeling},
  year      = {2014},
  volume    = {13},
  number    = {3},
  pages     = {941 - 962},
  note      = {Domain-specific modeling language;Enterprise modeling;Method engineering;Modeling tool;Reference modeling;},
  abstract  = {The paper presents a method for multi- perspective enterprise modeling (MEMO) and a corresponding (meta-) modeling environment. An extensive analysis of requirements for enterprise modeling serves to motivate and assess the method. The method is based on an elaborate conception of multi-perspective enterprise models and on an extensible language architecture. The language architecture is comprised of a meta modeling language and an extensible set of integrated domain-specific modeling languages (DSML). The DSML are supplemented with process models and with guidelines for their reflective use. The corresponding modeling environment integrates editors for various DSML into multi-language model editors. It includes a meta model editor which enables the convenient use, development and extension of the set of supported DSML and supports the generation of respective graphical model editors. Thus, it also serves as a foundation for method engineering. MEMO covers both software engineering as well as social, managerial and economic aspects of the firm. The presentation of MEMO is supplemented with a comparative overview of other approaches to enterprise modeling. The paper concludes bys summarizing fundamental technical, epistemological and political challenges for enterprise modeling research and discusses potential paths for future research. &copy; 2012 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16191366},
  key       = {Research},
  keywords  = {Computational linguistics;High level languages;Industry;Software engineering;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/s10270-012-0273-9},
}


@inproceedings{20143017986845,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {DSL methods for CPS simulation in the cloud experience report},
journal = {ACM International Conference Proceeding Series},
author = {Kourzanov, Peter},
year = {2014},
pages = {25 - 32},
address = {Dresden, Germany},
abstract = {This paper presents our approach to Cyber-physical System (CPS) simulation including a number of embedded nodes that form a wireless network. On one hand, we use the NS-2 discrete-event simulator as a C++ kernel for running network simulation scenarios, while on the other hand, a combination of components written using standard Scheme as well as a number of Domain-Specific Language (DSL) instances embedded into Scheme (implementing pattern-matching, logicrelational models, and Web programming) are used in a cloud-based tool-set that supports research exploration cycle where variation in network parameters is compared to the resulting CPS performance. These components cooperate to provide an intuitive Web-based user interface, analysis tools and a seamless work-flow including visualization. &copy; 2014 ACM.},
key = {Distributed computer systems},
keywords = {C++ (programming language);Cloud computing;Computer programming;Discrete event simulation;Embedded systems;Graphical user interfaces;Models;Problem oriented languages;},
note = {Cyber physical systems (CPSs);Declarative Programming;Discrete event models;Domain specific languages;Network simulation;},
URL = {http://dx.doi.org/10.1145/2559627.2559634},
} 

@Article{20152300912442,
  author    = {Popovic, Aleksandar and Lukovic, Ivan and Dimitrieski, Vladimir and Djukic, Verislav},
  title     = {A DSL for modeling application-specific functionalities of business applications},
  journal   = {Computer Languages, Systems and Structures},
  year      = {2015},
  volume    = {43},
  pages     = {69 - 95},
  note      = {Application specific;Domain specific languages;Information system development process;Integrated information system;Model transformation;Model-Driven Software Development;Platform independent model;System implementation;},
  abstract  = {Models have been widely used in the information system development process. Models are not just means for system analysis and documentation. They may be also transformed into system implementation, primarily program code. Generated program code of screen forms and transaction programs mainly implements generic functionalities that can be expressed by simple retrieval, insertion, update, or deletion operations over database records. Besides the program code of generic functionalities, each application usually includes program code for specific business logic that represents application-specific functionalities, which may include complex calculations, as well as a series of database operations. There is a lack of domain-specific and tool-supported techniques for specification of such application-specific functionalities at the level of platform-independent models (PIMs). In this paper, we propose an approach and a domain-specific language (DSL), named IIS<sup>&lowast;</sup>CFuncLang, aimed at enabling a complete specification of application-specific functionalities at the PIM level. We have developed algorithms for transformation of IIS<sup>&lowast;</sup>CFuncLang specifications into executable program code, such as PL/SQL program code. In order to support specification of application-specific functionalities using IIS<sup>&lowast;</sup>CFuncLang, we have also developed appropriate tree-based and textual editors. The language, editors, and the transformations are embedded into a Model-Driven Software Development tool, named Integrated Information Systems CASE (IIS<sup>&lowast;</sup>Case). IIS<sup>&lowast;</sup>Case supports platform-independent design and automated prototyping of information systems, which allows us to verify and test our approach in practice. &copy; 2015 Elsevier Ltd.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {14778424},
  key       = {Application programs},
  keywords  = {Codes (symbols);Computational linguistics;Computer programming languages;Embedded systems;Graphical user interfaces;Information systems;Markup languages;Problem oriented languages;Software design;Software engineering;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.cl.2015.03.003},
}

@InProceedings{20134516952779,
  author    = {Wouters, Laurent},
  title     = {Towards the notation-driven development of DSMLs},
  year      = {2013},
  volume    = {8107 LNCS},
  pages     = {522 - 537},
  address   = {Miami, FL, United states},
  note      = {Abstract syntax;Concrete syntax;Domain specific modeling;Domain-specific modeling language;Empirical studies;Interface domains;ITS applications;Model-driven Engineering;},
  abstract  = {Domain-Specific Modeling Languages (DSML) enable domain experts to leverage Model-Driven Engineering methods and tools through concepts and notations from their own domain. The notation of a DSML is critical because it is the sole interface domain experts will have with their tool. Unfortunately, the current process for the development of DSMLs strongly emphasizes the abstract syntaxes and often treats the notations (concrete syntaxes) as byproducts. Focusing on the case of visual DSMLs, this paper proposes to automatically generate a DSML's abstract syntax from the specification of its concrete syntax. This shift towards the notation-driven development of DSMLs is expected to enable the production of DSMLs closer to domain experts' expectations. This approach is validated by its implementation in a prototype, its application on an industrial case and the results of an empirical study. &copy; 2013 Springer-Verlag.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03029743},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  key       = {Visual languages},
  keywords  = {Byproducts;Models;Specification languages;Syntactics;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-642-41533-3_32},
}

@InProceedings{20134216854465,
  author    = {Lindecker, David and Simko, Gabor and Madari, Istvan and Levendovszky, Tihamer and Sztipanovits, Janos},
  title     = {Multi-way semantic specification of domain-specific modeling languages},
  year      = {2013},
  pages     = {20 - 29},
  address   = {Phoenix, AZ, United states},
  note      = {Cyber-physical systems (CPS);Denotational semantics;Domain-specific modeling language;Formal modeling and analysis;Model-based design;Operational semantics;Semantic specification;Syntactic structure;},
  abstract  = {Increased emphasis on the use of model-based design methods, particularly for developing Cyber-Physical Systems (CPS), has created challenges in the area of developing domain-specific modeling languages (DSML). To meet the increased demand for DSMLs, rapid development tools and techniques are needed. While tools such as the Generic Modeling Environment (GME) for the specification of the syntactic structure of DSMLs are well established, proper techniques for the specification of semantics and methods for integrating the semantic specifications with the language design tool suite remain interesting challenges. Current efforts in semantic specification of DSMLs focus solely on operational semantics. In this paper we show how the specification of multiple types of semantics can bring added benefit. We also emphasize the use of FORMULA, a formal modeling and analysis language, and show how it can be used to specify the semantics of a DSML in a way that integrates with DSML development tools. As a case study, we consider the operational and denotational semantics of a Statecharts-like language and show that the two semantic specifications can be used for complementary applications. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of the International Symposium and Workshop on Engineering of Computer Based Systems},
  key       = {Specifications},
  keywords  = {Embedded systems;Semantics;Specification languages;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ECBS.2013.29},
}

@InProceedings{20160501879859,
  author    = {Sprogis, Arturs and Barzdins, Janis},
  title     = {Specification, configuration and implementation of DSL tool},
  year      = {2013},
  volume    = {249},
  pages     = {330 - 343},
  note      = {Extension mechanisms;Meta model;Precise definition;transformation;},
  abstract  = {A new specification method for DSL and DSL tools is proposed. The method is based on an advanced stereotype mechanism. A special feature of the proposed method is a precise definition of the extension mechanism for realization of non-standard features of DSL tools. In conclusions the architecture of a DSL tool building framework based on the proposed specification method is described. &copy; 2013 The authors and IOS Press. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {09226389},
  journal   = {Frontiers in Artificial Intelligence and Applications},
  key       = {Specifications},
  keywords  = {Artificial intelligence;DSL;},
  language  = {English},
  url       = {http://dx.doi.org/10.3233/978-1-61499-161-8-330},
}

@InProceedings{20131116105520,
  author    = {Combemale, Benoit and Cregut, Xavier and Pantel, Marc},
  title     = {A design pattern to build executable DSMLs and associated V V tools},
  year      = {2012},
  volume    = {1},
  pages     = {282 - 287},
  address   = {Hong Kong, China},
  note      = {Design Patterns;Domain-specific modeling language;Execution semantics;Graphical animation;Meta model;Model validation;Model-driven Engineering;Software languages;Systematic method;Target domain;Validation and verification;Virtual machines;},
  abstract  = {Model executability is now a key concern in model-driven engineering' mainly to support early validation and verification (V&amp;amp;V). Some approaches allow to weave executability into metamodels' defining executable domain-specific modeling languages (DSMLs). Model validation can then be achieved by simulation and graphical animation through direct interpretation of the conforming models. Other approaches address model executability by model compilation' allowing to reuse the virtual machines or V&amp;amp;V tools existing in the target domain. Nevertheless' systematic methods are currently not available to help the language designer in the definition of such an execution semantics and related tools. For instance' simulators are mostly hand-crafted in a tool specific manner for each DSML. In this paper' we propose to reify the elements commonly used to support state-based execution in a DSML. We infer a design pattern (called Executable DSML pattern) providing a general reusable solution for the expression of the executability concerns in DSMLs. It favors flexibility and improves reusability in the definition of semantics-based tools for DSMLs. We illustrate how this pattern can be applied to ease the development of V&amp;amp;V tools. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {15301362},
  journal   = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
  key       = {Computer simulation},
  keywords  = {Animation;Reusability;Semantics;Specification languages;Verification;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/APSEC.2012.79},
}

@Article{20133316608411,
  author    = {De Lara, Juan and Guerra, Esther and Sanchez Cuadrado, Jesus},
  title     = {Reusable abstractions for modeling languages},
  journal   = {Information Systems},
  year      = {2013},
  volume    = {38},
  number    = {8},
  pages     = {1128 - 1149},
  note      = {Abstraction;Domain-specific modeling language;Genericity;MetaDepth;Metamodeling;Model-driven Engineering;},
  abstract  = {Model-driven engineering proposes the use of models to describe the relevant aspects of the system to be built and synthesize the final application from them. Models are normally described using Domain-Specific Modeling Languages (DSMLs), which provide primitives and constructs of the domain. Still, the increasing complexity of systems has raised the need for abstraction techniques able to produce simpler versions of the models while retaining some properties of interest. The problem is that developing such abstractions for each DSML from scratch is time and resource consuming. In this paper, our goal is reducing the effort to provide modeling languages with abstraction mechanisms. For this purpose, we have devised some techniques, based on generic programming and domain-specific meta-modeling, to define generic abstraction operations that can be reused over families of modeling languages sharing certain characteristics. Abstractions can make use of clustering algorithms as similarity criteria for model elements. These algorithms can be made generic as well, and customized for particular languages by means of annotation models. As a result, we have developed a catalog of reusable abstractions using the proposed techniques, together with a working implementation in the MetaDepth multi-level meta-modeling tool. Our techniques and prototypes demonstrate that it is feasible to build reusable and adaptable abstractions, so that similar abstractions need not be developed from scratch, and their integration in new or existing modeling languages is less costly. &copy; 2013 Elsevier Ltd.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {03064379},
  key       = {Abstracting},
  keywords  = {Clustering algorithms;Computer programming languages;Computer software reusability;Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.is.2013.06.001},
}


@inproceedings{20162902597341,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {DSML tool building platform in WEB},
journal = {Communications in Computer and Information Science},
author = {Sprogis, Arturs},
volume = {615},
year = {2016},
pages = {99 - 109},
issn = {18650929},
address = {Riga, Latvia},
abstract = {The paper discusses how to build DSML tool building platform in WEB. Previously this was not possible due to the limitations of the browsers to render graphical diagrams but the technologies have evolved and currently the limitations are eliminated. Basically, the platform consists of three components &ndash; Presentation, engine, Interpreter and the Configurator. The paper gives an explanation what are the tasks for each of the component and how they interact with each other. To demonstrate a tool building process, a building of a simple flowchart editor is presented. &copy; Springer International Publishing Switzerland 2016.},
key = {Information systems},
keywords = {Computer science;Computers;Models;},
note = {Building process;Configurator;Three component;Tool-building Platforms;Web development;},
URL = {http://dx.doi.org/10.1007/978-3-319-40180-5_7},
} 

@InProceedings{20152500951424,
  author    = {Tcholtchev, Nikolay and Dudeck, Grit and Wagner, Michael and Hein, Christian and Prakash, Arun and Ritter, Tom},
  title     = {Integrating the modelica DSL into a platform for model-based tool interoperability},
  year      = {2014},
  pages     = {528 - 534},
  address   = {Vasteras, Sweden},
  note      = {Automotive domains;Cost-efficient design;Development and operations;Domain specific languages;MDE;Model-driven Engineering;Modelica;System development process;},
  abstract  = {Domain Specific Languages (DSL) are an important concept that is used in industry, in order to enable the fast and cost efficient design of specific functions/components, and/or to target particular aspects of the systems' development and operation. In the current paper, we describe our experiences on the integration of the Modelica DSL into a platform that enables the integration and interoperability of model-based tools across the various phases of the system development process. Thereby, we present our approach, compare different tools which were used, in order to efficiently complete the integration, and finally exemplify the outcome on a case study from the automotive domain. &copy; 2014 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings - IEEE 38th Annual International Computers, Software and Applications Conference Workshops, COMPSACW 2014},
  key       = {Interoperability},
  keywords  = {Application programs;Computational linguistics;Computer programming languages;DSL;Integration;Modeling languages;Models;Problem oriented languages;XML;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/COMPSACW.2014.88},
}

@Article{20150500465603,
  author    = {Gibbs, Ivan and Dascalu, Sergiu and Harris, Frederick C.},
  title     = {A separation-based UI architecture with a DSL for role specialization},
  journal   = {Journal of Systems and Software},
  year      = {2015},
  volume    = {101},
  pages     = {69 - 85},
  note      = {Climate science;Code Generation;Development process;Development time;Domain specific languages;Model-driven Engineering;Related works;User experience;},
  abstract  = {This paper proposes an architecture and associated methodology to separate front end UI concerns from back end coding concerns to improve the platform flexibility, shorten the development time, and increase the productivity of developers. Typical UI development is heavily dependent upon the underlying platform, framework, or tool used to create it, which results in a number of problems. We took a separation-based UI architecture and modified it with a domain specific language to support the independence of UI creation thereby resolving some of the aforementioned problems. Amethodology incorporating this architecture into the development process is proposed. A climate science application was created to verify the validity of the methodology using modern practices of UX, DSLs, code generation, and model-driven engineering. Analyzing related work provides an overview of other methods similar to our method. Subsequently we evaluate the climate science application, conclude, and detail future work. &copy; 2014 Published by Elsevier Inc.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  issn      = {01641212},
  key       = {Climate models},
  keywords  = {Architecture;Computational linguistics;Computer programming languages;Problem oriented languages;Separation;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.jss.2014.11.039},
}

@InProceedings{20145100328971,
  author    = {Kuhn, Eva and Crass, Stefan and Hambock, Thomas},
  title     = {Approaching coordination in distributed embedded applications with the peer model DSL},
  year      = {2014},
  pages     = {64 - 68},
  address   = {Verona, Italy},
  note      = {Complex synchronization;Concurrent activities;Coordination strategy;Distributed embedded system;Domain specific languages;Embedded application;Embedded system softwares;Graphical documentation;},
  abstract  = {Coordination in distributed embedded systems requires complex synchronization of many concurrent activities. This task becomes especially difficult when network and system failures have to be assumed. The Peer Model is a novel programming model for the design of coordination strategies among multiple nodes, aiming to bridge design and implementation. A major advantage is that designs based on the Peer Model are very flexible regarding changing requirements and policies. The motivating use case is an application in the railway domain where embedded nodes detect approaching trains and route this information over several forwarder nodes to the level crossing. In this paper, we present a Domain Specific Language for the Peer Model which allows to automatically generate a graphical documentation and source code for different embedded platforms. It lays the foundations for an embedded system software development tool chain. We prove the feasibility by implementing an event notification strategy for the level crossing use case.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings - 40th Euromicro Conference Series on Software Engineering and Advanced Applications, SEAA 2014},
  key       = {Embedded systems},
  keywords  = {Application programs;Complex networks;Computer programming languages;Coordination reactions;Design;Problem oriented languages;Railroad crossings;Software design;Systems engineering;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/SEAA.2014.72},
}

@InProceedings{20140417234410,
  author    = {Miao, Yongwu and Samaka, Mohammed and Impagliazzo, John},
  title     = {Facilitating teachers in developing online PBL courses},
  year      = {2013},
  pages     = {454 - 459},
  address   = {Kuta, Indonesia},
  note      = {Course authoring;Domain-specific modeling language;IMS-LD;learning deisgn;Model driven architectures;PBL;},
  abstract  = {Developing a sound online problem-based learning (PBL) course plan is difficult because teachers need comprehensive PBL and technical knowledge. This paper proposes a model-driven approach to develop a PBL authoring tool that helps teachers create and customize online PBL course plans in a cost-effective and flexible manner. A pilot study was conducted to assess teacher acceptance of the tool. The results reveal that after a short training session, teachers understood the authoring tool and thought the tool was easy to use to develop online PBL course plans. &copy; 2013 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings of 2013 IEEE International Conference on Teaching, Assessment and Learning for Engineering, TALE 2013},
  key       = {E-learning},
  keywords  = {Curricula;Engineering education;Personnel training;Specification languages;Teaching;Tools;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/TALE.2013.6654481},
}


@inproceedings{20132216374606,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Composition of domain specific modeling languages: An exploratory study},
journal = {MODELSWARD 2013 - Proceedings of the 1st International Conference on Model-Driven Engineering and Software Development},
author = {Campos, Edmilson and Freire, Marilia and Kulesza, Uira and Bezerra, Adorilson and Aranha, Eduardo},
year = {2013},
pages = {149 - 156},
address = {Barcelona, Spain},
abstract = {This paper presents an exploratory study in the context of composition of domain-specific modeling languages (DSMLs). It aims evaluating a composition method using Ecore-based DSMLs based on xText tool. The study was performed applying the method to modelling a composition of DSMLs from the domain of controlled experiments in software engineering. The study consists of four different DSMLs, whose ultimate goal is to generate executable workflows for each experiment subject. The study results present: (i) new adaptations that can be incorporated into the method in order to enable its application to the xText context; and (ii) a brief comparison of the method application using xText and XML based approaches.},
key = {Experiments},
keywords = {Software design;Specification languages;},
note = {Composition method;Controlled experiment;Domain specific languages;Domain specific modeling languages;Domain-specific modeling language;Experimental software engineering;Exploratory studies;Model composition;},
} 


@inproceedings{20151100647520,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Quality assurance of textual models within eclipse using OCL and model transformations},
journal = {CEUR Workshop Proceedings},
author = {Arendt, Thorsten and Taentzer, Gabriele and Weber, Alexander},
volume = {1092},
year = {2013},
pages = {1 - 10},
issn = {16130073},
address = {Miami, FL, United states},
abstract = {Modern software development processes often use domainspecific modeling languages (DSMLs) combined with custom code generators and/or interpreters. Especially textual DSMLs as provided by Eclipse Xtext are becoming more and more popular. As a consequence, software quality assurance frequently leads back to quality assurance of the involved textual models. Here, various quality aspects have to be considered depending on the modeling purpose and domain. In this paper, we present a quality assurance tool set for textual models in Eclipse using several interrelated components like Xtext, EMF Refactor, Henshin and the OCL tools which are all based on the Eclipse Modeling Framework (EMF). The practicability and flexibility of this tool set are demonstrated by the design and implementation of a case study that is based on a textual modeling language for simple web applications named SWM (Simple Web Modeling Language).},
key = {Modeling languages},
keywords = {Computational linguistics;Computer software selection and evaluation;Embedded systems;Quality assurance;Social networking (online);Software design;Software engineering;Systems analysis;},
note = {Design and implementations;Domain-specific modeling language;Eclipse modeling framework;Interrelated components;Model based development;Quality assurance tools;Software development process;Software quality assurance;},
} 


@article{20144900276683,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Developing frameworks from extended feature models},
journal = {Advances in Intelligent Systems and Computing},
author = {Viana, Matheus and Penteado, Rosngela and do Prado, Antnio and Durelli, Rafael},
volume = {263},
year = {2014},
pages = {263 - 284},
issn = {21945357},
abstract = {Frameworks are composed of concrete and abstract classes implementing the functionality of a domain. Applications can reuse framework design and code to improve their quality and be developed more efficiently. However, framework development is a complex task, since it must be adaptable enough to be reused by several applications. In this chapter we present the From Features to Framework (F3) approach, which aims to facilitate the development of frameworks. This approach is divided in two steps: Domain Modeling, in which framework domain is defined in a extended feature model; and Framework Construction, in which the framework is designed and implemented by following a set of patterns from its feature model. Since these steps can be systematically applied, we also present the design of a tool that supports the use of the F3 approach on framework development. Moreover, we performed an experiment that showed that the F3 approach makes framework development easier and more efficient. &copy; Springer International Publishing Switzerland 2014.},
key = {Computer software reusability},
keywords = {Specification languages;},
note = {Domain model;Domain-specific modeling language;Extended feature models;Feature modeling;Framework;Framework designs;Framework development;Patterns;},
URL = {http://dx.doi.org/10.1007/978-3-319-04717-1_12},
} 


@inproceedings{20122115055169,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Using parameterized attributes to improve testing capabilities with domain-Specific Modeling Languages},
journal = {Proceedings - 2012 IEEE 19th International Conference and Workshops on Engineering of Computer-Based Systems, ECBS 2012},
author = {Hill, James H.},
year = {2012},
pages = {43 - 51},
address = {Novi Sad, Serbia},
abstract = {Domain-specific modeling languages (DSMLs) show promise in improving model-based testing and experimentation (TE) capabilities for software systems. This is because its intuitive graphical languages reduce complexities associated with error-prone, tedious, and time-consuming tasks. Despite the benefits of using DSMLs to facilitate model-based TE, it is hard for testers to capture many variations of similar tests without manually duplicating modeling effort. This paper therefore presents a method called parameterized attributes that is used to capture points-of-variation in models. It also shows how parameterized attributes is realized in an open-source tool named the Generic Modeling Environment (GME) Template Engine. Finally, this paper quantitatively evaluates applying parameterized attributes to TE of a representative distributed software system. Experience and results so show that parameterized attributes can reduce modeling effort after an initial model (or design) is constructed. &copy; 2012 IEEE.},
key = {Parameterization},
keywords = {Computer software;High level languages;Specification languages;},
note = {Distributed software system;Domain-specific modeling language;Error prones;Generic modeling;Graphical languages;Model based testing;Open source tools;Parameterized;Software systems;Template engines;Time-consuming tasks;},
URL = {http://dx.doi.org/10.1109/ECBS.2012.47},
} 

@Article{20120314686436,
  author    = {Hemingway, Graham and Neema, Himanshu and Nine, Harmon and Sztipanovits, Janos and Karsai, Gabor},
  title     = {Rapid synthesis of high-level architecture-based heterogeneous simulation: A model-based integration approach},
  journal   = {Simulation},
  year      = {2012},
  volume    = {88},
  number    = {2},
  pages     = {217 - 232},
  note      = {Distributed simulations;Domain-specific modeling language;Heterogeneous simulation;High level architecture;model-based integration;Multi paradigm modeling;},
  abstract  = {Virtual evaluation of complex command and control concepts demands the use of heterogeneous simulation environments. Development challenges include how to integrate multiple simulation engines with varying semantics and how to integrate simulation models and manage the complex interactions between them. While existing simulation frameworks may provide many of the required run-time services needed to coordinate among multiple simulation engines, they lack an overarching integration approach that connects and relates the interoperability of heterogeneous domain models and their interactions. This paper outlines some of the challenges encountered in developing a command and control simulation environment and discusses our use of the Generic Modeling Environment tool suite to create a model-based integration approach that allows for rapid synthesis of complex high-level architecture-based simulation environments. &copy; Simulation Councils Inc. 2011.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {00375497},
  key       = {Computer simulation},
  keywords  = {Architecture;Circuit simulation;Command and control systems;Computer simulation languages;Integration;Interoperability;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1177/0037549711401950},
}


@inproceedings{20124415619273,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Graph transformation concepts for meta-model evolution guaranteeing permanent type conformance throughout model migration},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Mantz, Florian and Jurack, Stefan and Taentzer, Gabriele},
volume = {7233 LNCS},
year = {2012},
pages = {3 - 18},
issn = {03029743},
address = {Budapest, Hungary},
abstract = {Meta-modeling has become the key technology to define domain-specific modeling languages for model-driven engineering. However, these modeling languages can change quite frequently which requires the evolution of their meta-models as well as the co-evolution (or migration) of their models. In this paper, we present an approach towards meta-model model co-evolution based on graph transformation concepts that targets to consider this challenge in a formal setting. Models are specified as graphs while model relations, especially type-instance relations, are defined by graph morphisms specifying type conformance of models to their meta-models. We present a basic approach to automatic deduction of model migrations from meta-model evolution steps which are specified by single transformation rules. Throughout that migration process, type conformance is ensured permanently. A first implementation is given using existing technology, namely the Eclipse Modeling Framework (EMF) and the EMF model transformation tool Henshin which is based on graph transformation concepts. Our evolution approach is presented at two small evolution scenarios for Petri nets and state machines. &copy; 2012 Springer-Verlag.},
key = {Mathematical models},
keywords = {Graph theory;Petri nets;Specification languages;},
note = {AS graph;Co-evolution;Domain-specific modeling language;Eclipse modeling framework;Formal setting;Graph morphisms;Graph Transformation;Henshin;Key technologies;Meta model;Metamodeling;Migration process;Model transformation;Model-driven Engineering;Modeling languages;State machine;Transformation rules;},
URL = {http://dx.doi.org/10.1007/978-3-642-34176-2_3},
} 


@article{20161202134980,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Ontological approach for DSL development},
journal = {Computer Languages, Systems and Structures},
author = {Pereira, Maria Joao Varanda and Fonseca, Joao and Henriques, Pedro Rangel},
volume = {45},
year = {2016},
pages = {35 - 52},
issn = {14778424},
abstract = {This paper presents a project whose main objective is to explore the ontological based development of Domain Specific Languages (DSL), more precisely, of their underlying Grammar. After reviewing the basic concepts characterizing Ontologies and DSLs, we introduce a tool, Onto2Gra, that takes profit of the knowledge described by the ontology and automatically generates a grammar for a DSL that allows to discourse about the domain described by that ontology. This approach represents a rigorous method to create, in a secure and effective way, a grammar for a new specialized language restricted to a concrete domain. The usual process of creating a grammar from the scratch is, as every creative action, difficult, slow and error prone; so this proposal is, from a grammar engineering point of view, of uttermost importance. After the grammar generation phase, the Grammar Engineer can manipulate it to add syntactic sugar to improve the final language quality or even to add specific semantic actions. The Onto2Gra project is composed of three engines. The main one is OWL2DSL, the component that converts an OWL ontology into a complete Attribute Grammar for the construction of an internal representation of all the input data. The two additional modules are Onto2OWL, converts ontologies written in OntoDL into standard OWL, and DDesc2OWL, converts domain instances written in the new DSL into the initial OWL ontology.},
key = {Ontology},
keywords = {Birds;Computational linguistics;Computer programming languages;DSL;Problem oriented languages;Semantics;},
note = {Attribute grammars;Domain specific languages;Grammar engineering;Grammars;Internal representation;Ontological approach;Problem domain;Specific semantics;},
URL = {http://dx.doi.org/10.1016/j.cl.2015.12.004},
} 

@Article{20145200366617,
  author    = {Freudenthal, Margus},
  title     = {Simpl DSL toolkit},
  journal   = {Science of Computer Programming},
  year      = {2015},
  volume    = {114},
  pages     = {85 - 91},
  note      = {Abstract Syntax Trees;Code Generation;Data type;Simpl DSL toolkit;Target language;Typechecking;},
  abstract  = {This paper describes LDTA tool challenge entry that is implemented using Simpl DSL toolkit. Simpl is targeted at enterprise software development, helping to create DSL implementations that can be embedded into other systems. Simpl builds up on top of existing tools and programming languages and adds: a simple language for grammar descriptions that can be used to generate both the parser and the data types for representing abstract syntax trees; a pretty-printing library; an IDE framework; and integration layer that combines all components into a single whole and minimizes the need for boilerplate code. When implementing the challenge, Simpl provided direct support for parsing and code generation tasks. Name and type checking were implemented in Scala. In addition to the challenge task, Simpl was used to create an Eclipse-based IDE for the target language. &copy; 2014 Elsevier B.V. All rights reserved.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {01676423},
  key       = {Abstract data types},
  keywords  = {Embedded systems;Enterprise software;Formal languages;Integrodifferential equations;Software design;Syntactics;Trees (mathematics);},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.scico.2014.11.018},
}


@inproceedings{20123015277503,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {DSL-based support for semi-automated architectural component model abstraction throughout the software lifecycle},
journal = {QoSA'12 - Proceedings of the 8th International ACM SIGSOFT Conference on the Quality of Software Architectures},
author = {Haitzer, Thomas and Zdun, Uwe},
year = {2012},
pages = {61 - 70},
address = {Bertinoro, Italy},
abstract = {In this paper we present an approach for supporting the semi-automated abstraction of architectural models throughout the software lifecycle. It addresses the problem that the design and the implementation of a software system often drift apart as software systems evolve, leading to architectural knowledge evaporation. Our approach provides concepts and tool support for the semi-automatic abstraction of architectural knowledge from implemented systems and keeping the abstracted architectural knowledge up-to-date. In particular, we propose architecture abstraction concepts that are supported through a domainspecific language (DSL). Our main focus is on providing architectural abstraction specifications in the DSL that only need to be changed, if the architecture changes, but can tolerate non-architectural changes in the underlying source code. The DSL and its tools support abstracting the source code into UML component models for describing the architecture. Once the software architect has defined an architectural abstraction in the DSL, we can automatically generate UML component models from the source code and check whether the architectural design constraints are fulfilled by the models. Our approach supports full traceability between source code elements and architectural abstractions, and allows software architects to compare different versions of the generated UML component model with each other. We evaluate our research results by studying the evolution of architectural abstractions in different consecutive versions and the execution times for five existing open source systems. Copyright &copy; 2012 ACM.},
key = {Open systems},
keywords = {Abstracting;Architectural design;Automation;Computer programming languages;Computer software;DSL;Life cycle;Software architecture;},
note = {Architectural abstraction;Architectural components;Model transformation;Software Evolution;UML;},
URL = {http://dx.doi.org/10.1145/2304696.2304709},
} 


@inproceedings{20140617279512,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Noise estimation in DSL systems using linear regression},
journal = {International Conference on Advanced Technologies for Communications},
author = {Farias, F.S. and Borges, G.S. and Monteiro, W.B. and Silva, D.L.L. and Costa, J.C.W.A.},
year = {2013},
pages = {291 - 294},
issn = {21621039},
address = {Ho Chi Minh, Viet nam},
abstract = {The Digital Subscriber Line (DSL) systems performance tightly depends on noise interference. The users (lines) in the binder create mutual interference (crosstalk), therefore decreasing the rates of all users. Crosstalk noise is more predominant in DSL and its major performance bottleneck is to limit high-speed data rate. This study proposes a new real-time monitoring methodology for noise estimation based on Management Information Base (MIB) metrics. Linear regression is used for fitting, in which input parameters are MIBs and the output is the estimated noise power. The results confirm the possibility of estimating noise with a general equation. Moreover, it is showing the result improvement if a Loop Topology Identification tool is used as prior knowledge. &copy; 2013 IEEE.},
key = {Telecommunication lines},
keywords = {Crosstalk;DSL;Estimation;Interactive computer systems;Linear regression;Monitoring;Real time systems;},
note = {backhaul;Digital subscriber line systems;Management information base;Mutual interference;Network measurement;Noise;Performance bottlenecks;Real time monitoring;},
URL = {http://dx.doi.org/10.1109/ATC.2013.6698124},
} 

@InProceedings{20121114843650,
  author    = {Ureche, Vlad and Rompf, Tiark and Sujeeth, Arvind and Chafi, Hassan and Odersky, Martin},
  title     = {StagedSAC: A case study in performance-oriented DSL development},
  year      = {2012},
  pages     = {73 - 82},
  address   = {Philadelphia, PA, United states},
  note      = {Array algorithms;Compiler optimizations;Domain specific languages;Functional semantics;High-level programming;Language features;Multidimensional arrays;Optimizing compilation;Parallel code;SAC;Single assignment C;Staging;},
  abstract  = {Domain-specific languages (DSLs) can bridge the gap between high-level programming and efficient execution. However, implementing compiler tool-chains for performance oriented DSLs requires significant effort. Recent research has produced methodologies and frameworks that promise to reduce this development effort by enabling quick transition from library-only, purely embedded DSLs to optimizing compilation. In this case study we report on our experience implementing a compiler for StagedSAC. StagedSAC is a DSL for arithmetic processing with multidimensional arrays modeled after the stand-alone language SAC (Single Assignment C). The main language feature of both SAC and StagedSAC is a loop construction that enables high-level and concise implementations of array algorithms. At the same time, the functional semantics of the two languages allow for advanced compiler optimizations and parallel code generation. We describe how we were able to quickly evolve from a pure library DSL to a performance-oriented compiler with a good speedup and only minor syntax changes using the technique of Lightweight Modular Staging. We also describe the optimizations we perform to obtain fast code and how we plan to generate parallel code with minimal effort using the Delite framework. Copyright &copy; 2012 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {07308566},
  journal   = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
  key       = {Program compilers},
  keywords  = {C (programming language);Computer programming languages;DSL;Optimization;Problem oriented languages;Research;Semantics;},
  language  = {English},
}


@inproceedings{20143918179796,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {DSL-based architecting and DSL-based architectures},
journal = {ACM International Conference Proceeding Series},
author = {Sobernig, Stefan and Strembeck, Mark},
year = {2014},
pages = {University of Vienna - },
address = {Vienna, Austria},
abstract = {The International Workshop on DSL Architecting and DSL-based Architectures (DADA'14) aims at exploring current perspectives on DSL architecting and on DSL-based architectures in research and industry. The workshop is co-located with the 8th European Conference on Software Architecture (ECSA'14) in Vienna, Austria. &copy; 2014 ACM.},
key = {Software architecture},
keywords = {Computer programming languages;DSL;Industrial research;},
note = {Co-located;Design decisions;Design documentation;Domain specific languages;International workshops;Vienna , Austria;},
URL = {http://dx.doi.org/10.1145/2642803.2642818},
} 


@article{20151000615120,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {On developing hybrid modeling methods using metamodeling platforms: A case of physical devices DSML based on ADOxx},
journal = {International Journal of Information System Modeling and Design},
author = {Zivkovic, Srdjan and Miksa, Krzystof and Kuhn, Harald},
volume = {6},
number = {1},
year = {2015},
pages = {47 - 66},
issn = {19478186},
abstract = {It has been acknowledged that model-based approaches and domain-specific modeling (DSM) languages, methods and tools are beneficial for the engineering of increasingly complex systems and software. Instead of general-purpose one-size-fits-all modeling languages, DSM methods facilitate model-based analysis and design of complex systems by providing modeling concepts tailored to the specific problem domain. Furthermore, hybrid DSM methods combine single DSM methods into integrated modeling methods, to allow for multi-perspective modeling. Metamodeling platforms provide flexible means for design and implementation of such hybrid modeling methods and appropriate domain-specific modeling tools. In this paper, we report on the conceptualization of a hybrid DSM method in the domain of network physical devices management, and its implementation based on the ADOxx metamodeling platform. The method introduces a hybrid modeling approach. A dedicated DSM language (DSML) is used to model the structure of physical devices and their configurations, whereas the formal language for knowledge representation OWL2 is used to specify configuration-related constraints. The outcome of the work is a hybrid, semantic technology-enabled DSM tool that allows for efficient and consistency-preserving model-based configuration of network equipment. Copyright &copy; 2015, IGI Global.},
key = {Modeling languages},
keywords = {Complex networks;Computational linguistics;Formal languages;Knowledge representation;Semantic Web;Semantics;},
note = {Domain specific modeling;Metamodeling;Model method;Modeling tool;Semantic technologies;},
URL = {http://dx.doi.org/10.4018/ijismd.2015010103},
} 

@InProceedings{20143918179800,
  author    = {Stevanetic, Srdjan and Haitzer, Thomas and Zdun, Uwe},
  title     = {Supporting software evolution by integrating DSL-based architectural abstraction and understandability related metrics},
  year      = {2014},
  pages     = {University of Vienna -},
  address   = {Vienna, Austria},
  note      = {Architectural Abstraction;Architectural components;Empirical evaluations;Software Evolution;Software metrics;Understandability;},
  abstract  = {Software architecture erosion and architectural drift are well known software evolution problems. While there exist a number of approaches to address these problems, so far in these approaches the understandability of the resulting architectural models (e.g., component models) is seldom studied. However, reduced understandability of the architectural models might lead to problems similar to architecture erosion and architectural drift. To address this problem, we propose to extend our existing DSL-based architecture abstraction approach with empirically evaluated understandability metrics. While the DSL-based architecture abstraction approach enables software architects to keep source code and architecture consistent, the understandability metrics extensions enables them, while working with the DSL, to continuously judge the understandability of the architectural component models they create with the DSL. We studied the applicability of our approach in a case study of an existing open source system. &copy; 2014 ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {ACM International Conference Proceeding Series},
  key       = {Open systems},
  keywords  = {Abstracting;DSL;Erosion;Open source software;Software architecture;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2642803.2642822},
}


@article{20121014836324,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Development of data acquisition systems by using a domain-specific modeling language},
journal = {Computers in Industry},
author = {Kos, Tomaz and Kosar, Tomaz and Mernik, Marjan},
volume = {63},
number = {3},
year = {2012},
pages = {181 - 192},
issn = {01663615},
abstract = {Data acquisition is the process of capturing and measuring physical data and then converting the results into a digital form that is further manipulated by a computer program. Within the industry, data acquisition systems (measurement systems) are used in a wide variety of fields, including product quality testing. Usually measuring systems are complicated devices, however newer data acquisition systems tend to be easier to use. As such, they open the door for the development of customized software, which can be easily manipulated, not only by programmers but also by domain experts, enabling them to understand and modify programs. Raising the level of abstraction, particularly with those programs that use visual models, can be an effective aid for domain experts, who are then able to model their programs on their own. This paper describes the design and use of a domain-specific modeling language called the Sequencer, integrated with the measuring equipment DEWESoft, which enables domain experts to model their own data acquisitions. Specifically, in this paper the Sequencer is exposed to: domain concepts identification, the construction of modeling notation, a connection with execution framework, and the end-users' point of view on the modeling tool. The use of the Sequencer will be presented on car brake tests. For this purpose, the Sequencer has already been successfully applied in the automotive industry. &copy; 2011 Elsevier B.V.},
key = {Specification languages},
keywords = {Data acquisition;Measurements;Problem oriented languages;},
note = {Brake tests;DEWESoft;Domain specific languages;Domain-specific modeling language;Measuring systems;Sequencer;},
URL = {http://dx.doi.org/10.1016/j.compind.2011.09.004},
} 

@InProceedings{20144600197675,
  author    = {Wang, Disi and Miao, Yongwu and Hoppe, H. Ulrich and Samaka, Mohammed},
  title     = {A domain-specific modeling language approach to support various forms of online PBL},
  year      = {2014},
  pages     = {611 - 613},
  address   = {Athens, Greece},
  note      = {Authoring tool;DSML;PBL;PBL script;Scripting languages;},
  abstract  = {Problem-based learning (PBL) can be organized and conducted in a variety of forms. By adopting a Domain-Specific Modeling Language (DSML) approach we have developed a PBL scripting language, which provides natural concepts that teachers can understand and use in practical PBL. Based on this PBL scripting language, a web-based PBL authoring tool has been developed, which enables teachers to develop their own PBL strategies as PBL scripts. &copy; 2014 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings - IEEE 14th International Conference on Advanced Learning Technologies, ICALT 2014},
  key       = {Teaching},
  keywords  = {Social networking (online);Specification languages;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ICALT.2014.178},
}


@article{20155201726740,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {DSML4CP: A Domain-specific Modeling Language for Concurrent Programming},
journal = {Computer Languages, Systems and Structures},
author = {Azadi Marand, Elaheh and Azadi Marand, Elham and Challenger, Moharram},
volume = {44},
year = {2015},
pages = {319 - 341},
issn = {14778424},
abstract = {Nowadays, concurrent programs are an inevitable part of many software applications. They can increase the computation performance of the applications by parallelizing their computations. One of the approaches to realize the concurrency is using multi thread programming. However, these systems are structurally complex considering the control of the parallelism (such as thread synchronization and resource control) and also considering the interaction between their components. So, the design of these systems can be difficult and their implementation can be error-prone especially when the addressed system is big and complex. On the other hand, a Domain-specific Modeling Language (DSML) is one of the Model Driven Development (MDD) approaches which tackles this problem. Since DSMLs provide a higher abstraction level, they can lead to reduce the complexities of the concurrent programs. With increasing the abstraction level and generating the artifacts automatically, the performance of developing the software (both in design and implementation phases) is increased, and the efficiency is raised by reducing the probability of occurring errors. Thus, in this paper, a DSML is proposed for concurrent programs, called DSML4CP, to work in a higher level of abstraction than code level. To this end, the concepts of concurrent programs and their relationships are presented in a metamodel. The proposed metamodel provides a context for defining abstract syntax, and concrete syntax of the DSML4CP. This new language is supported by a graphical modeling tool which can visualize different instance models for domain problems. In order to clarify the expressions of the language; the static semantic controls are realized in the form of constraints. Finally, the architectural code generation is fulfilled via model transformation rules using the templates of the concurrent programs. To increase level of the DSML's leverage and to demonstrate the general support of concurrent programming by the DSML, the transformation mechanism of the tool supports two well-known and highly used programming languages for code generation; Java and C#. The performed experiments on two case studies indicate a high performance for proposed language. In this regard, the results show automatic generation of 79% of the final code and 86% of the functions/modules on average. &copy; 2015 Elsevier Ltd. All rights reserved.},
key = {Concurrency control},
keywords = {Abstracting;Application programs;Automatic programming;Codes (symbols);Computational linguistics;Computer programming;Computer simulation languages;Embedded systems;Java programming language;Modeling languages;Network components;Problem oriented languages;Semantics;Specification languages;Syntactics;Visual languages;},
note = {Code Generation;Concurrent programming;Constraint control;Domain specific modeling languages;Meta model;},
URL = {http://dx.doi.org/10.1016/j.cl.2015.09.002},
} 

@InProceedings{20164402963055,
  author    = {Monthe, Valery M. and Nana, Laurent and Kouamou, Georges E. and Tangha, Claude},
  title     = {RsaML: A domain specific modeling language for describing robotic software architectures with integration of real-time properties},
  year      = {2016},
  volume    = {1697},
  address   = {Pittsburgh, PA, United states},
  note      = {Conceptual model;Domain specific modeling languages;Eclipse modeling framework;Level of abstraction;Real-time and embedded systems;Real-time properties;Robotic architectures;Robotic softwares;},
  abstract  = {This paper deals with the problem of expression and rep-resentation of robotics software architectures, at a level of abstraction high enough, and independent of the implemen-tation platform, taking into account real-time properties. It also addresses the problem of standard representation, communication between domain experts, and therefore that of reusability of these architectures. It presents RsaML (Robotic Software Architecture Modeling Language), a Do-main Specific Modeling Language (DSML) for robotics soft-ware architectures that we proposed in order to solve the problems mentioned above. The conceptual model defin-ing the terminology, and the hierarchy of concepts used for the description and representation of robotic architectures in RsaML are presented in this paper. RsaML is defined through a meta-model which represents the abstract syntax of the language. Real-time properties of robotics software architectures are identified and included in the meta model. The use of RsaML is illustrated through the definition of a robotic system and the description of its architecture with the help of the language. The support tool used for this work is the Eclipse Modeling Framework (EMF).},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {16130073},
  journal   = {CEUR Workshop Proceedings},
  key       = {Robotics},
  keywords  = {Computer architecture;Embedded systems;Modeling languages;Problem solving;Real time systems;Reusability;Software architecture;Specification languages;Visual languages;},
  language  = {English},
}


@inproceedings{20152100860906,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
copyright = {Compendex},
title = {Domain specific modeling language for object localization in marine observatories},
journal = {SENSORCOMM 2014 - 8th International Conference on Sensor Technologies and Applications},
author = {Aoun, Charbel Geryes and Alloush, Iyas and Kermarrec, Yvon and Zein, Oussama Kassem and Champeau, Joel},
year = {2014},
pages = {130 - 136},
address = {Lisbon, Portugal},
abstract = {Marine observatories (MO) based on sensor networks provide a continuous observation of the ocean. The logical and physical components that are used in these observatories provide data exchanged environment between different devices (Smart Sensor, Data Fusion). These components provide new functionalities or services due to the stable running of this network. In this paper, we present our approach in extending the modeling languages to include new domain-specific concepts and constraints. Thus, we propose a meta-model that is used to generate a new design tool (ArchiMO). We illustrate our proposal with an example from the MO domain. Additionally, we generate the corresponding simulation code using our selfdeveloped domain-specific model compiler. Our approach helps to reduce the complexity and time of the design activity. It provides a way to share the different viewpoints of the designers in the domain of MO. Copyright &copy; (2014) by International Academy.},
key = {Modeling languages},
keywords = {Complex networks;Computational linguistics;Data fusion;Electronic data interchange;Object recognition;Observatories;Sensor data fusion;Sensor networks;Specification languages;},
note = {Continuous observation;Design activity;Domain specific modeling;Domain specific modeling languages;Marine observatories;Object localization;Physical components;Underwater objects;},
} 

@Article{20161902348748,
  author    = {Weichhart, Georg and Guedria, Wided and Naudet, Yannick},
  title     = {Supporting interoperability in complex adaptive enterprise systems: A domain specific language approach},
  journal   = {Data and Knowledge Engineering},
  year      = {2016},
  volume    = {105},
  pages     = {90 - 106},
  note      = {Adaptive enterprise;Agent interaction protocols;Complex adaptive systems;Domain specific languages;Domain-specific language approaches;Enterprise interoperability;Scala;Software environments;},
  abstract  = {From a Complex Adaptive Systems (CAS) theory perspective a new approach for supporting Enterprise Interoperability (EI) is described. Particular needs informed by the theory are presented and a software environment supporting these requirements is proposed. The infrastructure aims at serving as a tool for solving problems in the EI domain, and includes a Domain Specific Language (DSL) supporting engineering interoperability solutions. The Ontology of Enterprise Interoperability (OoEI) provides the underlying conceptualisation of the Enterprise Interoperability (EI) domain and is used as basis. The DSL enhances the ontology with CAS related concepts. The CAS perspective provides a particular focus on dynamic aspects, which requires a new approach currently only addressed to a limited extend. The research interoperability infrastructure provides components to address the decentralised nature of a CAS by providing software agents and agent interaction protocols that facilitate the identification of interoperability problems and agent negotiations to find solutions. It is realised using the functional programming language Scala. &copy; 2016 Elsevier B.V.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  issn      = {0169023X},
  key       = {Interoperability},
  keywords  = {Adaptive systems;Computational linguistics;Computer programming languages;Functional programming;Multi agent systems;Problem oriented languages;Software agents;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.datak.2016.04.001},
}

@InProceedings{20130916066201,
  author    = {Franchi, Enrico},
  title     = {A domain specific language approach for agent-based social network modeling},
  year      = {2012},
  pages     = {607 - 612},
  address   = {Istanbul, Turkey},
  note      = {Agent based;Agent-based model;Agent-based modeling;Domain specific languages;Domain-specific language approaches;Political science;Research tools;Social Network Analysis;Social Networks;Software instruments;},
  abstract  = {Although in the past twenty years agent-based modeling has been widely adopted as a research tool in the fields of social and political sciences, there is lack of software instruments specifically created for social network simulations. Restricting the field of interest specifically to social network models and simulations instead of supporting general agent-based ones, allows for the creation of easier to use, more focused tools. In this work, we propose PyNetSYM, an agent-based modeling framework designed to be friendly to programmers and non-programmers alike. PyNetSYM provides a domain-specific language to specify social network simulations expressed as agent-based models. PyNetSYM was created to deal with large simulations and to work effortlessly with other social network analysis toolkits. &copy; 2012 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceedings of the 2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2012},
  key       = {Social networking (online)},
  keywords  = {Computational methods;Computer programming;Problem oriented languages;Social sciences computing;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/ASONAM.2012.102},
}

@InProceedings{20161202125998,
  author    = {Sporer, Harald},
  title     = {A model-based domain-specific language approach for the automotive E/E-System design},
  year      = {2015},
  pages     = {357 - 362},
  address   = {Prague, Czech republic},
  note      = {Automotive embedded systems;Development process;Domain specific languages;Domain specific modeling;Domain-specific language approaches;Enterprise architects;High-quality products;Software architectural;},
  abstract  = {The electrical and electronic systems (E/E-Systems) in the automotive world have been getting more and more complex over the past decades. New functionality, which is mainly realized through embedded E/E-Systems, as well as the growing connectivity (Car2X-Communication), will keep this trend alive in the upcoming years. Additionally, new standards and regulations have been released during the last years (e.g. ISO 26262), which leads to an even higher system complexity. Therefore, well-defined development processes are crucial to manage this complexity and achieve high quality products. To accomplish an appropriated guidance through these processes, a tool chain has to be established, which supports each phase of the E/E-System development. However, it isn't enough to provide a stand-alone solution for the assistance at each phase. A smooth transition of the development artefacts between the different levels as well as their bilateral traceability is crucial. Common approaches utilize tools like Enterprise Architect or Artisan Studio to model the E/E-System design in SysML or a kind of UML2 profile. Usually, several abstraction layers are designed with these tools, starting from the system architectural design down to the software architectural design. Although, in the majority of cases the design should represent a mechatronics-based system, the hardware as well as the mechanics view is not considered. The aim of this work is to remedy the deficiencies regarding the missing representation of hardware and mechanics artefacts within the E/E-System design. Therefore, a model-based domainspecific language was developed that describes the system in a more comprehensive way. Additionally, it makes it easier for domain experts, who are not that familiar with UML or SysML, to create an architectural design. Furthermore, the already existing SysML models are not ignored at the presented methodology, but supported through a translator, which converts the DSL model into a SysML representation. &copy; 2015 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {Todos A},
  journal   = {Proceeding of the 2015 Research in Adaptive and Convergent Systems, RACS 2015},
  key       = {Architectural design},
  keywords  = {Abstracting;Automobile electronic equipment;Computational linguistics;Computer programming languages;Design;Embedded systems;Hardware;Problem oriented languages;Reconfigurable hardware;},
  language  = {English},
  url       = {http://dx.doi.org/10.1145/2811411.2811533},
}

@InProceedings{20164302934714,
  author    = {Durelli, Gianluca C. and Spada, Fabrizio and Pilato, Christian and Santambrogio, Marco D.},
  title     = {Scala-based domain-specific language for creating accelerator-based SoCs},
  year      = {2016},
  volume    = {2016-August},
  pages     = {225 - 232},
  address   = {Chicago, IL, United states},
  note      = {Domain specific languages;Embedded application;Hardware components;Industrial standards;Processing elements;Specialized hardware;System level integration;System-on-chip architecture;},
  abstract  = {Nowadays, thanks to technology miniaturization and industrial standards, it is possible to create System-on-Chip (SoC) architectures featuring a combination of many components, like processor cores and specialized hardware accelerators. However, designing an SoC to accelerate an embedded application is particularly complex. After decomposing this application into tasks and assigning each of them to a processing element, the designer must create the required hardware components and integrate them into the final system. Currently, this process is not well supported by commercial tool flows and has to be manually performed. This is time consuming and error prone. This paper proposes a Domain-Specific Language (DSL) based on Scala to specify the architecture of accelerator-based SoCs. We leverage this DSL to coordinate commercial High-Level Synthesis (HLS) tools in order to create the corresponding accelerators with proper standard interfaces for system-level integration. &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  journal   = {Proceedings - IEEE 28th International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2014},
  key       = {System-on-chip},
  keywords  = {Computer programming languages;Distributed computer systems;Electron beam lithography;Hardware;High level synthesis;Masks;Problem oriented languages;Programmable logic controllers;Reconfigurable hardware;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/IPDPSW.2016.169},
}

@Article{20164502996560,
  author    = {Franky, Maria Consuelo and Pavlich-Mariscal, Jaime A. and Acero, Maria Catalina and Zambrano, Angee and Olarte, John C. and Camargo, Jorge and Pinzon, Nicolas},
  title     = {A practical experience of implementing a model driven environment in a software development organization},
  journal   = {International Journal of Web Information Systems},
  year      = {2016},
  volume    = {12},
  number    = {4},
  pages     = {533 - 556},
  note      = {Code Generation;Enterprise applications;Legacy component;Model-driven Engineering;Xtext;},
  abstract  = {Purpose - This purpose of this paper is to present ISML-MDE, a model-driven environment that includes ISML, a platform-independent modeling language for enterprise applications; ISML-GEN, a code generation framework to automatically generate code from models; and LionWizard, a tool to automatically integrate different components into a unified codebase. Design/methodology/approach - The development comprises five stages: standardizing architecture; refactoring and adapting existing components; automating their integration; developing a modeling language; and creating code generators. After development, model-to-code ratios in ISML-MDE are measured for different applications. Findings - The average model-to-code ratio is approximately 1:4.6 when using the code generators from arbitrary models. If a model transformation is performed previously to the code generation, this ratio raises to 1:115. The current validation efforts show that ISML properly supports several DSL essential characteristics described by Kahraman and Bilgen (2015). Research limitations/implications - ISML-MDE was tested on relatively small applications. Further validation of the approach requires measurement of development times and their comparison with previous similar projects, to determine the gains in productivity. Originality/value - The value of ISML-MDE can be summarized as follows: ISML-MDE has the potential to significantly reduce development times, because of an adequate use of models and transformations. The design of ISML-MDE addresses real-world development requirements, obtained from a tight interaction between the researchers and the software development company. The underlying process has been thoroughly documented and it is believed it can be used as a reference for future developments of MDE tools under similar conditions. &copy; Emerald Group Publishing Limited.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {A},
  issn      = {17440084},
  key       = {Software design},
  keywords  = {Codes (symbols);Modeling languages;Software engineering;Unified Modeling Language;},
  language  = {English},
  url       = {http://dx.doi.org/10.1108/IJWIS-04-2016-0025},
}

@InProceedings{20164603016499,
  author    = {Mora Segura, Angel and Pescador, Ana and De Lara, Juan and Wimmer, Manuel},
  title     = {An extensible meta-modelling assistant},
  year      = {2016},
  pages     = {79 - 88},
  address   = {Vienna, Austria},
  note      = {Domain specific languages;Heterogeneous data;Language engineering;Meta-modelling;Model transformation;Model-driven Engineering;Modelling environment;Process modelling;},
  abstract  = {Meta-models play a pivotal role in Model-Driven Engineering (MDE). They are used to create domain-specific models, and to type model management operations like model transformations or code generators. However, even though creating meta-models is a common activity, it is currently mostly a manual activity, which does not profit from existing knowledge. In order to facilitate the meta-modelling task, we propose an extensible meta-modelling assistant. While primarily focussed on helping in the creation of meta- models, it can also help in creating models. The assistant permits the provision of heterogeneous data description sources (like ontologies, RDF data, XML schemas, database schemas and meta-models), and enables their uniform querying. Different kinds of queries are supported, and improved through synonym search. Query results are prioritized through sense disambiguation, can be graphically visualized, and incorporated into the (meta-)model being built. The assistant has been realized within Eclipse, and its architecture has been designed to be independent of the meta-modelling technology used. As a proof- of-concept, we show its integration within DSL-tao, a pattern-based meta-modelling tool built by our group, and two other tools developed by third-parties. The usefulness of the system is illustrated with a running example in the process modelling domain. &copy; 2016 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {A},
  journal   = {Proceedings - 2016 IEEE 20th International Enterprise Distributed Object Computing Conference, EDOC 2016},
  key       = {Modeling languages},
  keywords  = {Computer programming languages;Models;Natural language processing systems;Problem oriented languages;Query processing;XML;},
  language  = {English},
  url       = {http://dx.doi.org/10.1109/EDOC.2016.7579377},
}

@Article{20164703029299,
  author    = {Bettini, Lorenzo},
  title     = {Implementing type systems for the IDE with Xsemantics},
  journal   = {Journal of Logical and Algebraic Methods in Programming},
  year      = {2016},
  volume    = {85},
  number    = {5},
  pages     = {655 - 680},
  note      = {Eclipse;Efficient implementation;Featherweight Java;Implementation;Implementation techniques;Lambda calculus;Operational semantics;Type systems;},
  abstract  = {Xsemantics is a DSL for writing type systems, reduction rules and, in general, relation rules for languages implemented in Xtext (Xtext is an Eclipse framework for rapidly building languages together with all the typical IDE tooling). Xsemantics aims at reducing the gap between the formalization of a language (i.e., type system and operational semantics) and the actual implementation in Xtext, since it uses a syntax that resembles the rules in a formal setting. In this paper we present the main features of Xsemantics for implementing type systems and reduction rules through examples (Featherweight Java and lambda calculus). We show how such implementations are close to the actual formalizations, and how Xsemantics can be a helpful tool when proving the type safety of a language. We also describe the new features of Xsemantics that help achieving a modular and efficient implementation of type systems. In particular, we focus on specific implementation techniques for implementing type systems that are suited for the IDE (in our context, Eclipse), in order to keep the tooling responsive and guarantee a good user experience. &copy; 2015 Elsevier Inc.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {F},
  issn      = {23522216},
  key       = {Java programming language},
  keywords  = {Calculations;Differentiation (calculus);Digital subscriber lines;DSL;Integrodifferential equations;Semantics;},
  language  = {English},
  url       = {http://dx.doi.org/10.1016/j.jlamp.2015.11.005},
}

@InProceedings{20164502992673,
  author    = {Solms, Fritz and Pieterse, Vreda},
  title     = {Towards a generic DSL for automated marking systems},
  year      = {2016},
  volume    = {642},
  pages     = {59 - 66},
  address   = {Cullinan, South africa},
  note      = {Automated assessment;Automatic assessment;Domain specific languages;Dynamic assessment;Learning opportunity;Programming assignments;Specific languages;Syntax;},
  abstract  = {The automated static and dynamic assessment of programs makes it practical to increase the learning opportunities of large student classes through the regular assessment of programming assignments. Automatic assessments are traditionally specified in tool-specific languages which are closely linked to the functionality and implementation of a particular tool. This paper considers existing specification languages for assessments and proposes a generic and extensible domain-specific language for the specification of programming assignment assessments. &copy; Springer International Publishing AG 2016.},
  copyright = {Compilation and indexing terms, Copyright 2016 Elsevier Inc.},
  groups    = {F},
  issn      = {18650929},
  journal   = {Communications in Computer and Information Science},
  key       = {Digital subscriber lines},
  keywords  = {Automation;Computer aided software engineering;Computer programming languages;DSL;Problem oriented languages;Software testing;Specification languages;Specifications;},
  language  = {English},
  url       = {http://dx.doi.org/10.1007/978-3-319-47680-3_6},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:Todos E\;0\;;
}
