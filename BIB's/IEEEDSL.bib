@INPROCEEDINGS{6405348, 
author={I. Macia and R. Arcoverde and E. Cirilo and A. Garcia and A. von Staa}, 
booktitle={Software Maintenance (ICSM), 2012 28th IEEE International Conference on}, 
title={Supporting the identification of architecturally-relevant code anomalies}, 
year={2012}, 
pages={662-665}, 
abstract={Code anomalies are likely to be critical to the systems' maintainability when they are related to architectural problems. Many tools have been developed to support the identification of code anomalies. However, those tools are restricted to only analyze source code structure and identify individual anomaly occurrences. These limitations are the main reasons why state-of-art tools are often unable to identify architecturally-relevant code anomalies, i.e. those related to architectural problems. To overcome these shortcomings we propose SCOOP, a tool that includes: (i) architecture-code traces in the analysis of the source code, and (ii) exploits relationships between multiple occurrences of code anomalies to detect the architecturally-relevant ones. Our preliminary evaluation indicated that SCOOP was able to detect anomalous code elements related to 293 out of 368 architectural problems found in 3 software systems.}, 
keywords={program diagnostics;software maintenance;SCOOP tool;architectural problem;architecturally-relevant code anomaly;code anomaly identification;software maintainability;software system;source code analysis;Computer architecture;Conferences;Couplings;DSL;Measurement;Software maintenance;Software systems;architectural problem;code anomaly;pattern}, 
doi={10.1109/ICSM.2012.6405348}, 
ISSN={1063-6773}, 
month={Sept},}
@INPROCEEDINGS{7377601, 
author={D. Kovacevic and M. Krunic and N. Cetic and J. Kovacevic}, 
booktitle={Telecommunications Forum Telfor (TELFOR), 2015 23rd}, 
title={Xtext-based eclipse editor for linker configuration file}, 
year={2015}, 
pages={862-865}, 
abstract={This paper presents implementation of the text editor for linker configuration files. The editor contains tools and options such as spell checker, autocomplete or syntax highlighting, etc. which facilitate development process. The solution contains a description of the syntax that should be used for writing configuration files which further determine the manner of interpretation and linking of object files. Xtext Eclipse framework has been used as development platform. Xtext provides very sophisticated, modern and practical API for describing and defining huge range of domain-specific languages. Syntax developed in Xtext is independent of Eclipse IDE and it can be used in any Java environment.}, 
keywords={Java;application program interfaces;program compilers;text analysis;API;IDE;Java environment;Xtext-based eclipse editor;autocomplete;domain-specific languages;integrated development component;linker configuration file;object files;spell checker;syntax description;syntax highlighting;DSL;Digital signal processing;Domain specific languages;Grammar;Java;Joining processes;Syntactics;Eclipse;Xtext;configuration;editor configuration files linker;grammar;linker;plugin;syntax}, 
doi={10.1109/TELFOR.2015.7377601}, 
month={Nov},}
@INPROCEEDINGS{7363638, 
author={J. Y. Mori and C. H. Llanos and M. Hüebner}, 
booktitle={Embedded and Ubiquitous Computing (EUC), 2015 IEEE 13th International Conference on}, 
title={A Framework to the Design and Programming of Many-Core Focal-Plane Vision Processors}, 
year={2015}, 
pages={193-198}, 
abstract={The Focal-Plane Image Processing area aims to bring processing elements as near as possible to the pixels and to the camera's focal-plane. Most of the works reported in the literature uses only simple processing elements, in general analog ones, with few flexibility. With the technology advances, a new generation of Vision Processors is emerging. It is expected that multi/many-core systems will be integrated to the pixel sensors, offering several opportunities for parallelism exploration, resulting in high performance and flexible processing systems. The programmability is one of the main problems in this area, since most programmers are not able to create parallel algorithms and applications. In this work, we propose a methodology to the design and programming of many-core focal-plane vision processors. The application is described using a Domain Specific Language, from which the parallelism characteristics are extracted. Afterwards, a new abstract model is derived using techniques such as Program Slicing (PS) and Task-Graph Clustering (TGC). The abstract model is then transformed in a SystemC/TLM2.0 description, in order to allow for different timing accuracy simulations. The results of the simulations are used together with an ASIP design tool in order to determine both the microarchitecture of processing elements and the communication structure of the new system. Finally, from the model derived before, a new source code is generated and programmed into the new platform. In this context, the main concepts and ideas are described in this work, as well as some partial results.}, 
keywords={graph theory;image processing;image sensors;multiprocessing systems;program slicing;ASIP design tool;SystemC/TLM2.0;domain specific language;focal-plane image processing;many-core focal-plane vision processor;multicore system;pixel sensor;program slicing;task-graph clustering;Analytical models;Arrays;Image processing;Parallel processing;Program processors;Programming;Real-Time;computer vision;embedded computing;focal-plane image processing;many-core architecture}, 
doi={10.1109/EUC.2015.24}, 
month={Oct},}
@INPROCEEDINGS{7306085, 
author={C. B. De Oliveira and R. Menotti and J. M. P. Cardoso and E. Marques}, 
booktitle={2015 Forum on Specification and Design Languages (FDL)}, 
title={A special-purpose language for implementing pipelined FPGA-based accelerators}, 
year={2015}, 
pages={1-8}, 
abstract={A common use for Field-Programmable Gate Arrays (FPGAs) is the implementation of hardware accelerators. A way of doing so is to specify the internal logic of such accelerators by using Hardware Description Languages (HDLs). However, HDLs rely on the expertise of developers and their knowledge about hardware development with FPGAs. Regarding this, efforts have been focused on developing High-level Synthesis (HLS) tools in an attempt to increase the overall abstraction level required for using FPGAs. However, the solutions presented by such tools are commonly considered inefficient in comparison to the ones achieved by a specialized hardware designer. An alternative solution to program FPGAs is the use of Domain- Specific Languages (DSLs), as they can provide higher abstraction levels than HDLs still allowing the developers to deal with specific issues leading to more efficient designs and not always covered by HLS tools. In this paper we present our recent work on a DSL named LALP (Language for Aggressive Loop Pipelining), which has been developed focusing on the development of FPGAbased, aggressively pipelined, hardware accelerators. We present the recent LALP extensions and the challenges we are facing regarding to the compilation of LALP to FPGAs.}, 
keywords={field programmable gate arrays;hardware description languages;pipeline processing;DSL;HDL;HLS tool;LALP;domain-specific language;field-programmable gate array;hardware description language;high-level synthesis tool;language for aggressive loop pipelining;pipelined FPGA-based accelerator;special-purpose language;Arrays;Clocks;Delays;Field programmable gate arrays;Hardware;Pipeline processing;Radiation detectors}, 
ISSN={1636-9874}, 
month={Sept},}
@ARTICLE{7432157, 
author={V. Oksman and R. Strobel and X. Wang and D. Wei and R. Verbin and R. Goodson and M. Sorbara}, 
journal={IEEE Communications Magazine}, 
title={The ITU-T's new G.fast standard brings DSL into the gigabit era}, 
year={2016}, 
volume={54}, 
number={3}, 
pages={118-126}, 
abstract={This article explores the recently issued ITU-T Recommendations specifying "G.fast" (G.9701 [1] and G.9700 [2]) that bring user bit rates up to 1 Gb/s over twisted pairs from the distribution point to customer premises. The overview and some key research challenges of G.fast are discussed in [3]. The standardized G.fast transmission method and advanced crosstalk cancellation techniques are presented here with specific performance projections and measurement results achieved during the first demonstrations and trials, showing bit rates of 500 Mb/s over 250 m and available reach up to 400 m. A description of standardized tools for dynamic performance maintenance, resource allocation, and power saving enhancing G.fast applications concludes this article.}, 
keywords={crosstalk;digital subscriber lines;resource allocation;DSL;G.fast transmission method;ITU-T Recommendations;advanced crosstalk cancellation techniques;dynamic performance maintenance;resource allocation;twisted pairs;Bit rate;Channel estimation;Crosstalk;DSL;ITU Standards;Robustness;Synchronization}, 
doi={10.1109/MCOM.2016.7432157}, 
ISSN={0163-6804}, 
month={March},}
@INPROCEEDINGS{7070443, 
author={V. Roussev}, 
booktitle={System Sciences (HICSS), 2015 48th Hawaii International Conference on}, 
title={Building a Forensic Computing Language}, 
year={2015}, 
pages={5228-5233}, 
abstract={The primary goal of this discussion is to motivate the need for the development of a domain-specific language (DSL) focused on the requirements of forensic and security analysis. We argue that, at present, there is no adequate mechanism that a) allows analysts to specify the forensic computation as a tool-agnostic, logical sequence of steps, b) provides a formal specification for tool developers, and c) seamlessly integrates different available tools to provides a complete and extensible solution. We present an initial design sketch for a forensic DSL called nugget, and use it to illustrate the ideas behind our approach.}, 
keywords={digital forensics;formal specification;specification languages;domain-specific language;forensic DSL;forensic computing language;formal specification;nugget;security analysis;Abstracts;Computers;DSL;Forensics;Runtime;digital forensics;dsl;nugget forensic computing language}, 
doi={10.1109/HICSS.2015.617}, 
ISSN={1530-1605}, 
month={Jan},}
@INPROCEEDINGS{6227234, 
author={D. Di Ruscio and P. Pelliccione and A. Pierantonio}, 
booktitle={2012 34th International Conference on Software Engineering (ICSE)}, 
title={EVOSS: A tool for managing the evolution of free and open source software systems}, 
year={2012}, 
pages={1415-1418}, 
abstract={Software systems increasingly require to deal with continuous evolution. In this paper we present the EVOSS tool that has been defined to support the upgrade of free and open source software systems. EVOSS is composed of a simulator and of a fault detector component. The simulator is able to predict failures before they can affect the real system. The fault detector component has been defined to discover inconsistencies in the system configuration model. EVOSS improves the state of the art of current tools, which are able to predict a very limited set of upgrade faults, while they leave a wide range of faults unpredicted.}, 
keywords={configuration management;public domain software;software fault tolerance;software maintenance;software management;EVOSS tool;evolution management;fault detector component;free and open source software systems;simulator component;system configuration model;upgrade fault prediction;Analytical models;DSL;Fault detection;Linux;Open source software;Tagging;Configuration management and deployment;Model-driven software engineering;Software evolution;Tools and environments}, 
doi={10.1109/ICSE.2012.6227234}, 
ISSN={0270-5257}, 
month={June},}
@INPROCEEDINGS{6729768, 
author={C. Şenbalcı and S. Altuntaş and Z. Bozkus and T. Arsan}, 
booktitle={2013 High Capacity Optical Networks and Emerging/Enabling Technologies}, 
title={Big data platform development with a domain specific language for telecom industries}, 
year={2013}, 
pages={116-120}, 
abstract={This paper introduces a system that offer a special big data analysis platform with Domain Specific Language for telecom industries. This platform has three main parts that suggests a new kind of domain specific system for processing and visualization of large data files for telecom organizations. These parts are Domain Specific Language (DSL), Parallel Processing/Analyzing Platform for Big Data and an Integrated Result Viewer. In addition to these main parts, Distributed File Descriptor (DFD) is designed for passing information between these modules and organizing communication. To find out benefits of this domain specific solution, standard framework of big data concept is examined carefully. Big data concept has special infrastructure and tools to perform for data storing, processing, analyzing operations. This infrastructure can be grouped as four different parts, these are infrastructure, programming models, high performance schema free databases, and processing-analyzing. Although there are lots of advantages of Big Data concept, it is still very difficult to manage these systems for many enterprises. Therefore, this study suggest a new higher level language, called as DSL which helps enterprises to process big data without writing any complex low level traditional parallel processing codes, a new kind of result viewer and this paper also presents a Big Data solution system that is called Petaminer.}, 
keywords={data analysis;parallel databases;parallel languages;telecommunication computing;DFD;DSL;Domain Specific Language;big data platform development;data analyzing operations;data processing;data storing operation;distributed file descriptor;higher level language;parallel processing codes;parallel processing/analyzing platform;telecom industry;DSL;Data handling;Data storage systems;Information management;Telecommunications;Web sites;Writing;Big Data Analysis;Domain Specific Language;Parallel Processing and Analyzing}, 
doi={10.1109/HONET.2013.6729768}, 
ISSN={1949-4092}, 
month={Dec},}
@INPROCEEDINGS{7117975, 
author={Y. Korenkov and I. Loginov and A. Lazdin}, 
booktitle={2015 17th Conference of Open Innovations Association (FRUCT)}, 
title={PEG-based language workbench}, 
year={2015}, 
pages={75-81}, 
abstract={In this article we present a new tool for language-oriented programming which provides to user convenient means to describe the domain specific languages in the form of language based on parsing expression grammars and helpful tools for grammar debugging. Also we consider the sample of using this toolkit as a part of an integrated development environment.}, 
keywords={grammars;program debugging;programming environments;specification languages;PEG-based language workbench;domain specific languages;grammar debugging;integrated development environment;language-oriented programming tool;parsing expression grammars;toolkit;DSL;Domain specific languages;Grammar;Object oriented modeling;Programming;Syntactics}, 
doi={10.1109/FRUCT.2015.7117975}, 
ISSN={2305-7254}, 
month={April},}
@INPROCEEDINGS{6486028, 
author={D. Adolf and E. Ferranti and S. Koch}, 
booktitle={Smart Grid Communications (SmartGridComm), 2012 IEEE Third International Conference on}, 
title={SmartScript - a domain-specific language for appliance control in Smart Grids}, 
year={2012}, 
pages={465-470}, 
abstract={This paper describes an auto-configuring agent based software architecture connecting appliances, smart meters, solar panels, and a KNX building automation system, resulting in a complete demand-side smart grid. The agents are responsible for providing access to all datapoints in the system as well as sending commands to the active components. To control the system, a domain-specific language (DSL) called SmartScript was developed, whose benefits are twofold. The first one is to provide users, experts in electrical engineering and/or building automation but not in software systems, with a high level tool which they can use to control a demand-side smart grid. The second benefit is to provide a layer to implement and test quickly and effectively energy-aware algorithms without having to deal with all the underlying connections. Finally, some demo applications created using SmartScript (i.e., smartphone interface, voice-controlled building automation system) are presented in this work, in order to give an example of how SmartScript can be used.}, 
keywords={building management systems;demand side management;home automation;smart meters;smart phones;smart power grids;software agents;software architecture;solar cells;specification languages;DSL;KNX building automation system;SmartScript;appliance control;autoconfiguring agent-based software architecture;demand side smart grid control;domain-specific language;electrical engineering;energy-aware algorithms;smart meters;smartphone interface;solar panels;voice-controlled building automation system;Automation;Buildings;Home appliances;Protocols;Smart grids;Software;Software architecture}, 
doi={10.1109/SmartGridComm.2012.6486028}, 
month={Nov},}
@INPROCEEDINGS{6840004, 
author={O. D. Ramos-Cantor and M. Lossow and H. Droste and G. Kadel and M. Pesavento}, 
booktitle={WTC 2014; World Telecommunications Congress 2014; Proceedings of}, 
title={A Network Simulation Tool for User Traffic Modeling and Quality of Experience Analysis in a Hybrid Access Architecture}, 
year={2014}, 
pages={1-6}, 
abstract={A Hybrid Access Architecture, where network users can be simultaneously served by different technologies, has been envisioned in order to increase the achievable data rates and enhance the user experience. This proposed access is promising to users where the costs of replacing existing technology are unmanageable and the complementary technology is underused. In order to understand the implications of a Hybrid Access between Digital Subscriber Line (DSL) and Long Term Evolution (LTE) in Downlink (DL) operation, a Network Simulation Tool has been developed, where the services demanded by the users are defined and modeled. Additionally, the Traffic and QoE Simulator (TQoES) establishes an algorithm to select the kind of access to be used by specific services, and reliably simulates the behavior of users within an LTE network based on 3GPP recommendations.}, 
month={June},}
@INPROCEEDINGS{6462290, 
author={F. Alhosban and L. Burd}, 
booktitle={2012 Frontiers in Education Conference Proceedings}, 
title={Aural instruction with visualization in E-Learning}, 
year={2012}, 
pages={1-6}, 
abstract={This research investigates the effectiveness of using aural instructions together with visualisation in teaching some concepts of data structures to novice computer science students. A prototype learning system, known as the Data Structure Learning (DSL) tool, was developed and used first in a short mini study that showed that, used together with visualisations of algorithms, aural instructions produced faster student response times than did textual instructions. This result suggested that the additional use of the auditory sensory channel did indeed reduce the cognitive load. The tool was then used in a second, longitudinal, study over two academic terms in which students studying the Data Structures module were offered the opportunity to use the DSL approach with either aural or textual instructions. Both the quantitative data provided by the automatic recording of DSL use and an end-of-study questionnaire showed appreciation by students of the help the tool had provided and enthusiasm for its future use and development. These findings were supported by qualitative data provided by student written feedback at the end of each task, by interviews at the end of the experiment and by interest from the lecturer in integrating use of the tool with the teaching of the module.}, 
keywords={computer aided instruction;computer science education;data structures;data visualisation;DSL tool;auditory sensory channel;aural instruction;cognitive load;computer science student;data structure learning;e-learning;prototype learning system;teaching;textual instruction;visualization;DSL;Data structures;Data visualization;Electronic learning;Interviews;Visualization;Aural Instructions;Cognitive Load;Computer Science Learning;Data Structure Learning Tool;Visualization}, 
doi={10.1109/FIE.2012.6462290}, 
ISSN={0190-5848}, 
month={Oct},}
@INPROCEEDINGS{6399719, 
author={S. Schivo and J. Scholma and B. Wanders and R. A. U. Camacho and P. E. van der Vet and M. Karperien and R. Langerak and J. van de Pol and J. N. Post}, 
booktitle={Bioinformatics Bioengineering (BIBE), 2012 IEEE 12th International Conference on}, 
title={Modelling biological pathway dynamics with Timed Automata}, 
year={2012}, 
pages={447-453}, 
abstract={When analysing complex interaction networks occurring in biological cells, a biologist needs computational support in order to understand the effects of signalling molecules (e.g. growth factors, drugs). ANIMO (Analysis of Networks with Interactive MOdelling) is a tool that allows the user to create and explore executable models of biological networks, helping to derive hypotheses and to plan wet-lab experiments. The tool is based on the formalism of Timed Automata, which can be analysed via the UPPAAL model checker. Thanks to Timed Automata, we can provide a formal semantics for the domain-specific language used to represent signalling networks. This enforces precision and uniformity in the definition of signalling pathways, contributing to the integration of signalling event models into complex, crosstalk-driven networks. We propose an approach to discretization of reaction kinetics that allows us to efficiently use UPPAAL as the computational engine to explore the dynamic cell behaviour. A user friendly interface makes the use of Timed Automata completely transparent to the biologist, while keeping the expressive power intact. This allows to define relatively simple, yet faithful models of complex biological interactions. The resulting timed behaviour is displayed graphically, allowing for an intuitive and interactive modelling experience.}, 
keywords={bioinformatics;cellular biophysics;complex networks;drugs;finite automata;formal languages;formal verification;human computer interaction;molecular biophysics;reaction kinetics;ANIMO;UPPAAL model checker;analysis of networks with interactive modelling;biological cells;biological pathway dynamic modelling;complex biological interaction network analysis;computational engine;crosstalk-driven networks;domain-specific language;drugs;dynamic cell behaviour;formal semantics;growth factors;reaction kinetic discretization;signalling event model;signalling molecules;signalling network representation;signalling pathway;timed automata formalism;user friendly interface;wet-lab experiments;Analytical models;Automata;Biological system modeling;Computational modeling;Data models;Kinetic theory;dynamic behaviour;modelling;signalling pathway;timed automata}, 
doi={10.1109/BIBE.2012.6399719}, 
month={Nov},}
@INPROCEEDINGS{6569751, 
author={A. M. Törsel}, 
booktitle={2013 IEEE Sixth International Conference on Software Testing, Verification and Validation}, 
title={A Testing Tool for Web Applications Using a Domain-Specific Modelling Language and the NuSMV Model Checker}, 
year={2013}, 
pages={383-390}, 
abstract={Test case generation from formal models using model checking software is an established method. This paper presents a model-based testing approach for web applications based on a domain-specific language model. It is shown how the domain-specific language is transformed into the input language of the NuSMV model checker and how the resulting traces are converted into executable test scripts for various test automation tools. The presented approach has been implemented with comprehensive automation in a research tool which architecture is outlined.}, 
keywords={Internet;automatic programming;formal verification;program testing;specification languages;NuSMV model checker software;Web applications;domain-specific modelling language;executable test scripts;model-based testing approach;test automation tools;test case generation;Adaptation models;Automation;DSL;Model checking;Software;Web pages;model checking;model-based testing;test automation;web applications}, 
doi={10.1109/ICST.2013.54}, 
ISSN={2159-4848}, 
month={March},}
@INPROCEEDINGS{7005365, 
author={B. Butzin and F. Golatowski and C. Niedermeier and N. Vicari and E. Wuchner}, 
booktitle={Proceedings of the 2014 IEEE Emerging Technology and Factory Automation (ETFA)}, 
title={A model based development approach for building automation systems}, 
year={2014}, 
pages={1-6}, 
abstract={As of today, building automation systems are present in almost any commercial building. They perform climate control, lightning control, access control, surveillance, and quite a few other tasks. As a result of their evolutionary development, building automation systems are divided into separate silos of disciplines that are not well integrated with each other. As of today, a variety of communication protocols, data models and engineering approaches are used by different vendors. Existing standardized building automation protocols as BACnet or KNX allow integration of some disciplines on the communication level but fail to provide means for common description of devices, services and data on the semantic level. This means that building automation applications that span multiple disciplines require a high effort for development, engineering and maintenance. If devices from multiple vendors are integrated in one installation, a set of different engineering tools and vendor-specific knowledge is required. In the ITEA “Building as a Service” (BaaS) project we try to overcome these deficiencies and define a common way to develop, engineer, commission, operate and maintain building automation systems following a service oriented approach. The whole process will be supported by semantic models to reduce costs and time-to-market, which is a quite new approach. In this paper we will present the current state of the work with special regard to domain modeling and model driven processes that are currently being specified for the BaaS platform.}, 
keywords={authorisation;building management systems;data models;lightning;protocols;service-oriented architecture;BACnet;BaaS platform;ITEA BaaS project;KNX;access control;building as a service;building automation applications;building automation systems;climate control;commercial building;communication protocols;data models;evolutionary development;lightning control;model based development approach;standardized building automation protocols;surveillance;Building automation;Data models;Domain specific languages;Ontologies;Protocols;Semantics;building automation;data model;domain specific language;semantic model;service oriented architecture}, 
doi={10.1109/ETFA.2014.7005365}, 
ISSN={1946-0740}, 
month={Sept},}
@INPROCEEDINGS{6462650, 
author={S. Creff and J. Champeau and A. Monégier and J. M. Jézéquel}, 
booktitle={2012 19th Asia-Pacific Software Engineering Conference}, 
title={Relationships Formalization for Model-Based Product Lines}, 
year={2012}, 
volume={1}, 
pages={158-163}, 
abstract={Model-Based Engineering (MBE) and Product Line Engineering (PLE) have been combined, to handle new system development constraints like: increasing complexity, higher product quality and cost reduction. Many authors have pointed out the need of modularization in the variability and in the core assets space. Existing approaches focus on separating and delimiting concerns or providing generic composition mechanisms. In Model-Based Product Lines, with an increasing number of models to manage, organizing the modeling space becomes central to support product line consistency, maintenance and product derivation process. To organize the modeling space, we propose to precisely describe the dependencies among modeling artifacts and clarify their use. Thus, we introduce the Product Line Modeling Space (PLiMoS) language that specializes relationships, based on an intentional framework, for the product line domain. The Domain Specific Language (DSL) provides a solution to model the modeling space and preserves independence with the product line tooling.}, 
keywords={cost reduction;product development;software cost estimation;software maintenance;software quality;software reusability;specification languages;DSL;Domain Specific Language;MBE;PLE;PLiMoS language;cost reduction;generic composition mechanism;maintenance;model-based engineering;model-based product lines;modeling artifact;product derivation process;product line consistency;product line domain;product line engineering;product line modeling space;product line tooling;product quality;relationships formalization;system development constraint;Abstracts;Complexity theory;Context;Context modeling;Principal component analysis;Software;Unified modeling language;DSL;Feature Models;Intentional Relations;MBE;Modeling Space;PLE;Relationships}, 
doi={10.1109/APSEC.2012.127}, 
ISSN={1530-1362}, 
month={Dec},}
@INPROCEEDINGS{6617336, 
booktitle={Live Programming (LIVE), 2013 1st International Workshop on}, 
title={Contents}, 
year={2013}, 
pages={1-1}, 
abstract={The following topics are dealt with: live mashup tools; live coding; live development environment; live logic programming; cyberphysical programming; live DSL environments; and sound improvisation.}, 
keywords={cybernetics;interactive programming;logic programming;music;cyberphysical programming;live DSL environments;live coding;live development environment;live logic programming;live mashup tools;sound improvisation}, 
doi={10.1109/LIVE.2013.6617336}, 
month={May},}
@INPROCEEDINGS{7128889, 
author={N. Visic and H. G. Fill and R. A. Buchmann and D. Karagiannis}, 
booktitle={2015 IEEE 9th International Conference on Research Challenges in Information Science (RCIS)}, 
title={A domain-specific language for modeling method definition: From requirements to grammar}, 
year={2015}, 
pages={286-297}, 
abstract={The core process a modeling method engineer needs to accomplish starts with the acquisition of domain knowledge and requirements, and ends with the deployment of a usable modeling tool. In between, a key intermediate deliverable of this process is the modeling method specification which, ideally, should be platform independent. On one hand, it takes input from a structured understanding of the application domain and scenarios; on the other hand, it provides sufficiently structured input to support the implementation of tool support for modeling activities. It is quite common that such modeling methods are domain-specific, in the sense that they provide concepts from the domain as “first-class modeling citizens”. However, for the purposes of this paper, we raise the level of abstraction for “domain specificity” and consider “modeling method engineering” as the application domain. Consequently, we raise several research questions - whether a domain-specific language can support this domain, and what would be its requirements, properties, constructs and grammar. We propose an initial draft of such a language - one that abstracts away from meta-modeling platforms by establishing a meta2 layer of abstraction where a modeling method can be defined in a declarative manner, then the final modeling tool is generated by automated compilation of the method definition for the meta-modeling environment of choice.}, 
keywords={formal specification;grammars;knowledge based systems;domain knowledge;domain specificity;domain-specific language;grammar;metamodeling platform;modeling method engineering;modeling method specification;Analytical models;Computational modeling;DSL;Domain specific languages;Metamodeling;Semantics;Unified modeling language;domain-specific language;meta-modeling;modeling method;modeling tool}, 
doi={10.1109/RCIS.2015.7128889}, 
ISSN={2151-1349}, 
month={May},}
@INPROCEEDINGS{6645668, 
author={G. Milosavljević and M. Filipović and V. Marsenić and D. Pejaković and I. Dejanović}, 
booktitle={Intelligent Software Methodologies, Tools and Techniques (SoMeT), 2013 IEEE 12th International Conference on}, 
title={Kroki: A mockup-based tool for participatory development of business applications}, 
year={2013}, 
pages={235-242}, 
abstract={This paper presents Kroki (fr. croquis - sketch), a tool for participatory development of business applications based on mockups. Kroki provides a graphical editor for visual creation of mockups and two engines (Web and desktop) for mockup execution. Kroki is developed in order to foster development agility, communication and better understanding of end-user needs. The mockup editor and engines are based on our EUIS (Enterprise User Interface Specification) DSL for specifying user interfaces of business applications.}, 
keywords={business data processing;graphical user interfaces;search engines;EUIS DSL;Kroki tool;Web engine;business application development;desktop engine;development agility;end-user needs;enterprise user interface specification;graphical editor;mockup editor;mockup execution;mockup visual creation;mockup-based tool;Business;Cities and towns;Navigation;Unified modeling language}, 
doi={10.1109/SoMeT.2013.6645668}, 
month={Sept},}
@INPROCEEDINGS{7459436, 
author={S. Ma and Z. Aklah and D. Andrews}, 
booktitle={2016 Design, Automation Test in Europe Conference Exhibition (DATE)}, 
title={Run time interpretation for creating custom accelerators}, 
year={2016}, 
pages={900-905}, 
abstract={Despite the significant advancements that have been made in High Level Synthesis, the reconfigurable computing community has not yet managed to achieve a wide-spread use of Field Programmable Gate Arrays (FPGAs) by programmers. Existing barriers that prevent programmers from using FPGAs include the need to work within vendor specific CAD tools, knowledge of hardware programming models, and the requirement to pass each design through a very time-consuming synthesis, place and route process. In this paper we present a new approach that takes these barriers out of the design flows for programmers. We move synthesis out of the programmers path and instead rely on composing pre-synthesized building blocks using a domain-specific language that supports programming patterns tailored to FPGA accelerators. Our results show that the achieved performance of run time assembling accelerators is equivalent to synthesizing a custom block of hardware using automated HLS tools.}, 
keywords={field programmable gate arrays;high level synthesis;specification languages;CAD tool;FPGA;HLS;building block synthesis;custom accelerator;design flow;domain-specific language;field programmable gate array;high level synthesis;run time interpretation;DSL;Field programmable gate arrays;Hardware;Integrated circuit interconnections;Program processors;Programming;Switches}, 
month={March},}
@INPROCEEDINGS{7510564, 
author={J. Deantoni}, 
booktitle={2016 Architecture-Centric Virtual Integration (ACVI)}, 
title={Modeling the Behavioral Semantics of Heterogeneous Languages and their Coordination}, 
year={2016}, 
pages={12-18}, 
abstract={In the software and system modeling community, research on domain-specific modeling languages (DSMLs) is focused on providing technologies for developing languages and tools that allow domain experts to develop system solutions efficiently. Unfortunately, the current lack of support for explicitly relating concepts expressed in different DSMLs makes it very difficult for software and system engineers to reason about information spread across models describing different system aspects. As a particular challenge, we present in this paper how we dealt with relationships between heterogeneous behavioral models to support their concurrent and coordinated execution. This was achieved by providing dedicated meta-language to define the behavioral semantics of DSMLs and their coordination. The approach made explicit a formal model of the control flow (MoCC); domain-specific actions (DSA) and a well-defined protocol between them (incl., mapping, feedback and callback) reified through explicit domain-specific events (DSE). The protocol is then used to infer a relevant behavioral language interface for specifying coordination patterns to be applied on conforming executable models. As a result, heterogeneous languages and their relationships can be developed in the GEMOC studio, which provides extensive support to run and debug heterogeneous models. This is outlined in the paper on the definition of the Marked Graph language and its coordination with a scenario language.}, 
keywords={formal verification;programming language semantics;DSA;DSE;DSML;GEMOC studio;behavioral language interface;behavioral semantics;callback task;concurrent execution;coordinated execution;coordination patterns;domain-specific modeling languages;domain-specifications;explicit domain-specific events;feedback task;formal MoCC;formal model-of-the-control flow;heterogeneous behavioral semantics modeling;heterogeneous languages;heterogeneous model debugging;heterogeneous model run;mapping task;marked graph language;meta-language;system modeling community;Concurrent computing;Context;DSL;Metamodeling;Semantics;Software;Syntactics;behavioral semantics;concurrency theory;coordination;heterogeneous modeling;model of computation;simulation}, 
doi={10.1109/ACVI.2016.9}, 
month={April},}
@INPROCEEDINGS{7018445, 
author={X. Zhu and C. Phung and L. Pareto and S. Ehnebom and M. Krekola and M. Christerson and M. Helander}, 
booktitle={Model-Driven Engineering and Software Development (MODELSWARD), 2014 2nd International Conference on}, 
title={An industrial case study on using language workbench technology for realizing Model-Driven Engineering}, 
year={2014}, 
pages={17-29}, 
abstract={Model Driven Engineering (MDE) is a proven approach to improve software development processes by automation. However, traditional development of MDE tooling requires a high upfront cost. Recent developments in language workbench technologies promise to significantly reduce these investment costs. By providing domain experts with targeted projections, the speed and quality of delivering customer value is improved. This paper provides results from an industrial case study in the telecommunications domain and compares the value of using a language workbench to traditional MDE technologies. Evaluation of the approach was based on qualitative research strategy which involved a proof of concept implementation and effort estimations by tooling experts. Our results, using the Intentional Domain Workbench, indicate that applying a language workbench promises significant improvements in several aspects of MDE based software development. Most notably in this paper: (1) improved speed in development of domain specific tooling and (2) improved speed in software development process re-engineering.}, 
keywords={software tools;Intentional Domain Workbench;MDE based software development;Model-Driven Engineering;customer value;domain specific tooling;language workbench technology;software development process re-engineering;Abstracts;Adaptation models;DSL;Interviews;Software;Telecommunications;Unified modeling language;Domain-Specific Languages;Language Workbench;Model-Driven Engineering;Projectional Editor;Software Interface Development}, 
month={Jan},}
@INPROCEEDINGS{7515417, 
author={I. Portugal and P. Alencar and D. Cowan}, 
booktitle={2016 IEEE International Conference on Software Science, Technology and Engineering (SWSTE)}, 
title={A Preliminary Survey on Domain-Specific Languages for Machine Learning in Big Data}, 
year={2016}, 
pages={108-110}, 
abstract={The proliferation of data often called Big Data has created problems with traditional approaches to data capture, storage, analysis and visualization, thus opening up new areas of research. Machine Learning algorithms are one area that has been used in Big Data for analysis. However, because of the challenges Big Data imposes, these algorithms need to be adapted and optimized to specific applications. One important decision made by software engineers is the choice of the language that is used in the implementation of these algorithms. This literature survey identifies and describes domain-specific languages and frameworks used for Machine Learning in Big Data with the intention of assisting software engineers in making more informed choices and providing beginners with an overview of the main languages used in this domain. This is the first survey that aims at better understanding how domain-specific languages for Machine Learning are used as a tool for research in Big Data.}, 
keywords={Big Data;learning (artificial intelligence);specification languages;Big Data;data analysis;data capture;data proliferation;data storage;data visualization;domain-specific languages;machine learning;Big data;Computational modeling;DSL;Domain specific languages;Machine learning algorithms;Programming;Software;BD;Big Data;DSL;ML;Machine Learning;domain-specific languages;literature survey}, 
doi={10.1109/SWSTE.2016.23}, 
month={June},}
@INPROCEEDINGS{6694495, 
author={K. Falkner and V. Chiprianov and N. Falkner and C. Szabo and G. Puddy}, 
booktitle={Military Communications and Information Systems Conference (MilCIS), 2013}, 
title={Modeling scenarios for the performance prediction of distributed real-time embedded systems}, 
year={2013}, 
pages={1-6}, 
abstract={Autonomous defence systems are typically characterized by hard constraints on space, weight and power. These constraints have a strong impact on the non-functional properties and especially performance of the final system. System execution modelling tools permit early prediction of the performance of model driven systems; however they are intended for one shot analysis, not for repeatable, interactive use. In this paper we propose a Domain Specific Language for describing scenarios to repeatedly test a system execution model within a Synthetic Environment. We exemplify it by describing and executing a scenario involving an UAV and a CMS.}, 
keywords={autonomous aerial vehicles;defence industry;distributed programming;embedded systems;military computing;CMS;UAV;autonomous defence systems;distributed real-time embedded systems;domain specific language;model driven systems;system execution modelling;Analytical models;Data models;Engines;Hardware;Middleware;Predictive models;Unified modeling language;formatting;insert;style;styling}, 
doi={10.1109/MilCIS.2013.6694495}, 
month={Nov},}
@INPROCEEDINGS{6849709, 
author={G. S. Ouedraogo and M. Gautier and O. Sentieys}, 
booktitle={2014 9th International Conference on Cognitive Radio Oriented Wireless Networks and Communications (CROWNCOM)}, 
title={Frame-based modeling for automatic synthesis of FPGA-Software Defined Radio}, 
year={2014}, 
pages={341-346}, 
abstract={Software Defined Radio (SDR) is now becoming a ubiquitous concept to describe and implement Physical Layers (PHYs) of wireless systems. Moreover, even though the FPGA is expected to play a key role in SDR, describing a PHY at the Register-Transfer-Level (RTL) requires tremendous efforts. This paper introduces a novel methodology to rapidly implement PHYs for SDR. The work relies upon High-Level Synthesis tools and dataflow modeling in order to infer an efficient RTL control unit for the application. The proposed software-based over-layer partly handles the complexity of programming an FPGA and integrates reconfigurable features. It consists essentially of a Domain-Specific Language (DSL) combined to a DSL-Compiler. An IEEE 802.11a transceiver has been explored via this approach in order to show the flexibility features.}, 
keywords={field programmable gate arrays;program compilers;radio transceivers;software radio;specification languages;wireless LAN;DSL-compiler;FPGA-software defined radio;IEEE 802.11a transceiver;PHY;RTL control unit;SDR;dataflow modeling;domain-specific language;frame-based modeling;high-level synthesis tools;physical layers;register-transfer-level;DSL;Encoding;Field programmable gate arrays;Physical layer;Receivers;Software;Synchronization}, 
doi={10.4108/icst.crowncom.2014.255289}, 
ISSN={2166-5370}, 
month={June},}
@INPROCEEDINGS{6196521, 
author={J. Barateiro and J. Borbinha}, 
booktitle={2012 16th IEEE Mediterranean Electrotechnical Conference}, 
title={Managing risk data: From spreadsheets to information systems}, 
year={2012}, 
pages={673-676}, 
abstract={The goal of Risk Management is to define prevention and control mechanisms to address the risks attached to specific activities and valuable assets. Many Risk Management efforts operate in silos with narrowly focused, functionally driven, and disjointed activities. That fact leads to a fragmented view of risks, where each activity uses its own language, customs and metrics. That limits an organization-wide perception of risks, where interdependent risks are not anticipated, controlled or managed. The lack of integrated solutions to manage risk information, lead the experts to use spreadsheets as their main tool, impeding collaboration, communication and reuse of risk information. In order to address these issues, this paper presents a solution that integrates a Risk Management framework, including a XML-based Domain Specific Language for Risk Management. The proposed framework is supported by an information system to manage the definition or risks.}, 
keywords={XML;management information systems;risk management;spreadsheet programs;XML-based domain specific language;information systems;interdependent risks;risk control mechanisms;risk data management;risk information reusage;risk prevention mechanisms;silos;spreadsheets;Computer architecture;Information systems;Organizations;Risk management;Unified modeling language;XML}, 
doi={10.1109/MELCON.2012.6196521}, 
ISSN={2158-8473}, 
month={March},}
@INPROCEEDINGS{7522164, 
author={J. Opiła}, 
booktitle={2016 39th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)}, 
title={Prototyping of visualization designs of 3D vector fields using POVRay rendering engine}, 
year={2016}, 
pages={343-348}, 
abstract={There is a persistent quest for novel methods of visualization in order to get insight into complex phenomena in variety of scientific domains. Researchers, ex. VTK team, achieved excellent results; however, some problems connected with implementation of new techniques and quality of the final images still persist. Results of inspection of number of visualization styles of 3D vector field employing POVRay ray-tracing engine are discussed, i.e. hedgehogs, oriented glyphs, streamlines, isosurface component approach and texturing design. All styles presented have been tested using water molecule model and compared concerning computing time, informativeness and general appearance. It is shown in the work that Scene Description Language (SDL), domain specific language implemented in POVRay is flexible enough to use it as a tool for fast prototyping of novel and exploratory visualization techniques. Visualizations discussed in the paper were computed using selected components of API of ScPovPlot3D, i.e. templates written in the SDL language. Results are compared to designs already implemented in VTK.}, 
keywords={data visualisation;ray tracing;rendering (computer graphics);vectors;3D vector field;API;POVRay rendering engine;ScPovPlot3D;domain specific language;exploratory visualization;hedgehogs;isosurface component approach;oriented glyph;ray-tracing engine;scene description language;streamlines;texturing design;visualization design prototyping;Data visualization;Electrostatics;Engines;Extraterrestrial measurements;Libraries;Three-dimensional displays;Visualization;POVRay;ScPovPlot3D;VTK;vector field visualization;visual data analysis}, 
doi={10.1109/MIPRO.2016.7522164}, 
month={May},}
@INPROCEEDINGS{7502813, 
author={F. A. Lopes and L. Lima and M. Santos and R. Fidalgo and S. Fernandes}, 
booktitle={NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium}, 
title={High-level modeling and application validation for SDN}, 
year={2016}, 
pages={197-205}, 
abstract={Software-Defined Networking (SDN) enables applications running on its control plane. The Northbound API allows programmers to develop SDN applications for a number of policy-based network management tasks. However, there is still a clear need for supporting the development of controller-agnostic modeled applications. In this paper, we show how the Model-Driven Networking (MDN), a framework composed of CASE tool and Domain-Specific Modeling Language (DSML), can be a feasible solution to create applications independent from controllers and to enable proper verification of SDN applications. Our evaluation demonstrates that MDN framework is viable for using in real scenarios and independent from SDN controllers. Moreover, our performance tests show that: (i) MDN's code generation is two times faster than other approaches; and (ii) it can validate several constraints and complex topologies at millisecond-timescale.}, 
keywords={programming languages;software defined networking;CASE tool;DSML;MDN;SDN application;application validation;controller-agnostic modeled application;domain-specific modeling language;high-level modeling;model-driven networking;network topology;northbound API;policy-based network management task;software-defined networking;Computer aided software engineering;Computer languages;DSL;Network topology;Programming;Software;Topology;CASE;Domain-Specific Modeling Language;MDN;Software-Defined Networking;application;framework}, 
doi={10.1109/NOMS.2016.7502813}, 
month={April},}
@INPROCEEDINGS{7733727, 
author={S. Kchir and S. Dhouib and J. Tatibouet and B. Gradoussoff and M. Da Silva Simoes}, 
booktitle={2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA)}, 
title={RobotML for industrial robots: Design and simulation of manipulation scenarios}, 
year={2016}, 
pages={1-8}, 
abstract={Robotic systems are a typical example of complex systems. Their design involves a combination of different technologies, requiring a multi-disciplinary approach. This is particularly challenging when a robotic system is required to interact either with humans or other entities within its environment. To tackle this complexity, we propose a design and validation approach based on MDE (Model-Driven Engineering) principles for industrial manipulators. We propose an extension of RobotML for manipulation, a modelling environment based on the Papyrus tool, which was developed specifically for the robotics domain. The extension is aiming to model a complete robotic setting, including protagonists, objects, their properties, the interactions between them, the services provided by the robots, and the actions they can perform. Then we propose to use model execution techniques to validate the design models. We illustrate our approach on a robotic scenario dedicated to the Sybot collaborative robot.}, 
keywords={DSL;Mobile communication;Robot kinematics;Service robots;Trajectory;Unified modeling language}, 
doi={10.1109/ETFA.2016.7733727}, 
month={Sept},}
@INPROCEEDINGS{7464551, 
author={A. Caracciolo and M. Lungu and O. Truffer and K. Levitin and O. Nierstrasz}, 
booktitle={2016 7th International Workshop on Empirical Software Engineering in Practice (IWESEP)}, 
title={Evaluating an Architecture Conformance Monitoring Solution}, 
year={2016}, 
pages={41-44}, 
abstract={Architectural rules are often defined but rarely tested. Current tools offer limited functionality and often require significant effort to be configured, automated and integrated within existing platforms. We propose a platform that is aimed at reducing the overall cost of setting up and maintaining an architectural conformance monitoring environment by decoupling the conceptual representation of a user-defined rule from its technical specification prescribed by the underlying analysis tools. The user is no longer expected to encode her constraints according to the syntax of the chosen tool, but can use a simple high-level DSL that is automatically compiled to an executable specification through custom adapters developed to support the interaction with existing off-the-shelf tools. In this paper we analyze three case studies to show how this approach can be successfully adopted to support truly diverse industrial projects. By discussing qualitative aspects of the approach, we investigate limitations and opportunities for improving general quality assessment solutions in general and DSL-based conformance tools in particular.}, 
keywords={conformance testing;formal specification;monitoring;software architecture;architectural rules;architecture conformance monitoring;conceptual representation;conformance tools;high-level DSL;technical specification;user-defined rule;Context;DSL;Electronic mail;Maintenance engineering;Monitoring;Organizations;Quality assessment;architecture conformance checking;empirical;evaluation}, 
doi={10.1109/IWESEP.2016.12}, 
month={March},}
@INPROCEEDINGS{6569750, 
author={A. Calvagna and A. Gargantini and P. Vavassori}, 
booktitle={2013 IEEE Sixth International Conference on Software Testing, Verification and Validation}, 
title={Combinatorial Interaction Testing with CITLAB}, 
year={2013}, 
pages={376-382}, 
abstract={In this paper the CITLAB tool for Combinatorial Interaction Testing is presented. The tool allows importing/exporting models of combinatorial problems from/to different application domains, by means of a common interchange syntax notation and a corresponding interoperable semantic metamodel. Moreover, the tool is a framework allowing embedding and transparent invocation of multiple, different implementations of combinatorial algorithms. CITLAB has been designed tightly integrated with the Eclipse IDE framework, by means of its plug-in extension mechanism. It is intended to easy the spread of CIT testing both in industrial practice and in academic research, by allowing users and researchers to apply multiple test suite generation algorithms, each with its peculiarities, on the same problem models, and let them compare the results in order to select the one that best fits their needs, while alleviating from the pain of knowing all the different details and notations of the underlying CIT tools.}, 
keywords={combinatorial mathematics;interactive systems;open systems;testing;CITLAB tool;Eclipse IDE framework;combinatorial interaction testing;importing/exporting models;interchange syntax notation;interoperable semantic metamodel;multiple test suite generation algorithms;transparent invocation;Algorithm design and analysis;Biological system modeling;Generators;Grammar;Semantics;Syntactics;Testing;Combinatorial testing model;Eclipse;XTEXT;domain-specific language}, 
doi={10.1109/ICST.2013.53}, 
ISSN={2159-4848}, 
month={March},}
@INPROCEEDINGS{7522035, 
author={L. Bettini and P. Crescenzi}, 
booktitle={2015 10th International Joint Conference on Software Technologies (ICSOFT)}, 
title={Java-meets eclipse: An IDE for teaching Java following the object-later approach}, 
year={2015}, 
volume={2}, 
pages={1-12}, 
abstract={In this paper, we introduce a new Eclipse-based IDE for teaching Java following the object-later approach. In particular, this IDE allows the programmer to write code in Java-, a smaller version of the Java language that does not include object-oriented features. For the implementation of this language we used Xtext, an Eclipse framework for implementing Domain Specific Languages; besides the compiler mechanisms, Xtext also allows to easily implement all the IDE tooling mechanisms in Eclipse. By using Xtext we were able to provide an implementation of Java - with all the powerful features available when using an IDE like Eclipse (including debugging, automatic building, and project wizards). With our implementation, it is also straightforward to create self-assessment exercises for students, which are integrated in Eclipse and JUnit.}, 
keywords={Java;computer aided instruction;computer science education;Eclipse-based IDE;JUnit;Java language;Java teaching;Xtext;compiler mechanism;domain specific language;object-later approach;Complexity theory;Education;Graphical user interfaces;Java;Programming profession;Syntactics;DSL;EMF;Eclipse;IDE;Java;Xtext}, 
month={July},}
@INPROCEEDINGS{6257291, 
author={O. Krasts and A. Kleins and A. Teilans}, 
booktitle={Digital Information Processing and Communications (ICDIPC), 2012 Second International Conference on}, 
title={Domain specific language for securities settlement systems}, 
year={2012}, 
pages={80-83}, 
abstract={Actual problems during design, implementation and maintenance of securities settlement systems software are achieving complementarity of several different, connected, asynchronously communicating settlement systems and verification of this complementarity. The aim of this paper is to create domain specific language for modeling of settlement systems and their interactions. Then use models to calculate settlement systems behavior. Specific of settlement systems requires that they perform accordingly to business rules in any situation. This makes use of model checking a very desirable step in development process of settlement systems. Defining a domain specific language and creating editor supporting it is a first step to enable use of model checking techniques. Created models also can be used as input for other analysis methods and tools, for example, basis path testing, simulation and as base for deriving test cases.}, 
keywords={financial data processing;formal verification;securities trading;specification languages;asynchronously communicating settlement systems;business rules;domain specific language;model checking;securities settlement systems software;settlement systems behavior;Analytical models;Biological system modeling;Business;Computational modeling;Domain specific languages;Educational institutions;Unified modeling language;modeling;validatioan;verification}, 
doi={10.1109/ICDIPC.2012.6257291}, 
month={July},}
@INPROCEEDINGS{6718341, 
author={N. George and D. Novo and T. Rompf and M. Odersky and P. Ienne}, 
booktitle={Field-Programmable Technology (FPT), 2013 International Conference on}, 
title={Making domain-specific hardware synthesis tools cost-efficient}, 
year={2013}, 
pages={120-127}, 
abstract={Tools to design hardware at a high level of abstraction promise software-like productivity for hardware designs. Among them, tools like Spiral, HDL Coder, Optimus and MMAlpha target specific application domains and produce highly efficient implementations from high-level input specifications in a Domain Specific Language (DSL). But, developing similar domain-specific High-Level Synthesis (HLS) tools need enormous effort, which might offset their many advantages. In this paper, we propose a novel, cost-effective approach to develop domain-specific HLS tools. We develop the HLS tool by embedding its input DSL in Scala and using Lightweight Modular Staging (LMS), a compiler framework written in Scala, to perform optimizations at different abstraction levels. For example, to optimize computation on matrices, some optimizations are more effective when the program is represented at the level of matrices while others are better applied at the level of individual matrix elements. To illustrate the proposed approach, we create an HLS flow to automatically generate efficient hardware implementations of matrix expressions described in our own high-level specification language. Although a simple example, it shows how easy it is to reuse modules across different HLS flows and to integrate our flow with existing tools like LegUp, a C-to-RTL compiler, and FloPoCo, an arithmetic core generator. The results reveal that our approach can simultaneously achieve high productivity and design quality with a very reasonable tool development effort.}, 
keywords={circuit CAD;digital arithmetic;field programmable gate arrays;high level synthesis;matrix algebra;program compilers;specification languages;C-to-RTL compiler;DSL;FPGA;FloPoCo;HDL coder;HLS;LMS;LegUp;MMAlpha;Optimus;Scala;Spiral;arithmetic core generator;compiler framework;cost-efficiency;design quality;domain specific language;domain-specific hardware synthesis tools;domain-specific high-level synthesis tools;hardware design;hardware designs;high abstraction level;high-level specification language;lightweight modular staging;matrix computation optimizations;matrix expressions;software-like productivity;Adders;DSL;Generators;Hardware;Least squares approximations;Matrices;Optimization}, 
doi={10.1109/FPT.2013.6718341}, 
month={Dec},}
@INPROCEEDINGS{6979145, 
author={G. Watney and L. J. Reder and T. Canham}, 
booktitle={Space Mission Challenges for Information Technology (SMC-IT), 2014 IEEE International Conference on}, 
title={Modeling for Partitioned and Multi-core Flight Software Systems: (Instrument Software Framework)}, 
year={2014}, 
pages={54-61}, 
abstract={This paper presents an approach for modeling component based flight software systems that can be deployed to a wide variety of hardware and operating system configurations. Our focus is deployment to multiple ARINC653 partitions, however, the technique is effective across multiple processors as well. The modeling technique presented is two tiered: first software components are represented in System Modeling Language (SysML) utilizing an off-the-shelf Magic Draw Computer Aided Software Engineering (CASE) tool. A custom plug in is used to produce domain specific XML. Secondly, a Python code generator is used to map the domain specific XML to implementation C++ code. To facilitate the technique a new lite-weight component framework called the Instrument Software Framework (ISF) was developed. Component based software architectures have been shown to improve the quality of flight software systems. The modeling approach using SysML, XML and the ISF is explained. Separation of concerns of the deployment target environment from the component implementation are demonstrated by our technique. The ISF architecture will be described along with an essential Hub Component Design Pattern that enables swappable communication mediums between computing elements.}, 
keywords={C++ language;XML;aerospace computing;computer aided software engineering;multiprocessing systems;operating systems (computers);program compilers;software quality;ARINC653 partitions;C++ code;CASE tool;ISF architecture;Instrument Software Framework;MagicDraw computer aided software engineering tool;Python code generator;SysML;component based flight software systems;component based software architectures;component implementation;custom plugin;domain specific XML;flight software systems;hardware system configurations;hub component design pattern;lite-weight component framework;multicore flight software systems;multiple processors;operating system configurations;swappable communication mediums;system modeling language;target environment;Computational modeling;Instruments;Message systems;Ports (Computers);Software;Topology;XML;Domain Specific Language;Instrument Software Framework (ISF);SysML;flight software;modeling;partitions}, 
doi={10.1109/SMC-IT.2014.15}, 
month={Sept},}
@INPROCEEDINGS{7233083, 
author={H. Chanti and L. Thiry and M. Hassenforder and E. Blanchard and P. Fromy}, 
booktitle={Control, Engineering Information Technology (CEIT), 2015 3rd International Conference on}, 
title={Fire safety DSL based algebra}, 
year={2015}, 
pages={1-6}, 
abstract={A complex system as the one evaluating the fire safety level, generally need the intervention of several specialists. Each one uses his own languages and own tools. To model such a system, several specific languages are needed and must be formalized and then integrated. This kind of systems can have irreversible consequences because of the human involving. To make a system sure - by the proof - the specification and composition of models/languages must be formally described and based on mathematical foundations. In this context, the paper proposes to use a formal approach based on algebraic specifications to model, formalize and compose the specific languages needed to evaluate the fire safety level in buildings.}, 
keywords={algebraic specification;civil engineering computing;fires;safety;specification languages;Domain Specific Language;algebraic specifications;buildings;fire safety DSL;fire safety level;formal approach;Algebra;DSL;Mathematical model;Safety;Semantics;Transforms;Unified modeling language;Domain Specific Language (DSL);algebra;fire safety;formal languages}, 
doi={10.1109/CEIT.2015.7233083}, 
month={May},}
@INPROCEEDINGS{7289142, 
author={Z. Aouini and A. Kortebi and Y. Ghamri-Doudane}, 
booktitle={2015 International Wireless Communications and Mobile Computing Conference (IWCMC)}, 
title={Traffic monitoring in home networks: Enhancing diagnosis and performance tracking}, 
year={2015}, 
pages={545-550}, 
abstract={Home network complexity is dramatically growing in terms of topology (devices and connectivity technologies) and services leading to increasingly challenging management issues. In this context, enabling a better visibility of home network traffic usage and performance is a crucial step to provide efficient self-care and customer care. In this paper, we study home network traffic monitoring architectural approaches. In particular, we study the feasibility of a Home Gateway based flow monitoring approach, which will allow enhancing home network diagnostic and performance tracking. Our experimental evaluation aims at providing a better understanding of deployment possibilities and limits. The obtained experimental results, based on an open source tool, are promising in terms of resource consumption (an average load of 6,6% and 18MB for CPU and memory respectively ) as well as bandwidth utilization (average 156 Kbps) for typical DSL access speed scenario.}, 
keywords={home networks;internetworking;telecommunication traffic;DSL access speed scenario;bandwidth utilization;customer care;home gateway based flow monitoring approach;home network complexity;home network diagnostic;home network traffic monitoring architectural approaches;home network traffic usage;open source tool;performance tracking;resource consumption;self-care;Computer architecture;Home automation;Logic gates;Monitoring;Network topology;Performance evaluation;Topology;Home network monitoring;experimental test bed;passive measurements},
doi={10.1109/IWCMC.2015.7289142}, 
ISSN={2376-6492}, 
month={Aug},}
@INPROCEEDINGS{6363292, 
author={H. Nakamura and R. Nagano and K. Hisazumi and Y. Kamei and N. Ubayashi and A. Fukuda}, 
booktitle={Empirical Software Engineering in Practice (IWESEP), 2012 Fourth International Workshop on}, 
title={QORAL: An External Domain-Specific Language for Mining Software Repositories}, 
year={2012}, 
pages={23-29}, 
abstract={The mining software repositories (MSR) field integrates and analyzes data stored in repositories such as source control and bug repositories to provide support to practitioners. In order to provide useful information to practitioners, MSR researchers need to perform tasks iteratively, these tasks include extracting data from repositories, transforming them into specific data formats, and loading them into the statistical analysis tool. These tasks require a significant amount of man hours to implement and execute according to the requirements of the researchers. This paper proposes an external domain-specific language (DSL) called QORAL to facilitate the performance of multiple iterations and environment development. The results from a questionnaire used to evaluate QORAL indicate that it is easy to understand and modify source code.}, 
keywords={configuration management;data analysis;data mining;program debugging;software engineering;DSL;MSR;QORAL;bug repository;bug tracking system;data analysis;data extraction;data format;data integration;environment development;external domain-specific language;multiple iteration;software repository mining;source code modification;source control;statistical analysis tool;version control system;DSL;Data mining;Grammar;Libraries;Loading;Measurement;Software;DSL;MSR;QORAL}, 
doi={10.1109/IWESEP.2012.20}, 
month={Oct},}
@INPROCEEDINGS{7302512, 
author={S. Vinogradov and A. Ozhigin and D. Ratiu}, 
booktitle={Systems Engineering (ISSE), 2015 IEEE International Symposium on}, 
title={Modern model-based development approach for embedded systems practical experience}, 
year={2015}, 
pages={56-59}, 
abstract={Control functionality of modern rail vehicles is getting more and more complex. It contains several modules such as the traction control unit or the central control unit, as well as input and output stations, such as driver's cab terminals and process I/Os. A plethora of devices are connected to the vehicle and train bus and are able to communicate. The functions of the vehicle control and traction systems are configured by using function blocks from which loadable programs are generated. The languages used to program the control units are well established in the field. However, one-size-fits-all approach cannot adequately address the increased complexity of the software in modern trains. In this paper we describe our preliminary experience with using the multi-paradigm modeling tool “mbeddr” in the railway domain. The following aspects have been in focus during the work: (a) matching the application requirements and domain specific language used for implementation; (b) integration of model-based approach into traditional product lifecycle; (c) reengineering existing functionality using modeling and code generation capabilities of mbeddr. The system example we chose was the application logic of automated train driving system implemented in development environment of Siemens process automation framework.}, 
keywords={embedded systems;rail traffic control;traction;I/O process;Siemens process automation framework;application logic;application requirements;automated train driving system;central control unit;code generation capabilities;domain specific language;driver cab terminals;embedded systems;function blocks;input stations;loadable programs;mbeddr tool;model-based approach;model-based development approach;modeling capabilities;multiparadigm modeling tool;output stations;product lifecycle;rail vehicle control functionality;railway domain;reengineering;traction control unit;traction systems;train bus;vehicle bus;Complexity theory;Control systems;Domain specific languages;Formal verification;Mathematical model;Rail transportation;Software;language engineering;model based development}, 
doi={10.1109/SysEng.2015.7302512}, 
month={Sept},}
@INPROCEEDINGS{7323094, 
author={G. Kövesdán and M. Asztalos and L. Lengyel}, 
booktitle={Model-Driven Engineering and Software Development (MODELSWARD), 2015 3rd International Conference on}, 
title={Aggregate Callback: A design pattern for flexible and robust runtime model building}, 
year={2015}, 
pages={149-156}, 
abstract={In modern software engineering environments, tools that use Domain-Specific Languages (DSLs) are often applied. The usual workflow of such tools is that the textual input written in the DSL is parsed and a semantic model is instantiated. This model is later passed to another software component that processes it, e.g. a model transformation, a code generator or a simulator. Building the semantic model inside the parser is often a complex task. The model must be built in such a way that the constraints of the problem domain are enforced so that the consistency of the output is guaranteed. This paper presents a design pattern, referred as Aggregate Callback that supports enforcing constraints in the model and thus helps creating correct models. We have found that the Aggregate Callback pattern is useful for tool developers that build models in their applications.}, 
keywords={program compilers;software engineering;DSL;aggregate callback pattern;code generation;domain-specific languages;robust runtime model building;semantic model;software engineering environments;Aggregates;Concrete;Context modeling;DSL;Generators;Robustness;Software;Agility;Code Generation;Design Pattern;Domain-Specific Modeling;Model Transformation;Modeling}, 
month={Feb},}
@INPROCEEDINGS{7134025, 
author={O. Günalp and C. Escoffier and P. Lalanda}, 
booktitle={Pervasive Computing and Communication Workshops (PerCom Workshops), 2015 IEEE International Conference on}, 
title={Demo abstract: Reproducible deployment of pervasive applications}, 
year={2015}, 
pages={211-213}, 
abstract={Pervasive systems present stringent requirements that make software deployment especially challenging. The unknown and fluctuating environment in which pervasive applications are executed discards traditional approaches. As a result, there is an increasing need for a reproducible and dynamic deployment process. In last years, we developed several industrial pervasive platforms and applications. Based on these experiences we propose Rondo, a tool suite for deploying pervasive applications. Rondo includes a domain-specific language for declaratively describing applications, a deployment manager that can dynamically apply these descriptions and development tools for helping the description of applications. In this paper we present this tool suite and a set of deployment scenarios in which we validated our approach, including a web framework and a home automation platform.}, 
keywords={Internet;home automation;software tools;ubiquitous computing;Rondo;Web framework;domain-specific language;home automation platform;industrial pervasive applications;industrial pervasive platforms;pervasive systems;reproducible dynamic deployment process;software deployment;tool suite;Assembly;Conferences;Context;DSL;Monitoring;Pervasive computing;Software}, 
doi={10.1109/PERCOMW.2015.7134025}, 
month={March},}
@INPROCEEDINGS{7582779, 
author={A. Pescador and J. de Lara}, 
booktitle={2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
title={DSL-maps: From requirements to design of domain-specific languages}, 
year={2016}, 
pages={438-443}, 
abstract={Domain-Specific Languages (DSLs) are central to Model-Driven Engineering, where they are used for creating models for particular domains. However, current research and tools for building DSLs focus on the design and implementation aspects of the DSL, while the requirements analysis phase, and its automated transition to design is largely neglected. In order to alleviate this situation, we propose DSL-maps, a notation inspired by mind-maps, to represent requirements for DSLs. The notation is supported by a tool, which helps in the automated transition into an initial meta-model design, using a customizable transformation and recommendations from a catalogue of meta-model design patterns.}, 
keywords={high level languages;pattern recognition;systems analysis;DSL-maps;domain-specific languages;meta-model design patterns;mind-maps;model-driven engineering;requirements analysis phase;Computational modeling;Concrete;Connectors;DSL;Software;Syntactics;Unified modeling language;Domain Analysis;Domain Specific Languages;Meta-Modelling Patterns;Model-Driven Engineering}, 
month={Sept},}
@INPROCEEDINGS{6425702, 
author={E. Franchi}, 
booktitle={Advances in Social Networks Analysis and Mining (ASONAM), 2012 IEEE/ACM International Conference on}, 
title={A Domain Specific Language Approach for Agent-Based Social Network Modeling}, 
year={2012}, 
pages={607-612}, 
abstract={Although in the past twenty years agent-based modeling has been widely adopted as a research tool in the fields of social and political sciences, there is lack of software instruments specifically created for social network simulations. Restricting the field of interest specifically to social network models and simulations instead of supporting general agent-based ones, allows for the creation of easier to use, more focused tools. In this work, we propose PyNetSYM, an agent-based modeling framework designed to be friendly to programmers and non-programmers alike. PyNetSYM provides a domain-specific language to specify social network simulations expressed as agent-based models. PyNetSYM was created to deal with large simulations and to work effortlessly with other social network analysis toolkits.}, 
keywords={social networking (online);social sciences;software agents;PyNetSYM;agent-based social network modeling;domain specific language approach;political science;social science;Analytical models;Concurrent computing;DSL;Libraries;Message systems;Object oriented modeling;Social network services;Agent Based Modeling;Social Network Analysis}, 
doi={10.1109/ASONAM.2012.102}, 
month={Aug},}
@INPROCEEDINGS{6200153, 
author={A. Gargantini and P. Vavassori}, 
booktitle={2012 IEEE Fifth International Conference on Software Testing, Verification and Validation}, 
title={CITLAB: A Laboratory for Combinatorial Interaction Testing}, 
year={2012}, 
pages={559-568}, 
abstract={Although the research community around combinatorial interaction testing has been very active for several years, it has failed to find common solutions on some issues. First of all, there is not a common abstract nor concrete language to express combinatorial problems. Combinatorial testing generator tools are strongly decoupled making difficult their interoperability and the exchange of models and data. In this paper, we propose an abstract and concrete specific language for combinatorial problems. It features and formally defines the concepts of parameters and types, constraints, seeds, and test goals. The language is defined by means of XTEXT, a framework for the definition of domain-specific languages. XTEXT is used to derive a powerful editor integrated with eclipse and with all the expected features of a modern editor. Eclipse is also used to build an extensible framework in which test generators, importers, and exporters can be easily added as plugins.}, 
keywords={Java;open systems;program testing;software tools;specification languages;CITLAB;XTEXT;abstract specific language;combinatorial interaction testing;combinatorial testing generator tool;concrete specific language;domain specific language;eclipse;interoperability;modern editor;Cameras;DSL;Generators;Grammar;Java;Syntactics;Testing;XTEXT;combinatorial testing;domain specific languages;eclipse;xtext}, 
doi={10.1109/ICST.2012.141}, 
ISSN={2159-4848}, 
month={April},}
@INPROCEEDINGS{6899203, 
author={S. Ciraci and J. C. Fuller and J. Daily and A. Makhmalbaf and D. Callahan}, 
booktitle={Computer Software and Applications Conference (COMPSAC), 2014 IEEE 38th Annual}, 
title={A Runtime Verification Framework for Control System Simulation}, 
year={2014}, 
pages={75-84}, 
abstract={In a standard workflow for the validation of a control system, the control system is implemented as an extension to a simulator. Such simulators are complex software systems, and engineers may unknowingly violate constraints a simulator places on extensions. As such, errors may be introduced in the implementation of either the control system or the simulator leading to invalid simulation results. This paper presents a novel runtime verification approach for verifying control system implementations within simulators. The major contribution of the approach is the two-tier specification process. In the first tier, engineers model constraints using a domain-specific language tailored to modeling a controller's response to changes in its input. The language is high-level and effectively hides the implementation details of the simulator, allowing engineers to specify design-level constraints independent of low-level simulator interfaces. In the second tier, simulator developers provide mapping rules for mapping design-level constraints to the implementation of the simulator. Using the rules, an automated tool transforms the design-level specifications into simulator-specific runtime verification specifications and generates monitoring code which is injected into the implementation of the simulator. During simulation, these monitors observe the input and output variables of the control system and report changes to the verifier. The verifier checks whether these changes follow the constraints of the control system. We describe application of this approach to the verification of the constraints of an HVAC control system implemented with the power grid simulator Grid LAB-D.}, 
keywords={control engineering computing;formal specification;formal verification;control system simulation;design-level specification;domain-specific language;low-level simulator interface;mapping design-level constraint;monitoring code;simulator-specific runtime verification specification;two-tier specification process;Automata;Control systems;Monitoring;Object oriented modeling;Runtime;Software systems;Time factors;control system;runtime verification;simulation;timed automata}, 
doi={10.1109/COMPSAC.2014.14}, 
month={July},}
@INPROCEEDINGS{7500572, 
author={J. Akhundov and M. Werner and V. Schaus and A. Gerndt}, 
booktitle={2016 IEEE Aerospace Conference}, 
title={Using timed automata to check space mission feasibility in the early design phases}, 
year={2016}, 
pages={1-9}, 
abstract={According to the model-based systems engineering paradigm, all engineers contribute to a single centralized data model of the system. The German Aerospace Center (DLR) develops a software tool Virtual Satellite which enables the engineers to store, exchange and alter their corresponding subsystem data on base of a distributed system model and thus contribute to the overall mission design during concurrent engineering (CE) sessions. Each engineer has their own scope of responsibilities, e.g. satellite trajectory, communication, or thermal analysis. Tracking implications of design changes on the whole system and feasibility aspects of the design is not trivial. Having an automated feasibility checking mechanism as a part of CE which would run iteratively after each design change provides a useful feedback mechanism for engineers and for the spacecraft client. For the purpose of mission feasibility checking a domain specific language (DSL) has been implemented using the Xtext Java framework. The extended parametric data model defined in the DSL serves as an executable representation of the spacecraft mission. The idea to use such an executable model to create a preliminary mission plan and hence confirm missions feasibility during conceptual study has already been introduced by Schaus et al. at the DLR. However, the vector of values of system variables was assumed to be equivalent with the currently active component, implying that component activities are mutually exclusive. This led to over-constraining of the execution model. Our work argues that concurrency considerations are critical from the earliest design phases. Since satellite is coupled with its environment and concurrency is an intrinsic property of the physical nature, considering concurrency allows for more realistic mission plans. The contributions of this paper are the introduction of concurrency considerations at the early space mission design phases and the use of timed automata tool (UPPAAL) for the - ission feasibility check during concurrent engineering sessions. As a result, with almost no overhead, the planned mission can be analyzed in a more realistic way. Furthermore, the run-times of the feasibility check amount to 10-100 milliseconds or less, which is also a significant improvement with respect to the previous work. This allows for more precision and fine granular modeling, and is a promising basis for model refinements in the consecutive mission design phases.}, 
keywords={aerospace computing;artificial satellites;automata theory;concurrent engineering;CE;DLR;DSL;German Aerospace Center;UPPAAL;Xtext Java framework;automated feasibility checking mechanism;concurrent engineering sessions;domain specific language;early design phases;extended parametric data model;software tool;space mission feasibility;spacecraft client;timed automata tool;virtual satellite;Automata;Concurrent computing;DSL;Modeling;Satellites;Space missions;Synchronization}, 
doi={10.1109/AERO.2016.7500572}, 
month={March},}
@INPROCEEDINGS{6825691, 
author={A. Thiery and T. Cerqueus and C. Thorpe and G. Sunyé and J. Murphy}, 
booktitle={Software Testing, Verification and Validation Workshops (ICSTW), 2014 IEEE Seventh International Conference on}, 
title={A DSL for Deployment and Testing in the Cloud}, 
year={2014}, 
pages={376-382}, 
abstract={Cloud computing is becoming increasingly prevalent, more and more software providers are offering their applications as Software-as-a-Service solutions rather than traditional on-premises installations. In order to ensure the efficacy of the testing phase, it is critical to create a test environment that sufficiently emulates the production environment. Thus, Cloud applications should be tested in the Cloud. Cloud providers offer command-line tools for interacting with their platforms. However, writing custom low-level scripts using the provider's tool can become very complex to maintain and manage when variability (in terms of providers and platforms) is introduced. The contributions in this paper include: the development of a high level Domain Specific Language for the abstract definition of the application deployment process, and resource requirements, and a generation process that transforms these definitions to automatically produce deployment and instantiation scripts for a variety of providers and platforms. These contributions significantly simplify and accelerate the testing process for Cloud applications.}, 
keywords={cloud computing;program testing;specification languages;DSL;application deployment process;cloud applications;cloud computing;cloud providers;command-line tools;custom low-level scripts;domain specific language;instantiation scripts;on-premises installations;resource requirements;software providers;software-as-a-service solutions;test environment;Context;DSL;Educational institutions;Grammar;Random access memory;Software;Testing;Cloud;DSL;Deployment;Testing in the Cloud}, 
doi={10.1109/ICSTW.2014.43}, 
month={March},}
@INPROCEEDINGS{7140372, 
author={F. A. Lopes and M. Santos and R. Fidalgo and S. Fernandes}, 
booktitle={2015 IFIP/IEEE International Symposium on Integrated Network Management (IM)}, 
title={Model-driven networking: A novel approach for SDN applications development}, 
year={2015}, 
pages={770-773}, 
abstract={Software-Defined Networking (SDN) has been receiving a great deal of attention from both academic and industry communities. One reason to this interest is that SDN enables the network programmability, through an external controller, which supports applications and policies built from SDN programming languages, thus breaking the traditional bind between control and data plane. Nevertheless, the application development in this context is still complex for such recent technology. Moreover, there is a strong need for methodologies and tools that explore the abstraction levels potentials supported by SDN. This paper presents a new approach based on the Model-Driven Engineering (MDE) paradigm, called Model-Driven Networking (MDN). MDN relies on a Domain-Specific Modelling Language (DSML) to create SDN applications. We argue that MDN raises the level of abstraction on development, thus reducing the complexity to implement SDN applications and avoiding inconsistent policies. In order to show the relevance and the technological viability of our proposal, we have specified a DSML and have built a tool for creating SDN applications using the MDN approach.}, 
keywords={software defined networking;specification languages;DSML;MDE paradigm;MDN;SDN applications development;SDN programming languages;domain-specific modelling language;external controller;model-driven engineering paradigm;model-driven networking;network programmability;software-defined networking;Biological system modeling;Complexity theory;Computational modeling;DSL;Proposals;Semantics;Syntactics;Domain-Specific Modeling Language;Model-Driven Engineering;Software-Defined Networking}, 
doi={10.1109/INM.2015.7140372}, 
ISSN={1573-0077}, 
month={May},}
@INPROCEEDINGS{6651125, 
author={A. Kumar and A. Gheith and M. Kistler}, 
booktitle={Parallel and Distributed Processing Symposium Workshops PhD Forum (IPDPSW), 2013 IEEE 27th International}, 
title={Experiences with Dynamic Binary Translation in a Full System Simulator}, 
year={2013}, 
pages={2168-2175}, 
abstract={In this paper we describe our experiences with a new full-system simulator for the Power™ architecture that achieves a high-level of simulation performance through careful design and the application of dynamic binary translation. Our simulator is written entirely in Java and can run simple applications and also boot whole operating systems. We chose Java because it has a wide developer base, portability, support for modern programming features such as inheritance, ease of scripting, built in serialization, and a broad selection of robust developer tools. To improve simulation performance, we treat the byte code for our instruction interpreter as an intermediate representation to drive dynamic binary translation. When running as a pure instruction interpreter, the simulator can achieve simulation speeds of over 100 MIPS. For simple applications, dynamic binary translation can improve simulation performance by a factor of 2 or more, to over 200 MIPS. We continue to work on dynamic binary translation for booting a full operating system, and we are also exploring dynamic translation of Java byte code directly to host object code.}, 
keywords={Java;operating systems (computers);program interpreters;Java byte code;Power™ architecture;dynamic binary translation;dynamic translation;full system simulator;instruction interpreter;operating system booting;portability;programming features;simulation performance improvement;Complexity theory;Computational modeling;DSL;Java;Programming;Registers;Standards;Java;interpreter;partial evaluation;simulation}, 
doi={10.1109/IPDPSW.2013.250}, 
month={May},}
@INPROCEEDINGS{6645251, 
author={F. Pérez and P. Valderas and J. Fons}, 
booktitle={2013 IEEE Symposium on Visual Languages and Human Centric Computing}, 
title={A domain-specific language for enabling doctors to specify biomechanical protocols}, 
year={2013}, 
pages={99-102}, 
abstract={New technologies are entering medical practice at an astounding pace. However, these technologies often cause to doctors learn and use difficulties. Then, doctors require assistance of a biomedical engineer. This is currently happening in a local hospital that has new technology to analyze biomechanical protocols in patients. Protocols are used to measure performances and identify changes in human body movements and muscles. Doctors are neither familiar with the concepts nor tools used, so biomedical engineers carry out descriptions of protocols rather than doctors. In this paper, we present the design of a domain-specific language that enables doctors to specify biomechanical protocols by addressing learning barriers (using design patterns). We also make doctors' descriptions compatible with the existing tools, and we also support legacy biomedical descriptions (combining meta-modeling and model transformations).}, 
keywords={biomechanics;biomedical engineering;hospitals;protocols;specification languages;biomechanical protocols;biomedical engineer;design patterns;doctors;domain-specific language;hospital;human body movements;learning barriers;legacy biomedical descriptions;medical practice;meta-modeling;model transformations;muscles;patients;Biomechanics;Catalogs;DSL;Medical services;Motion measurement;Muscles;Protocols}, 
doi={10.1109/VLHCC.2013.6645251}, 
ISSN={1943-6092}, 
month={Sept},}
@INPROCEEDINGS{6679649, 
author={J. McDaniel and C. Curtis and P. Brisk}, 
booktitle={2013 IEEE Biomedical Circuits and Systems Conference (BioCAS)}, 
title={Automatic synthesis of microfluidic large scale integration chips from a domain-specific language}, 
year={2013}, 
pages={101-104}, 
abstract={BioCoder is a domain-specific language by which chemists and biologists can express experimental protocols in a manner that is unambiguous and clearly repeatable. This paper presents a software toolchain that converts a protocol specified in a restricted subset of BioCoder to a technology-specific description of the protocol, targeting flow-based microfluidic large-scale integration (mLSI) chips. The technology-specific description can then be used to either: (1) execute the protocol on a capable chip; or (2) to derive the architecture of a new mLSI chip that can execute the protocol.}, 
keywords={bioMEMS;biology computing;lab-on-a-chip;microfluidics;programming languages;software tools;BioCoder;domain specific language;experimental protocols;flow based microfluidic large scale integration;mLSI chip automatic synthesis;microfluidic large scale integration chips;software toolchain;technology specific protocol description;Assembly;Biology;Computer architecture;Fluids;Heating;Microfluidics;Protocols;domain-specific language;microfluidic Large Scale Integration (mLSI)}, 
doi={10.1109/BioCAS.2013.6679649}, 
ISSN={2163-4025}, 
month={Oct},}
@INPROCEEDINGS{6596418, 
author={D. V. Annenkov and E. A. Cherkashin}, 
booktitle={Information Communication Technology Electronics Microelectronics (MIPRO), 2013 36th International Convention on}, 
title={Generation technique for Django MVC web framework using the stratego transformation language}, 
year={2013}, 
pages={1084-1087}, 
abstract={Domain Specific Languages (DSL) allows one to raise level of abstraction, improve development productivity, and establish an equitable communication between domain experts and developers. Language-oriented programming (LOP) is a new paradigm based on DSL construction, allowing separating domain-specific and technology-specific aspects of a system under development. LOP shares some ideas with model-driven architecture and model-driven development. Spoofax language workbench is used as a primary tool for DSL design, and based on Stratego, a transformation language with programmable rewriting strategies, and Syntax Definition Formalism as language for grammar definition. As an example of DSL a simple textual language for domain modeling is considered. Rewriting rules and strategies are used as an uniform approach to generate, validate DSL code, and make arbitrary abstract syntax tree transformations. Rules for code generation implemented using so called “string interpolation” technique. Source DSL code translated to python code that can be deployed within Django web framework resulting to a web-application with create/update/delete functionality on a corresponding database. Developed DSL is an example of “definition by transformation“ approach. To get real benefits from DSL we need to add more domain specific features in DSL.}, 
keywords={Internet;computational linguistics;interpolation;object-oriented languages;DSL;DSL code;Django MVC Web framework;Django Web framework;LOP;Spoofax language workbench;Stratego transformation language;code generation;domain specific aspects;domain specific languages;driven architecture model;driven development model;generation technique;grammar definition;language oriented programming;programmable rewriting strategies;rewriting rules;rewriting strategies;string interpolation technique;syntax definition formalism;syntax tree transformations;textual language}, 
month={May},}
@ARTICLE{6418129, 
author={F. Rosique and M. Jimenez and A. Iborra}, 
journal={IEEE Latin America Transactions}, 
title={A Graphical Modeling Language for Home Automation}, 
year={2012}, 
volume={10}, 
number={6}, 
pages={2249-2255}, 
abstract={Home automation systems have emerged as one of the most attractive fields in engineering, thanks to the burgeoning demand from society for information systems. Today, the development of these systems is confined to the immediate context of the solution and is platform-dependent. This has intensified the need for suitable tools to tackle their development while enhancing quality and productivity. On one hand, domain specific languages allow the description of the system by means of graphic models easily and intuitively, using domain concepts. On the other hand, the model driven development approach stands out as a good option for solving the problems of the existing methods, as well as contributing tools that pioneer the development of domain specific languages. The present article proposes an alternative methodology and tools for the development of home automation applications following the model driven approach together with the use of a domain specific language.}, 
keywords={formal specification;home automation;information systems;software tools;specification languages;domain concepts;domain specific languages;graphic models;graphical modeling language;home automation applications;home automation systems;information systems;model driven approach;model driven development approach;Computational modeling;Computer integrated manufacturing;DSL;Domain specific languages;Home automation;Software;Visualization;home automation;model driven engineering}, 
doi={10.1109/TLA.2012.6418129}, 
ISSN={1548-0992}, 
month={Dec},}
@INPROCEEDINGS{7118976, 
author={S. Das}, 
booktitle={2015 IEEE Aerospace Conference}, 
title={An efficient way to enable prognostics in an onboard system}, 
year={2015}, 
pages={1-7}, 
abstract={Prognostics and Health Management (PHM) systems are becoming increasingly important for monitoring and maintaining high value assets. In order to enable real time onboard diagnostic and prognostic capabilities, mechanisms for reading, manipulating and analyzing the data need to be architected into the onboard system. Machine learning and statistical algorithms provide tools to develop data models for enabling prognostics that are typically developed off-board by mining historical data. Once trained, the logic of processing real time data is then embedded on a real time onboard system. A straightforward approach for incorporating the knowledge and intelligence for real time data processing is to add the needed logic and algorithms as an integral part of the onboard software. While this method can serve the purpose of enabling real time health assessment and analysis, it is very restrictive in nature. Every time the analytics need to be updated or algorithms need refinement, it requires a refresh of the complete onboard software. The ability to fine tune onboard embedded logic for the purpose of making the analysis smarter is crucial for creating a successful and sound health monitoring system. In addition, it is desired that the process of encoding logic and algorithms should be simple and easy to incorporate into the system. User friendliness of the process of embedding intelligent logic is critical for long term maintenance of the system as well. This paper discusses an approach to build algorithms and logic into an onboard system such that they are programmatically decoupled from the onboard software. The approach described in this paper allows users the ease of use and flexibility in building knowledge into the system. In addition, as more historical data is collected and richer knowledge is discovered from mining the data, algorithms can be improved over time without having to update the onboard software.}, 
keywords={condition monitoring;learning (artificial intelligence);structural engineering computing;PHM systems;complete onboard software;data models;health management;historical data;intelligent logic;machine learning;onboard embedded logic;prognostic capabilities;real time data processing;real time health assessment;real time onboard diagnostic capabilities;real time onboard system;sound health monitoring system;statistical algorithms;user friendliness;DSL;Hidden Markov models;Maintenance engineering;Mathematical model;Prognostics and health management;Real-time systems;Software}, 
doi={10.1109/AERO.2015.7118976}, 
ISSN={1095-323X}, 
month={March},}
@INPROCEEDINGS{6424560, 
author={T. Miyajima and D. Thomas and H. Amano}, 
booktitle={Networking and Computing (ICNC), 2012 Third International Conference on}, 
title={A Domain Specific Language and Toolchain for OpenCV Runtime Binary Acceleration Using GPU}, 
year={2012}, 
pages={175-181}, 
abstract={Computationally intensive applications, such as OpenCV, can be off-loaded to accelerators to reduce execution time. However, developing an accelerated system requires a significant amount of time, requiring the developer to first choose an accelerator and which parts to off-load, then to port and the offloaded kernels to the accelerator using many accelerator-specific tools. In addition to the low-level parallelism of the accelerator, the developer also needs to extract and utilize system-level parallelism found within the application, while making sure that the application still executes correctly. This paper presents Courier, a tool chain and a domain specific language for Runtime Binary Acceleration, designed to simplify many of the steps involved in accelerating an application. The Courier tool chain can extract dataflow from a running software binary file, explore the off-loaded execution time on an accelerator, and then actually accelerate the original binary. By utilizing Courier, both expert and non-expert users can easily extract system-level parallelism and decide which part should be off-loaded to accelerators in a mixed software-hardware environment, without special knowledge on the target application source code and accelerator architecture. In a case study an OpenCV application is accelerated by 2.06 times using Courier, without requiring the application source code or any re-compilation of the application.}, 
keywords={computer vision;data flow computing;graphics processing units;operating system kernels;program compilers;specification languages;Courier tool chain;GPU;OpenCV runtime binary acceleration;accelerated system;accelerator architecture;accelerator-specific tools;accelerators;computationally intensive applications;dataflow;domain specific language;low-level parallelism;mixed software-hardware environment;off-loaded execution time;offloaded kernels;software binary file;system-level parallelism;target application source code;toolchain;Acceleration;Data transfer;Field programmable gate arrays;Graphics processing units;Parallel processing;Runtime;Domain Spefic Language;Dynamic Off-loading;GPU;OpenCV;Runtime Binary Acceleration}, 
doi={10.1109/ICNC.2012.34}, 
month={Dec},}
@INPROCEEDINGS{6532141, 
author={A. Iliasov and A. Romanovsky}, 
booktitle={Dependable Transportation Systems/Recent Advances in Software Dependability (WDTS-RASD), 2012 Workshop on}, 
title={SafeCap Domain Language for Reasoning about Safety and Capacity}, 
year={2012}, 
pages={1-10}, 
abstract={The on-going UK SAFECAP project develops modeling techniques and tools for improving railway capacity while ensuring that safety standards are maintained. This paper reports recent SAFECAP results on designing a Domain Specific Language (DSL) that will allow engineers to improve the node and junction capacity while guaranteeing operational safety. The SAFECAP DSL is introduced to define railway topology, its logical structure and signalling rules. The formal semantics of this graphical DSL, defined as part of our work, allows us to reason about system safety. The tooling environment, the SAFECAP Platform, offers graphical editing of railway schemas and an interface to a range of verification for ensuring railway operational safety. The work on extending the environment and its deployment in the railway sector continues with our SAFECAP partners: Invensys Rail and Swansea University.}, 
keywords={inference mechanisms;railway safety;specification languages;SAFECAP domain language;Swansea university;UK SAFECAP project;domain specific language;graphical DSL;invensys rail;modelling techniques;railway capacity;railway operational safety;railway topology;reasoning;safety standards;domain language;formal verification;railway modelling;route-based signalling;safety}, 
doi={10.1109/WDTS-RASD.2012.11}, 
month={Nov},}
@INPROCEEDINGS{7180130, 
author={V. Karakoidas and D. Mitropoulos and P. Louridas and G. Gousios and D. Spinellis}, 
booktitle={2015 IEEE/ACM 12th Working Conference on Mining Software Repositories}, 
title={Generating the Blueprints of the Java Ecosystem}, 
year={2015}, 
pages={510-513}, 
abstract={Examining a large number of software artifacts can provide the research community with data regarding quality and design. We present a dataset obtained by statically analyzing 22730 jar files taken from the Maven central archive, which is the de-facto application library repository for the Java ecosystem. For our analysis we used three popular static analysis tools that calculate metrics regarding object-oriented design, program size, and package design. The dataset contains the metrics results that every tool reports for every selected jar of the ecosystem. Our dataset can be used to produce interesting research results, such as measure the domain-specific language usage.}, 
keywords={Java;information retrieval systems;libraries;object-oriented programming;program diagnostics;software metrics;software packages;Java ecosystem;Maven central archive;blueprints;de-facto application library repository;jar files;object-oriented design;package design;software artifacts;software metrics;static analysis tools;DSL;Databases;Java;Libraries;Measurement;Software;XML;Chidamber and Kemerer;Java;Maven;Software Metrics}, 
doi={10.1109/MSR.2015.76}, 
ISSN={2160-1852}, 
month={May},}
@INPROCEEDINGS{7323104, 
author={C. Sanz and A. Salas and M. de Miguel and A. Alonso and J. A. de la Puente and C. Benac}, 
booktitle={Model-Driven Engineering and Software Development (MODELSWARD), 2015 3rd International Conference on}, 
title={Automated model-based testing based on an agnostic-platform modeling language}, 
year={2015}, 
pages={1-8}, 
abstract={Currently multiple Domain Specific Languages (DSLs) are used for model-driven software development, in some specific domains. Software development methods, such as agile development, are test-centered, and their application in model-based frameworks requires model support for test development. We introduce a specific language to define generic test models, which can be automatically transformed into executable tests for particular testing platforms. The resulting test models represent the test plan for applications also built according to a model-based approach. The approach presented here includes some customisations for the application of the developed languages and transformation tools for some specific testing platforms. These languages and tools have been integrated with some specific DSL designed for software development.}, 
keywords={program testing;software development management;DSL;agnostic platform modeling language;automated model;generic test models;model driven software development;multiple domain specific languages;software development methods;Architecture;Complexity theory;Computer architecture;Engines;Software;Testing;Unified modeling language;Agile Development;Automated Testing;Model-based Testing}, 
month={Feb},}
@INPROCEEDINGS{6693130, 
author={D. Wüest and N. Seyff and M. Glinz}, 
booktitle={Automated Software Engineering (ASE), 2013 IEEE/ACM 28th International Conference on}, 
title={Semi-automatic generation of metamodels from model sketches}, 
year={2013}, 
pages={664-669}, 
abstract={Traditionally, metamodeling is an upfront activity performed by experts for defining modeling languages. Modeling tools then typically restrict modelers to using only constructs defined in the metamodel. This is inappropriate when users want to sketch graphical models without any restrictions and only later assign meanings to the sketched elements. Upfront metamodeling also complicates the creation of domain-specific languages, as it requires experts with both domain and metamodeling expertise. In this paper we present a new approach that supports modelers in creating metamodels for diagrams they have sketched or are currently sketching. Metamodels are defined in a semi-automatic, interactive way by annotating diagram elements and automated model analysis. Our approach requires no metamodeling expertise and supports the co-evolution of models and meta-models.}, 
keywords={SysML;computer graphics;automated model analysis;diagram elements annotation;domain-specific languages;graphical models;metamodels semiautomatic generation;model sketches;Adaptation models;Computational modeling;Context;DSL;Libraries;Metamodeling;Unified modeling language;Sketch;end-user;inference;metamodel;model;semiautomated}, 
doi={10.1109/ASE.2013.6693130}, 
month={Nov},}
@INPROCEEDINGS{7323106, 
author={K. Beckmann}, 
booktitle={Model-Driven Engineering and Software Development (MODELSWARD), 2015 3rd International Conference on}, 
title={Integrating existing proprietary system models into a model-driven test process for an industrial automation scenario}, 
year={2015}, 
pages={255-262}, 
abstract={The introduction of modern model-driven software development methodologies into the industrial practise still proves to be a challenge. Especially small or medium-sized enterprises (SMEs) need an incremental and continuous modernisation process, which incorporates existing projects, is customised and cost-effective. Particularly, suitable solutions for model-based or -driven testing with test automation to increase the efficiency are in demand. This paper presents an approach for integrating existing proprietary system models of an SME partner for describing industrial automation processes into a model-driven test process, utilising a domain-specific language for the test specification. The test objectives focuses on the correct implementation of the communication and synchronisation of distributed state machines. The presented approach is integrated into a test framework, which is based on the Eclipse Modelling Framework (EMF) and the Eclipse Test and Performance Tools Platform Project (TPTP) framework. To separate the possibly changeable system and DSL-specific models from the implementation of the test framework, a stable and more generic test meta model was defined.}, 
keywords={factory automation;program testing;small-to-medium enterprises;software engineering;EMF;SME;domain-specific language;eclipse modelling framework;eclipse test and performance tools platform project;generic test meta model;industrial automation;model-driven test process;modern model-driven software development;proprietary system model;small or medium-sized enterprises;test specification;Adaptation models;Automation;Biological system modeling;DSL;Object oriented modeling;Software;Unified modeling language;DSL;MDSD;MDT;Metamodelling;Model-driven Testing;Testing}, 
month={Feb},}
@INPROCEEDINGS{7203036, 
author={S. Barnett and R. Vasa and J. Grundy}, 
booktitle={2015 IEEE/ACM 37th IEEE International Conference on Software Engineering}, 
title={Bootstrapping Mobile App Development}, 
year={2015}, 
volume={2}, 
pages={657-660}, 
abstract={Modern IDEs provide limited support for developers when starting a new data-driven mobile app. App developers are currently required to write copious amounts of boilerplate code, scripts, organise complex directories, and author actual functionality. Although this scenario is ripe for automation, current tools are yet to address it adequately. In this paper we present RAPPT, a tool that generates the scaffolding of a mobile app based on a high level description specified in a Domain Specific Language (DSL). We demonstrate the feasibility of our approach by an example case study and feedback from a professional development team. Demo at: https://www.youtube.com/watch?v=ffquVgBYpLM.}, 
keywords={application program interfaces;mobile computing;specification languages;DSL;IDE;RAPPT tool;data-driven mobile app;domain specific language;integrated development environment;mobile application development;Androids;DSL;Humanoid robots;Mobile communication;Motion pictures;Productivity;Software engineering;Code Generation;Mobile App Prototyping;Model Driven Development}, 
doi={10.1109/ICSE.2015.216}, 
ISSN={0270-5257}, 
month={May},}
@INPROCEEDINGS{6927222, 
author={M. Gautier and G. S. Ouedraogo and O. Sentieys}, 
booktitle={Digital System Design (DSD), 2014 17th Euromicro Conference on}, 
title={Design Space Exploration in an FPGA-Based Software Defined Radio}, 
year={2014}, 
pages={22-27}, 
abstract={The FPGA (Field Programmable Gate Array) technology is expected to play a key role in the development of Software Defined Radio (SDR) platforms. To this aim, leveraging the nascent High-Level Synthesis (HLS) tools, a design flow from high-level specifications to Register-Transfer Level (RTL) description can be thought. Based on such a flow, this paper describes the Design Space Exploration (DSE) that can be achieved using loop optimizations. The mainstream objective is to demonstrate the compile-time flexibility of an architecture when associated with a reconfigurable platform. Throughout both IEEE 802.15.4 and IEEE 802.11g waveform examples, we show how the FPGA resources can be tuned according to a targeted throughput.}, 
keywords={field programmable gate arrays;optimisation;software radio;DSE;FPGA-based software defined radio throughput;HLS tool;RTL;SDR platform;compile-time flexibility;design space exploration;field programmable gate array technology;high-level synthesis tool;loop optimization;reconfigurable platform;register-transfer level;DSL;Estimation;Field programmable gate arrays;IEEE 802.15 Standards;IP networks;Table lookup;Throughput;Design Space Exploration;Field Programmable Gate Array (FPGA);High- Level Synthesis (HLS);Software Defined Radio (SDR)}, 
doi={10.1109/DSD.2014.44}, 
month={Aug},}
@INPROCEEDINGS{7323141, 
author={P. M. S. Nazari and B. Rumpe}, 
booktitle={Model-Driven Engineering and Software Development (MODELSWARD), 2015 3rd International Conference on}, 
title={Using software categories for the development of generative software}, 
year={2015}, 
pages={498-503}, 
abstract={In model-driven development (MDD) software emerges by systematically transforming abstract models to concrete source code. Ideally, performing those transformations is to a large extent the task of code generators. One approach for developing a new code generator is to write a reference implementation and separate it into handwritten and generatable code. Typically, the generator developer manually performs this separation - a process that is often time-consuming, labor-intensive, difficult to maintain and may produce more code than necessary. Software categories provide a way for separating code into designated parts with defined dependencies, for example, “Business Logic” code that may not directly use “Technical” code. This paper presents an approach that uses the concept of software categories to semi-automatically determine candidates for generated code. The main idea is to iteratively derive the categories for uncategorized code from the dependencies of categorized code. The candidates for generated or handwritten code finally are code parts belonging to specific (previously defined) categories. This approach helps the generator developer in finding candidates for generated code more easily and systematically than searching by hand and is a step towards tool-supported development of generative software.}, 
keywords={program compilers;software engineering;source code (software);MDD software;code generator;concrete source code;generative software development;handwritten code;model-driven development software;software category;tool-supported development;DSL;Games;Generators;Java;Libraries;Software systems;Code Generators;Model-driven Development;Software Categories}, 
month={Feb},}
@INPROCEEDINGS{6200121, 
author={T. Mesz´ros and T. Levendovszky}, 
booktitle={2012 IEEE Fifth International Conference on Software Testing, Verification and Validation}, 
title={Verified Operational Patterns with Graph Transformation}, 
year={2012}, 
pages={954-961}, 
abstract={Using object-oriented patterns such as design patterns, architectural patterns, and refactoring operations has considerably simplified the design process of software systems. With the proliferation of Domain-Specific Languages, the generalization of OO patterns is a natural demand. A straightforward idea is to adapt OO patterns with automated tool support to the practice of Domain-Specific Modeling as well. A possible solution for that is using graph transformations to formalize and realize such patterns. One may expect, however, that the patterns are realized in a way that they are correct and do exactly what we expect them to. In this paper, we present how one can precisely define the requirements for a domain-specific model pattern, and how to verify the requirements on the implemented patterns. The presented concept is motivated and illustrated with a case study from the state chart domain.}, 
keywords={graph grammars;object-oriented methods;pattern classification;software architecture;software maintenance;software tools;OO patterns;architectural patterns;automated tool support;domain-specific language proliferation;domain-specific model pattern;graph transformation;object-oriented patterns;refactoring operations;software system design process;state chart domain;verified operational patterns;Adaptation models;Containers;Joining processes;Object oriented modeling;Semantics;Software systems;Unified modeling language;Active Model Patterns;Graph Transformation;Transformation Verification}, 
doi={10.1109/ICST.2012.201}, 
ISSN={2159-4848}, 
month={April},}
@INPROCEEDINGS{7582830, 
author={T. Szabó and S. Alperovich and S. Erdweg and M. Voelter}, 
booktitle={2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
title={An extensible framework for variable-precision data-flow analyses in MPS}, 
year={2016}, 
pages={870-875}, 
abstract={Data-flow analyses are used as part of many software engineering tasks: they are the foundations of program understanding, refactorings and optimized code generation. Similar to general-purpose languages (GPLs), state-of-the-art domain-specific languages (DSLs) also require sophisticated data-flow analyses. However, as a consequence of the different economies of DSL development and their typically relatively fast evolution, the effort for developing and evolving such analyses must be lowered compared to GPLs. This tension can be resolved with dedicated support for data-flow analyses in language workbenches. In this tool paper we present MPS-DF, which is the component in the MPS language workbench that supports the definition of data-flow analyses for DSLs. Language developers can define data-flow graph builders declaratively as part of a language definition and compute analysis results efficiently based on these data-flow graphs. MPS-DF is extensible such that it does not compromise the support for language composition in MPS. Additionally, clients of MPS-DF analyses can run the analyses with variable precision thus trading off precision for performance. This allows clients to tailor an analysis to a particular use case.}, 
keywords={data flow analysis;data flow graphs;program compilers;software maintenance;specification languages;DSL;GPL;MPS-DF analysis;code generation;data flow analysis;data flow graph;domain-specific language;extensible framework;general-purpose language;software engineering;software refactoring;Algorithm design and analysis;DSL;Encoding;Lattices;Software;Switches;Syntactics;Data-flow Analysis;Domain-specific Language;Inter-procedural Analysis;Language Workbench}, 
month={Sept},}
@INPROCEEDINGS{6755332, 
author={W. Deneke and W. N. Li and C. Thompson}, 
booktitle={2013 IEEE 16th International Conference on Computational Science and Engineering}, 
title={Automatic Composition of ETL Workflows from Business Intents}, 
year={2013}, 
pages={1036-1042}, 
abstract={Extract-Transform-Load (ETL) tools have provided organizations with the ability to build and maintain workflows (consisting of graphs of data transformation tasks) that can process the flood of digital age data. Currently, however, the specification of ETL workflows is largely manual, human time intensive, and error prone. As requirements become increasingly complex, users must have considerable technical expertise and domain knowledge to build and maintain these workflows. This paper describes a domain-specific modeling approach to automate the composition of data processing workflows. A high-level domain-specific language is used to assertion ally express the desired results of a workflow, from which the composition of the procedural workflow satisfying these goal statements can be generated. This problem solving approach results in an intuitive interface that is usable even by casual users for the rapid composition of workflows that are accurate and error free.}, 
keywords={business data processing;data handling;graph theory;high level languages;ETL tools;ETL workflows;automatic composition;business intents;data processing workflows;data transformation tasks;digital age data flood;domain knowledge;domain-specific modeling approach;extract-transform-load tools;high-level domain-specific language;human time intensive;technical expertise;Data models;Data processing;Distributed databases;Organizations;Semantics;Standards organizations;content type;domain-specific language;domain-specific modeling;extract-transform-load (ETL);semantic annotation;workflows}, 
doi={10.1109/CSE.2013.151}, 
month={Dec},}
@INPROCEEDINGS{6418285, 
author={M. Biňas and P. Štancel and M. Novák and M. Michalko}, 
booktitle={Emerging eLearning Technologies Applications (ICETA), 2012 IEEE 10th International Conference on}, 
title={Interactive eBook as a supporting tool for education process}, 
year={2012}, 
pages={39-44}, 
abstract={This paper is trying to rediscover the usage of eBooks today in the form of a textbook. It describes the concept of electronic textbook, which provides to the reader some interactivity with the goal of improving his study experience. This concept is based on the results of Technical University of Košice.}, 
keywords={computer aided instruction;electronic publishing;interactive systems;Technical University of Košice;education process;electronic textbook;interactive eBook usage;Computers;Consumer electronics;DSL;Educational institutions;Electronic publishing;Smart phones;XML}, 
doi={10.1109/ICETA.2012.6418285}, 
month={Nov},}
@INPROCEEDINGS{6630615, 
author={U. Thomas and G. Hirzinger and B. Rumpe and C. Schulze and A. Wortmann}, 
booktitle={Robotics and Automation (ICRA), 2013 IEEE International Conference on}, 
title={A new skill based robot programming language using UML/P Statecharts}, 
year={2013}, 
pages={461-466}, 
abstract={This paper introduces the new robot programming language LightRocks(Light Weight Robot Coding for Skills), a domain specific language (DSL) for robot programming. The language offers three different level of abstraction for robot programming. On lowest level skills are coded by domain experts. On a more abstract level these skills are supposed to be combined by shop floor workers or technicians to define tasks. The language is designed to allow as much flexibility as necessary on the lowest level of abstraction and is kept as simple as possible with the more abstract layers. A Statechart like model is used to describe the different levels of detail. For this we apply the UML/P and the language workbench MontiCore. To this end we are able to generate code while hiding controller specific implementation details. In addition the development in LightRocks is supported by a generic graphical editor implemented as an Eclipse plugin.}, 
keywords={Unified Modeling Language;formal specification;program compilers;robot programming;DSL;Eclipse plugin;Light Weight Robot Coding for Skills;LightRocks;MontiCore language workbench;UML/P Statecharts;abstract layer;abstraction;code generation;controller specific implementation detail hiding;domain specific language;generic graphical editor;shop floor workers;skill based robot programming language;task definition;technicians;DSL;Robot programming;Robot sensing systems;Unified modeling language}, 
doi={10.1109/ICRA.2013.6630615}, 
ISSN={1050-4729}, 
month={May},}
@INPROCEEDINGS{7185068, 
author={W. T. Sun and A. Girault and G. Delaval}, 
booktitle={10th IEEE International Symposium on Industrial Embedded Systems (SIES)}, 
title={A formal approach for the synthesis and implementation of fault-tolerant industrial embedded systems}, 
year={2015}, 
pages={1-9}, 
abstract={We demonstrate the feasibility of a complete workflow to synthesize and implement correct-by-construction fault tolerant distributed embedded systems consisting of real-time periodic tasks. Correct-by-construction is provided by the use of discrete controller synthesis (DCS), a formal method thanks to which we are able to guarantee that the synthesized controlled system guarantees the functionality of its tasks even in the presence of processor failures. For this step, our workflow uses the Heptagon domain specific language and the Sigali DCS tool. The correct implementation of the resulting distributed system is a challenge, all the more since the controller itself must be tolerant to the processor failures. We achieve this step thanks to the libDGALS realtime library (1) to generate the glue code that will migrate the tasks upon processor failures, maintaining their internal state through migration, and (2) to make the synthesized controller itself fault-tolerant.}, 
keywords={embedded systems;fault tolerant computing;multiprocessing systems;HEPTAGON;SIGALI DCS tool;correct-by-construction embedded systems;discrete controller synthesis;domain specific language;fault tolerant distributed embedded systems;fault-tolerant controller;fault-tolerant industrial embedded systems;formal method;glue code;libDGALS real-time library;migration;multiprocessor distributed system;multitask distributed system;processor failures;real-time periodic tasks;Contracts;Control systems;Energy consumption;Fault tolerance;Fault tolerant systems;Integrated circuit modeling;Process control}, 
doi={10.1109/SIES.2015.7185068}, 
ISSN={2150-3109}, 
month={June},}
@INPROCEEDINGS{6686034, 
author={O. Díaz and C. Arellano}, 
booktitle={Cloud and Green Computing (CGC), 2013 Third International Conference on}, 
title={Integrating Microblogging Into Domain Specific Language Editors}, 
year={2013}, 
pages={219-225}, 
abstract={Micro logging is emerging as a suitable means for question-answering in working settings. This leads to different efforts to seamlessly integrate microblogging into the daily-used tools. Specifically, microblogging is being regarded as particularly useful during software development, akin to the tradition of Q&A forums. This paper looks at a particular kind of software: the one being developed by domain experts through the use of Domain Specific Languages (DSLs). We believe this setting is specially amenable to benefit from Q&A microblogging due to inherent limitations of the target audience. This brings the twist of domain specific ness into microblogging, i.e. the Q&A process is now framed by the semantics of the DSL constructs. This permits the introduction of editing assistants that embed domain knowledge about the kind of questions that can be posed, and the way answers can be selected. This opens an opportunity for more focused and assisted microblogging. This paper introduces Crowd Call, an in place microblogging mediator for DSL editors. The aim is to make microblogging a natural gesture during the conception of the DSL expressions, making transparent the interplay between the DSL editor and the Social Networking Services. In addition, Crowd Call can be configured to the constructs and resolution strategies of the DSL at hand so that questions and answers are framed by the semantics of the DSL. The approach is illustrated for three DSLs: the Google Spreadsheets formula language, SQL and Sticklet. We show how Crowd Call-mediated microblogging is tuned for the semantics of each DSL.}, 
keywords={SQL;question answering (information retrieval);social networking (online);specification languages;text editing;CrowdCall-mediated microblogging;DSL constructs;DSL editors;DSL expressions;DSL semantics;Google Spreadsheets formula language;Q and A microblogging;Q and A process;SQL;Sticklet;domain experts;domain knowledge;domain specific language editors;inplace microblogging mediator;question answering;resolution strategies;social networking services;software development;Communities;Computer languages;DSL;Google;Semantics;Social network services;Software;Domain Specific Languages;Microblogging;Social Networking Services}, 
doi={10.1109/CGC.2013.42}, 
month={Sept},}
@INPROCEEDINGS{6465139, 
author={O. Batarseh and L. F. McGinnis}, 
booktitle={Proceedings of the 2012 Winter Simulation Conference (WSC)}, 
title={System modeling in SYsML and system analysis in Arena}, 
year={2012}, 
pages={1-12}, 
abstract={A Model Driven Architecture approach is employed to support the practice of discrete-event simulation. OMG's System Model Language, OMG SysML™, is used to define a platform independent model (PIM) and auto-translate it into an appropriate platform specific model (PSM). The implementation and the nature of the transformation from PIM to PSM are clearly addressed to enable: (i) formal modeling of systems using their own semantics in SysML, (ii) SysML model verification and validation by stakeholders, (iii) automatic translation of system models expressed in SysML into analysis models as the PSM, and (iv) maintainability of this approach to accommodate system changes and extensions very easily. The proposed approach can be used for any analysis tool and application domain. In this paper, we choose to model transaction-based examples elicited from the manufacturing domain in SysML and translate them into Arena™ models using the Atlas Transformation Language.}, 
keywords={discrete event simulation;formal verification;software architecture;specification languages;Arena;Atlas Transformation Language;OMG SysML;PIM;PSM;System Model Language;analysis tool;discrete-event simulation;formal modeling;manufacturing domain;model driven architecture;model transaction;model validation;model verification;platform independent model;platform specific model;semantics;system analysis;system model automatic translation;system modeling;Analytical models;DSL;Libraries;Object oriented modeling;Semantics;Unified modeling language}, 
doi={10.1109/WSC.2012.6465139}, 
ISSN={0891-7736}, 
month={Dec},}
@INPROCEEDINGS{7542954, 
author={R. Turner and L. Yilmaz and J. Smith and D. Li and S. Chada and A. Smith and A. Tregubov}, 
booktitle={2016 11th System of Systems Engineering Conference (SoSE)}, 
title={DATASEM: A simulation suite for SoSE management research}, 
year={2016}, 
pages={1-6}, 
abstract={The Systems Engineering Research Center (A US DoD University-Affiliated Research Center) has been researching systems engineering and management problems in the evolution of Systems of Systems (SoSs) since 2011. In 2015, an initial Demonstration and Analysis Tool for Adaptive Systems Engineering Management (DATASEM) was developed to investigate how various combinations of organizational structure, work flow, and governance mechanisms affect the visibility, flow, and overall value produced in developing and evolving SoSs. This paper provides an overview of the “as developed” initial system, plans for improving and validating the system, lessons learned and early results.}, 
keywords={digital simulation;military computing;organisational aspects;systems engineering;DATASEM;Demonstration and Analysis Tool for Adaptive Systems Engineering Management;SoSE management research;Systems Engineering Research Center;US DoD university-affiliated research center;governance mechanisms;organizational structure;simulation suite;systems of systems;workflow;Adaptation models;Adaptive systems;DSL;Modeling;Organizations;System of systems;System of systems;adaptive;agile;kanban;lean;management simulation;scheduling;software engineering;systems engineering;value-based}, 
doi={10.1109/SYSOSE.2016.7542954}, 
month={June},}
@INPROCEEDINGS{6613839, 
author={P. Mayer and A. Schroeder}, 
booktitle={2013 21st International Conference on Program Comprehension (ICPC)}, 
title={Patterns of cross-language linking in java frameworks}, 
year={2013}, 
pages={113-122}, 
abstract={The term Cross-Language Linking refers to the ability to specify, locate, navigate, and keep intact the connections between artifacts defined in different programming languages used for building one software application. Although understanding cross-language links and keeping them intact during development and maintenance activities is an important productivity issue, there has been little research on understanding the characteristics of such connections. We have thus built a theory from case studies, specifically, three theory-selected Java cross-language frameworks, each of which links artifacts written in the Java programming language to artifacts written in a declarative, framework-specific domain specific language. Our main contribution is to identify, from these experiences, common patterns of cross-language linking in the domain of Java frameworks with DSLs, which besides their informative nature can also be seen as requirements for designing and building a linking language and tooling infrastructure.}, 
keywords={Java;software maintenance;DSL;Java frameworks;cross-language linking;programming languages;software application;software development;software maintenance;Atmospheric modeling;Frequency control;Springs;Cross-language;artifact linking;case study;language design;patterns;semantic models}, 
doi={10.1109/ICPC.2013.6613839}, 
ISSN={1092-8138}, 
month={May},}
@INPROCEEDINGS{6889947, 
author={A. Melingui and R. Merzouki and J. B. Mbede and C. Escande and B. Daachi and N. Benoudjit}, 
booktitle={2014 International Joint Conference on Neural Networks (IJCNN)}, 
title={Qualitative approach for inverse kinematic modeling of a Compact Bionic Handling Assistant trunk}, 
year={2014}, 
pages={754-761}, 
abstract={Compact Bionic Handling Assistant (CBHA) is a continuum manipulator, with pneumatic-based actuation and compliant gripper. This bionic arm is attached to a mobile robot named Robotino. Inspired by the elephant's trunk, it can reproduce biological behaviors of trunks, tentacles, or snakes. Unlike rigid link robot manipulators, the development of high performance control algorithm of continuum robot manipulators remains a challenge, particularly due to their complex mechanical design, hyper-redundancy and presence of uncertainties. Numerous studies have been investigated for modeling of such complex systems. Such continuum robots, like the CBHA present a set of nonlinearities and uncertainties, making difficult to build an accurate analytical model, which can be used for control strategies development. Hence, learning approach becomes a suitable tool in such scenarios in order to capture un-modeled nonlinear behaviors of the continuous robots. In this paper, we present a qualitative modeling approach, based on neuronal model of the inverse kinematic of CBHA. A penalty term constraint is added to the inverse objective function into Distal Supervised Learning (DSL) scheme to select one particular inverse model from the redundancy manifold. The inverse kinematic neuronal model is validated by conducting a real-time implementation on a CBHA trunk.}, 
keywords={biocybernetics;learning (artificial intelligence);manipulator kinematics;mobile robots;pneumatic systems;CBHA;DSL scheme;Robotino;compact bionic handling assistant trunk;compliant gripper;continuum robot manipulators;distal supervised learning;inverse kinematic;inverse kinematic modeling;inverse objective function;learning approach;mobile robot;pneumatic based actuation;qualitative approach;rigid link robot manipulators;unmodeled nonlinear behaviors;Biological neural networks;DSL;Kinematics;Manipulators;Training}, 
doi={10.1109/IJCNN.2014.6889947}, 
ISSN={2161-4393}, 
month={July},}
@INPROCEEDINGS{6645255, 
author={D. Asenov and P. Müller}, 
booktitle={2013 IEEE Symposium on Visual Languages and Human Centric Computing}, 
title={Customizing the visualization and interaction for embedded domain-specific languages in a structured editor}, 
year={2013}, 
pages={127-130}, 
abstract={Large software projects are often based on libraries that provide abstractions for a particular domain such as writing database queries, staging, or constraint solving. The API provided by such a library can be considered a domain-specific language within the implementation language of the library, a so-called internal or embedded domain-specific language (eDSL). Embedding a DSL leverages the tool infrastructure of the host language, but also restricts the syntax and IDE support to that of the host language. This restriction prevents programmers from using convenient specialized notations and, thus, has a negative effect on their productivity. To address this problem, we outline concepts for a structured code editor that enable developers of eDSLs to customize how eDSL code is rendered and what interactions are available. We demonstrate the benefits of our approach by customizing a structured editor for the .NET Code Contracts API. Our prototype shows in particular that we can customize many aspects of visualization and interaction with little effort.}, 
keywords={application program interfaces;embedded systems;programming languages;visual programming;.NET code contracts API;IDE;convenient specialized notations;eDSL code;editor customization;embedded domain-specific languages;internal domain-specific language;large software projects;structured code editor;visual programming;Context;Contracts;DSL;Libraries;Prototypes;Syntactics;Visualization;editor customization;embedded domain-specific languages;human-computer interaction;programming environments;structured editors;visual programming}, 
doi={10.1109/VLHCC.2013.6645255}, 
ISSN={1943-6092}, 
month={Sept},}
@INPROCEEDINGS{6569869, 
author={N. Jindal and V. Lotrich and E. Deumens and B. A. Sanders}, 
booktitle={Parallel Distributed Processing (IPDPS), 2013 IEEE 27th International Symposium on}, 
title={SIPMaP: A Tool for Modeling Irregular Parallel Computations in the Super Instruction Architecture}, 
year={2013}, 
pages={874-884}, 
abstract={Performance modeling is becoming an increasingly important part of the parallel application development process, particularly for expensive computations that will be run on very high-end systems where resources are scarce. We describe a performance modeling tool SIPMaP (Super Instruction Processor Modeling and Prediction) developed for the Super-Instruction Architecture (SIA). The SIA is designed for applications where the dominant data structures are large multi-dimensional arrays and it comprises a DSL, the Super-Instruction Assembly Language (SIAL) that supports expressing algorithms in terms of blocks (tiles), and its runtime system Super Instruction Processor (SIP) that manages distribution and disk storage of the arrays. SIPMaP generates performance models from the SIAL source code. In comparison with many applications where useful performance models have been developed and reported, these programs are irregular and have other difficult to model characteristics such as extensive overlapping of communication and computation.}, 
keywords={assembly language;data structures;parallel processing;software performance evaluation;DSL;SIA;SIAL;SIPMaP;data structures;high-end systems;irregular parallel computations;performance modeling;super instruction assembly language;super instruction processor modeling and prediction;super-instruction architecture;Arrays;Computational modeling;Data models;Indexes;Predictive models;Runtime;Servers;Domain Specific Language;High Performance Computing;Performance Modeling}, 
doi={10.1109/IPDPS.2013.35}, 
ISSN={1530-2075}, 
month={May},}
@INPROCEEDINGS{7160285, 
author={J. Opiła}, 
booktitle={Information and Communication Technology, Electronics and Microelectronics (MIPRO), 2015 38th International Convention on}, 
title={Prototyping of visualization styles of 3D scalar fields using POV-Ray rendering engine}, 
year={2015}, 
pages={312-317}, 
abstract={There is a persistent quest for novel methods of visualization in order to get insight into complex phenomena in scientific domains as various as physics, biomedicine or economics. Research teams involved achieved excellent results, however some problems with elaboration of novel visualization styles connected with flexibility of the software used and quality of the final images still persist. In the paper results of inspection of four visualization styles of 3D static scalar field employing POVRay ray-tracing engine are discussed, i.e. equipotential surface method using direct implementation of isosurface{} object, cellular trilinear interpolation approach, application of texture and eventually pseudo-particles design. All styles presented have been tested for hybrid visualizations and compared concerning computing time, informativeness and general appearance. It is shown in the work that Scene Description Language (SDL), domain specific language implemented in POV-Ray is flexible enough to use it as a tool for fast prototyping of novel visualization techniques. Visualizations discussed in the paper were computed using selected components of API of ScPovPlot3D, i.e. templates written in the SDL language.}, 
keywords={application program interfaces;data visualisation;rendering (computer graphics);3D static scalar field;API;POV-ray rendering engine;SDL language;ScPovPlot3D;biomedicine;cellular trilinear interpolation approach;complex phenomena;computing time;domain specific language;economics;general appearance;hybrid visualizations;informativeness;inspection;isosurface{} object;physics;pseudo-particles design;scene description language;texture design;visualization styles;Electric potential;Engines;Interpolation;Isosurfaces;Software;Three-dimensional displays;POVRay;ScPovPlot3D;pseudo-particles;scalar field visualization;visual data analysis}, 
doi={10.1109/MIPRO.2015.7160285}, 
month={May},}
@INPROCEEDINGS{6698124, 
author={F. S. Farias and G. S. Borges and W. B. Monteiro and D. L. L. Silva and J. C. W. A. Costa}, 
booktitle={2013 International Conference on Advanced Technologies for Communications (ATC 2013)}, 
title={Noise estimation in DSL systems using linear regression}, 
year={2013}, 
pages={291-294}, 
abstract={The Digital Subscriber Line (DSL) systems performance tightly depends on noise interference. The users (lines) in the binder create mutual interference (crosstalk), therefore decreasing the rates of all users. Crosstalk noise is more predominant in DSL and its major performance bottleneck is to limit high-speed data rate. This study proposes a new real-time monitoring methodology for noise estimation based on Management Information Base (MIB) metrics. Linear regression is used for fitting, in which input parameters are MIBs and the output is the estimated noise power. The results confirm the possibility of estimating noise with a general equation. Moreover, it is showing the result improvement if a Loop Topology Identification tool is used as prior knowledge.}, 
keywords={crosstalk;digital subscriber lines;regression analysis;DSL systems;MIB metrics;crosstalk noise;digital subscriber line;linear regression;loop topology identification tool;management information base;mutual interference;noise estimation;noise interference;Crosstalk;DSL;Estimation;Linear regression;Measurement;Noise;Real-time systems;Noise;backhaul;estimation;linear regression;monitoring;network measurement;real time systems}, 
doi={10.1109/ATC.2013.6698124}, 
ISSN={2162-1020}, 
month={Oct},}
@INPROCEEDINGS{6354323, 
author={V. Djukić and I. Luković and A. Popović and V. Ivančević}, 
booktitle={Computer Science and Information Systems (FedCSIS), 2012 Federated Conference on}, 
title={Using action reports for testing meta-models, models, generators and target interpreter in domain-specific modeling}, 
year={2012}, 
pages={1365-1372}, 
abstract={In this paper, we present an approach to testing of models and generated code as well as of target interpreters that relies on the use of modeling tools and model transformation languages. When compared to the existing Model Driven Development (MDD) approaches and tools supporting Domain Specific Modeling (DSM), contributions of our research include: (i) introduction of action reports, which allow semantic actions on elements of a graphical interface for modeling; (ii) creation of recommendations and of the interface for integrating modeling tools with applications; and (iii) construction of a language for the description of the structure of user controls as well as construction of a component for embedding such controls into modeling and meta-modeling tools. The basic idea behind the approach is to use a transformation language to construct complex objects and applications as well as specify operations on complex objects and the interface. In this manner, we not only generate the target platform code from the select domain-specific graphical language (DSGL) models but also directly use these models and appropriate tools as client applications. The applicability of action reports is demonstrated in the examples concerning validation of document models and their generators.}, 
keywords={graphical user interfaces;program compilers;program interpreters;program testing;program verification;software tools;specification languages;visual languages;DSGL model;action reports;code generation;document model validation;domain-specific graphical language model;domain-specific modeling;graphical interface;meta-modeling tools;model driven development;model testing;model transformation languages;modeling tools;semantic actions;target interpreter;user controls;DSL;Debugging;Generators;Software;Synchronization;Testing;Unified modeling language}, 
month={Sept},}
@INPROCEEDINGS{6404251, 
author={Pham Van Huong and Nguyen Ngoc Binh}, 
booktitle={Advanced Technologies for Communications (ATC), 2012 International Conference on}, 
title={An approach to design embedded systems by multi-objective optimization}, 
year={2012}, 
pages={165-169}, 
abstract={Embedded system design and optimization play an important role in the development trend of embedded technology. This paper presents a new approach to design and optimize embedded systems in the design phase based on Pareto multi-objective optimization. We defined two Domain Specific Languages and developed the framework that is to design the architecture model and the component diagram of embedded systems. And we integrated the code generation technology called Text Template Transformation Toolkit to this framework to generate parameters from models automatically. Then we also do multi-objective optimization to select the best trade-off configuration of the embedded system architecture and the best hardware-software partition based on the Pareto principle and Genetic Algorithm.}, 
keywords={Pareto optimisation;Unified Modeling Language;embedded systems;genetic algorithms;program compilers;software architecture;software tools;text analysis;Pareto multiobjective optimization;Pareto principle;architecture model;code generation technology;design embedded systems;domain specific languages;embedded system architecture;embedded system design;embedded system optimize;embedded technology;genetic algorithm;hardware-software partition;text template transformation toolkit;DSL;Embedded systems;Genetic algorithms;Linear programming;Optimization;Unified modeling language;DSL - Domain Specific Language;Embedded system;GA - Genetic Algorithm;Pareto principle;T4 - Text Template Transformation Toolkit;embedded system design;hardware-software partitioning;multi-objective optimization}, 
doi={10.1109/ATC.2012.6404251}, 
ISSN={2162-1020}, 
month={Oct},}
@INPROCEEDINGS{7529871, 
author={G. C. Durelli and F. Spada and C. Pilato and M. D. Santambrogio}, 
booktitle={2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
title={Scala-Based Domain-Specific Language for Creating Accelerator-Based SoCs}, 
year={2016}, 
pages={225-232}, 
abstract={Nowadays, thanks to technology miniaturization and industrial standards, it is possible to create System-on-Chip (SoC) architectures featuring a combination of many components, like processor cores and specialized hardware accelerators. However, designing an SoC to accelerate an embedded application is particularly complex. After decomposing this application into tasks and assigning each of them to a processing element, the designer must create the required hardware components and integrate them into the final system. Currently, this process is not well supported by commercial tool flows and has to be manually performed. This is time consuming and error prone. This paper proposes a Domain-Specific Language (DSL) based on Scala to specify the architecture of accelerator-based SoCs. We leverage this DSL to coordinate commercial High-Level Synthesis (HLS) tools in order to create the corresponding accelerators with proper standard interfaces for system-level integration.}, 
keywords={high level synthesis;integrated circuit design;specification languages;system-on-chip;DSL;HLS tools;Scala;SoC architectures;SoC design;accelerator-based SoC;embedded application;hardware accelerators;hardware components;high-level synthesis tools;industrial standards;processor cores;scala-based domain-specific language;system-level integration;system-on-chip architectures;technology miniaturization;Acceleration;Computer architecture;DSL;Hardware;Image edge detection;Protocols;Software}, 
doi={10.1109/IPDPSW.2016.169}, 
month={May},}
@INPROCEEDINGS{6845589, 
author={Zhai Xiaoshuai and Tong Chonglou}, 
booktitle={Electronics, Computer and Applications, 2014 IEEE Workshop on}, 
title={Research of NURBS curve interpolation algorithm}, 
year={2014}, 
pages={186-189}, 
abstract={This paper presents a real-time interpolation algorithm of three NURBS curve, which is based on simple NURBS curve interpolation algorithm. The paper proposes a simple and fast interpolation algorithm. Using the matrix representation of the NURBS curve, the whole interpolation process is divided into interpolated pretreatment and real-time interpolation. In the interpolated pretreatment, the system will achieve a large amount of calculation and the result of pretreatment directly apply to the real-time interpolation, which makes interpolation algorithm fulfill the real-time of NURBS curve's interpolation. Besides, the necessary contour error control is given. The NURBS curve interpolation achieved the machining velocity adapting the tool path.}, 
keywords={interpolation;matrix algebra;splines (mathematics);NURBS curve interpolation algorithm;contour error control;fast interpolation algorithm;machining velocity;matrix representation;real-time interpolation algorithm;Computer aided manufacturing;DSL;Interpolation;Machining;Splines (mathematics);Surface reconstruction;Surface topography;NURBS curve;error control;interpolated pretreatment;interpolation}, 
doi={10.1109/IWECA.2014.6845589}, 
month={May},}
@INPROCEEDINGS{6341588, 
author={M. F. Niazi and T. Seceleanu and H. Tenhunen}, 
booktitle={Computer Software and Applications Conference Workshops (COMPSACW), 2012 IEEE 36th Annual}, 
title={Towards Reuse-Based Development for the On-chip Distributed SoC Architecture}, 
year={2012}, 
pages={278-283}, 
abstract={The development of a reusable library of components for a multi-core segmented bus platform, the SegBus, is presented. The library is based on a plug-in that we develop and deploy within a modeling tool which eventually used by the SegBus DSL while developing applications targeting the SegBus platform. The steps required in building the library and embed it into a plug-in are discussed together with the certain use of it in our design methodology.}, 
keywords={multiprocessing systems;system buses;system-on-chip;SegBus DSL;multicore segmented bus platform;on-chip distributed SoC architecture;reusable library;reuse-based development;Analytical models;DSL;Design methodology;Libraries;Solid modeling;Unified modeling language;XML;System-on-Chip;UML;embedded systems;modeling;reusability}, 
doi={10.1109/COMPSACW.2012.58}, 
month={July},}
@INPROCEEDINGS{6892473, 
author={S. Foster and A. Miyazawa and J. Woodcock and A. Cavalcanti and J. Fitzgerald and P. G. Larsen}, 
booktitle={System of Systems Engineering (SOSE), 2014 9th International Conference on}, 
title={An approach for managing semantic heterogeneity in Systems of Systems Engineering}, 
year={2014}, 
pages={113-118}, 
abstract={Semantic heterogeneity is a significant challenge to integration in Systems of Systems Engineering (SoSE) due the large variety of languages, domains and tools which are used in their construction. In this paper we envision a strategy for managing this heterogeneity by decomposing domain specific languages into their “building block” theories which can be independently analysed, and used as a basis for linking with similar notations. This provides a systematic approach to building a tool-chain which integrates the different theories, methods and tools used in SoSE. Our approach has been piloted on the development of theories enabling machine-supported analysis of SysML models of SoSs. We conclude that the approach has further potential and identify lines of future research, notably in techniques for handling mixed discrete and continuous behaviour, timebands, mobility and model integration in SoSE.}, 
keywords={specification languages;systems engineering;theorem proving;SoSE;SoSs;SysML models;building block theory;domain specific languages;machine-supported analysis;semantic heterogeneity;systems of systems engineering;Analytical models;DSL;Mathematical model;Semantics;Unified modeling language;integration;modelling;systems of systems;theorem proving;tool-chain;unifying theories}, 
doi={10.1109/SYSOSE.2014.6892473}, 
month={June},}
@INPROCEEDINGS{7292577, 
author={E. Loiseau and P. Laforcade and S. Iksal}, 
booktitle={Software Paradigm Trends (ICSOFT-PT), 2014 9th International Conference on}, 
title={A meta-modeling approach for extending the instructional design semantics of Learning Management Systems}, 
year={2014}, 
pages={72-80}, 
abstract={Nowadays Learning Management Systems (LMS) are not restricted to distant learning. Nevertheless, the pedagogical expressiveness of courses designed by teachers is strongly dependent on their knowledge and level of expertise on the LMS they use. The GraphiT project aims to help teachers design pedagogically sound and technically executable learning designs. To this end, we propose to support teachers by providing them with an LMS-specific Visual Instructional Design Language, according to a Domain Specific Modeling approach and tooling. This paper focuses on the abstract syntax of such language. We propose a specific LMS-centered approach for raising the pedagogical expressiveness of their implicit learning design semantics. We discussed how the LMS low-level parameterisations could be abstracted in order to build higher-level building blocks. Based on the Moodle LMS, we present and verify our meta-modeling approach by formalising the abstract syntax of a Moodle-dedicated instructional design language.}, 
keywords={Context;Learning management systems;Least squares approximations;Metamodeling;Semantics;Syntactics;Visualization;Composition;Domain Specific Language;Meta-Modeling}, 
month={Aug},}
@INPROCEEDINGS{7490558, 
author={S. Jäger and R. Maschotta and T. Jungebloud and A. Wichmann and A. Zimmermann}, 
booktitle={2016 Annual IEEE Systems Conference (SysCon)}, 
title={Creation of domain-specific languages for executable system models with the Eclipse Modeling Project}, 
year={2016}, 
pages={1-8}, 
abstract={Model-based systems engineering is an increasingly accepted method supporting design decisions. System engineers or modelers have the choice between tools and system description languages that are either abstract and generic or specifically adapted to their domain. The latter approach is easier and more efficient but restrictive. The success of this approach strongly relies on the support of domain-specific tools. The design or adaptation of such software tools and their underlying conceptual models is a complex task, which can be supported by a model-based approach on the meta model level itself. This paper proposes a workflow for designing complex systems by using domain-specific models which may combine structural and behavioral aspects. It is loosely based on the Object Management Group's Model Driven Architecture approach. For this purpose we use the Eclipse Modeling Framework and Eclipse Sirius Project, which are part of the Eclipse Modeling Project. The paper describes the complete workflow based on a simple real-life system example to clarify our approach. It covering the design of the domain-specific language, semi-automatic model editor generation, modeling the system, and finally executing a simulation of its behavior.}, 
keywords={SysML;software architecture;software tools;specification languages;complex system design;design decisions;domain-specific languages;eclipse Sirius project;eclipse modeling project;executable system models;meta model level;model-based systems engineering;object management group model driven architecture approach;semiautomatic model editor generation;software tools;system description languages;Adaptation models;Analytical models;Biological system modeling;Software;Systems modeling;Unified modeling language;Eclipse Modeling Project;Ecore;Model-based system design;Sirius project;domain-specific language;meta model;simulation}, 
doi={10.1109/SYSCON.2016.7490558}, 
month={April},}
@INPROCEEDINGS{7158502, 
author={A. Caracciolo and M. F. Lungu and O. Nierstrasz}, 
booktitle={Software Architecture (WICSA), 2015 12th Working IEEE/IFIP Conference on}, 
title={A Unified Approach to Architecture Conformance Checking}, 
year={2015}, 
pages={41-50}, 
abstract={Software erosion can be controlled by periodically checking for consistency between the de facto architecture and its theoretical counterpart. Studies show that this process is often not automated and that developers still rely heavily on manual reviews, despite the availability of a large number of tools. This is partially due to the high cost involved in setting up and maintaining tool-specific and incompatible test specifications that replicate otherwise documented invariants. To reduce this cost, our approach consists in unifying the functionality provided by existing tools under the umbrella of a common business-readable DSL. By using a declarative language, we are able to write tool-agnostic rules that are simple enough to be understood by untrained stakeholders and, at the same time, can be interpreted as a rigorous specification for checking architecture conformance.}, 
keywords={program testing;software architecture;architecture conformance checking;common business-readable DSL;de facto architecture;declarative language;domain specific language;software erosion;test specifications;tool-agnostic rules;Computer architecture;Concrete;DSL;Manuals;Mathematical model;Monitoring;Software;architecture;conformance checking;erosion}, 
doi={10.1109/WICSA.2015.11}, 
month={May},}
@INPROCEEDINGS{7306135, 
author={E. F. d. Prado and D. Lucrédio}, 
booktitle={Components, Architectures and Reuse Software (SBCARS), 2015 IX Brazilian Symposium on}, 
title={A Flexible Model-Driven Game Development Approach}, 
year={2015}, 
pages={130-139}, 
abstract={Game developers are facing an increasing demand for new games every year. Game development tools can be of great help, but require highly specialized professionals. Also, just as any software development effort, game development has some challenges. Model-Driven Game Development (MDGD) is suggested as a means to solve some of these challenges, but with a loss in flexibility. We propose a MDGD approach that combines multiple domain-specific languages (DSLs) with design patterns to provide flexibility and allow generated code to be integrated with manual code. After experimentation, we observed that, with the approach, less experienced developers can create games faster and more easily, and the product of code generation can be customized with manually written code, providing flexibility. However, with MDGD, developers become less familiar with the code, making manual codification more difficult.}, 
keywords={computer games;program compilers;software engineering;MDGD approach;code generation;flexible model-driven game development approach;game development tool;multiple DSL;multiple domain-specific language;software development;Cameras;DSL;Engines;Games;Prototypes;Software;Vehicles;Code Generation;Model-Driven Game Development}, 
doi={10.1109/SBCARS.2015.24}, 
month={Sept},}
@INPROCEEDINGS{7092405, 
author={J. Deantoni and I. P. Diallo and C. Teodorov and J. Champeau and B. Combemale}, 
booktitle={2015 Design, Automation Test in Europe Conference Exhibition (DATE)}, 
title={Towards a meta-language for the concurrency concern in DSLs}, 
year={2015}, 
pages={313-316}, 
abstract={Concurrency is of primary interest in the development of complex software-intensive systems, as well as the deployment on modern platforms. Furthermore, Domain-Specific Languages (DSLs) are increasingly used in industrial processes to separate and abstract the various concerns of complex systems. However, reifying the definition of the DSL concurrency remains a challenge. This not only prevents leveraging the concurrency concern of a particular domain or platform, but it also hinders: a) the development of a complete understanding of the DSL semantics; b) the effectiveness of concurrency-aware analysis techniques; c) the analysis of the deployment on parallel architectures. In this paper, we introduce the key ideas leading toward MoCCML, a dedicated meta-language for formally specifying the concurrency concern within the definition of a DSL. The concurrency constraints can reflect the knowledge in a particular domain, but also the constraints of a particular platform. MoCCML comes with a complete language workbench to help a DSL designer in the definition of the concurrency directly within the concepts of the DSL itself, and a generic workbench to simulate and analyze any model conforming to this DSL. MoCCML is illustrated on the definition of an lightweight extension of SDF (Synchronous Data Flow [1]).}, 
keywords={concurrency (computers);formal specification;parallel architectures;production engineering computing;specification languages;DSL semantics;MoCCML;SDF;complex software-intensive systems;concurrency concern;concurrency constraints;concurrency-aware analysis techniques;dedicated meta-language;domain-specific languages;formal specification;industrial processes;parallel architectures;synchronous data flow;Analytical models;Automata;Computational modeling;Concurrent computing;DSL;Semantics;Syntactics}, 
doi={10.7873/DATE.2015.1052}, 
ISSN={1530-1591}, 
month={March},}
@INPROCEEDINGS{7005348, 
author={M. Moser and M. Pfeiffer and J. Pichler}, 
booktitle={Proceedings of the 2014 IEEE Emerging Technology and Factory Automation (ETFA)}, 
title={A novel domain-specific language for the robot welding automation domain}, 
year={2014}, 
pages={1-6}, 
abstract={Implementation, fault analysis, and maintenance of robot welding automation solutions are traditionally restricted to professional software developers only. Program code is written in a general purpose programming language and, hence, unmanageable by other stakeholders with limited or no programming skills. To tackle this problem we have implemented a domain-specific language (DSL) specifically designed to the domain of robot welding automation and to be intuitively manageable by all stakeholders. The created DSL supports a textual and visual notation and is embedded within a full featured tool chain which let our customer fully replace the creation and maintenance of welding automation solutions by our DSL-based development approach.}, 
keywords={programming languages;robotic welding;DSL-based development approach;domain-specific language;fault analysis;program code;programming language;robot welding automation;stakeholders;Automation;DSL;Programming;Robot control;Visualization;Welding;Domain-Specific Language;Industrial Automation}, 
doi={10.1109/ETFA.2014.7005348}, 
ISSN={1946-0740}, 
month={Sept},}
@INPROCEEDINGS{7527746, 
author={M. Bar-Sinai and L. Sweeney and M. Crosas}, 
booktitle={2016 IEEE Security and Privacy Workshops (SPW)}, 
title={DataTags, Data Handling Policy Spaces and the Tags Language}, 
year={2016}, 
pages={1-8}, 
abstract={Widespread sharing of scientific datasets holds great promise for new scientific discoveries and great risks for personal privacy. Dataset handling policies play the critical role of balancing privacy risks and scientific value. We propose an extensible, formal, theoretical model for dataset handling policies. We define binary operators for policy composition and for comparing policy strictness, such that propositions like "this policy is stricter than that policy" can be formally phrased. Using this model, The policies are described in a machine-executable and human-readable way. We further present the Tags programming language and toolset, created especially for working with the proposed model. Tags allows composing interactive, friendly questionnaires which, when given a dataset, can suggest a data handling policy that follows legal and technical guidelines. Currently, creating such a policy is a manual process requiring access to legal and technical experts, which are not always available. We present some of Tags' tools, such as interview systems, visualizers, development environment, and questionnaire inspectors. Finally, we discuss methodologies for questionnaire development. Data for this paper include a questionnaire for suggesting a HIPAA compliant data handling policy, and formal description of the set of data tags proposed by the authors in a recent paper.}, 
keywords={data handling;data privacy;programming languages;DataTags;Tags programming language;data handling policy space;privacy risk;Cryptography;Data handling;Data privacy;Interviews;Law;DSL;data handling policy;data repository;datatags;legal modeling}, 
doi={10.1109/SPW.2016.11}, 
month={May},}
@INPROCEEDINGS{7207420, 
author={O. Günalp and C. Escoffier and P. Lalanda}, 
booktitle={Services Computing (SCC), 2015 IEEE International Conference on}, 
title={Rondo: A Tool Suite for Continuous Deployment in Dynamic Environments}, 
year={2015}, 
pages={720-727}, 
abstract={Driven by the emergence of new computing environments, dynamically evolving software systems makes it impossible for developers to deploy software with human-centric processes. Instead, there is an increasing need for automation tools that continuously deploy software into execution, in order to push updates or adapt existing software regarding contextual and business changes. Existing solutions fall short on providing fault-tolerant, reproducible deployments that can scale on heterogeneous environments. In this paper we present Rondo, a tool suite that enables continuous deployment for dynamic, service-oriented applications. At the center of these tools, we propose a deterministic and idem potent deployment process. We provide with Rondo a deployment manager that implements this process and capable of conducting deployments and continuously adapting applications according to the changes in the current target platform. The tool suite also includes a domain-specific language for describing deployment requests. We validate our approach in multiple projects, for provisioning the platform as well as for installing applications and continuous reconfigurations.}, 
keywords={software fault tolerance;software tools;Rondo;application installing;automation tools;computing environments;continuous deployment;deployment requests;deterministic process;domain-specific language;dynamic application;dynamic environments;fault-tolerant deployment;human-centric processes;idem potent deployment process;reproducible deployment;service-oriented application;software systems;tool suite;Assembly;Computer architecture;Context;DSL;Program processors;Runtime;Continuous Deployment;Dynamism;Service-Oriented Computing}, 
doi={10.1109/SCC.2015.102}, 
month={June},}
@INPROCEEDINGS{6903184, 
author={N. Tcholtchev and G. Dudeck and M. Wagner and C. Hein and A. Prakash and T. Ritter}, 
booktitle={Computer Software and Applications Conference Workshops (COMPSACW), 2014 IEEE 38th International}, 
title={Integrating the Modelica DSL into a Platform for Model-Based Tool Interoperability}, 
year={2014}, 
pages={528-534}, 
abstract={Domain Specific Languages (DSL) are an important concept that is used in industry, in order to enable the fast and cost efficient design of specific functions/components, and/or to target particular aspects of the systems' development and operation. In the current paper, we describe our experiences on the integration of the Modelica DSL into a platform that enables the integration and interoperability of model-based tools across the various phases of the system development process. Thereby, we present our approach, compare different tools which were used, in order to efficiently complete the integration, and finally exemplify the outcome on a case study from the automotive domain.}, 
keywords={open systems;software engineering;specification languages;Modelica DSL;automotive domain;domain specific languages;model-based tool interoperability;model-based tools;system development process;systems development;systems operation;Adaptation models;DSL;Interoperability;Mathematical model;Object oriented modeling;Unified modeling language;DSL;MDE;Model Bus;Modelica;domain specific languages;model driven engineering;modeling;tool interoperability}, 
doi={10.1109/COMPSACW.2014.88}, 
month={July},}
@INPROCEEDINGS{7121747, 
author={M. Timmers and D. Eckard}, 
booktitle={Optical Fiber Communications Conference and Exhibition (OFC), 2015}, 
title={Copper is the new black for ultra broadband networks}, 
year={2015}, 
pages={1-3}, 
abstract={G.fast, the newest ITU protocol for copper access, will deliver anywhere from hundreds of Mb/s to close to 1Gb/s. Operators have an additional tool at their disposal to provide fiber like speeds over existing copper.}, 
keywords={broadband networks;optical fibre subscriber loops;protocols;G.fast;ITU protocol;copper access;fiber-to-the-home;ultra broadband networks;Broadband communication;Copper;DSL;Optical fiber cables;Optical fiber devices;Optical fiber networks;Optical fiber subscriber loops}, 
month={March},}
@INPROCEEDINGS{7577380, 
author={N. Kapre and S. Bayliss}, 
booktitle={2016 26th International Conference on Field Programmable Logic and Applications (FPL)}, 
title={Survey of domain-specific languages for FPGA computing}, 
year={2016}, 
pages={1-12}, 
abstract={High-performance FPGA programming has typically been the exclusive domain of a small band of specialized hardware developers. They are capable of reasoning about implementation concerns at the register-transfer level (RTL) which is analogous to assembly-level programming in software. Sometimes these developers are required to push further down to manage even lower levels of abstraction closer to physical aspects of the design such as detailed layout to meet critical design constraints. In contrast, software programmers have long since moved away from textual assembly-level programming towards relying on graphical integrated development environments (IDEs), high-level compilers, smart static analysis tools and runtime systems that optimize, manage and assist the program development tasks. Domain-specific languages (DSLs) can bridge this productivity gap by providing higher levels of abstraction in environments close to the domain of application expert. DSLs carefully limit the set of programming constructs to minimize programmer mistakes while also enabling a rich set of domain-specific optimizations and program transformations. With a large number of DSLs to choose from, an inexperienced FPGA user may be confused about how to select an appropriate one for the intended domain. In this paper, we review a combination of legacy and state-of-the-art DSLs available for FPGA development and provide a taxonomy and classification to guide selection and correct use of the framework.}, 
keywords={electronic engineering computing;field programmable gate arrays;parallel programming;program compilers;program diagnostics;programming environments;software engineering;DSL;FPGA computing;RTL;domain-specific languages;domain-specific optimizations;graphical IDE;graphical integrated development environments;high-level compilers;high-performance FPGA programming;productivity gap;program transformations;register-transfer level;runtime systems;smart static analysis tools;textual assembly-level programming;DSL;Field programmable gate arrays;Hardware;Hardware design languages;Productivity;Programming;Software}, 
doi={10.1109/FPL.2016.7577380}, 
month={Aug},}
@INPROCEEDINGS{6240414, 
author={M. J. Villanueva}, 
booktitle={2012 Sixth International Conference on Research Challenges in Information Science (RCIS)}, 
title={An agile model-driven approach for simplifying the development of genetic analysis tools}, 
year={2012}, 
pages={1-6}, 
abstract={In the last few years, genetic researchers have started to assemble their own genetic analysis tools by reusing and combining available software. Because software development environments are not widely accepted in the Genetics community, geneticists become software developers, and they are force to integrate different solutions and to face programming issues without the required knowledge. A solution to this issue lives in the simplification of the tailored tool development. Geneticists demand development environments where: 1) the required data can be expressed according to their knowledge, and 2) the most common functionality can be easily integrated without programming skills. This PhD work proposes the use of the model-driven paradigm for addressing both concerns and presents an agile way for developing genetic analysis tools.}, 
keywords={bioinformatics;genetics;programming environments;software prototyping;software reusability;software tools;PhD work;agile model-driven approach;genetic analysis tool development;geneticists;genetics community;model-driven paradigm;programming issues;software development environments;software reusability;tailored tool development;Bioinformatics;DNA;DSL;Genomics;Programming;Software;Bioinformatics;Domain-specific languages;Model-driven development}, 
doi={10.1109/RCIS.2012.6240414}, 
ISSN={2151-1349}, 
month={May},}
@ARTICLE{6200023, 
author={V. Garcia-Diaz and B. C. P. G-Bustelo and O. Sanjuan-Martinez and E. R. Nunez Valdez and J. M. C. Lovelle}, 
journal={IET Software}, 
title={MCTest: towards an improvement of match algorithms for models}, 
year={2012}, 
volume={6}, 
number={2}, 
pages={127-139}, 
abstract={Owing to the increasing importance of model-driven engineering (MDE) and the changes experienced by software systems over their life cycle, the calculation, representation and visualisation of matches and differences between two different versions of the same model are becoming more necessary and useful. This study shows the need for improvement in the algorithms for calculating the relationships between models and presents a tool to test different implementations, thus reducing the effort required to measure, compare or create new algorithms. To demonstrate the need for improvement and the framework developed, the authors have created different models that conform to the metamodel of a domain-specific language. Subsequently, the authors compared these models using the algorithms of the eclipse modelling framework (EMF) Compare tool, part of the eclipse modeling project, which is the framework of reference for MDE. Thus, in the case study, the authors tool is used to measure the quality of the comparisons performed by EMF Compare.}, 
keywords={data structures;data visualisation;software engineering;specification languages;EMF Compare tool;MCTest;eclipse modelling framework;match algorithm;match calculation;match representation;match visualisation;model-driven engineering;software system}, 
doi={10.1049/iet-sen.2011.0040}, 
ISSN={1751-8806}, 
month={April},}
@INPROCEEDINGS{6497134, 
author={B. Cole and G. Dubos and P. Banazadeh and J. Reh and K. Case and Y. F. Wang and S. Jones and F. Picha}, 
booktitle={Aerospace Conference, 2013 IEEE}, 
title={Domain-specific languages and diagram customization for a concurrent engineering environment}, 
year={2013}, 
pages={1-12}, 
abstract={A major open question for advocates of Model-Based Systems Engineering (MBSE) is the question of how system and subsystem engineers will work together. The Systems Modeling Language (SysML), like any language intended for a large audience, is in tension between the desires for simplicity and for expressiveness. In order to be more expressive, many specialized language elements may be introduced, which will unfortunately make a complete understanding of the language a more daunting task. While this may be acceptable for systems modelers, it will increase the challenge of including subsystem engineers in the modeling effort. One possible answer to this situation is the use of Domain-Specific Languages (DSL), which are fully supported by the Unified Modeling Language (UML). SysML is in fact a DSL for systems engineering. The expressive power of a DSL can be enhanced through the use of diagram customization. Various domains have already developed their own schematic vocabularies. Within the space engineering community, two excellent examples are the propulsion and telecommunication subsystems. A return to simple box-and-line diagrams (e.g., the SysML Internal Block Diagram) are in many ways a step backward. In order allow subsystem engineers to contribute directly to the model, it is necessary to make a system modeling tool at least approximate in accessibility to drawing tools like Microsoft PowerPoint and Visio. The challenge is made more extreme in a concurrent engineering environment, where designs must often be drafted in an hour or two. In the case of the Jet Propulsion Laboratory's Team X concurrent design team, a subsystem is specified using a combination of PowerPoint for drawing and Excel for calculation. A pilot has been undertaken in order to meld the drawing portion and the production of master equipment lists (MELs) via a SysML authoring tool, MagicDraw. Team X currently interacts with its customers in a process of sharing presentations. There are severa- inefficiencies that arise from this situation. The first is that a customer team must wait two weeks to a month (which is 2-4 times the duration of most Team X studies themselves) for a finalized, detailed design description. Another is that this information must be re-entered by hand into the set of engineering artifacts and design tools that the mission concept team uses after a study is complete. Further, there is no persistent connection to Team X or institutionally shared formulation design tools and data after a given study, again reducing the direct reuse of designs created in a Team X study. This paper presents the underpinnings of subsystem DSLs as they were developed for this pilot. This includes specialized semantics for different domains as well as the process by which major categories of objects were derived in support of defining the DSLs. The feedback given to us by the domain experts on usability, along with a pilot study with the partial inclusion of these tools is also discussed.}, 
keywords={Unified Modeling Language;aerospace propulsion;concurrent engineering;programming language semantics;systems engineering;DSL;Excel;Jet Propulsion Laboratory;MBSE;MEL;MagicDraw;Microsoft PowerPoint;SysML;Team X concurrent design team;UML;Visio;box-and-line diagrams;concurrent engineering environment;diagram customization;domain-specific languages;engineering artifacts;internal block diagram;master equipment lists;model-based systems engineering;propulsion;space engineering community;specialized language elements;specialized semantics;subsystem engineers;systems modeling language;telecommunication subsystems;unified modeling language;Concurrent engineering;Laboratories;Libraries;Propulsion;Servers;Shape;Tin}, 
doi={10.1109/AERO.2013.6497134}, 
ISSN={1095-323X}, 
month={March},}
@INPROCEEDINGS{7119032, 
author={L. Pomante and S. Candia and E. Incerto}, 
booktitle={2015 IEEE Aerospace Conference}, 
title={A Model-Driven approach for the development of an IDE for Spacecraft on-board software}, 
year={2015}, 
pages={1-17}, 
abstract={This paper presents the application of a Model-Driven Engineering (MDE) approach to the aerospace domain. Specifically, it shows the Model-Driven Development (MDD) of an Integrated Development Environment (IDE) for a Domain-Specific Language (DSL) targeted to the achievement of the so called “Spacecraft on-board software flexibility”. In fact, the goal of the presented work has been to deploy a full-featured IDE to be used for the development of the “On-board Command Procedures” (OBCPs). The OBCPs coding is done by using the “OBCP Definition Language” (ODL), specified by Thales Alenia Space Italy (TASI) on the basis of the requirements stated in the “Space Engineering: Spacecraft On-board Control Procedures” ECSS standard (ECSS-E-ST-70-01, 16 April 2010). This standard does not impose specific language syntax but provides the guidelines for its specification. By following such guidelines and by exploiting some MDE technologies and tools, such as Eclipse Modeling Framework (EMF) and Xtext, it has been possible to realize an Eclipse-based IDE able to provide to the ODL developer the entire features essential in a modern environment for software development. The considered features include the “traditional” ones as syntax-highlighting, code-completion, version-control, on-line error-checking, and also “advanced” ones like syntactic validation, semantic validation, and integrated code compilation. Moreover, by means of the adopted MDE approach, a very large part of the IDE code has been automatically generated starting from the Extended Backus-Naur Form (EBNF) specification of the ODL grammar so allowing for the IDE developers to be more focused on validation issues and on the quality of product than on the coding activity. All this has been obtained by following the paradigm “coding equals modeling”, for which each program represents a behavioral model compl- ant to the meta-model specified by the grammar of the language itself. The obtained result is a professional product that satisfies all the expected requirements, but this would be just a starting point since the ultimate goal of this work is to contribute to fostering the adoption of MDE approaches in the spacecraft software domain.}, 
keywords={aerospace computing;configuration management;program verification;programming environments;software quality;space vehicles;specification languages;DSL;EBNF specification;ECSS standard;ECSS-E-ST-70-01;EMF;Eclipse modeling framework;Eclipse-based IDE;IDE code;IDE development;MDD;MDE approach;MDE technologies;OBCP definition language;ODL;ODL grammar;TASI;Thales Alenia Space Italy;Xtext;aerospace domain;behavioral model;code-completion;coding activity;domain-specific language;extended Backus-Naur form specification;integrated code compilation;integrated development environment;language grammar;language syntax;model-driven engineering approach;on-board command procedures;on-line error-checking;product quality;semantic validation;software development;space engineering;spacecraft on-board software flexibility;spacecraft onboard control procedures;syntactic validation;version-control;Biographies;DSL;Syntactics;Terminology;Unified modeling language}, 
doi={10.1109/AERO.2015.7119032}, 
ISSN={1095-323X}, 
month={March},}
@INPROCEEDINGS{7027503, 
author={N. Ferry and H. Song and A. Rossini and F. Chauvel and A. Solberg}, 
booktitle={Utility and Cloud Computing (UCC), 2014 IEEE/ACM 7th International Conference on}, 
title={CloudMF: Applying MDE to Tame the Complexity of Managing Multi-cloud Applications}, 
year={2014}, 
pages={269-277}, 
abstract={The market of cloud computing encompasses an ever-growing number of cloud providers offering a multitude of infrastructure-as-a-service (IaaS) and platform-as-a-service (PaaS) solutions. The heterogeneity of these solutions hinders the proper exploitation of cloud computing since it prevents interoperability and promotes vendor lock-in, which increases the complexity of executing and managing multi-cloud applications (i.e., Applications that can be deployed across multiple cloud infrastructures and platforms). Providers of multi-cloud applications seek to exploit the peculiarities of each cloud solution and to combine the delivery models of IaaS and PaaS in order to optimise performance, availability, and cost. In this paper, we show how the Cloud Modelling Framework leverages upon model-driven engineering to tame this complexity by providing: (i) a tool-supported domain-specific language for specifying the provisioning and deployment of multi-cloud applications, and (ii) a models@run-time environment for enacting the provisioning, deployment, and adaptation of these applications.}, 
keywords={cloud computing;open systems;IaaS;MDE;PaaS;cloud MF;cloud computing;cloud modelling framework;infrastructure-as-a-service;interoperability;model-driven engineering;multicloud applications;platform-as-a-service;tool-supported domain-specific language;Adaptation models;Biological system modeling;Cloud computing;Containers;Engines;Sensors;Syntactics;Cloud ML;Cloud computing;Model-driven engineering;multi-cloud}, 
doi={10.1109/UCC.2014.36}, 
month={Dec},}
@INPROCEEDINGS{6735827, 
author={C. Liu and B. H. Shen and S. Y. Oh and M. Gerla and J. Palsberg and C. Banner and R. Butler}, 
booktitle={MILCOM 2013 - 2013 IEEE Military Communications Conference}, 
title={Agnostic Protocol Translation for Cross-Domain Information Sharing}, 
year={2013}, 
pages={1447-1452}, 
abstract={Network translation gateways can provide seamless interoperability among different airborne, ground and maritime domains. Effective interconnection between waveforms and protocols through the gateways requires manual intensive development and specialized protocol expertise. Therefore, enabling building versatile gateways that can effectively translate those protocols across different network domains is of utmost importance to improve system interoperability. High-level domain specific languages have been utilized to support agnostic protocol interoperability. However, protocol-specific knowledge specification, the core of protocol translation, is still left to protocol experts with manual coding without advanced tools in support of simplification, guidance or verification. Such a manual and unsupervised method of generating translation logic is complex, time-consuming and error-prone. In order to overcome these problems with much more productive gateway development, we present a novel, visual protocol-agnostic translation toolkit in this paper. This toolkit offers three advanced features: 1) simple, intuitive visualized specification of protocol-specific knowledge, 2) graph-based translation logic verification, and 3) automatic gateway generation. The first two features have not been addressed in currently available protocol translation solutions.}, 
keywords={high level languages;internetworking;open systems;protocols;agnostic protocol interoperability;agnostic protocol translation;airborne domains;automatic gateway generation;cross-domain information sharing;graph-based translation logic verification;ground domains;high-level domain specific languages;maritime domains;network translation gateways;protocol-specific knowledge specification;visual protocol-agnostic translation toolkit;DSL;Grammar;Logic gates;Protocols;Semantics;Syntactics;Visualization;automatic translation;cross domain communication;domain specific language;protocol-agnostic translation;system interoperative;visual specificatin}, 
doi={10.1109/MILCOM.2013.245}, 
ISSN={2155-7578}, 
month={Nov},}
@INPROCEEDINGS{7018502, 
author={K. Jacek and K. Nowakowski and Ż Kamil}, 
booktitle={Model-Driven Engineering and Software Development (MODELSWARD), 2014 2nd International Conference on}, 
title={Domain-specific languages as tools for teaching 3D graphics}, 
year={2014}, 
pages={498-508}, 
abstract={Model-driven engineering is constantly gaining importance, expanding to domains varying from the Web to the 3D graphics. Domain-specific languages besides contributing to the development process can be used in a didactic process conducted not only in schools. Thus this paper introduces new domain-specific language and discusses its usage in teaching construction of shaders and materials while working with 3D graphics. It presents the authors stance regarding the usefulness of domain-specific languages in education of 3D graphics development.}, 
keywords={computer graphics;computer science education;software engineering;specification languages;teaching;3D graphics development education;3D graphics teaching;didactic process;domain-specific languages;materials;model-driven engineering;shaders;DSL;Education;Games;Graphics;Materials;Solid modeling;Three-dimensional displays;3D Graphics;Domain-specific Languages;Model-Driven Engineering;Modeling Shaders;Teaching}, 
month={Jan},}
@INPROCEEDINGS{6275847, 
author={Y. Benchaïb and C. Chaudet}, 
booktitle={Sensor, Mesh and Ad Hoc Communications and Networks (SECON), 2012 9th Annual IEEE Communications Society Conference on}, 
title={Using VIRMANEL and SILUMOD to study protocol for mobile multihop networks}, 
year={2012}, 
pages={76-78}, 
abstract={In this demonstration, we show how to use a couple of tools we developed, VIRMANEL and SIMULOD, to study how the true implementation of an ad hoc routing protocol behaves under various mobility scenarios. VIRMANEL is a tool that configure virtual machines connections with respect to mobility. It features a GUI to observe the behavior of mobile nodes. SILUMOD is a domain-specific language that allows to describe mobility models. It defines the positions of the trajectory of moving through the appropriate keywords. These tools, published under the LGPL license, are used here to study the Linux implementation of OLSR.}, 
keywords={mobile ad hoc networks;routing protocols;GUI;LGPL license;Linux implementation;OLSR;SILUMOD;VIRMANEL;ad hoc routing protocol;domain-specific language;mobile multihop networks;mobile nodes;mobility models;mobility scenarios;virtual machines connections;Ad hoc networks;Mobile computing;Spread spectrum communication}, 
doi={10.1109/SECON.2012.6275847}, 
ISSN={2155-5486}, 
month={June},}
@INPROCEEDINGS{7152798, 
author={T. Duval and A. Blouin and J. M. Jézéquel}, 
booktitle={2014 IEEE 7th Workshop on Software Engineering and Architectures for Realtime Interactive Systems (SEARIS)}, 
title={When Model Driven Engineering meets virtual reality: Feedback from application to the Collaviz framework}, 
year={2014}, 
pages={27-34}, 
abstract={Despite the increasing use of 3D Collaborative Virtual Environments (3D CVE), their development is still a cumbersome task. The various concerns to consider (distributed system, 3D graphics, etc.) complexify the development as well as the evolution of CVEs. Software engineering recently proposed methods and tools to ease the development process of complex software systems. Among them, Model-Driven Engineering (MDE) considers models as first-class entities. A model is an abstraction of a specific aspect of the system under study for a specific purpose. MDE thus breaks down a complex system into as many models for different purposes, such as: generating code from models; building domain specific programming/modeling languages (DSL); generating tools such as graphical or textual editors. In this paper we leverage MDE for developing 3D CVEs. We show how the Collaviz framework took benefits from a DSL we built. The benefits are multiple: 3D CVE designers can focus on the behavior of their virtual objects without bothering with distributed and graphics features; configuring the content of 3D CVEs and their deployment on various software and hardware platforms can be automated through code generation. We detail the development process we propose and the experiments we conducted on Collaviz.}, 
keywords={groupware;program compilers;software engineering;specification languages;virtual reality;3D CVE;3D collaborative virtual environments;Collaviz framework;DSL;MDE;code generation;development process;domain specific modeling languages;domain specific programming language;generating tools;graphical editor;model driven engineering;software engineering;textual editor;virtual reality;Collaboration;Compass;Graphics;Hardware;Solid modeling;Three-dimensional displays;Transforms;Collaborative Virtual Environments;Frameworks;Model Driven Engineering;Software Engineering;Virtual Reality}, 
doi={10.1109/SEARIS.2014.7152798}, 
ISSN={2328-7772}, 
month={March},}
@INPROCEEDINGS{6229806, 
author={S. Karus}, 
booktitle={2012 Second International Workshop on Developing Tools as Plug-Ins (TOPI)}, 
title={XML development with plug-ins as a service}, 
year={2012}, 
pages={25-30}, 
abstract={XML has quickly become a mainstream language in software development. Not only is it used for message and document interchange, it is also used to define application logic and interfaces. However, modern general purpose integrated development environments have rather limited support for XML development. The wide variety of XML based languages makes it a challenge to build tools for comprehensive support of XML development. In this paper, we present a library exposed as an add-in for Microsoft Visual Studio and a command line tool to improve the experience of editing XML files by providing access to subscribable service-based pluggable helper tools. The tools offer developers new means to check their XML against good and bad practices and possibly even automatically fix errors in XML or improve the files conformance with development guidelines.}, 
keywords={XML;software libraries;Microsoft Visual Studio;XML based language;XML development;XML file editing;application logic;command line tool;document interchange;interface;library;message interchange;plug-in;software development;subscribable service-based pluggable helper tool;DSL;Guidelines;Libraries;Programming;Software;Visualization;XML;IDE;Visual Studio;XML;automation;quality assurance;rules;services}, 
doi={10.1109/TOPI.2012.6229806}, 
ISSN={2327-0748}, 
month={June},}
@INPROCEEDINGS{6861074, 
author={M. El Hamlaoui and S. Ebersold and B. Coulette and M. Nassar and A. Anwar}, 
booktitle={2014 IEEE Eighth International Conference on Research Challenges in Information Science (RCIS)}, 
title={Heterogeneous models matching for consistency management}, 
year={2014}, 
pages={1-12}, 
abstract={This work is situated in the context of the application of Model Driven Engineering to complex systems view-based modelling. In fact, view-based models - called also partial models - are manipulated by different actors (designers), and are thus generally heterogeneous, that is, described with different DSLs (Domain Specific Languages). Instead of building a single global model, which is not realistic, we propose to organize the different partial models as a network of related models, which provides a global view of the system through a correspondence model. As models are modelled separately by different designers, they also evolve separately that induces a problem of consistency. To solve it, we propose a semi-automatic process based on the correspondence model allowing detecting changes, calculating their impacts, and proposing modifications to maintain the consistency among them. The approach is supported by a tool chain and illustrated by the example of a Bug Tracking System.}, 
keywords={software engineering;Domain Specific Languages;consistency management;correspondence model;heterogeneous model matching;model driven engineering;Abstracts;Adaptation models;Analytical models;Business;DSL;Information systems;Unified modeling language;Heterogeneous models;change processing;consistency;correspondence model}, 
doi={10.1109/RCIS.2014.6861074}, 
ISSN={2151-1349}, 
month={May},}
@INPROCEEDINGS{6690551, 
author={A. Mos and T. Jacquin}, 
booktitle={2013 17th IEEE International Enterprise Distributed Object Computing Conference Workshops}, 
title={Improving Process Robustness through Domain-Specific Model Transformations}, 
year={2013}, 
pages={188-193}, 
abstract={Many forward-thinking organizations have adopted domain-specific languages (DSL) as the preferred method for describing business processes. Using DSL-based descriptions helps in removing uncertainty from the semantics of process models. DSLs can evolve in a managed way and with proper versioning of individual processes the original intentions of process designers can be preserved over time. However in collaborative projects, business processes written in different DSLs need to be converted to a common denominator format to facilitate exchange. Due to its widespread adoption, BPMN is ideally placed to serve as the exchange language for complex, cross-domain collaborations. This paper presents an approach for automatic two-way synchronization of domain-specific process models with BPMN diagrams. This approach can be valuable when collaboration between different stakeholders with different expertise is required, as well as when the company wants to leverage its investments in a BPM suite across its process portfolio. In addition, this approach ensures that changes to processes executed through the BPMS are valid with respect to their domain representations, minimizing the potential for runtime problems that are difficult to understand.}, 
keywords={business data processing;investment;specification languages;BPMN diagrams;DSL-based descriptions;business process description;business process model and notation;collaborative projects;domain representations;domain-specific languages;domain-specific model transformations;domain-specific process model;investments;process model semantics;process portfolio;process robustness improvement;stakeholder collaboration;two-way synchronization;DSL;Domain specific languages;Organizations;Semantics;Standards organizations;BPM;BPMN;domain-specific language;modeling;tooling}, 
doi={10.1109/EDOCW.2013.28}, 
ISSN={2325-6583}, 
month={Sept},}
@INPROCEEDINGS{6928791, 
author={E. Kühn and S. Craß and T. Hamböck}, 
booktitle={2014 40th EUROMICRO Conference on Software Engineering and Advanced Applications}, 
title={Approaching Coordination in Distributed Embedded Applications with the Peer Model DSL}, 
year={2014}, 
pages={64-68}, 
abstract={Coordination in distributed embedded systems requires complex synchronization of many concurrent activities. This task becomes especially difficult when network and system failures have to be assumed. The Peer Model is a novel programming model for the design of coordination strategies among multiple nodes, aiming to bridge design and implementation. A major advantage is that designs based on the Peer Model are very flexible regarding changing requirements and policies. The motivating use case is an application in the railway domain where embedded nodes detect approaching trains and route this information over several forwarder nodes to the level crossing. In this paper, we present a Domain Specific Language for the Peer Model which allows to automatically generate a graphical documentation and source code for different embedded platforms. It lays the foundations for an embedded system software development tool chain. We prove the feasibility by implementing an event notification strategy for the level crossing use case.}, 
keywords={concurrency control;distributed processing;embedded systems;railway engineering;software engineering;source code (software);system documentation;approaching train detection;complex synchronization;concurrent activities;distributed embedded systems;domain specific language;embedded nodes;embedded platforms;embedded system software devel- opment toolchain;event notification strategy;forwarder nodes;graphical documentation;level crossing;peer model;programming model;railway domain;source code;system failures;Containers;Documentation;Middleware;Peer-to-peer computing;Unified modeling language;Wiring}, 
doi={10.1109/SEAA.2014.72}, 
ISSN={1089-6503}, 
month={Aug},}
@INPROCEEDINGS{6511840, 
author={A. Bariic and V. Amaral and M. Goulão}, 
booktitle={Quality of Information and Communications Technology (QUATIC), 2012 Eighth International Conference on the}, 
title={Usability Evaluation of Domain-Specific Languages}, 
year={2012}, 
pages={342-347}, 
abstract={Domain-Specific Languages (DSLs) are claimed to bring important productivity improvements to developers, when compared to General-Purpose Languages (GPLs). The increased Usability is regarded as one of the key benefits of DSLs when compared to GPLs, and has an important impact on the achieved productivity of the DSL users. So, it is essential to build in good usability while developing the DSL. The purpose of this proposal is to contribute to the systematic activity of Software Language Engineering by focusing on the issue of the Usability evaluation of DSLs. Usability evaluation is often skipped, relaxed, or at least omitted from papers reporting development of DSLs. We argue that a systematic approach based on User Interface experimental validation techniques should be used to assess the impact of new DSLs. For that purpose, we propose to merge common Usability evaluation processes with the DSL development process. In order to provide reliable metrics and tools we should reuse and identify good practices that exist in Human-Computer Interaction community.}, 
keywords={human computer interaction;software engineering;specification languages;user interfaces;DSL development process;GPL;domain-specific languages;general-purpose language;human-computer interaction community;software language engineering;systematic approach;usability evaluation;user interface experimental validation techniques;Domain-Specific Languages;Software Language Engineering;Usability Evaluation}, 
doi={10.1109/QUATIC.2012.63}, 
month={Sept},}
@INPROCEEDINGS{7436963, 
author={R. I. Hadiwijaya and M. M. I. Liem}, 
booktitle={2015 International Conference on Data and Software Engineering (ICoDSE)}, 
title={A domain-specific language for automatic generation of checkers}, 
year={2015}, 
pages={7-12}, 
abstract={One of the important modules of a black-box automatic program grader is a "checker". In programming competition environment, a checker is a program written for the purpose to check the output of the contestant's program for a task that has many solutions. Usually, a checker is written manually as needed. In this paper, the idea of the output checker in the programming competition environment is extended to input checker and source code checker as a part of the automatic grader in our programming learning environment. Input checker validates the input coverage. The source code checker is used to validate a set of properties from a source code against the given coding specification. A Domain-Specific Language (DSL) grammar is designed and developed as a specification for the automatic generation of the output, input, and source code checkers. The DSL grammar and the checker generator tool set are used to evaluate source codes in our programming class. By writing the checkers specification in DSL, the specification is automatically documented and can be reused for similar properties.}, 
keywords={grammars;program verification;programming languages;source code (software);DSL grammar;black-box automatic program grader;checker generator tool;checkers automatic generation;domain-specific language;input checker;source code checker;DSL;Domain specific languages;Encoding;Generators;Programming;Testing;Domain-Specific Language;automatic program grading;property checker}, 
doi={10.1109/ICODSE.2015.7436963}, 
month={Nov},}
@INPROCEEDINGS{6840036, 
author={V. Vujović and M. Maksimović and B. Perišić and V. Milošević}, 
booktitle={Applied Computational Intelligence and Informatics (SACI), 2014 IEEE 9th International Symposium on}, 
title={A Graphical Editor for RESTful Sensor Web networks modeling}, 
year={2014}, 
pages={61-66}, 
abstract={Effectiveness of communication is measured by speed, ease, and accuracy in which the information can be understood. From the cognitive aspect graphical presentations are usually more effective than textual ones, especially when communication between end-users and/or domain practitioners is concerned. Model-Driven Engineering (MDE) graphical tools have become extremely popular concerning the development of applications for a large number of domains. In this paper the emphasis is put on the design and implementation of Graphical Editor for RESTful Sensor Web Network in order to equip designers, with no expert knowledge in specific solution-domain, with a tool that would enable them to easily define tasks, specify network architecture and implement RESTful services. Based on the pilot sensor network design model, the verification, validation and proper functionality of proposed Graphical Editor are performed.}, 
keywords={Web services;formal specification;formal verification;software architecture;wireless sensor networks;MDE graphical tools;RESTful sensor Web networks modeling;RESTful services;cognitive aspect;communication effectiveness;graphical editor functionality;graphical editor validation;graphical editor verification;graphical presentations;model-driven engineering graphical tools;network architecture specification;sensor network design model;wireless sensor network;Buildings;Computational modeling;DSL;Internet;Logic gates;Software;Wireless sensor networks}, 
doi={10.1109/SACI.2014.6840036}, 
month={May},}
@INPROCEEDINGS{6909375, 
author={V. Viyović and M. Maksimović and B. Perisić}, 
booktitle={IEEE 18th International Conference on Intelligent Engineering Systems INES 2014}, 
title={Sirius: A rapid development of DSM graphical editor}, 
year={2014}, 
pages={233-238}, 
abstract={Looking through the history of software development there are two mutually agreed factors used for software process and product effectiveness measurement: the level of abstraction and the level of reusability. The essential goals, among many, that have to be achieved are: increasing developer's productivity, decreasing cost (in time and money) of software construction while preserving desired quality level and improving software reusability and maintainability. Model Driven Software Development (MDSD), which is generally based on the model-centric approach to software development, appears as a challenging paradigm. MDSD is focused on the creation of semantically rich models concerning problem and solution domains while leaving the execution domain to the model based code generators. Created models are often based on a graphical representation and supported by graphical design tools, which, in the most common case, can't be universal. Depending on problem-domain, and based on Domain-Specific Model (DSM) appropriate graphical editing tool must be created. In this paper the emphasis is put on Sirius framework for developing a DSM Graphical Editor, which simplifies the product specification, reduces design time and rapidly increases the overall productivity. The main advantages of Sirius framework usage have been illustrated by the creation of a RESTful Sensor Web Network Editor.}, 
keywords={cost reduction;formal specification;software maintenance;software quality;software reusability;DSM graphical editor development;MDSD;RESTful Sensor Web Network Editor;Sirius;abstraction level;developer productivity;domain-specific model;graphical design tools;graphical representation;model based code generators;model driven software development;model-centric approach;product effectiveness measurement;product specification;quality level;reusability level;software construction cost reduction;software development;software maintainability;software process;software reusability;Buildings;DSL;Java;Object oriented modeling;Semantics;Software;Unified modeling language}, 
doi={10.1109/INES.2014.6909375}, 
ISSN={1543-9259}, 
month={July},}
@INPROCEEDINGS{6805441, 
author={W. Zhang and B. Møller-Pedersen}, 
booktitle={2013 20th Asia-Pacific Software Engineering Conference (APSEC)}, 
title={Tool Integration Models}, 
year={2013}, 
volume={1}, 
pages={485-494}, 
abstract={This paper presents an extension of a previously presented tool integration approach: tool integration for different scenarios may be specified as integration models, and these integration models can be executed or form the basis of code generation for implementing integration on different platforms. Integration models cover both the data and behavior parts of tool integration. The benefits of separating the details of integration models from the models being integrated through tool integration are illustrated and it is indicated what a DSL for making integration models would be.}, 
keywords={formal specification;program compilers;software tools;DSL;code generation;tool integration models;Adaptation models;IEC standards;Semantics;Software packages;Unified modeling language;Wind turbines;Artifact;Role;integration model;tool integration}, 
doi={10.1109/APSEC.2013.70}, 
ISSN={1530-1362}, 
month={Dec},}
@ARTICLE{6840824, 
author={S. Erdweg and S. Fehrenbach and K. Ostermann}, 
journal={IEEE Software}, 
title={Evolution of Software Systems with Extensible Languages and DSLs}, 
year={2014}, 
volume={31}, 
number={5}, 
pages={68-75}, 
abstract={Domain-specific languages (DSLs) provide various advantages regarding the maintainability of software systems. Unfortunately, existing software systems don't exploit DSLs and their maintenance benefits. Based on the extensible programming language SugarJ, the authors present a process for gradually integrating DSLs into existing software systems, report on their experience in integrating three DSLs into two existing software systems, and outline a roadmap for the development of tool support for the integration of DSLs.}, 
keywords={high level languages;software maintenance;DSL;SugarJ programming language;domain-specific languages;extensible languages;software system evolution;software system maintainability;DSL;Domain specific languages;Embedded systems;Java;Maintenance engineering;Programming;Software systems;Syntactics;SugarJ;domain-specific languages;extensible programming languages;language embedding;legacy applications;software engineering;software evolution;software maintenance}, 
doi={10.1109/MS.2014.99}, 
ISSN={0740-7459}, 
month={Sept},}
@INPROCEEDINGS{6710367, 
author={E. Tyugu and P. Grigorenko}, 
booktitle={Computer Science and Information Technologies (CSIT), 2013}, 
title={Components in model-based software development}, 
year={2013}, 
pages={1-8}, 
abstract={Model-based software development (MBSD) is rapidly gaining popularity. There are two main approaches to MBSD: transformational and compositional approaches. The first has been initiated in nineties by creating UML - a universal modeling language that has become a standard for software specification, and has influenced research in software engineering. One can say that UML has initiated model-driven software engineering (MDSE). The second - compositional approach has grown out of domain-specific language development. It uses visual specifications as input, and is represented by tools like MetaEdit+ and CoCoViLa. We give a survey of these approaches, and discuss in more detail the compositional approach, paying attention at combining compositional and object-oriented software specifications.}, 
keywords={Unified Modeling Language;formal specification;object-oriented programming;CoCoViLa tool;MBSD;MetaEdit+ tool;UML;compositional approach;compositional specifications;domain-specific language development;model-based software development;object-oriented software specifications;software engineering;software specification;transformational approach;universal modeling language;visual specifications;Computational modeling;Java;Mathematical model;Object oriented modeling;Software;Unified modeling language;Visualization;compositional software design;domain-specific modelling;model driven software development;software components;structural synthesis of programs}, 
doi={10.1109/CSITechnol.2013.6710367}, 
month={Sept},}
@INPROCEEDINGS{6690566, 
author={M. Farwick and T. Trojer and M. Breu and S. Ginther and J. Kleinlercher and A. Doblander}, 
booktitle={2013 17th IEEE International Enterprise Distributed Object Computing Conference Workshops}, 
title={A Case Study on Textual Enterprise Architecture Modeling}, 
year={2013}, 
pages={305-309}, 
abstract={Today's Enterprise Architecture Management (EAM) tools are based on forms and graphical modeling capabilities via web-based applications or desktop clients. However, recent developments in textual modeling tools have not yet been considered for EA modeling in research and practice. In this paper we present a novel EAM-tool approach, called Txture, that consists of a textual modeling environment and a web-application to provide enterprise-wide architecture visualizations for different stakeholder groups. The tool is in production use at a major Austrian data center, where it proofed to be intuitive and provide efficient modeling capabilities compared to traditional approaches. In this paper we present lessons learned from the development of the tool as well as usage it and report on its benefits and drawbacks.}, 
keywords={Internet;corporate modelling;data visualisation;Austrian data center;EA modeling;EAM tools;Txture;Web based applications;desktop clients;enterprise architecture management;enterprise wide architecture visualizations;graphical modeling;textual enterprise architecture modeling;textual modeling tools;Business;Computational modeling;Computer architecture;DSL;Data visualization;Documentation;Syntactics;DSL;case study;documentation;domain-specific language;enterprise architecture;textual;viewpoint;xtext}, 
doi={10.1109/EDOCW.2013.40}, 
ISSN={2325-6583}, 
month={Sept},}
@INPROCEEDINGS{6881940, 
author={F. Rabbi and W. MacCaull}, 
booktitle={2014 IEEE 27th International Symposium on Computer-Based Medical Systems}, 
title={User-Friendly UIs for the Execution of Clinical Practice Guidelines}, 
year={2014}, 
pages={489-490}, 
abstract={Workflow management systems (WfMS) can be used to manage complex processes, such as those described by Clinical Practise Guidelines (CPG). Such processes involve a variety of stakeholders, however, frequently their interfaces are not suited to the needs of the stakeholders involved. Here we propose that WfMSs be integrated with tools to build a variety of interfaces to meet the needs of different users. Using a CPG for the management of hypertension as a case study, we give examples of user-friendly interfaces which can be built easily using our domain specific language, and which integrate with our WfMS. One interface guides the clinician in the management of the disease, allowing her him the opportunity to view and interact with the process in a more holistic fashion, recording and recalling information relevant to the patient or the task. A second interface is more suited to the patient for the self management of lifestyle parameters, while other interfaces can be used by the patient, the clinician or the manager to represent trends or aggregate data.}, 
keywords={diseases;graphical user interfaces;human computer interaction;medical computing;workflow management software;CPG execution;WfMS;clinical practice guideline execution;complex process management;disease management;domain specific language;hypertension management;lifestyle parameter self management;user-friendly UI;user-friendly interfaces;workflow management systems;Biomedical monitoring;Diseases;Educational institutions;Guidelines;Hypertension;Monitoring;clinical practice guidelines;domain specific language;user friendly interface;workflow management system}, 
doi={10.1109/CBMS.2014.104}, 
ISSN={1063-7125}, 
month={May},}
@INPROCEEDINGS{7571278, 
author={J. R. Pansare and M. Ingle}, 
booktitle={2016 International Conference on Image, Vision and Computing (ICIVC)}, 
title={Vision-based approach for American Sign Language recognition using Edge Orientation Histogram}, 
year={2016}, 
pages={86-90}, 
abstract={Hand Gesture Recognition System (HGRS) for detection of American Sign Language (ASL) alphabets has become essential tool for specific end users (i.e. hearing and speech impaired) to interact with general users via computer system. ASL has been proved to be a powerful and conventional augmentative communication tool especially for specific users. ASL consists of 26 primary letters, of which 5 are vowels and 21 are consonants. Proposed Real-time static Alphabet American Sign Language Recognizer- (A-ASLR) is designed for the recognition of ASL alphabets into their translated version in text (i.e. A to Z). The architecture of A-ASLR system is fragmented into six consequent phases namely; image capturing, image pre-processing, region extraction, feature extraction, feature matching and pattern recognition. We have used Edge Orientation Histogram (EOH) in A-ASLR system. The system is developed for detection of ASL alphabets based on Vision-based approach. It works without using colored gloves or expensive sensory gloves on hand. Our A-ASLR system achieves the recognition rate of 88.26% within recognition time of 0.5 second in complex background with mixed lightning condition.}, 
keywords={computer vision;edge detection;feature extraction;image capture;image matching;natural language processing;sign language recognition;A-ASLR system;EOH;HGRS;alphabet American sign language recognition;edge orientation histogram;feature extraction;feature matching;hand gesture recognition system;image capturing;image preprocessing;pattern recognition;region extraction;vision-based approach;Computers;DSL;Feature extraction;Image recognition;Lighting;Pattern matching;American Sign Language (ASL);Edge Orientation Histogram (EOH);Sim-EOH algorithm;static hand gesture;vision-based approach}, 
doi={10.1109/ICIVC.2016.7571278}, 
month={Aug},}
@INPROCEEDINGS{7360009, 
author={E. Bautista and N. L. Serna}, 
booktitle={Computing Conference (CLEI), 2015 Latin American}, 
title={An MDE-based graphical tool for the validation of MySQL replication models}, 
year={2015}, 
pages={1-12}, 
abstract={At modeling level, diagramming tools such as Microsoft Visio are used to design MySQL replication models. However, this type of tools do not allow validating if the MySQL replication model is free of errors, showing errors if exists. Thus, we can have erroneous documentation of the MySQL replication models. Due to the lack of this feature, this is done manually, which becomes a tedious task, time consuming and error prone. This paper proposes a MDE-based graphical modeling tool under the Eclipse platform for the automatic validation of MySQL replication models. In addition, once a model has been validated, the tool is capable of generating the mysqlreplicate commands of configuration. The results of the experiments for the errors correction of MySQL replication models with 25 servers demonstrate that by using the proposed tool the time is reduced in more than 87% compared with the tool Microsoft Visio 2013.}, 
keywords={SQL;formal verification;programming environments;relational databases;replicated databases;Eclipse platform;MDE-based graphical modeling tool;Microsoft Visio 2013;MySQL replication models;automatic validation;model driven engineering;Biological system modeling;Computational modeling;DSL;Documentation;Error correction;Software;Unified modeling language;DSL;DSM;MDE;MySQL Replication}, 
doi={10.1109/CLEI.2015.7360009}, 
month={Oct},}
@ARTICLE{7483535, 
author={S. R. Mello Canovas and C. E. Cugnasca}, 
journal={IEEE Latin America Transactions}, 
title={Extending a Metamodel for Adaptive Programs: Specifying Adaptive Functions}, 
year={2016}, 
volume={14}, 
number={4}, 
pages={1923-1929}, 
abstract={Model Driven Engineering (MDE) is a software development approach based on the use of models as essential artifacts. In the ideal scenario, source code is automatically generated from models by steps of transformations defined by mapping functions. A metamodel is a special type of model that describes the syntax of a modeling language. They are important because mapping functions reference their elements to define transformations, allowing the application of MDE. This paper proposes an extension of a metamodel of a domain specific modeling language for adaptive programs. This extension includes metaclasses, properties and constraints for specifying adaptive functions. An existing mapping function, which generates partial source code in BADAL language, was then updated to consider the new metamodel elements, becoming able to generate code for adaptive functions from the model specification. The resulting metamodel and mapping function were used as input to generate a CASE tool for adaptive programs, allowing the use of MDE in a higher level of abstraction than before for this class of application.}, 
keywords={formal specification;program compilers;source code (software);BADAL language;CASE tool;MDE;adaptive function specification;adaptive programs;code generation;domain specific modeling language syntax;mapping functions;metamodel elements;model driven engineering;model specification;software development approach;source code;Adaptation models;Computer aided software engineering;Domain specific languages;Model driven engineering;Syntactics;Unified modeling language;Adaptive Programs;Domain Specific Language;Model Driven Engineering;Set Based Meta Modeling}, 
doi={10.1109/TLA.2016.7483535}, 
ISSN={1548-0992}, 
month={April},}
@INPROCEEDINGS{6337245, 
author={T. Holmes}, 
booktitle={Enterprise Distributed Object Computing Conference (EDOC), 2012 IEEE 16th International}, 
title={From Business Application Execution to Design Through Model-Based Reporting}, 
year={2012}, 
pages={143-153}, 
abstract={Cross-disciplinary models constitute essential instruments to master complexity. Often it is easier to relate to high-level concepts than to deal with low-level technical details. In model-driven engineering (MDE) models are designated a pivotal role from which systems are generated. As such, MDE enables different stakeholders of business applications to participate in the engineering process. Until now however, MDE does not penetrate phases beyond generation and deployment such as monitoring, analysis, and reporting. To display information from runtime and analytics it would be interesting if reporting could utilize models from design time. Therefore, this paper presents model-based reporting (MbR). Bridging the gap between reporting and design, it enables stakeholders to intuitively specify the reporting through a domain-specific language (DSL) while accelerating development cycles. In non-model-driven settings, MbR can help to introduce models as a first step towards MDE.}, 
keywords={business data processing;software engineering;DSL;MDE;MbR;business application execution;cross disciplinary models;domain specific language;engineering process;model based reporting;model driven engineering;Abstracts;Business;Context modeling;Correlation;DSL;Data models;Runtime;business applications;end-to-end;model-based;reporting}, 
doi={10.1109/EDOC.2012.25}, 
ISSN={1541-7719}, 
month={Sept},}
@INPROCEEDINGS{7382444, 
author={M. Sneps-Sneppe and D. Namiot}, 
booktitle={Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT), 2015 7th International Congress on}, 
title={On web-based domain-specific language for Internet of Things}, 
year={2015}, 
pages={287-292}, 
abstract={This paper discusses the challenges of the Internet of Things programming. Sensing and data gathering from the various sources are often the key elements of applications for Smart Cities. So, the effective programming models for them are very important. In this article, we discuss system software models and solutions, rather than network related aspects. In our paper, we present the web-based domain-specific language for Internet of Things applications. Our goal is to present the modern models for data processing in Internet of Things and Smart Cities applications. In our view, the use of this kind of tools should seriously reduce the time to develop new applications.}, 
keywords={Internet of Things;smart cities;systems software;Internet of Things;Web-based domain-specific language;smart cities;system software models;Computational modeling;Data models;Domain specific languages;Internet of things;Programming;Sensors;Smart cities;actors;domain-specific languages;micro-service;middleware;software standards}, 
doi={10.1109/ICUMT.2015.7382444}, 
month={Oct},}
@INPROCEEDINGS{6228998, 
author={N. Hallenberg and P. L. Carlsen}, 
booktitle={Automation of Software Test (AST), 2012 7th International Workshop on}, 
title={Declarative automated test}, 
year={2012}, 
pages={96-102}, 
abstract={Automated tests at the business level can be expensive to develop and maintain. One common approach is to have a domain expert instruct a QA developer to implement what she would do manually in the application. Though there exist record-replay tools specifically developed for this, these tend to scale poorly for more complicated test scenarios. We present a different solution: An Embedded Domain Specific Language (EDSL) in F#, containing the means to model the user interface, and the various manipulations of it. We hope that this DSL will bridge the gap between the business domain and technical domain of applications to such a degree that domain experts may be able to construct automatic tests without depending on QA developers, and that these tests will prove more maintainable.}, 
keywords={program testing;software quality;user interfaces;F#;QA developer;business level;declarative automated testing;domain expert;embedded domain specific language;record-replay tool;technical domain;user interface;Business;DSL;Documentation;Engines;Phantoms;Testing;User interfaces;Automated Testing;Domain Specific Language;F#;Functional Testing}, 
doi={10.1109/IWAST.2012.6228998}, 
month={June},}
@INPROCEEDINGS{7575079, 
author={E. Ruffaldi and I. Kostavelis and D. Giakoumis and D. Tzovaras}, 
booktitle={2016 21st International Conference on Methods and Models in Automation and Robotics (MMAR)}, 
title={ArchGenTool: A system-independent collaborative tool for robotic architecture design}, 
year={2016}, 
pages={7-12}, 
abstract={Complex robotic architectures require a collaborative effort in design and adherence to the design in the implementation phse. ArchGentTool is a collaborative architecture generation tool which supports the design of the robotic architecture in a multi-level fashion. It comprises high-level conceptual analysis of the system to be designed, as well as low-level implementation breakdown of its functional components, acting complementary to the ROS framework. The tool facilitates reusability and expandability of the architecture to any robotic system, as it can be adapted to different specifications. A case study with the RAMCIP service robot is presented.}, 
keywords={service robots;ArchGenTool;RAMCIP service robot;ROS framework;collaborative architecture generation tool;complex robotic architectures;high-level conceptual analysis;system-independent collaborative tool;Collaboration;Computer architecture;DSL;Hardware;Robots;Software;Unified modeling language}, 
doi={10.1109/MMAR.2016.7575079}, 
month={Aug},}
@ARTICLE{6898704, 
author={G. H. Wachsmuth and G. D. P. Konat and E. Visser}, 
journal={IEEE Software}, 
title={Language Design with the Spoofax Language Workbench}, 
year={2014}, 
volume={31}, 
number={5}, 
pages={35-43}, 
abstract={IDEs are essential for programming language developers, and state-of-the-art IDE support is mandatory for programming languages to be successful. Although IDE features for mainstream programming languages are typically implemented manually, this often isn't feasible for programming languages that must be developed with significantly fewer resources. The Spoofax language workbench is a platform for developing textual programming languages with state-of-the-art IDE support. Spoofax is a comprehensive environment that integrates syntax definition, name binding, type analysis, program transformation, code generation, and declarative specification of IDE components. It also provides high-level languages for each of these aspects. These languages are highly declarative, abstracting over the implementation of IDE features and letting engineers focus on language design.}, 
keywords={high level languages;software engineering;IDE support;Spoofax language workbench;high-level languages;language design;textual programming languages;Computer languages;DSL;Design methodology;Production;Programming;Syntactics;IDE;Spoofax;construction tools;design languages;integrated development environments;integrated environments;programming environments;programming languages;software engineering}, 
doi={10.1109/MS.2014.100}, 
ISSN={0740-7459}, 
month={Sept},}
@INPROCEEDINGS{7323105, 
author={C. Huang and A. Osaka and Y. Kamei and N. Ubayashi}, 
booktitle={Model-Driven Engineering and Software Development (MODELSWARD), 2015 3rd International Conference on}, 
title={Automated DSL construction based on software product lines}, 
year={2015}, 
pages={1-8}, 
abstract={DSL (Domain-Specific Language) is one of the important approaches for software abstraction. In the past decades, DSLs have been provided by expert engineers familiar with domain knowledge and programming language processors. It is not easy for ordinary programmers to construct DSLs for their own purposes. To deal with this problem, we propose a language workbench called Argyle that can automatically generate a DSL by only specifying a set of functions needed to the DSL and an execution platform supported by the DSL. Argyle is based on software product lines and consists of the following two steps: 1) development of the core assets for constructing a family of DSLs and 2) DSL configuration using these core assets. To demonstrate the effectiveness of our approach, we developed a prototype DSL for supporting MSR (Mining Software Repositories), the most active research field in software engineering.}, 
keywords={programming languages;software product lines;Argyle;MSR;automated DSL construction;domain-specific language;mining software repository;programming language processor;software engineering;software product line;DSL;Encoding;Metals;Program processors;Software product lines;Syntactics;Domain-specific Language;Language Workbench;Software Product Line}, 
month={Feb},}
@INPROCEEDINGS{6728120, 
author={M. Lethrech and I. Elmagrouni and M. Nassar and A. Kriouile and A. Kenzi}, 
booktitle={ISKO-Maghreb, 2013 3rd International Symposium}, 
title={A generic metamodel for adaptable service oriented systems modeling using DSM approach}, 
year={2013}, 
pages={1-6}, 
abstract={CAC (context aware computing) has recently emerged as a new computing paradigm promising adaptable systems development. Context awareness for services oriented systems (SOS) raises many challenges. Particularly, the challenge of engineering such systems which consists of the definition of modeling approaches, processes, techniques and tools to facilitate construction of these systems. In this paper, we propose a generic metamodel for Adaptable, Domain Specific and Service Oriented Systems. Our metamodel aims to facilitate the creation of Domain Specific Language (DSL) for adaptable and service oriented architecture. For a specific domain the language developer must produce their specific service metamodel based on our generic service metamodel.}, 
keywords={high level languages;service-oriented architecture;systems software;ubiquitous computing;CAC;DSM approach;adaptable domain specific service oriented systems modeling;adaptable service oriented architecture;context aware computing;domain specific language developer;generic service metamodel;Adaptation models;Computational modeling;Context;Context modeling;DSL;Unified modeling language;Adaptability;CAC;DSM;Meta Modeling;SOC}, 
doi={10.1109/ISKO-Maghreb.2013.6728120}, 
month={Nov},}
@INPROCEEDINGS{6975396, 
author={T. Holmes}, 
booktitle={2014 IEEE 18th International Enterprise Distributed Object Computing Conference Workshops and Demonstrations}, 
title={Facilitating Development and Provisioning of Service Topologies through Domain-Specific Languages}, 
year={2014}, 
pages={422-425}, 
abstract={In a model-driven engineering (MDE) context, the coordination of different roles such as enterprise architects and developers can be supported when dependencies between roles and artifacts are stated. Similarly, provisioning and deployment of service topologies can be facilitated. For specifying dependencies, an editor permits to define roles, artifacts, services, and service topologies in descriptive domain-specific languages (DSLs). Supporting coordination and automation, utilities are generated that synchronize workspaces, produce notifications, prepare the provisioning of service topologies, and perform their deployment. For showcasing the DSL editors and the coordination and automation tools a case study from a machine-to-machine context is taken. Addressing change impact and provisioning issues by minimizing turnaround cycles, the demonstration reveals possibilities of how to support MDE processes in the context of service topologies and shall foster a discussion on the potentials with regard to enterprise applications in general.}, 
keywords={DSL;Object oriented modeling;Servers;Software;Synchronization;Topology;Unified modeling language;DSL;MDE;automation;coordination;development;provisioning;service topology}, 
doi={10.1109/EDOCW.2014.72}, 
ISSN={2325-6583}, 
month={Sept},}
@INPROCEEDINGS{6642475, 
author={T. Bouabana-Tebibel and S. H. Rubin and K. Habib and S. Mellah and L. Allata}, 
booktitle={Information Reuse and Integration (IRI), 2013 IEEE 14th International Conference on}, 
title={A component-based language specific to complex systems modeling}, 
year={2013}, 
pages={217-224}, 
abstract={The modeling and design of complex systems continues to face grand challenges in feedback and control. Existing languages and tools, either textual or graphical, bring some improvement for such purposes, but much remains to be done in order to readily insure scalability. In this paper, we propose a language, which gathers specialization and composition properties. It is our belief that the latter properties bear the necessary capabilities to overcome the difficulties raised when developing these systems. The language is designed, on one hand, in a way to be specific to complex system domains. It supports, on the other hand, a component-based structure that conforms to a user-friendly component assembly. It is conceived in the spirit of SysML concepts. Its' programs generate Internal Block Diagrams. A programming tool is built on the basis of the Eclipse framework.}, 
keywords={object-oriented programming;specification languages;Eclipse framework;SysML concepts;complex system modeling;component-based language;component-based structure;domain-specific language;internal block diagrams;programming tool;user-friendly component assembly;Assembly;DSL;Grammar;Ports (Computers);Standards;Syntactics;Unified modeling language;Complex Systems;Component-Based Language;Domain-Specific Language;SysML}, 
doi={10.1109/IRI.2013.6642475}, 
month={Aug},}
@ARTICLE{6168851, 
author={D. Hrncic and M. Mernik and B. R. Bryant}, 
journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 
title={Improving Grammar Inference by a Memetic Algorithm}, 
year={2012}, 
volume={42}, 
number={5}, 
pages={692-703}, 
abstract={A memetic algorithm, a novel approach for solving NP-hard problems, has been applied in this paper for grammatical inference in the field of domain-specific languages (DSLs). DSLs are often designed by domain experts who have no knowledge about the syntax and semantics of programming languages. However, they are able to write sample programs to accomplish their goals and illustrate the features of their language. Grammatical inference is a technique to infer a context-free grammar from a set of positive (and negative) samples. This paper shows that grammatical inference may assist domain experts and software language engineers in developing DSLs by automatically producing a grammar, which describes a set of sample DSL programs. A memetic-algorithm-based tool is developed, which greatly improves results and robustness of the inference process.}, 
keywords={computational complexity;context-free grammars;evolutionary computation;inference mechanisms;programming language semantics;DSL programs;NP-hard problems;context-free grammar;domain-specific languages;grammar inference;grammatical inference;memetic algorithm;programming language semantics;programming language syntax;Domain specific languages;Grammar;Inference algorithms;Machine learning;Memetics;Domain-specific languages (DSLs);grammatical inference;memetic algorithms (MAs)}, 
doi={10.1109/TSMCC.2012.2186802}, 
ISSN={1094-6977}, 
month={Sept},}
@INPROCEEDINGS{7102598, 
author={E. Alegroth and G. Bache and E. Bache}, 
booktitle={2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)}, 
title={On the Industrial Applicability of TextTest: An Empirical Case Study}, 
year={2015}, 
pages={1-10}, 
abstract={Software systems are becoming more complex, not least in their Graphical User Interfaces (GUIs), which presents challenges for existing testing practices. Pressure to reduce time to market leaves less time for manual testing and increases the importance of test automation. Previous research has identified several generations of automated GUI-based test approaches with different cost-benefit tradeoffs. Whilst test automation provides fast quality feedback it can be associated with high costs and inability to identify defects not explicitly anticipated by the test designer. TextTest is a capture-replay tool for GUI-based testing with a novel approach that overcomes several of the challenges experienced with previous approaches. Firstly the tool supports Approval Testing, an approach where ASCII-art representations of the GUI's visual state are used to verify correct application behavior at the system level. Secondly it records and replays test scripts in a user defined domain specific language (DSL) that is readable by all stakeholders. In this paper we present a three phase industrial case study that aims to identify TextTest's applicability in industrial practice. The paper reports that the tool is associated with (1) low script development costs due to recording functionality, (2) low maintenance costs, on average 7 minutes per test case, (3) better defect finding ability than manual system testing, (4) high test case execution performance (In this case 500 test cases in 20 minutes), (5) high script readability due to DSL defined scripts, and (6) test suites that are robust to change (In this case 93 percent per iteration). However, the tool requires a higher degree of technical skill for customization work, test maintainers need skills in designing regular expressions and the tool's applicability is currently restricted to Java and Python based applications.}, 
keywords={Java;graphical user interfaces;program testing;software tools;ASCII-art representations;DSL defined scripts;Java based applications;Python based applications;TextTest;approval testing;automated GUI-based testing;capture-replay tool;graphical user interfaces;software systems;test automation;test case execution performance;user defined domain specific language;Companies;DSL;Data collection;Graphical user interfaces;Maintenance engineering;Manuals;Testing}, 
doi={10.1109/ICST.2015.7102598}, 
ISSN={2159-4848}, 
month={April},}
@INPROCEEDINGS{6601288, 
author={A. Sarimbekov and Y. Zheng and D. Ansaloni and L. Bulej and L. Marek and W. Binder and P. Tuma and Z. Qi}, 
booktitle={2013 22nd Australian Software Engineering Conference}, 
title={Productive Development of Dynamic Program Analysis Tools with DiSL}, 
year={2013}, 
pages={11-19}, 
abstract={Dynamic program analysis tools serve many important software engineering tasks such as profiling, debugging, testing, program comprehension, and reverse engineering. Many dynamic analysis tools rely on program instrumentation and are implemented using low-level instrumentation libraries, resulting in tedious and error-prone tool development. The recently released Domain-Specific Language for Instrumentation (DiSL) was designed to boost the productivity of tool developers targeting the Java Virtual Machine, without impairing the performance of the resulting tools. DiSL offers high-level programming abstractions especially designed for development of instrumentation-based dynamic analysis tools. In this paper, we present a controlled experiment aimed at quantifying the impact of the DiSL programming model and high-level abstractions on the development of dynamic program analysis instrumentations. The experiment results show that compared with a prevailing, state-of-the-art instrumentation library, the DiSL users were able to complete instrumentation development tasks faster, and with more correct results.}, 
keywords={Java;program debugging;reverse engineering;specification languages;system monitoring;virtual machines;DiSL;Java virtual machine;debugging;domain-specific language for instrumentation;error-prone tool development;high-level programming abstractions;instrumentation-based dynamic analysis tools;low-level instrumentation libraries;productive dynamic program analysis tool development;program comprehension;program instrumentation;reverse engineering;software engineering tasks;Context;Instruments;Java;Libraries;Productivity;Programming;Writing;Dynamic program analysis;bytecode instrumentation;controlled experiment;development productivity}, 
doi={10.1109/ASWEC.2013.12}, 
ISSN={1530-0803}, 
month={June},}
@INPROCEEDINGS{7203010, 
author={R. Abreu and H. Erdogmus and A. Perez}, 
booktitle={2015 IEEE/ACM 37th IEEE International Conference on Software Engineering}, 
title={CodeAware: Sensor-Based Fine-Grained Monitoring and Management of Software Artifacts}, 
year={2015}, 
volume={2}, 
pages={551-554}, 
abstract={Current continuous integration (CI) tools, although extensible, can be limiting in terms of flexibility. In particular, artifact analysis capabilities available through plug in mechanisms are both coarse-grained and centralized. To address this limitation, this paper introduces a new paradigm, Code Aware, for distributed and fine-grained artifact analysis. Code Aware is an ecosystem inspired by sensor networks, consisting of monitors and actuators, aimed at improving code quality and team productivity. Code ware's vision entails (a) the ability to probe software artifacts of any granularity and localization, from variables to classes or files to entire systems, (b) the ability to perform both static and dynamic analyses on these artifacts, and (c) the ability to describe targeted remediation actions, for example to notify interested developers, through automated actuators. We provide motivational examples for the use of Code Aware that leverage current CI solutions, sketch the architecture of its underlying ecosystem, and outline research challenges.}, 
keywords={productivity;program diagnostics;software quality;CI tools;CodeAware;artifact analysis capabilities;automated actuators;code quality improvement;continuous integration tools;distributed artifact analysis;dynamic analysis;ecosystem;fine-grained artifact analysis;monitors;plug in mechanisms;sensor-based fine-grained monitoring;software artifact management;static analysis;team productivity improvement;DSL;Ecosystems;Electronic mail;Monitoring;Probes;Software;Software engineering}, 
doi={10.1109/ICSE.2015.192}, 
ISSN={0270-5257}, 
month={May},}
@INPROCEEDINGS{6883052, 
author={K. Smeltzer}, 
booktitle={2014 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
title={A language for visualization variation and transformation}, 
year={2014}, 
pages={195-196}, 
abstract={Improvements in computer technology have spawned an exponential growth in both the scope and volume of data collection, as well as a corresponding shortage of capable analysts. This applies not just to scientists, but also to consumers who are gaining unprecedented access to data from their cars, homes, phones, and other devices. Meanwhile, visualization has emerged as an effective tool for exploring and gathering insight from large quantities of data. However, constructing effective visualizations is often difficult, and current tools often lack either the flexibility to extend to custom problem domains or else require low-level graphics programming expertise to generate even simple visualizations. Furthermore, most solutions are ad hoc, preventing users from transforming and evolving visualizations, instead forcing them into a rigid, linear workflow. One possible approach to solving these problems is through the definition of a domain-specific language (DSL). This approach offers a number of potential advantages, the most immediate being flexibility. A visualization DSL could support multiple levels of abstraction at once, each of which could be targeted at different user needs and expertise levels. This, in turn, could allow users with varying levels of expertise to make use of the abstraction layers they find most appropriate, and support the creation of simple and common visualizations without sacrificing the option for more detailed control when necessary. This layering could also allow implementation details to be hidden when desired. Pixel position information, for example, could be hidden behind a scalable and unitless environment which would allow the user to place and size visualization components in relation to one another.}, 
keywords={program diagnostics;visual languages;abstraction layers;computer technology;domain-specific language;pixel position information;visualization DSL;visualization components;visualization transformation;visualization variation;DSL;Data analysis;Data visualization;Image color analysis;Programming;Visualization}, 
doi={10.1109/VLHCC.2014.6883052}, 
ISSN={1943-6092}, 
month={July},}
@INPROCEEDINGS{6696493, 
author={N. Yakymets and S. Dhouib and H. Jaber and A. Lanusse}, 
booktitle={2013 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
title={Model-driven safety assessment of robotic systems}, 
year={2013}, 
pages={1137-1142}, 
abstract={Robotic systems (RSs) are often used for performing critical tasks with little or no human intervention. Such RSs must satisfy certain dependability requirements including reliability, availability, security and safety. In this paper, we focus on the safety aspect and propose a methodology and associated framework for safety assessment of RSs in the early phases of development. The methodology relies upon model-driven engineering approach and describes a preliminary safety assessment of safety-critical RSs using fault tree (FT) analysis (FTA). The framework supports a domain specific language for RSs called RobotML and includes facilities (i) to automatically generate or manually construct FTs and perform both qualitative and quantitative FTA, (ii) to make semantic connections with formal verification and FTA tools, (iii) to represent FTA results in the RobotML modeling environment. In the case study, we illustrate the proposed methodology and framework by considering a mobile robot developed in the scope of the Proteus project.}, 
keywords={control engineering computing;fault trees;formal verification;mobile robots;safety;safety-critical software;FTA tools;Proteus project;RobotML modeling environment;availability;dependability requirements;domain specific language;fault tree analysis;formal verification;mobile robot;model-driven engineering approach;model-driven safety assessment;reliability;robotic systems;safety aspect;safety assessment;safety-critical RS;security;Fault trees;Hazards;Mobile robots;Robot sensing systems;Unified modeling language}, 
doi={10.1109/IROS.2013.6696493}, 
ISSN={2153-0858}, 
month={Nov},}
@INPROCEEDINGS{6800525, 
author={W. Ecker and M. Velten and L. Zafari and A. Goyal}, 
booktitle={2014 Design, Automation Test in Europe Conference Exhibition (DATE)}, 
title={The metamodeling approach to system level synthesis}, 
year={2014}, 
pages={1-2}, 
abstract={This paper presents an industry proven Metamodeling based approach to System-Level-Synthesis which is seen as generic design automation strategy above today's implementation levels RTL (for digital) and Schematic Entry (for analog). The approach follows a new synthesis paradigm: The designer develops a simple domain and/or design specific language and a smart tool synthesizing implementation level models according to its needs. The overhead of making both a tool and a model pays off since the tool building is automated by code generation and reuse, both based on Metamodeling techniques. Also the focus on owns demand keeps development costs low. Finally, specification data is utilized. I.e. the domain specific language simplifies to a document structure as a table. This keeps also modeling effort low since specification content is used and no model need to be built. Furthermore, increases design consistency and thus decreases debug time. Using these concepts, single design steps have been speed up to a factor of 20x and implementations of chips (specification-to-tapeout) have been speed up to a factor of 3x.}, 
keywords={electronic design automation;program compilers;specification languages;RTL levels;code generation;design specific language;generic design automation strategy;metamodeling approach;schematic entry;smart tool;system level synthesis;Automation;Buildings;Data models;Engines;Generators;Metamodeling;Synthesizers;code generation;metamodeling;system level synthesis}, 
doi={10.7873/DATE.2014.324}, 
ISSN={1530-1591}, 
month={March},}
@INPROCEEDINGS{7582769, 
author={T. Szabó and S. Erdweg and M. Voelter}, 
booktitle={2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
title={IncA: A DSL for the definition of incremental program analyses}, 
year={2016}, 
pages={320-331}, 
abstract={Program analyses support software developers, for example, through error detection, code-quality assurance, and by enabling compiler optimizations and refactorings. To provide real-time feedback to developers within IDEs, an analysis must run efficiently even if the analyzed code base is large. To achieve this goal, we present a domain-specific language called IncA for the definition of efficient incremental program analyses that update their result as the program changes. IncA compiles analyses into graph patterns and relies on existing incremental matching algorithms. To scale IncA analyses to large programs, we describe optimizations that reduce caching and prune change propagation. Using IncA, we have developed incremental control flow and points-to analysis for C, well-formedness checks for DSLs, and 10 FindBugs checks for Java. Our evaluation demonstrates significant speedups for all analyses compared to their non-incremental counterparts.}, 
keywords={Java;program diagnostics;software engineering;specification languages;DSL;IncA analysis;Java;domain-specific language;incremental program analysis;software development;static program analysis;DSL;Java;Optimization;Pattern matching;Program processors;Runtime;Domain-specific Language;Incremental Computation;Language Workbench;Static Analysis}, 
month={Sept},}
@INPROCEEDINGS{6216638, 
author={Y. B. Hlaoui and L. J. Ben Ayed and I. Ben Fradj}, 
booktitle={Information Technology and e-Services (ICITeS), 2012 International Conference on}, 
title={A model driven approach to compose and develop Grid service workflow applications}, 
year={2012}, 
pages={1-7}, 
abstract={We use a Domain Specific Language (DSL) based on UML activity diagrams (UML-AD) to specify and compose systematically workflow models from Grid services. To be executed, workflow activity diagram models should be translated into BPEL4WS models which will be executed by the BPEL4WS engine. To reach this objective, we propose a meta-model based transformation from UML activity diagrams to BPEL4WS language. To ensure the correctness and the completion of the transformation, we propose a graph homomorphic mapping between the activity diagram and BPEL4WS language elements. To execute the BPEL4WS provided model, we propose in this paper an execution infrastructure based on The Globus Tool Kit.}, 
keywords={Unified Modeling Language;Web services;data models;graph theory;grid computing;meta data;BPEL4WS;Globus tool kit;UML activity diagram;UML-AD;domain specific language;graph homomorphic mapping;grid service workflow;meta model;model driven approach;workflow activity diagram model;Abstracts;Domain specific languages;Engines;Java;Semantics;Transforms;Unified modeling language;BPEL4WS;Grid service workflow;UML activity diagram s;homomorphic mapping;meta-model transformation}, 
doi={10.1109/ICITeS.2012.6216638}, 
month={March},}
@INPROCEEDINGS{6502525, 
author={M. Valero and S. Uluagac and S. Venkatachalam and K. C. Ramalingam and R. Beyah}, 
booktitle={2012 IEEE 9th International Conference on Mobile Ad-Hoc and Sensor Systems (MASS 2012)}, 
title={The Monitoring Core: A framework for sensor security application development}, 
year={2012}, 
pages={263-271}, 
abstract={Wireless sensor networks (WSNs) are used for the monitoring of physical and environmental phenomena, and applicable in a range of different domains (e.g., health care, military, critical infrastructure). When using WSNs in a variety of real-world applications, security is a vital problem that should be considered by developers. As the development of security applications (SAs) for WSNs require meticulous procedures and operations, the software implementation process can be more challenging than regular applications. Hence, in an effort to facilitate the design, development and implementation of WSN security applications, we introduce the Monitoring Core (M-Core). The M-Core is a modular, lightweight, and extensible software layer that gathers necessary data including the internal and the external status of the sensor (e.g., information about ongoing communications, neighbors, and sensing), and provides relevant information for the development of new SAs. Similar to other software development tools, the M-Core was developed to facilitate the design and development of new WSN SAs on different platforms. Moreover, a new user-friendly domain-specific language, the M-Core Control Language (MCL), was developed to further facilitate the use of the M-Core and reduce the developer's coding time. With the MCL, a user can implement new SAs without the overhead of learning the details of the underlying sensor software architecture (e.g., TinyOS). The M-Core has been implemented in TinyOS-2.x and tested on real sensors (Tmote Sky and MicaZ). Using the M-Core architecture, we implemented several SAs to show that the M-Core allows easy and rapid development of security programs efficiently and effectively.}, 
keywords={computerised monitoring;human computer interaction;software architecture;telecommunication security;wireless sensor networks;M-core architecture;M-core control language;MCL;SA;TinyOS-2.x;WSN security applications;environmental phenomena;extensible software layer;meticulous procedures;monitoring core;physical phenomena;real sensors;real-world applications;security applications;security programs;sensor external status;sensor internal status;sensor security application development;software implementation process;user-friendly domain-specific language;wireless sensor networks;M-Core Control Language (MCL);Monitoring Core (M-Core);Sensor Security Application Development;Wireless Sensor Network Applications}, 
doi={10.1109/MASS.2012.6502525}, 
ISSN={2155-6806}, 
month={Oct},}
@INPROCEEDINGS{6339417, 
author={A. Unutulmaz and G. Dündar and F. V. Fernández}, 
booktitle={Synthesis, Modeling, Analysis and Simulation Methods and Applications to Circuit Design (SMACD), 2012 International Conference on}, 
title={LDS based tools to ease template construction}, 
year={2012}, 
pages={61-64}, 
abstract={Layout Description Script (LDS) is a domain specific language (DSL) intended to describe analog layouts. This paper introduces an LDS based tool, Capture, and an add-on, LDS Analyzer, for LDS. Capture aims to convert layout images into layout templates. Components of a layout are extracted with this tool and a template is synthesized from the extracted data. LDS Analyzer is an enhanced LDS parser. Analyzer investigates an LDS statement and conducts either simple parsing or enhanced parsing which make use of symbolic variables.}, 
keywords={analogue circuits;circuit layout;electronic engineering computing;Layout Description Script Analyzer;analog layout;domain specific language;layout template;template construction;Circuit synthesis;Data mining;Design automation;Educational institutions;Layout;Optimization;Routing}, 
doi={10.1109/SMACD.2012.6339417}, 
month={Sept},}
@ARTICLE{6654153, 
author={F. Jacob and A. Wynne and Y. Liu and J. Gray}, 
journal={Computing in Science Engineering}, 
title={Domain-Specific Languages for Developing and Deploying Signature Discovery Workflows}, 
year={2014}, 
volume={16}, 
number={1}, 
pages={52-64}, 
abstract={Domain-agnostic signature discovery supports scientific investigation across domains through algorithm reuse. A new software tool defines two simple domain-specific languages that automate processes that support the reuse of existing algorithms in different workflow scenarios. The tool is demonstrated with a signature discovery workflow composed of services that wrap original scripts running high-performance computing tasks.}, 
keywords={parallel processing;software reusability;software tools;specification languages;workflow management software;algorithm reuse;domain-agnostic signature discovery;domain-specific languages;high-performance computing tasks;scientific investigation;scripts;signature discovery workflow;software tool;workflow scenarios;Clustering algorithms;DSL;Domain specific languages;Scientific computing;Software algorithms;Web services;XML;DSL;Taverna;domain-specific languages;scientific computing;signature discovery;workflow}, 
doi={10.1109/MCSE.2013.97}, 
ISSN={1521-9615}, 
month={Jan},}
@INPROCEEDINGS{6984103, 
author={A. R. d. Silva and S. Vlajic and S. Lazarevic and I. Antovic and V. Stanojevic and M. Milic}, 
booktitle={Quality of Information and Communications Technology (QUATIC), 2014 9th International Conference on the}, 
title={Preliminary Experience Using JetBrains MPS to Implement a Requirements Specification Language}, 
year={2014}, 
pages={134-137}, 
abstract={People prefer to use textual specification of requirements, but their representations are not suitable for automatic transformation and reuse. Use case modelling is commonly used to structure and document requirements. The integration of use cases within the Model Driven Development paradigm requires a rigorous definition of the use case specification. In this paper we describe the key part of SilabReq language for requirements specification based on use case and present the main result from our preliminary experience with implementation of the SilabReq language with JetBrains Meta Programming System.}, 
keywords={formal specification;programming languages;JetBrains MPS;JetBrains meta programming system;SilabReq language;model driven development paradigm;requirements specification language;textual requirements specification;use case modelling;use case specification;Abstracts;DSL;Natural languages;Programming;Software;Syntactics;Unified modeling language;language workbench;requirements;requirements specification;requirements specification tools;use case}, 
doi={10.1109/QUATIC.2014.24}, 
month={Sept},}
@INPROCEEDINGS{7515468, 
author={M. Bernardino and A. F. Zorzo and E. M. Rodrigues}, 
booktitle={2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)}, 
title={Canopus: A Domain-Specific Language for Modeling Performance Testing}, 
year={2016}, 
pages={157-167}, 
abstract={Despite all the efforts to reduce the cost of the testing phase in software development, it is still one of the most expensive phases. In order to continue to minimize those costs, in this paper, we propose a Domain-Specific Language (DSL), built on top of MetaEdit+ language workbench, to model performance testing for web applications. Our DSL, called Canopus, was developed in the context of a collaboration1 between our university and a Technology Development Laboratory (TDL) from an Information Technology (IT) company. We present, in this paper, the Canopus metamodels, its domain analysis, a process that integrates Canopus to Model-Based Performance Testing, and applied it to an industrial case study.}, 
keywords={Internet;program testing;software cost estimation;specification languages;Canopus metamodels;DSL;IT company;MetaEdit+ language workbench;TDL;Web applications;cost minimization;cost reduction;domain-specific language;information technology company;model-based performance testing;performance testing modeling;software development testing;technology development laboratory;Analytical models;Automation;Computational modeling;DSL;Load modeling;Testing;Unified modeling language;domain-specific language;domain-specific modeling;model-based testing;performance testing}, 
doi={10.1109/ICST.2016.13}, 
month={April},}
@INPROCEEDINGS{7306353, 
booktitle={2015 Forum on Specification and Design Languages (FDL)}, 
title={Design and Correctness}, 
year={2015}, 
pages={1-1}, 
abstract={This session presents a domain-specific language for high-level synthesis of hardware for FPGA platforms and describes its memory management for pipelined target architectures. It also presents a methodology to construct test sequences starting from PSL assertions and design under test written in VHDL using VSYML and SyntHorus tools. Finally it presents a top-down design flow to refine an architecture level description of a system into an RTL implementation, while refining operation properties concurrently.}, 
keywords={Domain specific languages;Field programmable gate arrays;Hardware;Memory management;Refining;Systems modeling}, 
ISSN={1636-9874}, 
month={Sept},}
@INPROCEEDINGS{7292575, 
author={L. Bettini}, 
booktitle={Software Paradigm Trends (ICSOFT-PT), 2014 9th International Conference on}, 
title={Developing user interfaces with EMF parsley}, 
year={2014}, 
pages={58-66}, 
abstract={In this paper we describe the main features of EMF Parsley, a new Eclipse project for implementing applications based on the Eclipse Modeling Framework (EMF). EMF Parsley aims at complementing the EMF reflective mechanisms with respect to rapidly creating user interfaces based on models, without having to deal with internal details and setup code. In particular, EMF Parsley uses injection mechanisms to easily customize all the aspects of such applications. Moreover, it provides a set of reusable user interface components like trees, tables and detail forms that manage the model with the introspective EMF capabilities, together with reusable views, editors and dialogs. Besides project wizards, to easily create projects based on EMF Parsley, the main developing tool is a DSL, implemented with Xtext/Xbase, that provides a rapid customization mechanism.}, 
keywords={Control systems;DSL;Google;Java;Labeling;Libraries;User interfaces;DSL;EMF;Eclipse;Modeling;User Interface}, 
month={Aug},}
@INPROCEEDINGS{6927454, 
author={N. George and H. Lee and D. Novo and T. Rompf and K. J. Brown and A. K. Sujeeth and M. Odersky and K. Olukotun and P. Ienne}, 
booktitle={2014 24th International Conference on Field Programmable Logic and Applications (FPL)}, 
title={Hardware system synthesis from Domain-Specific Languages}, 
year={2014}, 
pages={1-8}, 
abstract={Field Programmable Gate Arrays (FPGAs) are very versatile devices, but their complicated programming model has stymied their widespread usage. While modern High-Level Synthesis (HLS) tools provide better programming models, the interface they offer is still too low-level. In order to produce good quality hardware designs with these tools, the users are forced to manually perform optimizations that demand detailed knowledge of both the application and the implementation platform. Additionally, many HLS tools only generate isolated hardware modules that the user still needs to integrate into a system design before generating the FPGA bitstream. These problems make HLS tools difficult to use for application developers who have little hardware design knowledge. To address these problems, we propose an automated methodology to generate FPGA bitstreams from high-level programs written in Domain-Specific Languages (DSLs). We leverage the domain-knowledge conveyed by the DSL and its domain-specific semantics to extract application parallelism, perform optimizations and also identify a suitable system-architecture for the implementation, thereby, relieving the user from most of the hardware-level details. We demonstrate the high productivity and high design quality this approach offers by automatically generating hardware systems from applications written in OptiML, a machine-learning DSL. To evaluate our methodology, we use four OptiML applications and show that we can easily generate different solutions which achieve different trade-offs between performance and area. More importantly, the results reveal that our generated hardware achieves much better performance compared to the one obtained from using the HLS tool without platform-specific optimizations.}, 
keywords={field programmable gate arrays;learning (artificial intelligence);logic design;specification languages;FPGA bitstream;FPGAs;HLS tools;OptiML;application parallelism extraction;complicated programming model;domain-specific languages;domain-specific semantics;field programmable gate arrays;hardware system synthesis;hardware-level details;high-level programs;isolated hardware modules;machine-learning DSL;quality hardware designs;system design;system-architecture;DSL;Data structures;Field programmable gate arrays;Hardware;Kernel;Optimization;Parallel processing}, 
doi={10.1109/FPL.2014.6927454}, 
ISSN={1946-147X}, 
month={Sept},}
@INPROCEEDINGS{6645665, 
author={B. Trninić and G. Sladić and G. Milosavljević and B. Milosavljević and Z. Konjović}, 
booktitle={Intelligent Software Methodologies, Tools and Techniques (SoMeT), 2013 IEEE 12th International Conference on}, 
title={PolicyDSL: Towards generic access control management based on a policy metamodel}, 
year={2013}, 
pages={217-223}, 
abstract={The paper presents a generic access control management infrastructure suitable for a broad set of systems. The generic infrastructure is based on our policy metamodel (level M2), which is used for the specification of the needed policy model (level M1) such as RBAC, GTRBAC, etc. Having a defined policy model, the abstract and concrete syntaxes of PolicyDSL, our textual DSL for expressing access control policies, are dynamically generated. A security expert is then able to express the actual access control policies (level M0) for the given access control model using the generated DSL. The presented solution can be applied, with no changes, to a number of systems that are based on different access control models or their variants.}, 
keywords={authorisation;computational linguistics;formal specification;specification languages;GTRBAC;PolicyDSL;RBAC;abstract syntaxes;access control policies;concrete syntaxes;domain-specific languages;generic access control management;level M1;level M2;policy metamodel;role based access control;security expert;textual DSL;Access control;Concrete;DSL;Standards;Syntactics;Unified modeling language}, 
doi={10.1109/SoMeT.2013.6645665}, 
month={Sept},}
@ARTICLE{7458761, 
author={C. Ebert and G. Gallardo and J. Hernantes and N. Serrano}, 
journal={IEEE Software}, 
title={DevOps}, 
year={2016}, 
volume={33}, 
number={3}, 
pages={94-100}, 
abstract={Building on lean and agile practices, DevOps means end-to-end automation in software development and delivery. Hardly anybody will be able to approach it with a cookbook-style approach, but most developers will benefit from better connecting the previously isolated silos of development and operations. Many DevOps tools exist that can help them do this.}, 
keywords={software engineering;DevOps;cookbook-style approach;software delivery;software development;Automation;Cloud computing;DSL;Java;Monitoring;Production;AWS;Amazon Web Services;Ansible;Bamboo;Cacti;Chef;DevOps;Gradle;Graylog2;Jenkins;Logging;Loggly;Maven;Nagios;New Relic;Puppet;TeamCity;apache Ant;configuration management;continuous integration;microservices;software development;software engineering}, 
doi={10.1109/MS.2016.68}, 
ISSN={0740-7459}, 
month={May},}
@INPROCEEDINGS{6337714, 
author={G. Edwards and Y. Brun and N. Medvidovic}, 
booktitle={Software Architecture (WICSA) and European Conference on Software Architecture (ECSA), 2012 Joint Working IEEE/IFIP Conference on}, 
title={Automated Analysis and Code Generation for Domain-Specific Models}, 
year={2012}, 
pages={161-170}, 
abstract={Domain-specific languages (DSLs) concisely express the essential features of system designs. However, using a DSL for automated analysis and code generation requires developing specialized tools. We describe how to create model analysis and code generation tools that can be applied to a large family of DSLs, and show how we created the LIGHT platform, a suite of such tools for the family of software architecture-based DSLs. These tools can be easily reused off-the-shelf with new DSLs, freeing engineers from having to custom-develop them. The key innovation underlying our strategy is to enhance DSL metamodels with additional semantics, and then automatically synthesize configurations and plug-ins for flexible analysis and code generation frameworks. Our evaluation shows that, for a DSL of typical size, using our strategy relieves software engineers of developing approximately 17,500 lines of code, which amounts to several person-months of programming work.}, 
keywords={software architecture;software tools;specification languages;DSL metamodel enhancement;LIGHT platform;architecture-based DSL;automated analysis;automatic configuration synthesis;code generation;domain-specific languages;domain-specific models;model analysis;plug-ins;system designs;Analytical models;Computer architecture;DSL;Generators;Semantics;Software;Unified modeling language}, 
doi={10.1109/WICSA-ECSA.212.24}, 
month={Aug},}
@INPROCEEDINGS{6721539, 
author={J. Ozik and N. T. Collier and J. T. Murphy and M. J. North}, 
booktitle={2013 Winter Simulations Conference (WSC)}, 
title={The ReLogo agent-based modeling language}, 
year={2013}, 
pages={1560-1568}, 
abstract={ReLogo is a new agent-based modeling (ABM) domain specific language (DSL) for developing agent-based models in the free and open source Repast Suite of ABM tools; the Java based Repast Simphony ABM toolkit and the C++ high performance computing Repast HPC toolkit both incorporate ReLogo. The language is geared towards a wide range of modeling and programming expertise, combining the sophisticated and powerful ABM infrastructure and capabilities in the Repast Suite with the ease of use of the Logo programming language and its associated programming idioms. This paper will present how ReLogo combines a number of concepts, including object-oriented programming, simple integration of existing code libraries, statically and dynamically typed languages, domain specific languages, and the use of integrated development environments, to create an ABM tool that is easy to learn yet is also capable of creating large scale ABMs of real world complex systems.}, 
keywords={Java;multi-agent systems;parallel processing;public domain software;ABM tools;C++ high performance computing Repast HPC toolkit;DSL;Java based Repast Simphony ABM toolkit;Logo programming language;ReLogo agent-based modeling domain specific language;open source Repast Suite;Computational modeling;DSL;Java;Libraries;Object oriented modeling;Programming}, 
doi={10.1109/WSC.2013.6721539}, 
ISSN={0891-7736}, 
month={Dec},}
@INPROCEEDINGS{7365791, 
author={B. Scholz and K. Vorobyov and P. Krishnan and T. Westmann}, 
booktitle={Software Engineering Conference (ASWEC), 2015 24th Australasian}, 
title={A Datalog Source-to-Source Translator for Static Program Analysis: An Experience Report}, 
year={2015}, 
pages={28-37}, 
abstract={Static program analysis has many applications including bug checking for large scale code that requires a points-to analysis. To express static program analysis frameworks concisely, it is advantageous to employ a domain-specific language. In the last two decades, Data log has emerged as a domain-specific language for static program analysis. However, existing Data log systems have problems solving large scale code with millions of program variables. This work reports on techniques that translate a Data log program to SQL queries, which are executed on a relational database system. The advantage of a relational database system as an execution platform is the effective use of memory and disks. Further, we can also use an off-the shelf tool to execute the SQL queries. In order to achieve performance, we explore some of the design choices for a source-to-source translation from Data log to SQL that implement stratified negations, totally ordered domains, and comparisons. For each design point, we explain how Data log can be efficiently translated to SQL using the semi-naive evaluation approach. We report the results of our experiments using large data-sets including the OpenJDK7-b147 dataset for points-to, which guided us in the design of our translation schemes.}, 
keywords={DATALOG;SQL;program debugging;program diagnostics;relational databases;Naıve evaluation approach;OpenJDK7-b147 dataset;SQL query;bug checking;datalog program;datalog source-to-source translator;datalog system;domain-specific language;large scale code;relational database system;source-to-source translation;static program analysis;Australia;Electronic mail;Engines;Relational databases;Resource management;Semantics;Software engineering;Datalog;SQWL;program analysis;source-to-source translation}, 
doi={10.1109/ASWEC.2015.15}, 
ISSN={1530-0803}, 
month={Sept},}
@ARTICLE{6051438, 
author={D. Cassou and J. Bruneau and C. Consel and E. Balland}, 
journal={IEEE Transactions on Software Engineering}, 
title={Toward a Tool-Based Development Methodology for Pervasive Computing Applications}, 
year={2012}, 
volume={38}, 
number={6}, 
pages={1445-1463}, 
abstract={Despite much progress, developing a pervasive computing application remains a challenge because of a lack of conceptual frameworks and supporting tools. This challenge involves coping with heterogeneous devices, overcoming the intricacies of distributed systems technologies, working out an architecture for the application, encoding it in a program, writing specific code to test the application, and finally deploying it. This paper presents a design language and a tool suite covering the development life-cycle of a pervasive computing application. The design language allows us to define a taxonomy of area-specific building-blocks, abstracting over their heterogeneity. This language also includes a layer to define the architecture of an application, following an architectural pattern commonly used in the pervasive computing domain. Our underlying methodology assigns roles to the stakeholders, providing separation of concerns. Our tool suite includes a compiler that takes design artifacts written in our language as input and generates a programming framework that supports the subsequent development stages, namely, implementation, testing, and deployment. Our methodology has been applied on a wide spectrum of areas. Based on these experiments, we assess our approach through three criteria: expressiveness, usability, and productivity.}, 
keywords={program compilers;software architecture;ubiquitous computing;architectural pattern;area-specific building-blocks;compiler;design artifacts;development life-cycle;distributed systems technologies;pervasive computing applications;tool-based development methodology;Computational modeling;Computer architecture;Domain specific languages;Pervasive computing;Programming;Software architecture;Taxonomy;Methodology;domain-specific language;generative programming;pervasive computing;programming support;simulation;toolkit}, 
doi={10.1109/TSE.2011.107}, 
ISSN={0098-5589}, 
month={Nov},}
@INPROCEEDINGS{6890824, 
author={A. Rahman and D. Amyot}, 
booktitle={Model-Driven Requirements Engineering Workshop (MoDRE), 2014 IEEE 4th International}, 
title={A DSL for importing models in a requirements management system}, 
year={2014}, 
pages={37-46}, 
abstract={Requirements are artefacts often described with text and models. It is important to manage traceability between requirements and other software artefacts, including designs and test cases, also often captured with specialized models. Some Requirements Management Systems (RMS) support traceability relationships, between (textual) requirements artefacts in the RMS and model artefacts created outside the RMS, through complex standards or proprietary solutions. This paper proposes a new Domain-Specific Language (DSL) for describing the concepts of a modeling language intended to be traced using an RMS, with tool support handling the import and re-import of models and of their traceability links. The Model Import DSL (MI-DSL) is supported by an Xtext-based editor and the automatic generation of an import library targeting a leading RMS, namely IBM Rational DOORS. The language and the tools are demonstrated for model import and evolution scenarios with two different modeling languages. This work contributes a simple yet reliable mechanism to define and support traceability between requirements and models from different tools.}, 
keywords={formal specification;program diagnostics;program testing;software libraries;specification languages;IBM Rational DOORS;MI-DSL;RMS;Xtext-based editor;automatic generation;domain-specific language;import library;model artefacts;model import DSL;modeling language;requirements management system;software artefacts;test cases;textual requirements artefacts;tool support;traceability links;traceability relationships;Analytical models;Biological system modeling;Computational modeling;DSL;Libraries;Software;Unified modeling language;DOORS;DSL;evolution;model;requirements management;traceability}, 
doi={10.1109/MoDRE.2014.6890824}, 
month={Aug},}
@INPROCEEDINGS{7372080, 
author={C. Artho and M. Seidl and Q. Gros and E. H. Choi and T. Kitamura and A. Mori and R. Ramler and Y. Yamagata}, 
booktitle={Automated Software Engineering (ASE), 2015 30th IEEE/ACM International Conference on}, 
title={Model-Based Testing of Stateful APIs with Modbat}, 
year={2015}, 
pages={858-863}, 
abstract={Modbat makes testing easier by providing a user-friendly modeling language to describe the behavior of systems, from such a model, test cases are generated and executed. Modbat's domain-specific language is based on Scala, its features include probabilistic and non-deterministic transitions, component models with inheritance, and exceptions. We demonstrate the versatility of Modbat by finding a confirmed defect in the currently latest version of Java, and by testing SAT solvers.}, 
keywords={Java;application program interfaces;computability;program testing;simulation languages;Java;Modbat;SAT solvers;Scala;domain-specific language;model-based testing;nondeterministic transitions;probabilistic transitions;stateful API;user-friendly modeling language;Arrays;DSL;Data models;Java;Libraries;Testing;component-based systems;domain-specific language;exception testing;extended finite-state machines;model-based testing;software test tools}, 
doi={10.1109/ASE.2015.95}, 
month={Nov},}
@INPROCEEDINGS{7483269, 
author={M. Lachgar and A. Abdali}, 
booktitle={2015 Third World Conference on Complex Systems (WCCS)}, 
title={DSL and code generator for accelerating iOs apps development}, 
year={2015}, 
pages={1-8}, 
abstract={A mobile application has become an important new way to reach customers. The use of smartphones and tablets has also increased, but it's always difficult to create a new application. This requires specific knowledge and experience to successfully operate all features. The heterogeneity development tools and languages in mobile apps makes difficult to develop multi-platform mobile applications. Thus, it requires developers to make a choice on the platform, while ensuring the widest possible dissemination. The strategy "write once, deploy anywhere" is a smart way to develop mobile applications. In fact, it equips developers with what they need to keep ahead of the game. The aim of this work is to define an independent language of the platform then generate native code for iOS applications using an MDA approach. For this, we opt for a specific language (DSL) to increase the productivity of software engineers by abstracting low-level boilerplate code.}, 
keywords={mobile computing;program compilers;smart phones;DSL;MDA approach;code generator;iOs apps development;low-level boilerplate code;multiplatform mobile applications;smartphones;software engineers;Computational modeling;DSL;Data models;Mobile communication;Operating systems;Smart phones;Unified modeling language;Automatic code generation;Domain-Specific Language;Mobile development;Model Driven Architecture;Native Code;iOS Apps}, 
doi={10.1109/ICoCS.2015.7483269}, 
month={Nov},}
@INPROCEEDINGS{6322875, 
author={J. M. P. Cardoso}, 
booktitle={Reconfigurable Communication-centric Systems-on-Chip (ReCoSoC), 2012 7th International Workshop on}, 
title={Programming strategies for runtime adaptability}, 
year={2012}, 
pages={1-8}, 
abstract={Future advanced embedded computing systems are expected to dynamically adapt applications' behavior and runtime system according to, e.g., usage contexts, operating environments, resources' availability, and battery energy levels. Besides application's functionalities provided by high-level and/or executable binary codes, code for specifying strategies/policies to extend typical functionalities with adaptability behavior is required. A domain-specific language, able to program this adaptability behavior, will allow developers to specify strategies for adaptation, will improve portability, and will help tools to map those strategies to the target system. This paper presents our recent ideas for programming strategies focused on runtime adaptability. The ideas are exposed using extensions to LARA, an aspect-oriented programming language, agnostic to the target language and system. We show examples of using LARA to specify strategies and we comment on the possible implementations to make viable those strategies.}, 
keywords={aspect-oriented programming;binary codes;embedded systems;object-oriented languages;program compilers;program diagnostics;software portability;software process improvement;LARA;adaptability behavior;application functionalities;aspect-oriented programming language;domain-specific language;dynamic application behavior adaptation;embedded computing systems;executable binary codes;high-level binary codes;portability improvement;programming strategies;runtime adaptability;runtime system;strategy specification code;Batteries;Context;Energy states;Java;Reactive power;Runtime;Weaving;FPGAs;LARA;aspect-oriented programming;compilers;embedded computing;runtime adaptability}, 
doi={10.1109/ReCoSoC.2012.6322875}, 
month={July},}
@INPROCEEDINGS{7349651, 
author={P. Li and E. Brunet and F. Trahay and C. Parrot and G. Thomas and R. Namyst}, 
booktitle={Parallel Processing (ICPP), 2015 44th International Conference on}, 
title={Automatic OpenCL Code Generation for Multi-device Heterogeneous Architectures}, 
year={2015}, 
pages={959-968}, 
abstract={Using multiple accelerators, such as GPUs or Xeon Phis, is attractive to improve the performance of large data parallel applications and to increase the size of their workloads. However, writing an application for multiple accelerators remains today challenging because going from a single accelerator to multiple ones indeed requires to deal with potentially non-uniform domain decomposition, inter-accelerator data movements, and dynamic load balancing. Writing such code manually is time consuming and error-prone. In this paper, we propose a new programming tool called STEPOCL along with a new domain specific language designed to simplify the development of an application for multiple accelerators. We evaluate both the performance and the usefulness of STEPOCL with three applications and show that: (i) the performance of an application written with STEPOCL scales linearly with the number of accelerators, (ii) the performance of an application written using STEPOCL competes with a handwritten version, (iii) larger workloads run on multiple devices that do not fit in the memory of a single device, (iv) thanks to STEPOCL, the number of lines of code required to write an application for multiple accelerators is roughly divided by ten.}, 
keywords={graphics processing units;parallel processing;program compilers;resource allocation;specification languages;GPU;STEPOCL;Xeon Phis;automatic OpenCL code generation;data parallel applications;domain specific language;dynamic load balancing;interaccelerator data movements;multidevice heterogeneous architectures;programming tool;Arrays;Hardware;Kernel;Performance evaluation;Programming;Synchronization;Writing;Accelerators;Code generation;Heterogeneous architectures;OpenCL}, 
doi={10.1109/ICPP.2015.105}, 
ISSN={0190-3918}, 
month={Sept},}
@INPROCEEDINGS{6676947, 
author={J. v. d. Bos and T. v. d. Storm}, 
booktitle={Software Maintenance (ICSM), 2013 29th IEEE International Conference on}, 
title={TRINITY: An IDE for the Matrix}, 
year={2013}, 
pages={520-523}, 
abstract={Digital forensics software often has to be changed to cope with new variants and versions of file formats. Developers reverse engineer the actual files, and then change the source code of the analysis tools. This process is error-prone and time consuming because the relation between the newly encountered data and how the source code must be changed is implicit. TRINITY is an integrated debugging environment which makes this relation explicit using the DERRIC DSL for describing file formats. TRINITY consists of three simultaneous views: 1) the runtime state of an analysis, 2) a hex view of the actual data, and 3) the file format description. Cross-view trace ability links allow developers to better understand how the file format description should be modified. TRINITY aims to make the process of adapting digital forensics software more effective and efficient.}, 
keywords={data flow analysis;digital forensics;program debugging;reverse engineering;software maintenance;DERRIC DSL;IDE;TRINITY;actual data hexview;analysis runtime state;cross-view traceability links;digital forensics software;domain-specific language;file format description;integrated debugging environment;reverse engineering;Debugging;Digital forensics;Layout;Maintenance engineering;Reverse engineering;Runtime;Software;domain-specific language;integrated development environment;model-driven engineering;reverse engineering;software maintenance}, 
doi={10.1109/ICSM.2013.86}, 
ISSN={1063-6773}, 
month={Sept},}
@INPROCEEDINGS{7020511, 
author={G. Kövesdán and M. Asztalos and L. Lengyel}, 
booktitle={Cognitive Infocommunications (CogInfoCom), 2014 5th IEEE Conference on}, 
title={Fast android application development with component modeling}, 
year={2014}, 
pages={515-520}, 
abstract={Application of mobile and cyber-physical systems play an important role in cognitive infocommunications, especially in the Socio-Cognitive ICT area, because they are able to facilitate the requested information to users quickly. The Android platform is a good foundation for such systems since it runs on a wide variety of devices and provides some advanced mechanisms for integrating loosely coupled components. These capabilities facilitate efficient component-based development. However, these mechanisms also introduce some difficulties into the development process. On one hand, some functionalities are not encapsulated into a single piece of code but have to be implemented and configured at several distinct source files. On the other hand, it is easy to break the consistency among these artefacts. In this paper, we report on our work in progress tool, which addresses these issues by modeling commonly used functionalities in Android applications and generating a skeleton for the implementation. We also report on the design of this tool. The tool and the experiences of its development will be useful for software developers that aspire to create code generators and cognitive infocommunications related mobile applications based on the Android platform.}, 
keywords={Android (operating system);embedded systems;integrated software;mobile computing;object-oriented programming;program compilers;software development management;Android application development;code generator;cognitive infocommunication;component modeling;component-based development;cyber-physical system;loosely coupled component integration;mobile applications;socio-cognitive ICT;software developers;Androids;DSL;Generators;Humanoid robots;Java;Syntactics;Unified modeling language;Android;Socio-Cognitive ICT;code generation;cognitive infocommunications;cyber-physical system;domain-specific modeling;model transformation;modeling}, 
doi={10.1109/CogInfoCom.2014.7020511}, 
month={Nov},}
@INPROCEEDINGS{7377821, 
author={M. Jančár and S. Chodarev}, 
booktitle={Scientific Conference on Informatics, 2015 IEEE 13th International}, 
title={A generative framework for development of CRUD-based Linux desktop applications}, 
year={2015}, 
pages={133-138}, 
abstract={CRUD applications, i.e. applications focused on creating, reading, updating and deleting data records, have always been commonly used. Nonetheless, to the authors' knowledge there is no framework or tool targeting this class of applications in the Gnome desktop environment (using GTK+ widget toolkit). This paper describes a framework based on the model-driven development paradigm for generating CRUD desktop applications with a hierarchic layout and bindings between user interface elements from models expressed in YAML and in domain-specific languages embedded in Vala or Genie. It demonstrates a usability of the recent modern programming language - Vala - and also shows how to extend a functionality of its compiler.}, 
keywords={Linux;program compilers;programming languages;records management;user interfaces;CRUD-based Linux desktop applications;GTK+ widget toolkit;Genie;Gnome desktop environment;Vala;YAML;compiler functionality;data record creation;data record deletion;data record reading;data record updation;domain-specific languages;model-driven development paradigm;programming language;user interface elements;DSL;Generators;Informatics;Linux;Load modeling;Syntactics}, 
doi={10.1109/Informatics.2015.7377821}, 
month={Nov},}
@INPROCEEDINGS{6605868, 
author={A. J. Mooij and J. Hooman and R. Albers}, 
booktitle={Computer Software and Applications Conference Workshops (COMPSACW), 2013 IEEE 37th Annual}, 
title={Gaining Industrial Confidence for the Introduction of Domain-Specific Languages}, 
year={2013}, 
pages={662-667}, 
abstract={Domain-Specific Languages (DSLs) receive attention as the possible next abstraction step in programming. Despite the benefits of using DSLs, in the industry there is also some reluctance against their introduction in product development. We address a number of issues that are important to gain industrial confidence for the introduction of DSLs. These include the available tools, the quality of generated code, and the incorporation in the industrial workflow. Our observations are based on an industrial study project at Philips Healthcare, especially concerning the development of a DSL for collision prevention. We also relate our experiences to the literature.}, 
keywords={health care;product development;programming languages;software engineering;DSL;Philips healthcare;domain-specific languages;industrial confidence;product development;Abstracts;Concrete;DSL;Debugging;Generators;Guidelines;Syntactics}, 
doi={10.1109/COMPSACW.2013.83}, 
month={July},}
@INPROCEEDINGS{7245730, 
author={M. Schmid and O. Reiche and F. Hannig and J. Teich}, 
booktitle={2015 IEEE 26th International Conference on Application-specific Systems, Architectures and Processors (ASAP)}, 
title={Loop coarsening in C-based High-Level Synthesis}, 
year={2015}, 
pages={166-173}, 
abstract={Current tools for High-Level Synthesis (HLS) excel at exploiting Instruction-Level Parallelism (ILP), the support for Data-Level Parallelism (DLP), one of the key advantages of Field Programmable Gate Arrays (FPGAs), is in contrast very limited. This work examines the exploitation of DLP on FPGAs using code generation for C-based HLS of image filters and streaming pipelines, consisting of point and local operators. In addition to well known loop tiling techniques, we propose loop coarsening, which delivers superior performance and scalability. Loop tiling corresponds to splitting an image into separate regions, which are then processed in parallel by replicated accelerators. For data streaming, this also requires the generation of glue logic for the distribution of image data. Conversely, loop coarsening allows to process multiple pixels in parallel, whereby only the kernel operator is replicated within a single accelerator. We augment the FPGA back end of the heterogeneous Domain-Specific Language (DSL) framework HIPAcc by loop coarsening and compare the resulting FPGA accelerators to highly optimized software implementations for Graphics Processing Units (GPUs), all generated from the exact same code base. Moreover, we demonstrate the advantages of code generation for algorithm development by outlining how design space exploration enabled by HIPAcc can yield a more efficient implementation than hand-coded VHDL.}, 
keywords={C language;field programmable gate arrays;graphics processing units;hardware description languages;high level synthesis;image filtering;image segmentation;pipeline processing;program compilers;program control structures;C-based HLS;C-based high-level synthesis;DLP;FPGA accelerator;FPGA back end;GPU;HIPAcc;ILP;VHDL;algorithm development;code generation;data streaming;data-level parallelism;design space exploration;field programmable gate arrays;glue logic generation;graphics processing units;heterogeneous DSL framework;heterogeneous domain-specific language framework;image data distribution;image filter;image splitting;instruction-level parallelism;kernel operator;local operator;loop coarsening;loop tiling technique;parallel multiple pixel processing;point operator;replicated accelerators;streaming pipeline;Algorithm design and analysis;Field programmable gate arrays;Image processing;Kernel;Parallel processing;Pipelines;Streaming media}, 
doi={10.1109/ASAP.2015.7245730}, 
ISSN={1063-6862}, 
month={July},}
@ARTICLE{6875916, 
author={H. Choi and W. Choi and T. M. Quan and D. G. C. Hildebrand and H. Pfister and W. K. Jeong}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={Vivaldi: A Domain-Specific Language for Volume Processing and Visualization on Distributed Heterogeneous Systems}, 
year={2014}, 
volume={20}, 
number={12}, 
pages={2407-2416}, 
abstract={As the size of image data from microscopes and telescopes increases, the need for high-throughput processing and visualization of large volumetric data has become more pressing. At the same time, many-core processors and GPU accelerators are commonplace, making high-performance distributed heterogeneous computing systems affordable. However, effectively utilizing GPU clusters is difficult for novice programmers, and even experienced programmers often fail to fully leverage the computing power of new parallel architectures due to their steep learning curve and programming complexity. In this paper, we propose Vivaldi, a new domain-specific language for volume processing and visualization on distributed heterogeneous computing systems. Vivaldi's Python-like grammar and parallel processing abstractions provide flexible programming tools for non-experts to easily write high-performance parallel computing code. Vivaldi provides commonly used functions and numerical operators for customized visualization and high-throughput image processing applications. We demonstrate the performance and usability of Vivaldi on several examples ranging from volume rendering to image segmentation.}, 
keywords={data visualisation;image processing;microscopes;parallel processing;rendering (computer graphics);telescopes;visual languages;GPU accelerators;GPU clusters;Vivaldi Python-like grammar;customized visualization;distributed heterogeneous systems;domain-specific language;flexible programming tools;high-performance distributed heterogeneous computing systems;high-performance parallel computing code;high-throughput image processing applications;high-throughput processing;image data;image segmentation;many-core processors;microscopes;numerical operators;parallel architectures;parallel processing abstractions;programming complexity;steep learning curve;telescopes;volume processing;volume rendering;volumetric data visualization;Computational modeling;Data models;Data visualization;Graphics processing units;Image classification;Parallel processing;Rendering (computer graphics);Domain-specific language;GPU computing;distributed heterogeneous systems;volume rendering;0}, 
doi={10.1109/TVCG.2014.2346322}, 
ISSN={1077-2626}, 
month={Dec},}
@INPROCEEDINGS{6758722, 
author={T. Tuunanen and M. Przybilski}, 
booktitle={2014 47th Hawaii International Conference on System Sciences}, 
title={Domain Specific Case Tool for ICT-Enabled Service Design}, 
year={2014}, 
pages={955-964}, 
abstract={One major problem in service design is the limited availability of information gathered during the development process. In particular, information on end-user requirements is difficult for designers, developers, and maintainers to access. Here, we provide a mechanism that supports the gathering and modeling of various types of information throughout the service and software development life cycle. As various existing tools focus on a particular part of the life cycle, essential information is not available, or it is more difficult to obtain in later stages. The linkage between information collected in the different stages is often lost. The implemented tool support enables the modeling of requirements; the abstraction of these requirements in the form of the required system functionalities, which can also be modeled; and the connection with component-based software engineering to support the design of ICT-enabled services.}, 
keywords={object-oriented methods;object-oriented programming;software tools;ICT-enabled service design;component-based software engineering;development process;domain specific case tool;end-user requirements;information throughout;information-and-communications technology;service life cycle;software development life cycle;system functionalities;Adaptation models;Analytical models;Computational modeling;Computers;Software;Unified modeling language;DSL;ICT;RAD}, 
doi={10.1109/HICSS.2014.126}, 
ISSN={1530-1605}, 
month={Jan},}
@INPROCEEDINGS{6690570, 
author={I. Monahov and T. Reschenhofer and F. Matthes}, 
booktitle={2013 17th IEEE International Enterprise Distributed Object Computing Conference Workshops}, 
title={Design and Prototypical Implementation of a Language Empowering Business Users to Define Key Performance Indicators for Enterprise Architecture Management}, 
year={2013}, 
pages={337-346}, 
abstract={To measure the achievement of predefined Enterprise Architecture Management (EAM) goals, it is essential to empower business users to define organization-specific Key Performance Indicators (KPIs). However, to support tool-based calculation of such KPIs, a formal model-based query language is required for their definition and calculation. In this paper we first examine existing general-purpose query languages regarding their suitability for the definition of business-user-specific KPIs in a collaborative environment. Thereafter, we justify the demand for a domain-specific query language ensuring a balance between the strengths of existing query languages and the size and purpose of the EAM domain. Based on this, we outline important design details and a prototypical implementation of such a language in a EAM tool. Finally, our language design is being evaluated by the implementation of suggested EAM KPIs from literature on the one hand, and by the development of a prototype for the use in an EU project on the other hand.}, 
keywords={business data processing;groupware;query languages;EAM;EU project;business users;business-user-specific KPI;collaborative environment;domain-specific query language;enterprise architecture management;formal model-based query language;general-purpose query languages;language design;organization-specific key performance indicators;tool-based calculation;Business;Collaboration;Computer architecture;DSL;Database languages;Standards;Unified modeling language;Enterprise architecture management;domain specific language;key performance indicators}, 
doi={10.1109/EDOCW.2013.44}, 
ISSN={2325-6583}, 
month={Sept},}
@INPROCEEDINGS{6468530, 
author={K. L. Spafford and J. S. Vetter}, 
booktitle={High Performance Computing, Networking, Storage and Analysis (SC), 2012 International Conference for}, 
title={Aspen: A domain specific language for performance modeling}, 
year={2012}, 
pages={1-11}, 
abstract={We present a new approach to analytical performance modeling using Aspen, a domain specific langauge. Aspen (Abstract Scalable Performance Engineering Notation) fills an important gap in existing performance modeling techniques and is designed to enable rapid exploration of new algorithms and architectures. It includes a formal specification of an application's performance behavior and an abstract machine model. We provide an overview of Aspen's features and demonstrate how it can be used to express a performance model for a three dimensional Fast Fourier Transform. We then demonstrate the composability and modularity of Aspen by importing and reusing the FFT model in a molecular dynamics model. We have also created a number of tools that allow scientists to balance application and system factors quickly and accurately.}, 
keywords={fast Fourier transforms;formal specification;molecular dynamics method;physics computing;specification languages;Aspen language;FFT model;abstract machine model;abstract scalable performance engineering notation;analytical performance modeling;application performance behavior;domain specific language;fast Fourier transform;formal specification;molecular dynamics model;Analytical models;Computational modeling;Computer architecture;Hardware;Kernel;Mathematical model;Predictive models}, 
doi={10.1109/SC.2012.20}, 
ISSN={2167-4329}, 
month={Nov},}
@INPROCEEDINGS{6642514, 
author={R. Silva and A. Mota and R. R. Starr}, 
booktitle={Information Reuse and Integration (IRI), 2013 IEEE 14th International Conference on}, 
title={Creating GUI-based DSL formal tools}, 
year={2013}, 
pages={520-527}, 
abstract={In this paper we propose a rigorous methodology to create GUI-based DSLs formal tools. From a formal specification of a DSL we extract a metamodel and create a user-friendly (GUI) front-end. Then we use a code synthesizer to create a formally verified back-end. At the end we link both parts using a wrapper solution. We aim at providing a productive and trustworthy development methodology to safety critical industries.}, 
keywords={formal verification;graphical user interfaces;specification languages;trusted computing;GUI-based DSL formal tools;code synthesizer;formal specification;formally verified back-end;safety critical industries;trustworthy development methodology;user-friendly front-end;wrapper solution;Abstracts;DSL;Graphical user interfaces;Logic gates;Reactive power;Semantics;Syntactics}, 
doi={10.1109/IRI.2013.6642514}, 
month={Aug},}
@INPROCEEDINGS{6240732, 
author={A. Kerner and P. Cota}, 
booktitle={MIPRO, 2012 Proceedings of the 35th International Convention}, 
title={Analyses and optimisation of ADSL/VDSL lines using ericsson APM system - comparing results of two operators}, 
year={2012}, 
pages={681-685}, 
abstract={In this article we explain approach in using Access Performance Manager System (APM) for analyses of ADSL lines in production of broadband (BB) Operator. Results of monitoring and optimization are shown. In our case optimization is done by DAO subsystem. We compare results of two Operators with the same goal to maximize service availability with minimum decrease of service characteristics, specially speed in downstream. APM has purpose for monitoring of all performances of BB system as well as interdependency of lines. APM monitoring and optimization of line parameters is based on changing of End User Profiles and using line testing mechanism integrated in DSLAM devices. APM is designed around a selection of configurable batch jobs that store vital Line Test (SELT and Loop Diagnostic) and DSL-link parameters in the APM database. By selecting the appropriate view, it is possible to follow and understand faulty behaviour in detail. APM is also equipped with a real-time view that is essential when troubleshooting on a per-line basis or when re-configuring a DSL link online. Support for equipment/DSLAM of other vendors than Ericsson is also implemented in APM. APM offers several tools that are designed to solve different problems in a DSL-based network.}, 
keywords={digital subscriber lines;ADSL/VDSL lines analyses;ADSL/VDSL lines optimisation;APM monitoring;BB system;DAO subsystem;DSL link online;DSL-based network;DSL-link parameters;DSLAM devices;Ericsson APM system;SELT;access performance manager system;broadband operator;end user profiles;equipment/DSLAM;faulty behaviour;line testing mechanism;loop diagnostic;troubleshooting;vital line test;Broadband communication;DSL;Delay;IPTV;Monitoring;Optimization;Signal to noise ratio}, 
month={May},}
@INPROCEEDINGS{7385993, 
author={M. R. Blackburn and P. O. Denno}, 
booktitle={Complex Systems Engineering (ICCSE), 2015 International Conference on}, 
title={Using semantic web technologies to integrate models to analytical tools}, 
year={2015}, 
pages={1-5}, 
abstract={This paper discusses the potential advantages and pitfalls of using semantic web technologies in the process of preparing engineering analyses. Analytical tools are often not designed to be integrated with disparate information sources and general-purpose modeling tools and often do not support the detection of problems across domains. Conversely, modeling tools may not capture and represent explicitly the information needed to leverage the capabilities of analytical tools. The method described uses semantic web technology as the integrating mechanism between domain-specific models (DSM) and analytical tools. We describe a method and tools for representing analytical knowledge through semantic web ontologies that map between the metamodels of both the DSM and analytical tools. We compare an earlier tool chain prototype with a significantly revised prototype to reflect on the benefits of using semantic web technologies as an integrating mechanism. A potential advantage is the ability to explicitly and transparently represent the relationships between modeling and analytical tools.}, 
keywords={knowledge representation;semantic Web;DSM;analytical knowledge representation;analytical tools;domain specific models;engineering analyses;general purpose modeling tools;information sources;integrate models;semantic Web technologies;Analytical models;DSL;OWL;Ontologies;Prototypes;Resource description framework;cyber physical systems;domain specific modeling;metamodeling;model-centric engineering;ontologies;semantic web}, 
doi={10.1109/ComplexSys.2015.7385993}, 
month={Nov},}
@INPROCEEDINGS{6575306, 
author={M. Biely and P. Delgado and Z. Milosevic and A. Schiper}, 
booktitle={2013 43rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)}, 
title={Distal: A framework for implementing fault-tolerant distributed algorithms}, 
year={2013}, 
pages={1-8}, 
abstract={We introduce Distal, a new framework that simplifies turning pseudocode of fault tolerant distributed algorithms into efficient executable code. Without proper tool support, even small amounts of pseudocode normally ends up in several thousands of non-trivial lines of Java or C++. Distal is implemented as a library in Scala and consists of two main parts: a domain specific language (DSL) in which algorithms are expressed and an efficient messaging layer that deals with low level issues such as connection management, threading and (de)serialization. The DSL is designed such that implementations of distributed algorithms highly resemble the pseudocode found in research papers. By writing code that is close to the protocol description, one can be more convinced that the implemented system really reflects the protocol specification on paper. Distal does not only make it simple and intuitive to implement distributed algorithms but it also leads to efficient implementations.}, 
keywords={C++ language;Java;distributed algorithms;protocols;software fault tolerance;software libraries;C++;DSL;Distal;Java;Scala;domain specific language;executable code;fault tolerant distributed algorithms;protocol description;protocol specification;pseudocode turning;Algorithm design and analysis;DSL;Distributed algorithms;Fault tolerance;Fault tolerant systems;Java;Protocols;DSL;Paxos;SMR;fault-tolerant distributed algorithms}, 
doi={10.1109/DSN.2013.6575306}, 
ISSN={1530-0889}, 
month={June},}
@INPROCEEDINGS{6227148, 
author={M. Song and E. Tilevich}, 
booktitle={2012 34th International Conference on Software Engineering (ICSE)}, 
title={Metadata invariants: Checking and inferring metadata coding conventions}, 
year={2012}, 
pages={694-704}, 
abstract={As the prevailing programming model of enterprise applications is becoming more declarative, programmers are spending an increasing amount of their time and efforts writing and maintaining metadata, such as XML or annotations. Although metadata is a cornerstone of modern software, automatic bug finding tools cannot ensure that metadata maintains its correctness during refactoring and enhancement. To address this shortcoming, this paper presents metadata invariants, a new abstraction that codifies various naming and typing relationships between metadata and the main source code of a program. We reify this abstraction as a domain-specific language. We also introduce algorithms to infer likely metadata invariants and to apply them to check metadata correctness in the presence of program evolution. We demonstrate how metadata invariant checking can help ensure that metadata remains consistent and correct during program evolution; it finds metadata-related inconsistencies and recommends how they should be corrected. Similar to static bug finding tools, a metadata invariant checker identifies metadata-related bugs as a program is being refactored and enhanced. Because metadata is omnipresent in modern software applications, our approach can help ensure the overall consistency and correctness of software as it evolves.}, 
keywords={meta data;program debugging;software maintenance;specification languages;domain-specific language;enterprise application programming model;metadata coding convention checking;metadata coding convention inferring;metadata invariant checking;naming relationships;program evolution;program source code;static bug finding tools;typing relationships;Computer bugs;Inference algorithms;Java;Programming;Runtime;Syntactics;XML;bug finding;domain-specific languages;enhancement;frameworks;invariants;metadata;refactoring;software maintenance}, 
doi={10.1109/ICSE.2012.6227148}, 
ISSN={0270-5257}, 
month={June},}
@ARTICLE{6676814, 
author={S. Schivo and J. Scholma and B. Wanders and R. A. U. Camacho and P. E. van der Vet and M. Karperien and R. Langerak and J. van de Pol and J. N. Post}, 
journal={IEEE Journal of Biomedical and Health Informatics}, 
title={Modeling Biological Pathway Dynamics With Timed Automata}, 
year={2014}, 
volume={18}, 
number={3}, 
pages={832-839}, 
abstract={Living cells are constantly subjected to a plethora of environmental stimuli that require integration into an appropriate cellular response. This integration takes place through signal transduction events that form tightly interconnected networks. The understanding of these networks requires capturing their dynamics through computational support and models. ANIMO (analysis of Networks with Interactive Modeling) is a tool that enables the construction and exploration of executable models of biological networks, helping to derive hypotheses and to plan wet-lab experiments. The tool is based on the formalism of Timed Automata, which can be analyzed via the UPPAAL model checker. Thanks to Timed Automata, we can provide a formal semantics for the domain-specific language used to represent signaling networks. This enforces precision and uniformity in the definition of signaling pathways, contributing to the integration of isolated signaling events into complex network models. We propose an approach to discretization of reaction kinetics that allows us to efficiently use UPPAAL as the computational engine to explore the dynamic behavior of the network of interest. A user-friendly interface hides the use of Timed Automata from the user, while keeping the expressive power intact. Abstraction to single-parameter kinetics speeds up construction of models that remain faithful enough to provide meaningful insight. The resulting dynamic behavior of the network components is displayed graphically, allowing for an intuitive and interactive modeling experience.}, 
keywords={cellular biophysics;neurophysiology;ANIMO method;UPPAAL model checker;analysis of Networks with Interactive Modeling;biological pathway dynamics;cellular response;environmental stimuli;living cells;reaction kinetics;signal transduction events;tightly interconnected networks;timed automata;Automata;Biological system modeling;Computational modeling;Data models;Kinetic theory;Mathematical model;Dynamic behavior;Timed Automata;modeling;signaling pathway;0}, 
doi={10.1109/JBHI.2013.2292880}, 
ISSN={2168-2194}, 
month={May},}
@INPROCEEDINGS{7051890, 
author={F. P. Basso and C. M. L. Werner and T. C. Oliveira}, 
booktitle={Information Reuse and Integration (IRI), 2014 IEEE 15th International Conference on}, 
title={Towards facilities to introduce solutions for MDE in development environments with reusable assets}, 
year={2014}, 
pages={195-202}, 
abstract={Model Driven Engineering (MDE) is a software development paradigm that promotes improvements in productivity through reuse of software model specifications. Although much effort has been dedicated for more than ten years, MDE has not achieved expressive use. In this paper we address the problem of a lack of a knowledge base about MDE-based solutions, a reason that hampers MDE in practice. To surpass it we propose a domain specific language named RAS++ that represents these solutions as reusable assets. Assets are composed by reuse structures and semantics for the execution of technical solutions for Automated Software Engineering, fostering the integration of tasks for MDE in development environments. Facilities are introduced through some supporting tools: one to design reusable assets and other to integrate them in target development environments. Practical experiences have proven to be promising, suggesting that reusable assets promote some benefits not allowed by other approaches, such as the possibility of a distributed base of knowledge for ASE solutions.}, 
keywords={software reusability;specification languages;MDE-based solutions;RAS++;automated software engineering;domain specific language;knowledge base;model driven engineering;reusable asset design;reuse semantics;reuse structures;software development paradigm;software model specifications;Adaptation models;Automation;Context;Object oriented modeling;Proposals;Software;Unified modeling language;Asset Management Specification;Automated Software Engineering;Model Driven Engineering;Reusable Asset Specification;Reuse of Tasks}, 
doi={10.1109/IRI.2014.7051890}, 
month={Aug},}
@INPROCEEDINGS{6419547, 
author={S. Kartalija and I. Letvenčuk and J. Grahovac and J. Kovacevic}, 
booktitle={Telecommunications Forum (TELFOR), 2012 20th}, 
title={One solution of implementation assembler editor on the Java platform using the Xtext framework}, 
year={2012}, 
pages={1673-1676}, 
abstract={In this paper, using the Xtext framework describes the implementation of an assembler editor for the development of assembly code. This editor supports specific assembler instructions. In addition to the editors realized the set of additional tools which substantially facilitate the development and to use assembler editor. User, are available to other settings of the editor, the editor content monitoring, recognizing the same instructions and an automatic assistant to the prediction based on the user provides certain features of the language development. Xtext provides modern API for describing different aspects of DSL programming languages. Language developed in Xtext framework is independent of Eclipse and can be used in any Java environment.}, 
keywords={Java;application program interfaces;program assemblers;public domain software;API;DSL programming languages;Eclipse;Java environment;Java platform;Xtext framework;assembler editor;assembler instructions;assembly code;editor content monitoring;language development;Conferences;DSL;Digital signal processing;Domain specific languages;Electronic mail;Java;Reduced instruction set computing;DSL;Eclipse;IDE;Java;Xtext okvir;asembler uređivač;gramatika}, 
doi={10.1109/TELFOR.2012.6419547}, 
month={Nov},}
@INPROCEEDINGS{6229790, 
author={D. Ratiu and B. Schaetz and M. Voelter and B. Kolb}, 
booktitle={Software Engineering: Rigorous and Agile Approaches (FormSERA), 2012 Formal Methods in}, 
title={Language engineering as an enabler for incrementally defined formal analyses}, 
year={2012}, 
pages={9-15}, 
abstract={There is a big semantic gap between today's general purpose programming languages on the one hand and the input languages of formal verification tools on the other hand. This makes integrating formal analyses into the daily development practice artificially complex. In this paper we advocate that the use of language engineering techniques can substantially improve this situation along three dimensions. First, more abstract and thus more analyzable domain specific languages can be defined, avoiding the need for abstraction recovery from programs written in general purpose languages. Second, restrictions on the use of existing languages can be imposed and thereby more analyzable code can be obtained and analyses can be incrementally defined. Third, by expressing verification conditions and the verification results at the domain level, they are easier to define and the results of analyses are easier to interpret by end users. We exemplify our approach with three domain specific language fragments integrated into the C programming language, together with a set of analyses: completeness and consistency of decision tables, model-checking-based analyses for a dialect of state machines and consistency of feature models. The examples are based on the mbeddr stack, an extensible C language and IDE for embedded software development.}, 
keywords={C language;decision tables;finite state machines;formal verification;C programming language;abstraction recovery;daily development practice;decision tables completeness;decision tables consistency;domain level;domain specific languages;embedded software development;feature models consistency;formal analysis integration;formal verification tools;incrementally defined formal analysis;language engineering techniques;mbeddr stack;model checking-based analysis;programming languages;semantic gap;state machines;verification conditions;Abstracts;Analytical models;Computer languages;Concrete;DSL;Semantics;Syntactics}, 
doi={10.1109/FormSERA.2012.6229790}, 
month={June},}
@INPROCEEDINGS{7306927, 
author={F. Pramudianto and C. A. Kamienski and E. Souto and F. Borelli and L. L. Gomes and D. Sadok and M. Jarke}, 
booktitle={Ubiquitous Intelligence and Computing, 2014 IEEE 11th Intl Conf on and IEEE 11th Intl Conf on and Autonomic and Trusted Computing, and IEEE 14th Intl Conf on Scalable Computing and Communications and Its Associated Workshops (UTC-ATC-ScalCom)}, 
title={IoT Link: An Internet of Things Prototyping Toolkit}, 
year={2014}, 
pages={1-9}, 
abstract={The Internet of Things (IoT) application development is a complex task that requires a wide range of expertise. Currently, the IoT community lacks a development toolkit that enables inexperienced developers to develop IoT prototypes rapidly. Filling this gap, we propose a development toolkit based on a model-driven approach, called IoT Link. IoT Link allows inexperienced developers to compose mash up applications through a graphical domain-specific language that can be easily configured and wired together to create an IoT application. Through visual components, IoT Link encapsulates the complexity of communicating with devices and services on the internet and abstracts them as virtual objects that are accessible through different communication technologies. Consequently, it solves interoperability between heterogeneous IoT components. Based on the visual model, IoT Link is able to generate a complete Java project including an extendable Java code. In a controlled experiment, IoT Link was 42% faster than using a Java library and able to outperform the Java library's user satisfactions.}, 
keywords={Internet of Things;Java;open systems;software prototyping;software tools;Internet of Things;IoT Link;IoT application development;IoT prototyping toolkit;Java code;interoperability;Conferences;Internet of things;Java;Mashups;Object oriented modeling;Unified modeling language;Visualization;Internet of Things;code generation;development tool;mashup;model driven development}, 
doi={10.1109/UIC-ATC-ScalCom.2014.95}, 
month={Dec},}
@INPROCEEDINGS{7203102, 
author={A. Caracciolo}, 
booktitle={2015 IEEE/ACM 37th IEEE International Conference on Software Engineering}, 
title={A Unified Approach to Automatic Testing of Architectural Constraints}, 
year={2015}, 
volume={2}, 
pages={871-874}, 
abstract={Architectural decisions are often encoded in the form of constraints and guidelines. Non-functional requirements can be ensured by checking the conformance of the implementation against this kind of invariant. Conformance checking is often a costly and error-prone process that involves the use of multiple tools, differing in effectiveness, complexity and scope of applicability. To reduce the overall effort entailed by this activity, we propose a novel approach that supports verification of human-readable declarative rules through the use of adapted off-the-shelf tools. Our approach consists of a rule specification DSL, called Dicto, and a tool coordination framework, called Probo. The approach has been implemented in a soon to be evaluated prototype.}, 
keywords={automatic test software;formal specification;program testing;software architecture;Dicto;Probo;architectural decisions;automatic architectural constraint testing;conformance checking;error-prone process;human-readable declarative rule verification;nonfunctional requirements;rule specification DSL;tool coordination framework;unified approach;Computer architecture;DSL;Guidelines;Software;Software architecture;Stakeholders;Testing;architectural constraints;conformance checking;software architecture}, 
doi={10.1109/ICSE.2015.281}, 
ISSN={0270-5257}, 
month={May},}
@INPROCEEDINGS{6195190, 
author={R. Dreesen}, 
booktitle={Engineering of Computer Based Systems (ECBS), 2012 IEEE 19th International Conference and Workshops on}, 
title={ViDL: A Versatile ISA Description Language}, 
year={2012}, 
pages={222-231}, 
abstract={Application specific processors as part of systems-on-a-chip (SoCs) have become increasingly popular in recent years. The need for efficient development of such processors raises the demand for simple and reliable tools and respective specification languages. This paper presents the Versatile Instruction Set Architecture Description Language (ViDL), to formally define (application specific) instruction sets. Simulators and processor implementations are then generated from such specifications. The language features functional and domain specific concepts to allow for rapid and simple specification of realistic instruction sets. In contrast to related approaches, ViDL strictly abstracts from micro architectural aspects, such as the instruction pipeline and hazard resolution. These aspects are shifted from the developer to a generator, which greatly simplifies specification and increases reliability. From the very same ViDL specification, we can automatically generate consistent instruction set simulators (40 - 140 MIPS), web-based simulators, and a set of processors with different pipeline structures (2-7 stages, 300-650 MHz). Formalization of instruction sets (ARM, MIPS, Power, SRC, and Core VA) in ViDL has shown to be simple. It took only between 2 month and 90 minutes.}, 
keywords={ASIP;DSL;Generator;ISA;Instruction Set;Language;Processor;Simulator;ViDL}, 
doi={10.1109/ECBS.2012.49}, 
month={April},}
@INPROCEEDINGS{6340132, 
author={O. Dayibas and H. Oguztüzün}, 
booktitle={2012 IEEE 36th Annual Computer Software and Applications Conference}, 
title={Kutulu: A Domain-Specific Language for Feature-Driven Product Derivation}, 
year={2012}, 
pages={105-110}, 
abstract={Software Product Line Engineering (SPLE) defines processes to facilitate the development of a family of products in a pre-defined market more effectively. Its success depends on implementation of these processes utilizing best practices with proper tool support. This paper describes how to enhance domain design and variation management processes of SPLE with a domain-specific language (DSL), namely "Kutulu". It also introduces novel modeling tools and dependency injection-based realization approach that are well-suited for product derivation in SPL. Our DSL definition, developed tools and their position in the product line context are put forth in this paper.}, 
keywords={configuration management;formal specification;object-oriented languages;object-oriented programming;product development;Kutulu;SPLE;dependency injection-based realization approach;domain design;domain-specific language;feature-component binding;feature-driven product derivation;modeling tool;product development;software product line engineering;tool support;variation management process;Abstracts;Computer aided software engineering;DSL;Generators;Object oriented modeling;Software;Transforms;Dependency Injection;Domain-specific Language;Feature-Component Binding;Software Product Line;Variability Management}, 
doi={10.1109/COMPSAC.2012.20}, 
ISSN={0730-3157}, 
month={July},}
@INPROCEEDINGS{6274035, 
author={Y. Nomura and K. Kimura and H. Kurihara and R. Yamamoto and K. Yamamoto and S. Tokumoto}, 
booktitle={2012 IEEE Eighth World Congress on Services}, 
title={Massive Event Data Analysis and Processing Service Development Environment Using DFD}, 
year={2012}, 
pages={80-87}, 
abstract={In these days, there are a lot of massive event data appeared every day because networked devices such as smartphones and kind of sensors become very common. Every service provider intends to analyze the event data and discovers a new business rule for real time event processing service. We proposed a methodology which integrates such kind of data analysis and service development using DFD (Data Flow Diagram) which is independent from implementations, and we developed its prototype for evaluations. The methodology and the tool separate the concern of a developer and an analyst, moreover, we succeeded to confirm that the prototype tool reduced actual analysis and service development costs dramatically.}, 
keywords={business data processing;data analysis;data flow graphs;real-time systems;DFD;business rule discovery;data flow diagram;massive event data analysis service development;massive event data processing service development environment;networked devices;real-time event processing service;service development costs;service provider;Analytical models;DSL;Data analysis;Data models;Engines;Mathematical model;Real time systems;Analysis;Cloud;Dataflow languages;Event Processing;Productivity;Tools}, 
doi={10.1109/SERVICES.2012.46}, 
ISSN={2378-3818}, 
month={June},}
@INPROCEEDINGS{7579377, 
author={A. Mora Segura and A. Pescador and J. de Lara and M. Wimmer}, 
booktitle={2016 IEEE 20th International Enterprise Distributed Object Computing Conference (EDOC)}, 
title={An Extensible Meta-Modelling Assistant}, 
year={2016}, 
pages={1-10}, 
abstract={Meta-models play a pivotal role in Model-Driven Engineering (MDE). They are used to create domain-specific models, and to type model management operations like model transformations or code generators. However, even though creating meta-models is a common activity, it is currently mostly a manual activity, which does not profit from existing knowledge. In order to facilitate the meta-modelling task, we propose an extensible meta-modelling assistant. While primarily focussed on helping in the creation of meta- models, it can also help in creating models. The assistant permits the provision of heterogeneous data description sources (like ontologies, RDF data, XML schemas, database schemas and meta-models), and enables their uniform querying. Different kinds of queries are supported, and improved through synonym search. Query results are prioritized through sense disambiguation, can be graphically visualized, and incorporated into the (meta-)model being built. The assistant has been realized within Eclipse, and its architecture has been designed to be independent of the meta-modelling technology used. As a proof- of-concept, we show its integration within DSL-tao, a pattern-based meta-modelling tool built by our group, and two other tools developed by third-parties. The usefulness of the system is illustrated with a running example in the process modelling domain.}, 
keywords={data description;data visualisation;modelling;natural language processing;query processing;DSL-tao;Eclipse;domain-specific models;extensible metamodelling assistant;graphic visualization;heterogeneous data description sources;metamodels;model management operations;model-driven engineering;pattern-based metamodelling tool;query results;sense disambiguation;uniform data querying;Biological system modeling;DSL;Data models;Ontologies;Organizations;Resource description framework;Unified modeling language}, 
doi={10.1109/EDOC.2016.7579377}, 
month={Sept},}
@INPROCEEDINGS{6984583, 
author={F. Bergenti}, 
booktitle={2014 IEEE 26th International Conference on Tools with Artificial Intelligence}, 
title={An Introduction to the JADEL Programming Language}, 
year={2014}, 
pages={974-978}, 
abstract={This paper summarizes the current state of development of JADEL, a novel programming language that eases the implementation of agents and multi-agent systems. First, the introduction of a novel agent programming language is motivated and the approach that was used to design JADEL is presented. Then, the characteristic features of JADEL are described by means of a didactic example. The paper is concluded with a short discussion about current and planned developments of JADEL.}, 
keywords={multi-agent systems;object-oriented languages;object-oriented programming;parallel programming;JADE Language;JADEL programming language;agent programming language;multiagent system;DSL;Java;Multi-agent systems;Ontologies;Programming;Syntactics;JADE;multi-agent systems;programming languages}, 
doi={10.1109/ICTAI.2014.147}, 
ISSN={1082-3409}, 
month={Nov},}
@INPROCEEDINGS{6375611, 
author={M. Lipaczewski and S. Struck and F. Ortmeier}, 
booktitle={High-Assurance Systems Engineering (HASE), 2012 IEEE 14th International Symposium on}, 
title={Using Tool-Supported Model Based Safety Analysis -- Progress and Experiences in SAML Development}, 
year={2012}, 
pages={159-166}, 
abstract={Software controls in technical systems are becoming more and more important and complex. Model based safety analysis can give provably correct and complete results, often in a fully automatic way. These methods can answer both logical and probabilistic questions. In common practice, the needed models must be specified in different input languages of different tools depending on the chosen verification tool for the desired aspect. This is time consuming and error-prone. To cope with this problem we developed the safety analysis modeling language (SAML). In this paper, we present a new tool to intuitively create probabilistic, non-deterministic and deterministic specifications for formal analysis. The goal is to give tool-support during modeling and thus make building a formal model less error-prone. The model is then automatically transformed into the input language of state of the art verification engines. We illustrate the approach on a case-study from nuclear power plant domain.}, 
keywords={formal languages;formal specification;formal verification;probability;safety-critical software;SAML development;art verification engines;deterministic specifications;formal analysis;formal model;nondeterministic specifications;nuclear power plant domain;probabilistic specifications;safety analysis modeling language;software controls;tool-supported model based safety analysis;verification tool;Analytical models;Generators;Hazards;Probabilistic logic;Switches;S3E;SAML;dependability;domain specific language;eclipse based editor;formal analysis;safety assurance}, 
doi={10.1109/HASE.2012.34}, 
ISSN={1530-2059}, 
month={Oct},}
@INPROCEEDINGS{6957109, 
author={J. A. Akinyele and G. Barthe and B. Grégoire and B. Schmidt and P. Y. Strub}, 
booktitle={2014 IEEE 27th Computer Security Foundations Symposium}, 
title={Certified Synthesis of Efficient Batch Verifiers}, 
year={2014}, 
pages={153-165}, 
abstract={Many algorithms admit very efficient batch versions that compute simultaneously the output of the algorithms on a set of inputs. Batch algorithms are widely used in cryptography, especially in the setting of pairing-based computations, where they deliver significant speed-ups. AutoBatch is an automated tool that computes highly optimized batch verification algorithms for pairing-based signature schemes. Thanks to finely tuned heuristics, AutoBatch is able to rediscover efficient batch verifiers for several signature schemes of interest, and in some cases to output batch verifiers that outperform the best known verifiers from the literature. However, AutoBatch only provides weak guarantees (in the form of a LaTeX proof) of the correctness of the batch algorithms it outputs. In this paper, we verify the correctness and security of these algorithms using the EasyCrypt framework. To achieve this goal, we define a domain-specific language to describe verification algorithms based on pairings and provide an efficient algorithm for checking (approximate) observational equivalence between expressions of this language. By translating the output of AutoBatch to this language and applying our verification procedure, we obtain machine-checked correctness proofs of the batch verifiers. Moreover, we formalize notions of security for batch verifiers and we provide a generic proof in EasyCrypt that batch verifiers satisfy a security property called screening, provided they are correct and the original signature is unforgeable against chosen-message attacks. We apply our techniques to several well-known pairing-based signature schemes from the literature, and to Groth-Sahai zero-knowledge proofs.}, 
keywords={cryptography;digital signatures;formal verification;specification languages;theorem proving;AutoBatch;EasyCrypt framework;Groth-Sahai zero-knowledge proofs;LaTeX correctness proof;automated tool;batch versions;certified synthesis;correctness verification;cryptography;domain-specific language;generic proof;machine-checked correctness proofs;message attacks;observational equivalence checking;optimized batch verification algorithms;pairing-based computations;pairing-based signature schemes;screening;security property;Approximation algorithms;Equations;Optimization;Probabilistic logic;Public key;certified proofs;cryptographic design;cryptography;signature schemes}, 
doi={10.1109/CSF.2014.19}, 
ISSN={1063-6900}, 
month={July},}
@INPROCEEDINGS{6657075, 
author={X. Liu and J. Kubiatowicz}, 
booktitle={2013 IEEE 31st International Conference on Computer Design (ICCD)}, 
title={Chisel-Q: Designing quantum circuits with a scala embedded language}, 
year={2013}, 
pages={427-434}, 
abstract={We introduce Chisel-Q, a high-level functional language for generating quantum circuits. Chisel-Q permits quantum computing algorithms to be constructed using the meta-language features of Scala and its embedded DSL Chisel. With Chisel-Q, designers of quantum computing algorithms gain access to high-level, modern language features and abstractions. We describe a synthesis flow that transforms Chisel-Q into an explicit quantum circuit in the Quantum Assembly Language (QASM) format. We also discuss several optimizations to reduce the generated hardware cost. The Chisel-Q tool includes resource and performance estimation which can be used to compare different implementations of the same functionality. We compare the output of the generic Chisel-Q synthesis flow with hand-tuned versions of well-known quantum circuits.}, 
keywords={CAD;functional languages;quantum computing;Chisel-Q;DSL Chisel;Scala embedded language;high-level functional language;quantum assembly language;quantum circuits;quantum computing algorithms;Algorithm design and analysis;Hardware;Latches;Logic gates;Optimization;Quantum computing;Syntactics;Computer Aided Design;Quantum Computing}, 
doi={10.1109/ICCD.2013.6657075}, 
ISSN={1063-6404}, 
month={Oct},}
@INPROCEEDINGS{6984098, 
author={C. Sacramento and A. C. R. Paiva}, 
booktitle={Quality of Information and Communications Technology (QUATIC), 2014 9th International Conference on the}, 
title={Web Application Model Generation through Reverse Engineering and UI Pattern Inferring}, 
year={2014}, 
pages={105-115}, 
abstract={A great deal of effort in model-based testing is related to the creation of the model. In addition, the model itself, while a powerful tool of abstraction, can have conceptual errors, introduced by the tester. These problems can be reduced by generating those models automatically. This paper presents a dynamic reverse engineering approach that aims to extract part of the model of an existing web application through the identification of User Interface (UI) patterns. This reverse engineering approach explores automatically any web application, records information related to the interaction, analyses the gathered information, tokenizes it, and infers the existing UI patterns via syntactical analysing. After being complemented with additional information and validated, the model extracted is the input for the Pattern-Based Graphical User Interface Testing (PBGT) approach for testing existing web application under analysis.}, 
keywords={Internet;graphical user interfaces;program diagnostics;program testing;PBGT approach;UI pattern inference;Web application model generation;dynamic reverse engineering approach;model-based testing;pattern-based graphical user interface testing;syntactical analysis;user interface;Analytical models;DSL;Data mining;Graphical user interfaces;Reverse engineering;Testing;Reverse Engineering;UI Patterns;Web Application;Web Scraping}, 
doi={10.1109/QUATIC.2014.20}, 
month={Sept},}
@INPROCEEDINGS{6511821, 
author={A. Ribeiro and A. R. da Silva}, 
booktitle={Quality of Information and Communications Technology (QUATIC), 2012 Eighth International Conference on the}, 
title={Survey on Cross-Platforms and Languages for Mobile Apps}, 
year={2012}, 
pages={255-260}, 
abstract={Nowadays mobile applications are becoming increasingly more present in our daily life, allowing people to perform several tasks through the use of smartphones, tablets or equivalent devices. Despite the great benefits in terms of innovation and in the variety of available solutions, the rapid and continuous growth of the mobile market has resulted in some fragmentation of the platforms that support each mobile device. The existence of different mobile operating systems with different programming languages and development tools can be a problem when someone wants to release an application in as many platforms as possible. The typical approach of simply rewriting the application for each one of those platforms is usually impracticable either in terms of budget or development time, requiring a bigger effort to be made. Therefore, a solution that could generate an application for several platforms (multi or cross-platform) without compromising the overall quality of the application would decrease the time to market of the application and increase enormously the number of potential users. Providentially, during the last years some effort has been conducted to tackle this problem, especially with the emergence of tools and frameworks that facilitate the development of crossplatform mobile applications. This paper focuses on these technologies and attempts to provide a global view of the actual state of this area.}, 
keywords={mobile computing;programming languages;smart phones;software tools;cross-platform mobile application development tools;mobile applications;mobile device;mobile market;mobile operating systems;programming languages;smartphones;tablets;Application;Cross-platform;Domain Specific Language;Mobile;Model-driven development}, 
doi={10.1109/QUATIC.2012.56}, 
month={Sept},}
@INPROCEEDINGS{7020125, 
author={J. Schützel and D. Peng and A. M. Uhrmacher and L. F. Perrone}, 
booktitle={Proceedings of the Winter Simulation Conference 2014}, 
title={Perspectives on languages for specifying simulation experiments}, 
year={2014}, 
pages={2836-2847}, 
abstract={Domain specific languages have been used in modeling and simulation as tools for model description. In recent years, the efforts toward enabling simulation reproducibility have motivated the use of domain specific languages also as the means with which to express experiment specifications. In simulation areas ranging from computational biology to computer networks, the emerging trend is to treat the experimentation process as a first class object. Domain specific languages serve to specify individual sub-tasks in this process, such as configuration, observation, analysis, and evaluation of experimental results. Additionally, they can be used in a broader scope, for instance, to describe formally the experiment's goals. The research and development of domain specific languages for experiment specification explores all of these and additional possible applications. In this paper, we discuss various existing approaches for defining this type of domain specific languages and present a critical analysis of our findings.}, 
keywords={digital simulation;formal specification;simulation languages;specification languages;domain specific languages;experiment specification;model description;simulation experiments;Analytical models;Computational modeling;DSL;Data collection;Data models;Instruments;Mathematical model}, 
doi={10.1109/WSC.2014.7020125}, 
ISSN={0891-7736}, 
month={Dec},}
@INPROCEEDINGS{6648277, 
author={N. Stuban}, 
booktitle={Proceedings of the 36th International Spring Seminar on Electronics Technology}, 
title={Operational tests of a wireless fetal pulse oximeter}, 
year={2013}, 
pages={383-387}, 
abstract={Pulse oximeters are measuring the oxygen level of the arterial blood with a non-invasive method. The paper introduces the working principles and the build-up of modern pulse oximeters. The construction steps of a new kind of diagnostic tool, the wireless fetal pulse oximeter will be described also. Eliminating the catheter from the fetal blood oxygen monitoring system gives the possibility of free movement to the mother in labor. Furthermore, the uncomfortable feeling caused by the catheter can be reduced with this wireless device. With these advantages the wireless fetal pulse oximeter is a promising diagnostic tool for the labor rooms in the future. The radio range, the operation time, and the waterproof capability of the sealing of the prototype were examined in the paper.}, 
keywords={biomedical equipment;blood;blood vessels;obstetrics;oximetry;patient diagnosis;patient monitoring;arterial blood;diagnostic tool;fetal blood oxygen monitoring system;labor rooms;noninvasive method;operational tests;oxygen level measurement;prototype sealing waterproof capability;radio range;wireless device;wireless fetal pulse oximeter;Antenna measurements;Batteries;Battery charge measurement;Blood;Coatings;DSL;Wireless communication}, 
doi={10.1109/ISSE.2013.6648277}, 
ISSN={2161-2528}, 
month={May},}
@INPROCEEDINGS{7000030, 
author={M. T. C. F. Albuquerque and G. L. Ramalho and V. Corruble and A. L. M. Santos and F. Freitas}, 
booktitle={2014 Brazilian Symposium on Computer Games and Digital Entertainment}, 
title={Helping Developers to Look Deeper inside Game Sessions}, 
year={2014}, 
pages={31-40}, 
abstract={Game design and development activities are increasingly relying on the analysis of gamer's behavior and preferences data. Various tools are available to the developers to track and analyze general data concerning acquisition, retention and monetization aspects of game commercialization. This is good enough to give hints on where problems are, but not to enable a precise diagnosis, which demands fine-grained data. For this kind of data, there is not enough support or guidance to decide which data to capture, to write the code to capture it, to choose the best representation of it and to allow an adequate retrieval and presentation of it. This paper introduces GameGuts (GG), a framework devoted to give further assistance to developers in choosing, representing, accessing and presenting game sessions fine-grained data. As a case study, GG recorded sessions of a game platform with over a hundred thousand users. The logs were analyzed using a Visual Domain Specific Language (as a query language) and an ensemble of rules (as a compliance test). The results are encouraging, since we could - among other results - find bugs and catch cheaters, as well as spot design flaws.}, 
keywords={computer games;data analysis;query languages;visual languages;GameGuts;bugs;catch cheaters;design flaws;game commercialization;game design;game development activities;game platform;game sessions;gamer behavior analysis;general data analysis;general data tracking;preferences data;query language;rule ensemble;visual domain specific language;DSL;Database languages;Games;Measurement;Ontologies;Servers;Visualization;game analytics;game data mining;knowledge representation}, 
doi={10.1109/SBGAMES.2014.28}, 
ISSN={2159-6654}, 
month={Nov},}
@INPROCEEDINGS{7139899, 
author={A. Nordmann and S. Wrede and J. Steil}, 
booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)}, 
title={Modeling of movement control architectures based on motion primitives using domain-specific languages}, 
year={2015}, 
pages={5032-5039}, 
abstract={This paper introduces a model-driven approach for engineering complex movement control architectures based on motion primitives, which in recent years have been a central development towards adaptive and flexible control of complex and compliant robots. We consider rich motor skills realized through the composition of motion primitives as our domain. In this domain we analyze the control architectures of representative example systems to identify common abstractions. It turns out that the introduced notion of motion primitives implemented as dynamical systems with machine learning capabilities, provide the computational building block for a large class of such control architectures. Building on the identified concepts, we introduce domain-specific languages that allow the compact specification of movement control architectures based on motion primitives and their coordination respectively. Using a proper tool chain, we show how to employ this model-driven approach in a case study for the real world example of automatic laundry grasping with the KUKA LWR-IV, where executable source-code is automatically generated from the domain-specific language specification.}, 
keywords={learning (artificial intelligence);motion control;programming languages;robots;time-varying systems;KUKA LWR-IV;domain-specific language specification;dynamical systems;executable source-code;machine learning;motion primitives;movement control architectures;robot;Adaptation models;Adaptive systems;Computer architecture;DSL;Motion control;Robot kinematics}, 
doi={10.1109/ICRA.2015.7139899}, 
ISSN={1050-4729}, 
month={May},}
@INPROCEEDINGS{6641450, 
author={C. Hélène and L. Sébastien}, 
booktitle={High Performance Computing and Simulation (HPCS), 2013 International Conference on}, 
title={Algorithmic skeleton library for scientific simulations: SkelGIS}, 
year={2013}, 
pages={429-436}, 
abstract={Scientific simulations give rise to complex codes where data size and computation time become very important issues and sometimes a scientific barrier. Therefore, aiding parallelization has become a main topic in computer science. In this paper is introduced a new type of solution to give a totally transparent access to parallel programming for noncomputer scientists. This solution, named SkelGIS, takes place at the crossroads of domain specific languages, domain specific libraries and skeleton libraries, getting advantages of each domain. SkelGIS aims at providing a general solution for simulations in heterogeneous scientific domains. SkelGIS does not require a new language learning, nor to manipulate specific parallel tools, and it ensures a sequential programming style to the user with a totally hidden parallelization. Concepts and technical choices of the library are described in this paper. Furthermore, two very different benchmarks are studied to bring out performances of the library on light and complex simulations.}, 
keywords={digital libraries;geographic information systems;learning (artificial intelligence);parallel programming;scientific information systems;specification languages;SkelGIS;algorithmic skeleton library;complex codes;complex simulations;computation time;computer science;data size;domain specific languages;domain specific libraries;heterogeneous scientific domains;hidden parallelization;language learning;noncomputer scientists;parallel programming;scientific barrier;scientific simulations;sequential programming style;skeleton libraries;Computational modeling;DSL;Data structures;Libraries;Parallel processing;Programming;Skeleton;Algorithmic skeleton;DSL;scientific simulation}, 
doi={10.1109/HPCSim.2013.6641450}, 
month={July},}
@INPROCEEDINGS{6227067, 
author={M. Song and E. Tilevich}, 
booktitle={2012 34th International Conference on Software Engineering (ICSE)}, 
title={Detecting metadata bugs on the fly}, 
year={2012}, 
pages={1455-1456}, 
abstract={Programmers are spending a large and increasing amount of their time writing and modifying metadata, such as Java annotations and XML deployment descriptors. And yet, automatic bug finding tools cannot find metadata-related bugs introduced during program refactoring and enhancement. To address this shortcoming, we have created metadata invariants, a new programming abstraction that expresses naming and typing relationships between metadata and the main source code of a program. A paper that appears in the main technical program of ICSE 2012 describes the idea, concept, and prototype of metadata invariants [4]. The goal of this demo is to supplement that paper with a demonstration of our Eclipse plugin, Metadata Bug Finder (MBF). MBF takes as input a script written in our domain-specific language that describes a set of metadata coding conventions the programmer wishes to enforce. Then after each file save operation, MBF checks the edited codebase for the presence of any violations of the given metadata programming conventions. These violations are immediately reported to the programmer as potential metadata-related bugs. By making the programmer aware of these potential bugs, MBF prevents them from seeping into production, thereby improving the overall correctness of the edited codebase.}, 
keywords={meta data;program debugging;Eclipse plugin;ICSE 2012;Java annotations;MBF;XML deployment descriptors;domain-specific language;main source code;main technical program;metadata bug finder;metadata bugs detection;metadata coding conventions;metadata invariants;metadata programming conventions;program enhancement;program refactoring;programming abstraction;Computer bugs;Encoding;Java;Programming;Software;Testing;XML;bug finding;domain-specific languages;enhancement;frameworks;invariants;metadata;refactoring;software maintenance}, 
doi={10.1109/ICSE.2012.6227067}, 
ISSN={0270-5257}, 
month={June},}
@INPROCEEDINGS{7018471, 
author={J. S. Sottet and A. Vagner}, 
booktitle={Model-Driven Engineering and Software Development (MODELSWARD), 2014 2nd International Conference on}, 
title={Defining Domain Specific Transformations in Human-Computer interfaces development}, 
year={2014}, 
pages={246-253}, 
abstract={Early model-based approaches for Human-Computer Interaction (HCI) clearly depicted models and frameworks for generating User Interfaces (UI) but considered model transformations as black-boxes. In the 2000's, these approaches were criticized due to the poor quality of the produced UI. One of the main reasons of this poor quality can be easily observed in state of the art UI transformations: they are the heart of designers' know-how but are maintained by a minority of specialists. Meanwhile, mainstream UI design methods have shown a growing number of heterogeneous stakeholders that collaborate to produce modern and qualitative UI. We claim that these stakeholders must comprehend and interact with transformations and thus we need to make the transformation language affordable to these stakeholders. Indeed, such a simplification should hide transformations complexity and burden for any stakeholder, finally focusing on a specific part of the design domain: a Domain Specific Language (DSL) for transformations or Domain Specific Transformation Language (DSTL). We provide in this paper a method and a supporting tool for systematizing and finally executing DSTL for model-driven UI development. We depict that framework on a proof of concept implementation for an HCI-specific stakeholder: the usability expert.}, 
keywords={Abstracts;Analytical models;Complexity theory;Grammar;Human computer interaction;Usability;Domain Specific Transformation Languages;Human-Computer Interaction;Model Transformation;Model-Driven Development}, 
month={Jan},}
@INPROCEEDINGS{7273614, 
author={P. A. d. S. Duarte and F. M. Barreto and F. A. d. A. Gomes and W. V. d. Carvalho and F. A. M. Trinta}, 
booktitle={Computer Software and Applications Conference (COMPSAC), 2015 IEEE 39th Annual}, 
title={CRITiCAL: A Configuration Tool for Context Aware and mobiLe Applications}, 
year={2015}, 
volume={2}, 
pages={159-168}, 
abstract={This paper presents an approach for modelling and generating Context-Aware and Mobile (CAM) applications based on (i) Model-Driven Engineering and (ii) context acquisition middleware concepts. Our approach allows software engineers to build CAM applications by modelling contextual information and rule-based behaviour on a visual notation. These graphical models are transformed into an Android-based code, targeted for a context-aware middleware called LoCCAM, which encapsulates device sensors access. An initial user evaluation conducted with a group of fourteen computer science volunteers was implemented and indicates time reduction gains in the middleware configuration process and that the complexity in the writing of contextual behaviour of applications is also decreased.}, 
keywords={Android (operating system);configuration management;middleware;mobile computing;visual programming;Android-based code;CAM applications;CRITiCAL;LoCCAM;configuration tool;context acquisition middleware concept;context aware applications;context-aware middleware;contextual behaviour writing complexity;contextual information modelling;device sensor access encapsulation;graphical model;middleware configuration process;mobile applications;model-driven engineering;rule-based behaviour;software engineering;time reduction gain;visual notation;Adaptation models;Computer aided manufacturing;Context;Context modeling;DSL;Middleware;Android;Context-Aware;DSL;MDE;Middleware;Self-Adaptation}, 
doi={10.1109/COMPSAC.2015.91}, 
month={July},}
@INPROCEEDINGS{7018464, 
author={J. Tatibouët and A. Cuccuru and S. Gérard and F. Terrier}, 
booktitle={Model-Driven Engineering and Software Development (MODELSWARD), 2014 2nd International Conference on}, 
title={Towards a systematic, tool-independent methodology for defining the execution semantics of UML profiles with fUML}, 
year={2014}, 
pages={182-192}, 
abstract={The purpose of UML profile mechanism is to design domain specific languages (DSL) based on UML. It exists a wide range of UML profiles: MARTE, ROOM, SysML. Current profile design methodology only considers the syntactic part of the language and keeps informal the execution semantics description. This impairs Model Driven Engineering (MDE) promises which advocates for executable models. This paper presents a systematic approach to formalize the execution semantics of UML profiles using foundational UML (normative specification) which defines a precise semantics for a subset of UML. This approach is integrated into the reference profile design methodology. It is illustrated on a small profile to support Turing machines. It demonstrates capability to execute resulting profiled models through the defined semantics.}, 
keywords={Abstracts;Computational modeling;Runtime;Semantics;Syntactics;Turing machines;Unified modeling language;Alf;DSML;Execution;MoC;Profile;Semantics;Turing;fUML}, 
month={Jan},}
@INPROCEEDINGS{6511822, 
author={V. Amaral and B. Barroca and P. Carreira}, 
booktitle={Quality of Information and Communications Technology (QUATIC), 2012 Eighth International Conference on the}, 
title={Towards a Robust Solution in Building Automation Systems: Supporting Rapid Prototyping and Analysis}, 
year={2012}, 
pages={261-264}, 
abstract={It is presently required agile and systematic solutions aiming at streamlining the development, maintenance and configuration of complex Building Automation Systems (BASs) in an energy aware manner. We aim at defining usable Domain Specific Languages (DSLs) using a Software Language Engineering (SLE), as systematic approach for language development, and develop the right tools for specifying the behavior of BASs components along with their energy-related requirements. The goal is to not only assist the systems engineers while rapid-prototyping/developing affordable, high-quality, energy-efficient(EE) BASs, but also to take advantage of high level abstractions, efficient special-purpose verification algorithms and analysis tools for early validation and verification, in order to promote Quality of the generated software products. We are watching to the rise of Model-Driven Development as the pragmatic approach to build them, since this approach is based on the notion of explicit abstractions/models. This is achieved thanks to model transformations that, besides automatically translating any specification of a given language into other execution specifications, also allow us to derive analysis specifications. The problem with the referred types of transformation purposes is that we cannot guarantee quality and coherence between the derived specifications into execution specifications and combine it with analysis specifications unless we can either make use of testing over the execution, with the problems already known, or have mechanisms to study the transformations. While this problem is motivated by the concrete need of developing BASs, we foresee that it can be of general application in SLE. In this position paper we will give a state of the art in Building Automation and we give an overview of a possible solution that uses MDD and model transformations, in the context of a BAS solution, in order to check their correctness in w.r.t. the formal semantics of the lan- uages used in the target platforms (i.e either execution or analysis).}, 
keywords={building management systems;buildings (structures);civil engineering computing;energy conservation;formal specification;formal verification;rapid prototyping (industrial);software quality;BAS configuration;BAS development;BAS maintenance;DSL;SLE;analysis tool;building automation system;domain specific language;energy aware BAS;energy-related requirement;execution specification;explicit abstraction notion;formal semantics;language development;model transformation;model-driven development;rapid prototyping;software language engineering;software product quality;special-purpose verification algorithm;DSLTrans;Model Checking;Model Transformations;Model Transformations Analysis;Quality in MDD;Software Language Engineering}, 
doi={10.1109/QUATIC.2012.59}, 
month={Sept},}
@INPROCEEDINGS{7049679, 
author={P. Schug and A. Kotlov}, 
booktitle={Informatics in Control, Automation and Robotics (ICINCO), 2014 11th International Conference on}, 
title={Designing CAx-process chains - Model and modeling language for CAx-process chain methodology}, 
year={2014}, 
volume={02}, 
pages={724-733}, 
abstract={Product development and production processes are supported by software systems during the development and planning phases. The usage of these software tools during or prior to and post the different process steps is called CAx-processes. The combination of these CAx-processes form process chains, also known as CAx-process chains (CAx-PCs), which mirror the production processes virtually. The content of this paper introduces a solution for designing the software chains in conformity to the methodology for evaluation, analysis and optimization of CAx-PCs. The solution includes the definition of DSL expressing the model for CAx-PCs and the software prototype “CAx-process chain designer” for deriving the alternatives of CAx-PCs from the expressed model.}, 
keywords={product development;production engineering computing;production planning;specification languages;CAx-PCs;CAx-process chain designer;CAx-process chains;development phase;modeling language;planning phase;product development;production processes;software chains;software systems;software tools;Adaptation models;Analytical models;Optimization;Product development;Production;Software;Solid modeling;CAx;Chain;DSL;Model;Process}, 
doi={10.5220/0005054507240733}, 
month={Sept},}
@INPROCEEDINGS{6692589, 
author={J. Schafer and D. Klein}, 
booktitle={Vehicular Technology Conference (VTC Spring), 2013 IEEE 77th}, 
title={Implementing Situation Awareness for Car-to-X Applications Using Domain Specific Languages}, 
year={2013}, 
pages={1-5}, 
abstract={Car-to-X i.e. Car-to-Anything communication based on standardized IEEE 802.11p radio technology is comprised with wireless communication between cars (Car-to-Car) and between vehicles and the environment (Car-to-Infrastructure). In order to develop Car-to-X applications based on this standard one needs to model parameters such as the vehicle's position, velocity, acceleration etc. and parameters of the vehicle's environment. Typically, the underlying domain models are designed in an ad-hoc manner and the domain rules become hard-coded into the source- code of the application software. In this paper we describe an alternative and more flexible approach. The model is described in almost plain English using a Domain Specific Language (DSL) and translated into target code via parser technology based on the ANTLR tool-chain. This provides more flexibility not only in creating and maintaining the domain rules, but also with regards to generating code for entirely different target languages and technology environments. For instance, we demonstrate to generate Java code for a simulation environment and C-code for the embedded device from the same rule definitions.}, 
keywords={Java;mobile computing;wireless LAN;ANTLR tool-chain;C-code;Java code;car-to-anything communication;car-to-car communication;car-to-infrastructure communication;car-to-x applications;domain specific languages;model parameters;parser technology;situation awareness;source-code;standardized IEEE 802.11p radio technology;vehicle acceleration;vehicle position;vehicle velocity;wireless communication;Context;DSL;Engines;Grammar;Java;Runtime;Syntactics}, 
doi={10.1109/VTCSpring.2013.6692589}, 
ISSN={1550-2252}, 
month={June},}
@INPROCEEDINGS{7018466, 
author={E. Tyugu and M. Harf and P. Grigorenko}, 
booktitle={Model-Driven Engineering and Software Development (MODELSWARD), 2014 2nd International Conference on}, 
title={A case study of combining compositional and object-oriented software development}, 
year={2014}, 
pages={201-208}, 
abstract={We analyze an approach to software development where object-oriented and compositional software specifications are written in separate languages and are only loosely connected. It supports compositional design of software in a domain-specific language and automatic model-driven construction of code from classes written in Java. We justify our approach by giving examples of development of large simulation programs and services on large models. We present also an example of using our method in general purpose software development - this is bootstrapping the essential part of a software tool CoCoViLa, i.e. synthesizing CoCoViLa in CoCoViLa itself.}, 
keywords={Computational modeling;DSL;Java;Mathematical model;Object oriented modeling;Software;Unified modeling language;Compositional Software Design;Domain-specific Modeling;Model Driven Software Development;Structural Synthesis of Programs}, 
month={Jan},}
@INPROCEEDINGS{6955332, 
author={C. H. C. Jojoa and O. M. Drews}, 
booktitle={Computing Colombian Conference (9CCC), 2014 9th}, 
title={Domain Specific Language for Handling Modular Ontologies}, 
year={2014}, 
pages={48-53}, 
abstract={A Knowledge Object may be characterized in different forms, corresponding to different perspectives of the object. In the same sense, knowledge of a particular domain can be organized in different interconnected ontologies. The research on ontology modularization has advanced in proposing formalisms and tools to extend ontologies with inter-ontology connectors. Tools are needed to manipulate these new connectors. Existing tools are platform dependent, which presents problems of adaptability, portability and reusability. This paper presents the design and implementation of a Specific Domain Language for Handling Modular Ontologies, based on a model driven architecture (MDA).}, 
keywords={ontologies (artificial intelligence);software architecture;MDA;domain specific language;inter-ontology connectors;knowledge object;model driven architecture;modular ontologies;Adaptation models;Computer architecture;Connectors;Context modeling;Domain specific languages;OWL;Ontologies;Knowledge management;MDA architecture;e-connections;metamodels;modular ontologies}, 
doi={10.1109/ColumbianCC.2014.6955332}, 
month={Sept},}
@ARTICLE{5766765, 
author={D. D. a. V. Devedzic}, 
journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 
title={Incorporating the Ontology Paradigm Into Software Engineering: Enhancing Domain-Driven Programming in Clojure/Java}, 
year={2012}, 
volume={42}, 
number={1}, 
pages={3-14}, 
abstract={There is a notable overlap of the challenges with which the semantic technologies and software engineering deal. They can also complement and mutually improve each other. Current efforts mostly focus on improving software tools around the resource description framework (RDF) and Web Ontology Language (OWL) Web-oriented ecosystem that helps ontology engineers but is alien to software engineers. This paper presents an opposite approach taken from the software developer's viewpoint - an incorporation of the ontology paradigm into a general-purpose programming language, in a simple and agile way, on a small scale, and in an unpretentious manner. The objective is to help programmers write simple domain-driven code with richer semantics. The means to achieve this objective relies on metaprogramming to internalize the ontology modeling paradigm into a mainstream programming environment based on the Java ecosystem, in a lightweight manner suitable for small teams. An embedded meta domain-specific language (DSL), which is called Magic Potion, is implemented in Clojure and blends ontology, functional, object-oriented, and concurrent paradigms. An example from the technology enhanced learning (TEL) domain is used to illustrate Magic Potion in action.}, 
keywords={Java;functional programming;object-oriented programming;ontologies (artificial intelligence);semantic Web;software engineering;Clojure;Java ecosystem;Magic Potion;Web ontology language;Web oriented ecosystem;concurrent paradigms;domain driven code;domain driven programming;embedded meta domain specific language;functional paradigms;general purpose programming language;object oriented paradigms;ontology engineers;ontology modeling paradigm;resource description framework;semantic technologies;software engineering;technology enhanced learning domain;DSL;OWL;Object oriented modeling;Ontologies;Programming;Software;Clojure;domain-specific languages;modeling spaces;multiparadigm programming;ontologies;programming languages;semantic technologies;software engineering}, 
doi={10.1109/TSMCC.2011.2140316}, 
ISSN={1094-6977}, 
month={Jan},}
@INPROCEEDINGS{6969396, 
author={C. B. d. Oliveira and J. M. P. Cardoso and E. Marques}, 
booktitle={Parallel Distributed Processing Symposium Workshops (IPDPSW), 2014 IEEE International}, 
title={High-Level Synthesis from C vs. a DSL-Based Approach}, 
year={2014}, 
pages={257-262}, 
abstract={Field-Programmable Gate Arrays (FPGAs) are able to provide hardware accelerators still maintaining the required programmability. However, the advantages of using FPGAs still depend on the expertise of developers and their knowledge of Hardware Description Languages (HDLs). Although High-level Synthesis (HLS) tools have been developed in order to minimize this problem, they commonly present solutions considered many times inefficient when compared to the ones achieved by a specialized hardware designer. Domain-specific languages (DSLs) can provide alternative solutions to program FPGAs. They can provide higher abstraction levels than HDLs and they may allow the programmer to tune implementations whenever HLS tools are unable to generate efficient designs. In this paper we compare a DSL, named LALP (Language for Aggressive Loop Pipelining), with two typical HLS approaches and show the experimental results achieved in each case. The results show that the use of LALP provides superior performance than the achieved by the HLS tools in most cases.}, 
keywords={C language;field programmable gate arrays;hardware description languages;high level synthesis;C language;DSL;FPGA;HDL;HLS;LALP;domain-specific languages;field-programmable gate arrays;hardware description languages;high-level synthesis;language for aggressive loop pipelining;Benchmark testing;Clocks;Field programmable gate arrays;Hardware;Pipeline processing;Radiation detectors;Domain-Specific Languages;FPGA;Hardware Accelerators;High-Level Synthesis;Loop Pipelining}, 
doi={10.1109/IPDPSW.2014.34}, 
month={May},}