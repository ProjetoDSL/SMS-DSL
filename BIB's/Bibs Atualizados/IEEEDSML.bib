% Encoding: UTF-8

@InProceedings{7363638,
  author    = {J. Y. Mori and C. H. Llanos and M. Hüebner},
  title     = {A Framework to the Design and Programming of Many-Core Focal-Plane Vision Processors},
  booktitle = {Embedded and Ubiquitous Computing (EUC), 2015 IEEE 13th International Conference on},
  year      = {2015},
  pages     = {193-198},
  month     = {Oct},
  abstract  = {The Focal-Plane Image Processing area aims to bring processing elements as near as possible to the pixels and to the camera's focal-plane. Most of the works reported in the literature uses only simple processing elements, in general analog ones, with few flexibility. With the technology advances, a new generation of Vision Processors is emerging. It is expected that multi/many-core systems will be integrated to the pixel sensors, offering several opportunities for parallelism exploration, resulting in high performance and flexible processing systems. The programmability is one of the main problems in this area, since most programmers are not able to create parallel algorithms and applications. In this work, we propose a methodology to the design and programming of many-core focal-plane vision processors. The application is described using a Domain Specific Language, from which the parallelism characteristics are extracted. Afterwards, a new abstract model is derived using techniques such as Program Slicing (PS) and Task-Graph Clustering (TGC). The abstract model is then transformed in a SystemC/TLM2.0 description, in order to allow for different timing accuracy simulations. The results of the simulations are used together with an ASIP design tool in order to determine both the microarchitecture of processing elements and the communication structure of the new system. Finally, from the model derived before, a new source code is generated and programmed into the new platform. In this context, the main concepts and ideas are described in this work, as well as some partial results.},
  doi       = {10.1109/EUC.2015.24},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  keywords  = {graph theory;image processing;image sensors;multiprocessing systems;program slicing;ASIP design tool;SystemC/TLM2.0;domain specific language;focal-plane image processing;many-core focal-plane vision processor;multicore system;pixel sensor;program slicing;task-graph clustering;Analytical models;Arrays;Image processing;Parallel processing;Program processors;Programming;Real-Time;computer vision;embedded computing;focal-plane image processing;many-core architecture},
}

@InProceedings{7306085,
  author    = {C. B. De Oliveira and R. Menotti and J. M. P. Cardoso and E. Marques},
  title     = {A special-purpose language for implementing pipelined FPGA-based accelerators},
  booktitle = {2015 Forum on Specification and Design Languages (FDL)},
  year      = {2015},
  pages     = {1-8},
  month     = {Sept},
  abstract  = {A common use for Field-Programmable Gate Arrays (FPGAs) is the implementation of hardware accelerators. A way of doing so is to specify the internal logic of such accelerators by using Hardware Description Languages (HDLs). However, HDLs rely on the expertise of developers and their knowledge about hardware development with FPGAs. Regarding this, efforts have been focused on developing High-level Synthesis (HLS) tools in an attempt to increase the overall abstraction level required for using FPGAs. However, the solutions presented by such tools are commonly considered inefficient in comparison to the ones achieved by a specialized hardware designer. An alternative solution to program FPGAs is the use of Domain- Specific Languages (DSLs), as they can provide higher abstraction levels than HDLs still allowing the developers to deal with specific issues leading to more efficient designs and not always covered by HLS tools. In this paper we present our recent work on a DSL named LALP (Language for Aggressive Loop Pipelining), which has been developed focusing on the development of FPGAbased, aggressively pipelined, hardware accelerators. We present the recent LALP extensions and the challenges we are facing regarding to the compilation of LALP to FPGAs.},
  groups    = {IEEE DSL, SCOPUS},
  issn      = {1636-9874},
  keywords  = {field programmable gate arrays;hardware description languages;pipeline processing;DSL;HDL;HLS tool;LALP;domain-specific language;field-programmable gate array;hardware description language;high-level synthesis tool;language for aggressive loop pipelining;pipelined FPGA-based accelerator;special-purpose language;Arrays;Clocks;Delays;Field programmable gate arrays;Hardware;Pipeline processing;Radiation detectors},
}

@InProceedings{7427807,
  author    = {B. Hoisl and S. Sobernig},
  title     = {Open-Source Development Tools for Domain-Specific Modeling: Results from a Systematic Literature Review},
  booktitle = {2016 49th Hawaii International Conference on System Sciences (HICSS)},
  year      = {2016},
  pages     = {5001-5010},
  month     = {Jan},
  abstract  = {Domain-specific modeling languages (DSMLs) are key to empowering organizational experts in interacting with business information systems. For this task, developing DSMLs based on the Unified Modeling Language (UML) has become a popular option. However, a number of design decisions must be considered when developing UML-based DSMLs. In this paper, we extend a systematic literature review (SLR) to cover decisions with respect to model-driven development (MDD) tooling. We extract tooling information from the selected SLR papers and classify these software tools supporting DSML development. Using this classification, we report on usage frequencies for MDD-based tools as well as on their corresponding open-and closed-source license models. Results indicate that closed-source tools are mostly employed as editors for the language model and the diagrammatic syntax of a DSML only. For DSML development aspects other than these, primarily open-source tools are utilized (e.g., for constraint evaluation, model transformation).},
  doi       = {10.1109/HICSS.2016.620},
  groups    = {SCOPUS},
  issn      = {1530-1605},
  keywords  = {Unified Modeling Language;management information systems;public domain software;software tools;DSML development;MDD-based tools;SLR;UML-based DSML;Unified Modeling Language;business information systems;closed-source license models;domain-specific modeling languages;model-driven development tooling;open-source development tools;open-source license models;organizational experts;primarily open-source tools;software tool classification;systematic literature review;Business;Concrete;Information systems;Software;Syntactics;Systematics;Unified modeling language},
}

@InProceedings{6758697,
  author    = {D. Breuker},
  title     = {Towards Model-Driven Engineering for Big Data Analytics -- An Exploratory Analysis of Domain-Specific Languages for Machine Learning},
  booktitle = {2014 47th Hawaii International Conference on System Sciences},
  year      = {2014},
  pages     = {758-767},
  month     = {Jan},
  abstract  = {Graphical models and general purpose inference algorithms are powerful tools for moving from imperative towards declarative specification of machine learning problems. Although graphical models define the principle information necessary to adapt inference algorithms to specific probabilistic models, entirely model-driven development is not yet possible. However, generating executable code from graphical models could have several advantages. It could reduce the skills necessary to implement probabilistic models and may speed up development processes. Both advantages address pressing industry needs. They come along with increased supply of data scientist labor, the demand of which cannot be fulfilled at the moment. To explore the opportunities of model-driven big data analytics, I review the main modeling languages used in machine learning as well as inference algorithms and corresponding software implementations. Gaps hampering direct code generation from graphical models are identified and closed by proposing an initial conceptualization of a domain-specific modeling language.},
  doi       = {10.1109/HICSS.2014.101},
  groups    = {IEEE DSML},
  issn      = {1530-1605},
  keywords  = {Big Data;computer graphics;data analysis;inference mechanisms;learning (artificial intelligence);program compilers;specification languages;big data analytics;direct code generation;domain-specific languages;domain-specific modeling language;general purpose inference algorithms;graphical models;machine learning problems;model-driven development;model-driven engineering;modeling languages;probabilistic models;Adaptation models;Computational modeling;Data models;Graphical models;Inference algorithms;Random variables;Unified modeling language;Graphical Models;Machine Learning;Model-driven Engineering},
}

@InProceedings{7070443,
  author    = {V. Roussev},
  title     = {Building a Forensic Computing Language},
  booktitle = {System Sciences (HICSS), 2015 48th Hawaii International Conference on},
  year      = {2015},
  pages     = {5228-5233},
  month     = {Jan},
  abstract  = {The primary goal of this discussion is to motivate the need for the development of a domain-specific language (DSL) focused on the requirements of forensic and security analysis. We argue that, at present, there is no adequate mechanism that a) allows analysts to specify the forensic computation as a tool-agnostic, logical sequence of steps, b) provides a formal specification for tool developers, and c) seamlessly integrates different available tools to provides a complete and extensible solution. We present an initial design sketch for a forensic DSL called nugget, and use it to illustrate the ideas behind our approach.},
  doi       = {10.1109/HICSS.2015.617},
  groups    = {SCOPUS, ACM, Compendex, IEEE DSL},
  issn      = {1530-1605},
  keywords  = {digital forensics;formal specification;specification languages;domain-specific language;forensic DSL;forensic computing language;formal specification;nugget;security analysis;Abstracts;Computers;DSL;Forensics;Runtime;digital forensics;dsl;nugget forensic computing language},
}

@InProceedings{6729768,
  author    = {C. Şenbalcı and S. Altuntaş and Z. Bozkus and T. Arsan},
  title     = {Big data platform development with a domain specific language for telecom industries},
  booktitle = {2013 High Capacity Optical Networks and Emerging/Enabling Technologies},
  year      = {2013},
  pages     = {116-120},
  month     = {Dec},
  abstract  = {This paper introduces a system that offer a special big data analysis platform with Domain Specific Language for telecom industries. This platform has three main parts that suggests a new kind of domain specific system for processing and visualization of large data files for telecom organizations. These parts are Domain Specific Language (DSL), Parallel Processing/Analyzing Platform for Big Data and an Integrated Result Viewer. In addition to these main parts, Distributed File Descriptor (DFD) is designed for passing information between these modules and organizing communication. To find out benefits of this domain specific solution, standard framework of big data concept is examined carefully. Big data concept has special infrastructure and tools to perform for data storing, processing, analyzing operations. This infrastructure can be grouped as four different parts, these are infrastructure, programming models, high performance schema free databases, and processing-analyzing. Although there are lots of advantages of Big Data concept, it is still very difficult to manage these systems for many enterprises. Therefore, this study suggest a new higher level language, called as DSL which helps enterprises to process big data without writing any complex low level traditional parallel processing codes, a new kind of result viewer and this paper also presents a Big Data solution system that is called Petaminer.},
  doi       = {10.1109/HONET.2013.6729768},
  groups    = {SCOPUS, IEEE DSL},
  issn      = {1949-4092},
  keywords  = {data analysis;parallel databases;parallel languages;telecommunication computing;DFD;DSL;Domain Specific Language;big data platform development;data analyzing operations;data processing;data storing operation;distributed file descriptor;higher level language;parallel processing codes;parallel processing/analyzing platform;telecom industry;DSL;Data handling;Data storage systems;Information management;Telecommunications;Web sites;Writing;Big Data Analysis;Domain Specific Language;Parallel Processing and Analyzing},
}

@InProceedings{6486028,
  author    = {D. Adolf and E. Ferranti and S. Koch},
  title     = {SmartScript - a domain-specific language for appliance control in Smart Grids},
  booktitle = {Smart Grid Communications (SmartGridComm), 2012 IEEE Third International Conference on},
  year      = {2012},
  pages     = {465-470},
  month     = {Nov},
  abstract  = {This paper describes an auto-configuring agent based software architecture connecting appliances, smart meters, solar panels, and a KNX building automation system, resulting in a complete demand-side smart grid. The agents are responsible for providing access to all datapoints in the system as well as sending commands to the active components. To control the system, a domain-specific language (DSL) called SmartScript was developed, whose benefits are twofold. The first one is to provide users, experts in electrical engineering and/or building automation but not in software systems, with a high level tool which they can use to control a demand-side smart grid. The second benefit is to provide a layer to implement and test quickly and effectively energy-aware algorithms without having to deal with all the underlying connections. Finally, some demo applications created using SmartScript (i.e., smartphone interface, voice-controlled building automation system) are presented in this work, in order to give an example of how SmartScript can be used.},
  doi       = {10.1109/SmartGridComm.2012.6486028},
  groups    = {Compendex, IEEE DSL, SCOPUS},
  keywords  = {building management systems;demand side management;home automation;smart meters;smart phones;smart power grids;software agents;software architecture;solar cells;specification languages;DSL;KNX building automation system;SmartScript;appliance control;autoconfiguring agent-based software architecture;demand side smart grid control;domain-specific language;electrical engineering;energy-aware algorithms;smart meters;smartphone interface;solar panels;voice-controlled building automation system;Automation;Buildings;Home appliances;Protocols;Smart grids;Software;Software architecture},
}

@InProceedings{6399719,
  author    = {S. Schivo and J. Scholma and B. Wanders and R. A. U. Camacho and P. E. van der Vet and M. Karperien and R. Langerak and J. van de Pol and J. N. Post},
  title     = {Modelling biological pathway dynamics with Timed Automata},
  booktitle = {Bioinformatics Bioengineering (BIBE), 2012 IEEE 12th International Conference on},
  year      = {2012},
  pages     = {447-453},
  month     = {Nov},
  abstract  = {When analysing complex interaction networks occurring in biological cells, a biologist needs computational support in order to understand the effects of signalling molecules (e.g. growth factors, drugs). ANIMO (Analysis of Networks with Interactive MOdelling) is a tool that allows the user to create and explore executable models of biological networks, helping to derive hypotheses and to plan wet-lab experiments. The tool is based on the formalism of Timed Automata, which can be analysed via the UPPAAL model checker. Thanks to Timed Automata, we can provide a formal semantics for the domain-specific language used to represent signalling networks. This enforces precision and uniformity in the definition of signalling pathways, contributing to the integration of signalling event models into complex, crosstalk-driven networks. We propose an approach to discretization of reaction kinetics that allows us to efficiently use UPPAAL as the computational engine to explore the dynamic cell behaviour. A user friendly interface makes the use of Timed Automata completely transparent to the biologist, while keeping the expressive power intact. This allows to define relatively simple, yet faithful models of complex biological interactions. The resulting timed behaviour is displayed graphically, allowing for an intuitive and interactive modelling experience.},
  doi       = {10.1109/BIBE.2012.6399719},
  groups    = {ACM, IEEE DSL, SCOPUS, Compendex},
  keywords  = {bioinformatics;cellular biophysics;complex networks;drugs;finite automata;formal languages;formal verification;human computer interaction;molecular biophysics;reaction kinetics;ANIMO;UPPAAL model checker;analysis of networks with interactive modelling;biological cells;biological pathway dynamic modelling;complex biological interaction network analysis;computational engine;crosstalk-driven networks;domain-specific language;drugs;dynamic cell behaviour;formal semantics;growth factors;reaction kinetic discretization;signalling event model;signalling molecules;signalling network representation;signalling pathway;timed automata formalism;user friendly interface;wet-lab experiments;Analytical models;Automata;Biological system modeling;Computational modeling;Data models;Kinetic theory;dynamic behaviour;modelling;signalling pathway;timed automata},
}

@InProceedings{6569751,
  author    = {A. M. Törsel},
  title     = {A Testing Tool for Web Applications Using a Domain-Specific Modelling Language and the NuSMV Model Checker},
  booktitle = {2013 IEEE Sixth International Conference on Software Testing, Verification and Validation},
  year      = {2013},
  pages     = {383-390},
  month     = {March},
  abstract  = {Test case generation from formal models using model checking software is an established method. This paper presents a model-based testing approach for web applications based on a domain-specific language model. It is shown how the domain-specific language is transformed into the input language of the NuSMV model checker and how the resulting traces are converted into executable test scripts for various test automation tools. The presented approach has been implemented with comprehensive automation in a research tool which architecture is outlined.},
  doi       = {10.1109/ICST.2013.54},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  issn      = {2159-4848},
  keywords  = {Internet;automatic programming;formal verification;program testing;specification languages;NuSMV model checker software;Web applications;domain-specific modelling language;executable test scripts;model-based testing approach;test automation tools;test case generation;Adaptation models;Automation;DSL;Model checking;Software;Web pages;model checking;model-based testing;test automation;web applications},
}

@InProceedings{7005365,
  author    = {B. Butzin and F. Golatowski and C. Niedermeier and N. Vicari and E. Wuchner},
  title     = {A model based development approach for building automation systems},
  booktitle = {Proceedings of the 2014 IEEE Emerging Technology and Factory Automation (ETFA)},
  year      = {2014},
  pages     = {1-6},
  month     = {Sept},
  abstract  = {As of today, building automation systems are present in almost any commercial building. They perform climate control, lightning control, access control, surveillance, and quite a few other tasks. As a result of their evolutionary development, building automation systems are divided into separate silos of disciplines that are not well integrated with each other. As of today, a variety of communication protocols, data models and engineering approaches are used by different vendors. Existing standardized building automation protocols as BACnet or KNX allow integration of some disciplines on the communication level but fail to provide means for common description of devices, services and data on the semantic level. This means that building automation applications that span multiple disciplines require a high effort for development, engineering and maintenance. If devices from multiple vendors are integrated in one installation, a set of different engineering tools and vendor-specific knowledge is required. In the ITEA “Building as a Service” (BaaS) project we try to overcome these deficiencies and define a common way to develop, engineer, commission, operate and maintain building automation systems following a service oriented approach. The whole process will be supported by semantic models to reduce costs and time-to-market, which is a quite new approach. In this paper we will present the current state of the work with special regard to domain modeling and model driven processes that are currently being specified for the BaaS platform.},
  doi       = {10.1109/ETFA.2014.7005365},
  groups    = {SCOPUS, IEEE DSL},
  issn      = {1946-0740},
  keywords  = {authorisation;building management systems;data models;lightning;protocols;service-oriented architecture;BACnet;BaaS platform;ITEA BaaS project;KNX;access control;building as a service;building automation applications;building automation systems;climate control;commercial building;communication protocols;data models;evolutionary development;lightning control;model based development approach;standardized building automation protocols;surveillance;Building automation;Data models;Domain specific languages;Ontologies;Protocols;Semantics;building automation;data model;domain specific language;semantic model;service oriented architecture},
}

@InProceedings{6462650,
  author    = {S. Creff and J. Champeau and A. Monégier and J. M. Jézéquel},
  title     = {Relationships Formalization for Model-Based Product Lines},
  booktitle = {2012 19th Asia-Pacific Software Engineering Conference},
  year      = {2012},
  volume    = {1},
  pages     = {158-163},
  month     = {Dec},
  abstract  = {Model-Based Engineering (MBE) and Product Line Engineering (PLE) have been combined, to handle new system development constraints like: increasing complexity, higher product quality and cost reduction. Many authors have pointed out the need of modularization in the variability and in the core assets space. Existing approaches focus on separating and delimiting concerns or providing generic composition mechanisms. In Model-Based Product Lines, with an increasing number of models to manage, organizing the modeling space becomes central to support product line consistency, maintenance and product derivation process. To organize the modeling space, we propose to precisely describe the dependencies among modeling artifacts and clarify their use. Thus, we introduce the Product Line Modeling Space (PLiMoS) language that specializes relationships, based on an intentional framework, for the product line domain. The Domain Specific Language (DSL) provides a solution to model the modeling space and preserves independence with the product line tooling.},
  doi       = {10.1109/APSEC.2012.127},
  groups    = {ACM, IEEE DSL},
  issn      = {1530-1362},
  keywords  = {cost reduction;product development;software cost estimation;software maintenance;software quality;software reusability;specification languages;DSL;Domain Specific Language;MBE;PLE;PLiMoS language;cost reduction;generic composition mechanism;maintenance;model-based engineering;model-based product lines;modeling artifact;product derivation process;product line consistency;product line domain;product line engineering;product line modeling space;product line tooling;product quality;relationships formalization;system development constraint;Abstracts;Complexity theory;Context;Context modeling;Principal component analysis;Software;Unified modeling language;DSL;Feature Models;Intentional Relations;MBE;Modeling Space;PLE;Relationships},
}

@InProceedings{6417293,
  author    = {J. Eichler and A. Fuchs and N. Lincke},
  title     = {Supporting Security Engineering at Design Time with Adequate Tooling},
  booktitle = {Computational Science and Engineering (CSE), 2012 IEEE 15th International Conference on},
  year      = {2012},
  pages     = {194-201},
  month     = {Dec},
  abstract  = {Security engineering is considered to be a challenging task in order to build systems that remain dependable in the face of malice, error, or mischance. Recent approaches propose the application of domain specific modeling languages (DSMLs) in order to facilitate security engineering activities. To support the development and application of adequate DSMLs, agile approaches and frameworks to provide appropriate tooling are needed. In this paper, we document our experiences developing modeling tools for two different DSMLs in the domain of security engineering. We sketch the language and implementation requirements for our modeling tools, design and implementation considerations, and report on pitfalls and remaining issues with regard to the development of modeling tools based on our experiences.},
  doi       = {10.1109/ICCSE.2012.34},
  groups    = {SCOPUS},
  keywords  = {programming languages;security of data;software tools;DSML;design time;domain specific modeling languages;modeling tool development;security engineering activities;tooling;Adaptation models;Analytical models;Biological system modeling;Concrete;Security;Syntactics;Unified modeling language;MDD tools;model-driven development;security engineering},
}

@InProceedings{7128889,
  author    = {N. Visic and H. G. Fill and R. A. Buchmann and D. Karagiannis},
  title     = {A domain-specific language for modeling method definition: From requirements to grammar},
  booktitle = {2015 IEEE 9th International Conference on Research Challenges in Information Science (RCIS)},
  year      = {2015},
  pages     = {286-297},
  month     = {May},
  abstract  = {The core process a modeling method engineer needs to accomplish starts with the acquisition of domain knowledge and requirements, and ends with the deployment of a usable modeling tool. In between, a key intermediate deliverable of this process is the modeling method specification which, ideally, should be platform independent. On one hand, it takes input from a structured understanding of the application domain and scenarios; on the other hand, it provides sufficiently structured input to support the implementation of tool support for modeling activities. It is quite common that such modeling methods are domain-specific, in the sense that they provide concepts from the domain as “first-class modeling citizens”. However, for the purposes of this paper, we raise the level of abstraction for “domain specificity” and consider “modeling method engineering” as the application domain. Consequently, we raise several research questions - whether a domain-specific language can support this domain, and what would be its requirements, properties, constructs and grammar. We propose an initial draft of such a language - one that abstracts away from meta-modeling platforms by establishing a meta2 layer of abstraction where a modeling method can be defined in a declarative manner, then the final modeling tool is generated by automated compilation of the method definition for the meta-modeling environment of choice.},
  doi       = {10.1109/RCIS.2015.7128889},
  groups    = {Compendex, SCOPUS, IEEE DSL},
  issn      = {2151-1349},
  keywords  = {formal specification;grammars;knowledge based systems;domain knowledge;domain specificity;domain-specific language;grammar;metamodeling platform;modeling method engineering;modeling method specification;Analytical models;Computational modeling;DSL;Domain specific languages;Metamodeling;Semantics;Unified modeling language;domain-specific language;meta-modeling;modeling method;modeling tool},
}

@InProceedings{7459436,
  author    = {S. Ma and Z. Aklah and D. Andrews},
  title     = {Run time interpretation for creating custom accelerators},
  booktitle = {2016 Design, Automation Test in Europe Conference Exhibition (DATE)},
  year      = {2016},
  pages     = {900-905},
  month     = {March},
  abstract  = {Despite the significant advancements that have been made in High Level Synthesis, the reconfigurable computing community has not yet managed to achieve a wide-spread use of Field Programmable Gate Arrays (FPGAs) by programmers. Existing barriers that prevent programmers from using FPGAs include the need to work within vendor specific CAD tools, knowledge of hardware programming models, and the requirement to pass each design through a very time-consuming synthesis, place and route process. In this paper we present a new approach that takes these barriers out of the design flows for programmers. We move synthesis out of the programmers path and instead rely on composing pre-synthesized building blocks using a domain-specific language that supports programming patterns tailored to FPGA accelerators. Our results show that the achieved performance of run time assembling accelerators is equivalent to synthesizing a custom block of hardware using automated HLS tools.},
  groups    = {ACM, IEEE DSL, SCOPUS},
  keywords  = {field programmable gate arrays;high level synthesis;specification languages;CAD tool;FPGA;HLS;building block synthesis;custom accelerator;design flow;domain-specific language;field programmable gate array;high level synthesis;run time interpretation;DSL;Field programmable gate arrays;Hardware;Integrated circuit interconnections;Program processors;Programming;Switches},
}

@InProceedings{7510564,
  author    = {J. Deantoni},
  title     = {Modeling the Behavioral Semantics of Heterogeneous Languages and their Coordination},
  booktitle = {2016 Architecture-Centric Virtual Integration (ACVI)},
  year      = {2016},
  pages     = {12-18},
  month     = {April},
  abstract  = {In the software and system modeling community, research on domain-specific modeling languages (DSMLs) is focused on providing technologies for developing languages and tools that allow domain experts to develop system solutions efficiently. Unfortunately, the current lack of support for explicitly relating concepts expressed in different DSMLs makes it very difficult for software and system engineers to reason about information spread across models describing different system aspects. As a particular challenge, we present in this paper how we dealt with relationships between heterogeneous behavioral models to support their concurrent and coordinated execution. This was achieved by providing dedicated meta-language to define the behavioral semantics of DSMLs and their coordination. The approach made explicit a formal model of the control flow (MoCC); domain-specific actions (DSA) and a well-defined protocol between them (incl., mapping, feedback and callback) reified through explicit domain-specific events (DSE). The protocol is then used to infer a relevant behavioral language interface for specifying coordination patterns to be applied on conforming executable models. As a result, heterogeneous languages and their relationships can be developed in the GEMOC studio, which provides extensive support to run and debug heterogeneous models. This is outlined in the paper on the definition of the Marked Graph language and its coordination with a scenario language.},
  doi       = {10.1109/ACVI.2016.9},
  groups    = {IEEE DSL, SCOPUS},
  keywords  = {formal verification;programming language semantics;DSA;DSE;DSML;GEMOC studio;behavioral language interface;behavioral semantics;callback task;concurrent execution;coordinated execution;coordination patterns;domain-specific modeling languages;domain-specifications;explicit domain-specific events;feedback task;formal MoCC;formal model-of-the-control flow;heterogeneous behavioral semantics modeling;heterogeneous languages;heterogeneous model debugging;heterogeneous model run;mapping task;marked graph language;meta-language;system modeling community;Concurrent computing;Context;DSL;Metamodeling;Semantics;Software;Syntactics;behavioral semantics;concurrency theory;coordination;heterogeneous modeling;model of computation;simulation},
}

@InProceedings{6694495,
  author    = {K. Falkner and V. Chiprianov and N. Falkner and C. Szabo and G. Puddy},
  title     = {Modeling scenarios for the performance prediction of distributed real-time embedded systems},
  booktitle = {Military Communications and Information Systems Conference (MilCIS), 2013},
  year      = {2013},
  pages     = {1-6},
  month     = {Nov},
  abstract  = {Autonomous defence systems are typically characterized by hard constraints on space, weight and power. These constraints have a strong impact on the non-functional properties and especially performance of the final system. System execution modelling tools permit early prediction of the performance of model driven systems; however they are intended for one shot analysis, not for repeatable, interactive use. In this paper we propose a Domain Specific Language for describing scenarios to repeatedly test a system execution model within a Synthetic Environment. We exemplify it by describing and executing a scenario involving an UAV and a CMS.},
  doi       = {10.1109/MilCIS.2013.6694495},
  groups    = {IEEE DSL, SCOPUS},
  keywords  = {autonomous aerial vehicles;defence industry;distributed programming;embedded systems;military computing;CMS;UAV;autonomous defence systems;distributed real-time embedded systems;domain specific language;model driven systems;system execution modelling;Analytical models;Data models;Engines;Hardware;Middleware;Predictive models;Unified modeling language;formatting;insert;style;styling},
}

@InProceedings{6849709,
  author    = {G. S. Ouedraogo and M. Gautier and O. Sentieys},
  title     = {Frame-based modeling for automatic synthesis of FPGA-Software Defined Radio},
  booktitle = {2014 9th International Conference on Cognitive Radio Oriented Wireless Networks and Communications (CROWNCOM)},
  year      = {2014},
  pages     = {341-346},
  month     = {June},
  abstract  = {Software Defined Radio (SDR) is now becoming a ubiquitous concept to describe and implement Physical Layers (PHYs) of wireless systems. Moreover, even though the FPGA is expected to play a key role in SDR, describing a PHY at the Register-Transfer-Level (RTL) requires tremendous efforts. This paper introduces a novel methodology to rapidly implement PHYs for SDR. The work relies upon High-Level Synthesis tools and dataflow modeling in order to infer an efficient RTL control unit for the application. The proposed software-based over-layer partly handles the complexity of programming an FPGA and integrates reconfigurable features. It consists essentially of a Domain-Specific Language (DSL) combined to a DSL-Compiler. An IEEE 802.11a transceiver has been explored via this approach in order to show the flexibility features.},
  doi       = {10.4108/icst.crowncom.2014.255289},
  groups    = {IEEE DSL, SCOPUS},
  issn      = {2166-5370},
  keywords  = {field programmable gate arrays;program compilers;radio transceivers;software radio;specification languages;wireless LAN;DSL-compiler;FPGA-software defined radio;IEEE 802.11a transceiver;PHY;RTL control unit;SDR;dataflow modeling;domain-specific language;frame-based modeling;high-level synthesis tools;physical layers;register-transfer-level;DSL;Encoding;Field programmable gate arrays;Physical layer;Receivers;Software;Synchronization},
}

@InProceedings{6196521,
  author    = {J. Barateiro and J. Borbinha},
  title     = {Managing risk data: From spreadsheets to information systems},
  booktitle = {2012 16th IEEE Mediterranean Electrotechnical Conference},
  year      = {2012},
  pages     = {673-676},
  month     = {March},
  abstract  = {The goal of Risk Management is to define prevention and control mechanisms to address the risks attached to specific activities and valuable assets. Many Risk Management efforts operate in silos with narrowly focused, functionally driven, and disjointed activities. That fact leads to a fragmented view of risks, where each activity uses its own language, customs and metrics. That limits an organization-wide perception of risks, where interdependent risks are not anticipated, controlled or managed. The lack of integrated solutions to manage risk information, lead the experts to use spreadsheets as their main tool, impeding collaboration, communication and reuse of risk information. In order to address these issues, this paper presents a solution that integrates a Risk Management framework, including a XML-based Domain Specific Language for Risk Management. The proposed framework is supported by an information system to manage the definition or risks.},
  doi       = {10.1109/MELCON.2012.6196521},
  groups    = {SCOPUS, Compendex, IEEE DSL},
  issn      = {2158-8473},
  keywords  = {XML;management information systems;risk management;spreadsheet programs;XML-based domain specific language;information systems;interdependent risks;risk control mechanisms;risk data management;risk information reusage;risk prevention mechanisms;silos;spreadsheets;Computer architecture;Information systems;Organizations;Risk management;Unified modeling language;XML},
}

@InProceedings{7522164,
  author    = {J. Opiła},
  title     = {Prototyping of visualization designs of 3D vector fields using POVRay rendering engine},
  booktitle = {2016 39th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)},
  year      = {2016},
  pages     = {343-348},
  month     = {May},
  abstract  = {There is a persistent quest for novel methods of visualization in order to get insight into complex phenomena in variety of scientific domains. Researchers, ex. VTK team, achieved excellent results; however, some problems connected with implementation of new techniques and quality of the final images still persist. Results of inspection of number of visualization styles of 3D vector field employing POVRay ray-tracing engine are discussed, i.e. hedgehogs, oriented glyphs, streamlines, isosurface component approach and texturing design. All styles presented have been tested using water molecule model and compared concerning computing time, informativeness and general appearance. It is shown in the work that Scene Description Language (SDL), domain specific language implemented in POVRay is flexible enough to use it as a tool for fast prototyping of novel and exploratory visualization techniques. Visualizations discussed in the paper were computed using selected components of API of ScPovPlot3D, i.e. templates written in the SDL language. Results are compared to designs already implemented in VTK.},
  doi       = {10.1109/MIPRO.2016.7522164},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  keywords  = {data visualisation;ray tracing;rendering (computer graphics);vectors;3D vector field;API;POVRay rendering engine;ScPovPlot3D;domain specific language;exploratory visualization;hedgehogs;isosurface component approach;oriented glyph;ray-tracing engine;scene description language;streamlines;texturing design;visualization design prototyping;Data visualization;Electrostatics;Engines;Extraterrestrial measurements;Libraries;Three-dimensional displays;Visualization;POVRay;ScPovPlot3D;VTK;vector field visualization;visual data analysis},
}

@InProceedings{7502813,
  author    = {F. A. Lopes and L. Lima and M. Santos and R. Fidalgo and S. Fernandes},
  title     = {High-level modeling and application validation for SDN},
  booktitle = {NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium},
  year      = {2016},
  pages     = {197-205},
  month     = {April},
  abstract  = {Software-Defined Networking (SDN) enables applications running on its control plane. The Northbound API allows programmers to develop SDN applications for a number of policy-based network management tasks. However, there is still a clear need for supporting the development of controller-agnostic modeled applications. In this paper, we show how the Model-Driven Networking (MDN), a framework composed of CASE tool and Domain-Specific Modeling Language (DSML), can be a feasible solution to create applications independent from controllers and to enable proper verification of SDN applications. Our evaluation demonstrates that MDN framework is viable for using in real scenarios and independent from SDN controllers. Moreover, our performance tests show that: (i) MDN's code generation is two times faster than other approaches; and (ii) it can validate several constraints and complex topologies at millisecond-timescale.},
  doi       = {10.1109/NOMS.2016.7502813},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  keywords  = {programming languages;software defined networking;CASE tool;DSML;MDN;SDN application;application validation;controller-agnostic modeled application;domain-specific modeling language;high-level modeling;model-driven networking;network topology;northbound API;policy-based network management task;software-defined networking;Computer aided software engineering;Computer languages;DSL;Network topology;Programming;Software;Topology;CASE;Domain-Specific Modeling Language;MDN;Software-Defined Networking;application;framework},
}

@InProceedings{6569750,
  author    = {A. Calvagna and A. Gargantini and P. Vavassori},
  title     = {Combinatorial Interaction Testing with CITLAB},
  booktitle = {2013 IEEE Sixth International Conference on Software Testing, Verification and Validation},
  year      = {2013},
  pages     = {376-382},
  month     = {March},
  abstract  = {In this paper the CITLAB tool for Combinatorial Interaction Testing is presented. The tool allows importing/exporting models of combinatorial problems from/to different application domains, by means of a common interchange syntax notation and a corresponding interoperable semantic metamodel. Moreover, the tool is a framework allowing embedding and transparent invocation of multiple, different implementations of combinatorial algorithms. CITLAB has been designed tightly integrated with the Eclipse IDE framework, by means of its plug-in extension mechanism. It is intended to easy the spread of CIT testing both in industrial practice and in academic research, by allowing users and researchers to apply multiple test suite generation algorithms, each with its peculiarities, on the same problem models, and let them compare the results in order to select the one that best fits their needs, while alleviating from the pain of knowing all the different details and notations of the underlying CIT tools.},
  doi       = {10.1109/ICST.2013.53},
  groups    = {IEEE DSL, SCOPUS},
  issn      = {2159-4848},
  keywords  = {combinatorial mathematics;interactive systems;open systems;testing;CITLAB tool;Eclipse IDE framework;combinatorial interaction testing;importing/exporting models;interchange syntax notation;interoperable semantic metamodel;multiple test suite generation algorithms;transparent invocation;Algorithm design and analysis;Biological system modeling;Generators;Grammar;Semantics;Syntactics;Testing;Combinatorial testing model;Eclipse;XTEXT;domain-specific language},
}

@InProceedings{7522035,
  author    = {L. Bettini and P. Crescenzi},
  title     = {Java-meets eclipse: An IDE for teaching Java following the object-later approach},
  booktitle = {2015 10th International Joint Conference on Software Technologies (ICSOFT)},
  year      = {2015},
  volume    = {2},
  pages     = {1-12},
  month     = {July},
  abstract  = {In this paper, we introduce a new Eclipse-based IDE for teaching Java following the object-later approach. In particular, this IDE allows the programmer to write code in Java-, a smaller version of the Java language that does not include object-oriented features. For the implementation of this language we used Xtext, an Eclipse framework for implementing Domain Specific Languages; besides the compiler mechanisms, Xtext also allows to easily implement all the IDE tooling mechanisms in Eclipse. By using Xtext we were able to provide an implementation of Java - with all the powerful features available when using an IDE like Eclipse (including debugging, automatic building, and project wizards). With our implementation, it is also straightforward to create self-assessment exercises for students, which are integrated in Eclipse and JUnit.},
  groups    = {IEEE DSL},
  keywords  = {Java;computer aided instruction;computer science education;Eclipse-based IDE;JUnit;Java language;Java teaching;Xtext;compiler mechanism;domain specific language;object-later approach;Complexity theory;Education;Graphical user interfaces;Java;Programming profession;Syntactics;DSL;EMF;Eclipse;IDE;Java;Xtext},
}

@InProceedings{6257291,
  author    = {O. Krasts and A. Kleins and A. Teilans},
  title     = {Domain specific language for securities settlement systems},
  booktitle = {Digital Information Processing and Communications (ICDIPC), 2012 Second International Conference on},
  year      = {2012},
  pages     = {80-83},
  month     = {July},
  abstract  = {Actual problems during design, implementation and maintenance of securities settlement systems software are achieving complementarity of several different, connected, asynchronously communicating settlement systems and verification of this complementarity. The aim of this paper is to create domain specific language for modeling of settlement systems and their interactions. Then use models to calculate settlement systems behavior. Specific of settlement systems requires that they perform accordingly to business rules in any situation. This makes use of model checking a very desirable step in development process of settlement systems. Defining a domain specific language and creating editor supporting it is a first step to enable use of model checking techniques. Created models also can be used as input for other analysis methods and tools, for example, basis path testing, simulation and as base for deriving test cases.},
  doi       = {10.1109/ICDIPC.2012.6257291},
  groups    = {IEEE DSL, SCOPUS},
  keywords  = {financial data processing;formal verification;securities trading;specification languages;asynchronously communicating settlement systems;business rules;domain specific language;model checking;securities settlement systems software;settlement systems behavior;Analytical models;Biological system modeling;Business;Computational modeling;Domain specific languages;Educational institutions;Unified modeling language;modeling;validatioan;verification},
}

@InProceedings{6718341,
  author    = {N. George and D. Novo and T. Rompf and M. Odersky and P. Ienne},
  title     = {Making domain-specific hardware synthesis tools cost-efficient},
  booktitle = {Field-Programmable Technology (FPT), 2013 International Conference on},
  year      = {2013},
  pages     = {120-127},
  month     = {Dec},
  abstract  = {Tools to design hardware at a high level of abstraction promise software-like productivity for hardware designs. Among them, tools like Spiral, HDL Coder, Optimus and MMAlpha target specific application domains and produce highly efficient implementations from high-level input specifications in a Domain Specific Language (DSL). But, developing similar domain-specific High-Level Synthesis (HLS) tools need enormous effort, which might offset their many advantages. In this paper, we propose a novel, cost-effective approach to develop domain-specific HLS tools. We develop the HLS tool by embedding its input DSL in Scala and using Lightweight Modular Staging (LMS), a compiler framework written in Scala, to perform optimizations at different abstraction levels. For example, to optimize computation on matrices, some optimizations are more effective when the program is represented at the level of matrices while others are better applied at the level of individual matrix elements. To illustrate the proposed approach, we create an HLS flow to automatically generate efficient hardware implementations of matrix expressions described in our own high-level specification language. Although a simple example, it shows how easy it is to reuse modules across different HLS flows and to integrate our flow with existing tools like LegUp, a C-to-RTL compiler, and FloPoCo, an arithmetic core generator. The results reveal that our approach can simultaneously achieve high productivity and design quality with a very reasonable tool development effort.},
  doi       = {10.1109/FPT.2013.6718341},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  keywords  = {circuit CAD;digital arithmetic;field programmable gate arrays;high level synthesis;matrix algebra;program compilers;specification languages;C-to-RTL compiler;DSL;FPGA;FloPoCo;HDL coder;HLS;LMS;LegUp;MMAlpha;Optimus;Scala;Spiral;arithmetic core generator;compiler framework;cost-efficiency;design quality;domain specific language;domain-specific hardware synthesis tools;domain-specific high-level synthesis tools;hardware design;hardware designs;high abstraction level;high-level specification language;lightweight modular staging;matrix computation optimizations;matrix expressions;software-like productivity;Adders;DSL;Generators;Hardware;Least squares approximations;Matrices;Optimization},
}

@InProceedings{6979145,
  author    = {G. Watney and L. J. Reder and T. Canham},
  title     = {Modeling for Partitioned and Multi-core Flight Software Systems: (Instrument Software Framework)},
  booktitle = {Space Mission Challenges for Information Technology (SMC-IT), 2014 IEEE International Conference on},
  year      = {2014},
  pages     = {54-61},
  month     = {Sept},
  abstract  = {This paper presents an approach for modeling component based flight software systems that can be deployed to a wide variety of hardware and operating system configurations. Our focus is deployment to multiple ARINC653 partitions, however, the technique is effective across multiple processors as well. The modeling technique presented is two tiered: first software components are represented in System Modeling Language (SysML) utilizing an off-the-shelf Magic Draw Computer Aided Software Engineering (CASE) tool. A custom plug in is used to produce domain specific XML. Secondly, a Python code generator is used to map the domain specific XML to implementation C++ code. To facilitate the technique a new lite-weight component framework called the Instrument Software Framework (ISF) was developed. Component based software architectures have been shown to improve the quality of flight software systems. The modeling approach using SysML, XML and the ISF is explained. Separation of concerns of the deployment target environment from the component implementation are demonstrated by our technique. The ISF architecture will be described along with an essential Hub Component Design Pattern that enables swappable communication mediums between computing elements.},
  doi       = {10.1109/SMC-IT.2014.15},
  groups    = {IEEE DSL, SCOPUS},
  keywords  = {C++ language;XML;aerospace computing;computer aided software engineering;multiprocessing systems;operating systems (computers);program compilers;software quality;ARINC653 partitions;C++ code;CASE tool;ISF architecture;Instrument Software Framework;MagicDraw computer aided software engineering tool;Python code generator;SysML;component based flight software systems;component based software architectures;component implementation;custom plugin;domain specific XML;flight software systems;hardware system configurations;hub component design pattern;lite-weight component framework;multicore flight software systems;multiple processors;operating system configurations;swappable communication mediums;system modeling language;target environment;Computational modeling;Instruments;Message systems;Ports (Computers);Software;Topology;XML;Domain Specific Language;Instrument Software Framework (ISF);SysML;flight software;modeling;partitions},
}

@InProceedings{7338247,
  author    = {A. Pescador and A. Garmendia and E. Guerra and J. Sánchez Cuadrado and J. de Lara},
  title     = {Pattern-based development of Domain-Specific Modelling Languages},
  booktitle = {Model Driven Engineering Languages and Systems (MODELS), 2015 ACM/IEEE 18th International Conference on},
  year      = {2015},
  pages     = {166-175},
  month     = {Sept},
  abstract  = {Model-Driven Engineering (MDE) promotes the use of models to conduct all phases of software development in an automated way. Models are frequently defined using Domain- Specific Modelling Languages (DSMLs), which many times need to be developed for the domain at hand. However, while constructing DSMLs is a recurring activity in MDE, there is scarce support for gathering, reusing and enacting knowledge for their design and implementation. This forces the development of every new DSML to start from scratch. To alleviate this problem, we propose the construction of DSMLs and their modelling environments aided by patterns which gather knowledge of specific domains, design alternatives, concrete syntax, dynamic semantics and functionality for the modelling environment. They may have associated services, realized via components. Our approach is supported by a tool that enables the construction of DSMLs through the application of patterns, and synthesizes a graphical modelling environment according to them.},
  doi       = {10.1109/MODELS.2015.7338247},
  groups    = {Compendex, SCOPUS},
  keywords  = {software engineering;specification languages;DSML;MDE;associated service;concrete syntax;design alternative;domain-specific modelling language;dynamic semantics;graphical modelling environment;model-driven engineering;pattern-based development;scarce support;software development;Complexity theory;Concrete;Productivity;Semantics;Software;Syntactics;Taxonomy;Domain-Specific Modelling Languages;Meta-Modelling;Meta-Modelling Patterns;Modelling Environments},
}

@InProceedings{7233083,
  author    = {H. Chanti and L. Thiry and M. Hassenforder and E. Blanchard and P. Fromy},
  title     = {Fire safety DSL based algebra},
  booktitle = {Control, Engineering Information Technology (CEIT), 2015 3rd International Conference on},
  year      = {2015},
  pages     = {1-6},
  month     = {May},
  abstract  = {A complex system as the one evaluating the fire safety level, generally need the intervention of several specialists. Each one uses his own languages and own tools. To model such a system, several specific languages are needed and must be formalized and then integrated. This kind of systems can have irreversible consequences because of the human involving. To make a system sure - by the proof - the specification and composition of models/languages must be formally described and based on mathematical foundations. In this context, the paper proposes to use a formal approach based on algebraic specifications to model, formalize and compose the specific languages needed to evaluate the fire safety level in buildings.},
  doi       = {10.1109/CEIT.2015.7233083},
  groups    = {SCOPUS, IEEE DSL},
  keywords  = {algebraic specification;civil engineering computing;fires;safety;specification languages;Domain Specific Language;algebraic specifications;buildings;fire safety DSL;fire safety level;formal approach;Algebra;DSL;Mathematical model;Safety;Semantics;Transforms;Unified modeling language;Domain Specific Language (DSL);algebra;fire safety;formal languages},
}

@InProceedings{6363292,
  author    = {H. Nakamura and R. Nagano and K. Hisazumi and Y. Kamei and N. Ubayashi and A. Fukuda},
  title     = {QORAL: An External Domain-Specific Language for Mining Software Repositories},
  booktitle = {Empirical Software Engineering in Practice (IWESEP), 2012 Fourth International Workshop on},
  year      = {2012},
  pages     = {23-29},
  month     = {Oct},
  abstract  = {The mining software repositories (MSR) field integrates and analyzes data stored in repositories such as source control and bug repositories to provide support to practitioners. In order to provide useful information to practitioners, MSR researchers need to perform tasks iteratively, these tasks include extracting data from repositories, transforming them into specific data formats, and loading them into the statistical analysis tool. These tasks require a significant amount of man hours to implement and execute according to the requirements of the researchers. This paper proposes an external domain-specific language (DSL) called QORAL to facilitate the performance of multiple iterations and environment development. The results from a questionnaire used to evaluate QORAL indicate that it is easy to understand and modify source code.},
  doi       = {10.1109/IWESEP.2012.20},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  keywords  = {configuration management;data analysis;data mining;program debugging;software engineering;DSL;MSR;QORAL;bug repository;bug tracking system;data analysis;data extraction;data format;data integration;environment development;external domain-specific language;multiple iteration;software repository mining;source code modification;source control;statistical analysis tool;version control system;DSL;Data mining;Grammar;Libraries;Loading;Measurement;Software;DSL;MSR;QORAL},
}

@InProceedings{7302512,
  author    = {S. Vinogradov and A. Ozhigin and D. Ratiu},
  title     = {Modern model-based development approach for embedded systems practical experience},
  booktitle = {Systems Engineering (ISSE), 2015 IEEE International Symposium on},
  year      = {2015},
  pages     = {56-59},
  month     = {Sept},
  abstract  = {Control functionality of modern rail vehicles is getting more and more complex. It contains several modules such as the traction control unit or the central control unit, as well as input and output stations, such as driver's cab terminals and process I/Os. A plethora of devices are connected to the vehicle and train bus and are able to communicate. The functions of the vehicle control and traction systems are configured by using function blocks from which loadable programs are generated. The languages used to program the control units are well established in the field. However, one-size-fits-all approach cannot adequately address the increased complexity of the software in modern trains. In this paper we describe our preliminary experience with using the multi-paradigm modeling tool “mbeddr” in the railway domain. The following aspects have been in focus during the work: (a) matching the application requirements and domain specific language used for implementation; (b) integration of model-based approach into traditional product lifecycle; (c) reengineering existing functionality using modeling and code generation capabilities of mbeddr. The system example we chose was the application logic of automated train driving system implemented in development environment of Siemens process automation framework.},
  doi       = {10.1109/SysEng.2015.7302512},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  keywords  = {embedded systems;rail traffic control;traction;I/O process;Siemens process automation framework;application logic;application requirements;automated train driving system;central control unit;code generation capabilities;domain specific language;driver cab terminals;embedded systems;function blocks;input stations;loadable programs;mbeddr tool;model-based approach;model-based development approach;modeling capabilities;multiparadigm modeling tool;output stations;product lifecycle;rail vehicle control functionality;railway domain;reengineering;traction control unit;traction systems;train bus;vehicle bus;Complexity theory;Control systems;Domain specific languages;Formal verification;Mathematical model;Rail transportation;Software;language engineering;model based development},
}

@InProceedings{7134025,
  author    = {O. Günalp and C. Escoffier and P. Lalanda},
  title     = {Demo abstract: Reproducible deployment of pervasive applications},
  booktitle = {Pervasive Computing and Communication Workshops (PerCom Workshops), 2015 IEEE International Conference on},
  year      = {2015},
  pages     = {211-213},
  month     = {March},
  abstract  = {Pervasive systems present stringent requirements that make software deployment especially challenging. The unknown and fluctuating environment in which pervasive applications are executed discards traditional approaches. As a result, there is an increasing need for a reproducible and dynamic deployment process. In last years, we developed several industrial pervasive platforms and applications. Based on these experiences we propose Rondo, a tool suite for deploying pervasive applications. Rondo includes a domain-specific language for declaratively describing applications, a deployment manager that can dynamically apply these descriptions and development tools for helping the description of applications. In this paper we present this tool suite and a set of deployment scenarios in which we validated our approach, including a web framework and a home automation platform.},
  doi       = {10.1109/PERCOMW.2015.7134025},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  keywords  = {Internet;home automation;software tools;ubiquitous computing;Rondo;Web framework;domain-specific language;home automation platform;industrial pervasive applications;industrial pervasive platforms;pervasive systems;reproducible dynamic deployment process;software deployment;tool suite;Assembly;Conferences;Context;DSL;Monitoring;Pervasive computing;Software},
}

@Article{6839148,
  author   = {B. Combemale and J. DeAntoni and B. Baudry and R. B. France and J. M. Jézéquel and J. Gray},
  title    = {Globalizing Modeling Languages},
  journal  = {Computer},
  year     = {2014},
  volume   = {47},
  number   = {6},
  pages    = {68-71},
  month    = {June},
  abstract = {In the software and systems modeling community, domain-specific modeling language (DSML) research is focused on providing technologies for developing languages and tools that allow domain experts to develop system solutions efficiently. Unfortunately, it's very difficult for software and systems engineers to reason about information spread across models describing different system aspects because of the current lack of support for explicitly relating concepts expressed in different DSMLs. Here, we describe a research initiative that broadens the DSML research focus beyond independent DSML development to one that supports globalized DSMLs-that is, DSMLs that facilitate coordination of work across different domains of expertise. Coordinating domain-specific modeling languages provides support for language heterogeneity in software-intensive systems' development and runtime management.},
  doi      = {10.1109/MC.2014.147},
  groups   = {IEEE DSML},
  issn     = {0018-9162},
  keywords = {software development management;specification languages;domain-specific modeling language;globalized DSMLs;independent DSML development;language heterogeneity;runtime management;software-intensive systems development;Adaptation models;Analytical models;Computational modeling;Computer languages;Domain specific languages;Globalization;Software development;model-driven engineering;modeling language;software engineering;software language engineering},
}

@InProceedings{6425702,
  author    = {E. Franchi},
  title     = {A Domain Specific Language Approach for Agent-Based Social Network Modeling},
  booktitle = {Advances in Social Networks Analysis and Mining (ASONAM), 2012 IEEE/ACM International Conference on},
  year      = {2012},
  pages     = {607-612},
  month     = {Aug},
  abstract  = {Although in the past twenty years agent-based modeling has been widely adopted as a research tool in the fields of social and political sciences, there is lack of software instruments specifically created for social network simulations. Restricting the field of interest specifically to social network models and simulations instead of supporting general agent-based ones, allows for the creation of easier to use, more focused tools. In this work, we propose PyNetSYM, an agent-based modeling framework designed to be friendly to programmers and non-programmers alike. PyNetSYM provides a domain-specific language to specify social network simulations expressed as agent-based models. PyNetSYM was created to deal with large simulations and to work effortlessly with other social network analysis toolkits.},
  doi       = {10.1109/ASONAM.2012.102},
  groups    = {Compendex, ACM, SCOPUS, IEEE DSL},
  keywords  = {social networking (online);social sciences;software agents;PyNetSYM;agent-based social network modeling;domain specific language approach;political science;social science;Analytical models;Concurrent computing;DSL;Libraries;Message systems;Object oriented modeling;Social network services;Agent Based Modeling;Social Network Analysis},
}

@InProceedings{6200153,
  author    = {A. Gargantini and P. Vavassori},
  title     = {CITLAB: A Laboratory for Combinatorial Interaction Testing},
  booktitle = {2012 IEEE Fifth International Conference on Software Testing, Verification and Validation},
  year      = {2012},
  pages     = {559-568},
  month     = {April},
  abstract  = {Although the research community around combinatorial interaction testing has been very active for several years, it has failed to find common solutions on some issues. First of all, there is not a common abstract nor concrete language to express combinatorial problems. Combinatorial testing generator tools are strongly decoupled making difficult their interoperability and the exchange of models and data. In this paper, we propose an abstract and concrete specific language for combinatorial problems. It features and formally defines the concepts of parameters and types, constraints, seeds, and test goals. The language is defined by means of XTEXT, a framework for the definition of domain-specific languages. XTEXT is used to derive a powerful editor integrated with eclipse and with all the expected features of a modern editor. Eclipse is also used to build an extensible framework in which test generators, importers, and exporters can be easily added as plugins.},
  doi       = {10.1109/ICST.2012.141},
  groups    = {ACM, IEEE DSL, SCOPUS},
  issn      = {2159-4848},
  keywords  = {Java;open systems;program testing;software tools;specification languages;CITLAB;XTEXT;abstract specific language;combinatorial interaction testing;combinatorial testing generator tool;concrete specific language;domain specific language;eclipse;interoperability;modern editor;Cameras;DSL;Generators;Grammar;Java;Syntactics;Testing;XTEXT;combinatorial testing;domain specific languages;eclipse;xtext},
}

@InProceedings{6899203,
  author    = {S. Ciraci and J. C. Fuller and J. Daily and A. Makhmalbaf and D. Callahan},
  title     = {A Runtime Verification Framework for Control System Simulation},
  booktitle = {Computer Software and Applications Conference (COMPSAC), 2014 IEEE 38th Annual},
  year      = {2014},
  pages     = {75-84},
  month     = {July},
  abstract  = {In a standard workflow for the validation of a control system, the control system is implemented as an extension to a simulator. Such simulators are complex software systems, and engineers may unknowingly violate constraints a simulator places on extensions. As such, errors may be introduced in the implementation of either the control system or the simulator leading to invalid simulation results. This paper presents a novel runtime verification approach for verifying control system implementations within simulators. The major contribution of the approach is the two-tier specification process. In the first tier, engineers model constraints using a domain-specific language tailored to modeling a controller's response to changes in its input. The language is high-level and effectively hides the implementation details of the simulator, allowing engineers to specify design-level constraints independent of low-level simulator interfaces. In the second tier, simulator developers provide mapping rules for mapping design-level constraints to the implementation of the simulator. Using the rules, an automated tool transforms the design-level specifications into simulator-specific runtime verification specifications and generates monitoring code which is injected into the implementation of the simulator. During simulation, these monitors observe the input and output variables of the control system and report changes to the verifier. The verifier checks whether these changes follow the constraints of the control system. We describe application of this approach to the verification of the constraints of an HVAC control system implemented with the power grid simulator Grid LAB-D.},
  doi       = {10.1109/COMPSAC.2014.14},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  keywords  = {control engineering computing;formal specification;formal verification;control system simulation;design-level specification;domain-specific language;low-level simulator interface;mapping design-level constraint;monitoring code;simulator-specific runtime verification specification;two-tier specification process;Automata;Control systems;Monitoring;Object oriented modeling;Runtime;Software systems;Time factors;control system;runtime verification;simulation;timed automata},
}

@InProceedings{6901554,
  author    = {D. Wang and Y. Miao and H. U. Hoppe and M. Samaka},
  title     = {A Domain-Specific Modeling Language Approach to Support Various Forms of Online PBL},
  booktitle = {2014 IEEE 14th International Conference on Advanced Learning Technologies},
  year      = {2014},
  pages     = {611-613},
  month     = {July},
  abstract  = {Problem-based learning (PBL) can be organized and conducted in a variety of forms. By adopting a Domain-Specific Modeling Language (DSML) approach we have developed a PBL scripting language, which provides natural concepts that teachers can understand and use in practical PBL. Based on this PBL scripting language, a web-based PBL authoring tool has been developed, which enables teachers to develop their own PBL strategies as PBL scripts.},
  doi       = {10.1109/ICALT.2014.178},
  groups    = {Compendex, SCOPUS},
  issn      = {2161-3761},
  keywords  = {Internet;authoring languages;computer aided instruction;DSML;PBL scripting language;PBL scripts;PBL strategies;Web-based PBL authoring tool;domain-specific modeling language approach;online PBL;problem-based learning;Abstracts;Brain modeling;Conferences;Educational institutions;Electronic mail;Organizations;User interfaces;DSML;PBL;PBL authoring tool;PBL script;PBL scripting language},
}

@InProceedings{7500572,
  author    = {J. Akhundov and M. Werner and V. Schaus and A. Gerndt},
  title     = {Using timed automata to check space mission feasibility in the early design phases},
  booktitle = {2016 IEEE Aerospace Conference},
  year      = {2016},
  pages     = {1-9},
  month     = {March},
  abstract  = {According to the model-based systems engineering paradigm, all engineers contribute to a single centralized data model of the system. The German Aerospace Center (DLR) develops a software tool Virtual Satellite which enables the engineers to store, exchange and alter their corresponding subsystem data on base of a distributed system model and thus contribute to the overall mission design during concurrent engineering (CE) sessions. Each engineer has their own scope of responsibilities, e.g. satellite trajectory, communication, or thermal analysis. Tracking implications of design changes on the whole system and feasibility aspects of the design is not trivial. Having an automated feasibility checking mechanism as a part of CE which would run iteratively after each design change provides a useful feedback mechanism for engineers and for the spacecraft client. For the purpose of mission feasibility checking a domain specific language (DSL) has been implemented using the Xtext Java framework. The extended parametric data model defined in the DSL serves as an executable representation of the spacecraft mission. The idea to use such an executable model to create a preliminary mission plan and hence confirm missions feasibility during conceptual study has already been introduced by Schaus et al. at the DLR. However, the vector of values of system variables was assumed to be equivalent with the currently active component, implying that component activities are mutually exclusive. This led to over-constraining of the execution model. Our work argues that concurrency considerations are critical from the earliest design phases. Since satellite is coupled with its environment and concurrency is an intrinsic property of the physical nature, considering concurrency allows for more realistic mission plans. The contributions of this paper are the introduction of concurrency considerations at the early space mission design phases and the use of timed automata tool (UPPAAL) for the - ission feasibility check during concurrent engineering sessions. As a result, with almost no overhead, the planned mission can be analyzed in a more realistic way. Furthermore, the run-times of the feasibility check amount to 10-100 milliseconds or less, which is also a significant improvement with respect to the previous work. This allows for more precision and fine granular modeling, and is a promising basis for model refinements in the consecutive mission design phases.},
  doi       = {10.1109/AERO.2016.7500572},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  keywords  = {aerospace computing;artificial satellites;automata theory;concurrent engineering;CE;DLR;DSL;German Aerospace Center;UPPAAL;Xtext Java framework;automated feasibility checking mechanism;concurrent engineering sessions;domain specific language;early design phases;extended parametric data model;software tool;space mission feasibility;spacecraft client;timed automata tool;virtual satellite;Automata;Concurrent computing;DSL;Modeling;Satellites;Space missions;Synchronization},
}

@InProceedings{7018448,
  author    = {A. Koshima and V. Englebert},
  title     = {Collaborative editing of EMF/Ecore meta-models and models conflict detection, reconciliation, and merging in DiCoMEF},
  booktitle = {Model-Driven Engineering and Software Development (MODELSWARD), 2014 2nd International Conference on},
  year      = {2014},
  pages     = {55-66},
  month     = {Jan},
  abstract  = {Despite the fact that Domain Specific Modeling tools become very powerful and more frequently used, the support for their cooperation has not reached its full strength and demand for model management is growing. In cooperative work, the decision agents are semi-autonomous and therefore a solution for reconciliating DSM after a concurrent evolution is needed. Conflict detection and reconciliation are important steps for merging of concurrently evolved (meta)models in order to ensure collaboration. In this work, we present a conflict detection, reconciliation and merging framework for concurrently evolved meta-models and models. Besides, we formally specify the EMF Ecore meta-model into set constructs that help to analyze the (meta)model and operations performed on it.},
  groups    = {Science Direct, SCOPUS},
  keywords  = {groupware;object-oriented methods;specification languages;DiCoMEF;EMF metamodel;Ecore metamodels;collaborative editing;conflict detection model;conflict merging model;conflict reconciliation model;domain specific modeling;model management;Adaptation models;Biological system modeling;Collaboration;Erbium;History;Semantics;Unified modeling language;Collaborative Modeling;Conflict Detection;DSML;EMF;Merging},
}

@InProceedings{6825691,
  author    = {A. Thiery and T. Cerqueus and C. Thorpe and G. Sunyé and J. Murphy},
  title     = {A DSL for Deployment and Testing in the Cloud},
  booktitle = {Software Testing, Verification and Validation Workshops (ICSTW), 2014 IEEE Seventh International Conference on},
  year      = {2014},
  pages     = {376-382},
  month     = {March},
  abstract  = {Cloud computing is becoming increasingly prevalent, more and more software providers are offering their applications as Software-as-a-Service solutions rather than traditional on-premises installations. In order to ensure the efficacy of the testing phase, it is critical to create a test environment that sufficiently emulates the production environment. Thus, Cloud applications should be tested in the Cloud. Cloud providers offer command-line tools for interacting with their platforms. However, writing custom low-level scripts using the provider's tool can become very complex to maintain and manage when variability (in terms of providers and platforms) is introduced. The contributions in this paper include: the development of a high level Domain Specific Language for the abstract definition of the application deployment process, and resource requirements, and a generation process that transforms these definitions to automatically produce deployment and instantiation scripts for a variety of providers and platforms. These contributions significantly simplify and accelerate the testing process for Cloud applications.},
  doi       = {10.1109/ICSTW.2014.43},
  groups    = {ACM, SCOPUS, IEEE DSL, Compendex},
  keywords  = {cloud computing;program testing;specification languages;DSL;application deployment process;cloud applications;cloud computing;cloud providers;command-line tools;custom low-level scripts;domain specific language;instantiation scripts;on-premises installations;resource requirements;software providers;software-as-a-service solutions;test environment;Context;DSL;Educational institutions;Grammar;Random access memory;Software;Testing;Cloud;DSL;Deployment;Testing in the Cloud},
}

@InProceedings{7140372,
  author    = {F. A. Lopes and M. Santos and R. Fidalgo and S. Fernandes},
  title     = {Model-driven networking: A novel approach for SDN applications development},
  booktitle = {2015 IFIP/IEEE International Symposium on Integrated Network Management (IM)},
  year      = {2015},
  pages     = {770-773},
  month     = {May},
  abstract  = {Software-Defined Networking (SDN) has been receiving a great deal of attention from both academic and industry communities. One reason to this interest is that SDN enables the network programmability, through an external controller, which supports applications and policies built from SDN programming languages, thus breaking the traditional bind between control and data plane. Nevertheless, the application development in this context is still complex for such recent technology. Moreover, there is a strong need for methodologies and tools that explore the abstraction levels potentials supported by SDN. This paper presents a new approach based on the Model-Driven Engineering (MDE) paradigm, called Model-Driven Networking (MDN). MDN relies on a Domain-Specific Modelling Language (DSML) to create SDN applications. We argue that MDN raises the level of abstraction on development, thus reducing the complexity to implement SDN applications and avoiding inconsistent policies. In order to show the relevance and the technological viability of our proposal, we have specified a DSML and have built a tool for creating SDN applications using the MDN approach.},
  doi       = {10.1109/INM.2015.7140372},
  groups    = {Compendex, IEEE DSL, SCOPUS},
  issn      = {1573-0077},
  keywords  = {software defined networking;specification languages;DSML;MDE paradigm;MDN;SDN applications development;SDN programming languages;domain-specific modelling language;external controller;model-driven engineering paradigm;model-driven networking;network programmability;software-defined networking;Biological system modeling;Complexity theory;Computational modeling;DSL;Proposals;Semantics;Syntactics;Domain-Specific Modeling Language;Model-Driven Engineering;Software-Defined Networking},
}

@InProceedings{6645251,
  author    = {F. Pérez and P. Valderas and J. Fons},
  title     = {A domain-specific language for enabling doctors to specify biomechanical protocols},
  booktitle = {2013 IEEE Symposium on Visual Languages and Human Centric Computing},
  year      = {2013},
  pages     = {99-102},
  month     = {Sept},
  abstract  = {New technologies are entering medical practice at an astounding pace. However, these technologies often cause to doctors learn and use difficulties. Then, doctors require assistance of a biomedical engineer. This is currently happening in a local hospital that has new technology to analyze biomechanical protocols in patients. Protocols are used to measure performances and identify changes in human body movements and muscles. Doctors are neither familiar with the concepts nor tools used, so biomedical engineers carry out descriptions of protocols rather than doctors. In this paper, we present the design of a domain-specific language that enables doctors to specify biomechanical protocols by addressing learning barriers (using design patterns). We also make doctors' descriptions compatible with the existing tools, and we also support legacy biomedical descriptions (combining meta-modeling and model transformations).},
  doi       = {10.1109/VLHCC.2013.6645251},
  groups    = {SCOPUS, IEEE DSL},
  issn      = {1943-6092},
  keywords  = {biomechanics;biomedical engineering;hospitals;protocols;specification languages;biomechanical protocols;biomedical engineer;design patterns;doctors;domain-specific language;hospital;human body movements;learning barriers;legacy biomedical descriptions;medical practice;meta-modeling;model transformations;muscles;patients;Biomechanics;Catalogs;DSL;Medical services;Motion measurement;Muscles;Protocols},
}

@InProceedings{6679649,
  author    = {J. McDaniel and C. Curtis and P. Brisk},
  title     = {Automatic synthesis of microfluidic large scale integration chips from a domain-specific language},
  booktitle = {2013 IEEE Biomedical Circuits and Systems Conference (BioCAS)},
  year      = {2013},
  pages     = {101-104},
  month     = {Oct},
  abstract  = {BioCoder is a domain-specific language by which chemists and biologists can express experimental protocols in a manner that is unambiguous and clearly repeatable. This paper presents a software toolchain that converts a protocol specified in a restricted subset of BioCoder to a technology-specific description of the protocol, targeting flow-based microfluidic large-scale integration (mLSI) chips. The technology-specific description can then be used to either: (1) execute the protocol on a capable chip; or (2) to derive the architecture of a new mLSI chip that can execute the protocol.},
  doi       = {10.1109/BioCAS.2013.6679649},
  groups    = {IEEE DSL},
  issn      = {2163-4025},
  keywords  = {bioMEMS;biology computing;lab-on-a-chip;microfluidics;programming languages;software tools;BioCoder;domain specific language;experimental protocols;flow based microfluidic large scale integration;mLSI chip automatic synthesis;microfluidic large scale integration chips;software toolchain;technology specific protocol description;Assembly;Biology;Computer architecture;Fluids;Heating;Microfluidics;Protocols;domain-specific language;microfluidic Large Scale Integration (mLSI)},
}

@Article{6418129,
  author   = {F. Rosique and M. Jimenez and A. Iborra},
  title    = {A Graphical Modeling Language for Home Automation},
  journal  = {IEEE Latin America Transactions},
  year     = {2012},
  volume   = {10},
  number   = {6},
  pages    = {2249-2255},
  month    = {Dec},
  abstract = {Home automation systems have emerged as one of the most attractive fields in engineering, thanks to the burgeoning demand from society for information systems. Today, the development of these systems is confined to the immediate context of the solution and is platform-dependent. This has intensified the need for suitable tools to tackle their development while enhancing quality and productivity. On one hand, domain specific languages allow the description of the system by means of graphic models easily and intuitively, using domain concepts. On the other hand, the model driven development approach stands out as a good option for solving the problems of the existing methods, as well as contributing tools that pioneer the development of domain specific languages. The present article proposes an alternative methodology and tools for the development of home automation applications following the model driven approach together with the use of a domain specific language.},
  doi      = {10.1109/TLA.2012.6418129},
  groups   = {IEEE DSL},
  issn     = {1548-0992},
  keywords = {formal specification;home automation;information systems;software tools;specification languages;domain concepts;domain specific languages;graphic models;graphical modeling language;home automation applications;home automation systems;information systems;model driven approach;model driven development approach;Computational modeling;Computer integrated manufacturing;DSL;Domain specific languages;Home automation;Software;Visualization;home automation;model driven engineering},
}

@InProceedings{6424560,
  author    = {T. Miyajima and D. Thomas and H. Amano},
  title     = {A Domain Specific Language and Toolchain for OpenCV Runtime Binary Acceleration Using GPU},
  booktitle = {Networking and Computing (ICNC), 2012 Third International Conference on},
  year      = {2012},
  pages     = {175-181},
  month     = {Dec},
  abstract  = {Computationally intensive applications, such as OpenCV, can be off-loaded to accelerators to reduce execution time. However, developing an accelerated system requires a significant amount of time, requiring the developer to first choose an accelerator and which parts to off-load, then to port and the offloaded kernels to the accelerator using many accelerator-specific tools. In addition to the low-level parallelism of the accelerator, the developer also needs to extract and utilize system-level parallelism found within the application, while making sure that the application still executes correctly. This paper presents Courier, a tool chain and a domain specific language for Runtime Binary Acceleration, designed to simplify many of the steps involved in accelerating an application. The Courier tool chain can extract dataflow from a running software binary file, explore the off-loaded execution time on an accelerator, and then actually accelerate the original binary. By utilizing Courier, both expert and non-expert users can easily extract system-level parallelism and decide which part should be off-loaded to accelerators in a mixed software-hardware environment, without special knowledge on the target application source code and accelerator architecture. In a case study an OpenCV application is accelerated by 2.06 times using Courier, without requiring the application source code or any re-compilation of the application.},
  doi       = {10.1109/ICNC.2012.34},
  groups    = {ACM, SCOPUS, IEEE DSL},
  keywords  = {computer vision;data flow computing;graphics processing units;operating system kernels;program compilers;specification languages;Courier tool chain;GPU;OpenCV runtime binary acceleration;accelerated system;accelerator architecture;accelerator-specific tools;accelerators;computationally intensive applications;dataflow;domain specific language;low-level parallelism;mixed software-hardware environment;off-loaded execution time;offloaded kernels;software binary file;system-level parallelism;target application source code;toolchain;Acceleration;Data transfer;Field programmable gate arrays;Graphics processing units;Parallel processing;Runtime;Domain Spefic Language;Dynamic Off-loading;GPU;OpenCV;Runtime Binary Acceleration},
}

@InProceedings{6665300,
  author    = {F. Van Broeckhoven and O. De Troyer},
  title     = {ATTAC-L: A modeling language for educational virtual scenarios in the context of preventing cyber bullying},
  booktitle = {Serious Games and Applications for Health (SeGAH), 2013 IEEE 2nd International Conference on},
  year      = {2013},
  pages     = {1-8},
  month     = {May},
  abstract  = {Cyber bullying (bullying via electronic communication tools) is a relatively recent phenomenon that especially occurs among early adolescents. As cyber bullying may have a serious impact on the mental (and physical) well-being of victims, it is important to develop effective evidence-based interventions against cyber bullying. The “Friendly ATTAC”-project has the aim to develop so-called virtual interactive scenarios (i.e. digital games) to modify behavior patterns associated with cyber bullying among youngsters. The scenarios will be developed during brainstorming sessions involving people from the different disciplines and with different backgrounds, but specialized in the domain of cyber bullying. To allow this non-technical people to specify the virtual interactive scenarios that should be developed, we have developed a domain specific modeling language that allow them to do so in an intuitive and close to natural language way. This paper presents this language in an informal way.},
  doi       = {10.1109/SeGAH.2013.6665300},
  groups    = {SCOPUS},
  keywords  = {Games;Lifting equipment;cyber bullying;domain specific modeling languages;serious games},
}

@InProceedings{6532141,
  author    = {A. Iliasov and A. Romanovsky},
  title     = {SafeCap Domain Language for Reasoning about Safety and Capacity},
  booktitle = {Dependable Transportation Systems/Recent Advances in Software Dependability (WDTS-RASD), 2012 Workshop on},
  year      = {2012},
  pages     = {1-10},
  month     = {Nov},
  abstract  = {The on-going UK SAFECAP project develops modeling techniques and tools for improving railway capacity while ensuring that safety standards are maintained. This paper reports recent SAFECAP results on designing a Domain Specific Language (DSL) that will allow engineers to improve the node and junction capacity while guaranteeing operational safety. The SAFECAP DSL is introduced to define railway topology, its logical structure and signalling rules. The formal semantics of this graphical DSL, defined as part of our work, allows us to reason about system safety. The tooling environment, the SAFECAP Platform, offers graphical editing of railway schemas and an interface to a range of verification for ensuring railway operational safety. The work on extending the environment and its deployment in the railway sector continues with our SAFECAP partners: Invensys Rail and Swansea University.},
  doi       = {10.1109/WDTS-RASD.2012.11},
  groups    = {ACM, IEEE DSL, SCOPUS},
  keywords  = {inference mechanisms;railway safety;specification languages;SAFECAP domain language;Swansea university;UK SAFECAP project;domain specific language;graphical DSL;invensys rail;modelling techniques;railway capacity;railway operational safety;railway topology;reasoning;safety standards;domain language;formal verification;railway modelling;route-based signalling;safety},
}

@InProceedings{6226010,
  author    = {H. Cho and J. Gray and E. Syriani},
  title     = {Creating visual Domain-Specific Modeling Languages from end-user demonstration},
  booktitle = {2012 4th International Workshop on Modeling in Software Engineering (MISE)},
  year      = {2012},
  pages     = {22-28},
  month     = {June},
  abstract  = {Domain-Specific Modeling Languages (DSMLs) have received recent interest due to their conciseness and rich expressiveness for modeling a specific domain. However, DSML adoption has several challenges because development of a new DSML requires both domain knowledge and language development expertise (e.g., defining abstract/concrete syntax and specifying semantics). Abstract syntax is generally defined in the form of a metamodel, with semantics associated to the metamodel. Thus, designing a metamodel is a core DSML development activity. Furthermore, DSMLs are often developed incrementally by iterating across complex language development tasks. An iterative and incremental approach is often preferred because the approach encourages end-user involvement to assist with verifying the DSML correctness and feedback on new requirements. However, if there is no tool support, iterative and incremental DSML development can be mundane and error-prone work. To resolve issues related to DSML development, we introduce a new approach to create DSMLs from a set of domain model examples provided by an end-user. The approach focuses on (1) the identification of concrete syntax, (2) inducing abstract syntax in the form of a metamodel, and (3) inferring static semantics from a set of domain model examples. In order to generate a DSML from user-supplied examples, our approach uses graph theory and metamodel design patterns.},
  doi       = {10.1109/MISE.2012.6226010},
  groups    = {Compendex, SCOPUS},
  issn      = {2156-7883},
  keywords  = {graph theory;specification languages;DSML adoption;DSML development;abstract syntax;domain knowledge;end-user demonstration;graph theory;incremental approach;iterative approach;language development expertise;metamodel design patterns;visual domain-specific modeling languages;Abstracts;Concrete;Engines;Semantics;Syntactics;Unified modeling language;Visualization;Domain-Specific Modeling Languages;Graph Theory;Metamodel;Metamodel Design Patterns;Metamodel Inference;Semantic Inference},
}

@InProceedings{7180130,
  author    = {V. Karakoidas and D. Mitropoulos and P. Louridas and G. Gousios and D. Spinellis},
  title     = {Generating the Blueprints of the Java Ecosystem},
  booktitle = {2015 IEEE/ACM 12th Working Conference on Mining Software Repositories},
  year      = {2015},
  pages     = {510-513},
  month     = {May},
  abstract  = {Examining a large number of software artifacts can provide the research community with data regarding quality and design. We present a dataset obtained by statically analyzing 22730 jar files taken from the Maven central archive, which is the de-facto application library repository for the Java ecosystem. For our analysis we used three popular static analysis tools that calculate metrics regarding object-oriented design, program size, and package design. The dataset contains the metrics results that every tool reports for every selected jar of the ecosystem. Our dataset can be used to produce interesting research results, such as measure the domain-specific language usage.},
  doi       = {10.1109/MSR.2015.76},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  issn      = {2160-1852},
  keywords  = {Java;information retrieval systems;libraries;object-oriented programming;program diagnostics;software metrics;software packages;Java ecosystem;Maven central archive;blueprints;de-facto application library repository;jar files;object-oriented design;package design;software artifacts;software metrics;static analysis tools;DSL;Databases;Java;Libraries;Measurement;Software;XML;Chidamber and Kemerer;Java;Maven;Software Metrics},
}

@InProceedings{7323106,
  author    = {K. Beckmann},
  title     = {Integrating existing proprietary system models into a model-driven test process for an industrial automation scenario},
  booktitle = {Model-Driven Engineering and Software Development (MODELSWARD), 2015 3rd International Conference on},
  year      = {2015},
  pages     = {255-262},
  month     = {Feb},
  abstract  = {The introduction of modern model-driven software development methodologies into the industrial practise still proves to be a challenge. Especially small or medium-sized enterprises (SMEs) need an incremental and continuous modernisation process, which incorporates existing projects, is customised and cost-effective. Particularly, suitable solutions for model-based or -driven testing with test automation to increase the efficiency are in demand. This paper presents an approach for integrating existing proprietary system models of an SME partner for describing industrial automation processes into a model-driven test process, utilising a domain-specific language for the test specification. The test objectives focuses on the correct implementation of the communication and synchronisation of distributed state machines. The presented approach is integrated into a test framework, which is based on the Eclipse Modelling Framework (EMF) and the Eclipse Test and Performance Tools Platform Project (TPTP) framework. To separate the possibly changeable system and DSL-specific models from the implementation of the test framework, a stable and more generic test meta model was defined.},
  groups    = {ACM, IEEE DSL, SCOPUS},
  keywords  = {factory automation;program testing;small-to-medium enterprises;software engineering;EMF;SME;domain-specific language;eclipse modelling framework;eclipse test and performance tools platform project;generic test meta model;industrial automation;model-driven test process;modern model-driven software development;proprietary system model;small or medium-sized enterprises;test specification;Adaptation models;Automation;Biological system modeling;DSL;Object oriented modeling;Software;Unified modeling language;DSL;MDSD;MDT;Metamodelling;Model-driven Testing;Testing},
}

@InProceedings{7203036,
  author    = {S. Barnett and R. Vasa and J. Grundy},
  title     = {Bootstrapping Mobile App Development},
  booktitle = {2015 IEEE/ACM 37th IEEE International Conference on Software Engineering},
  year      = {2015},
  volume    = {2},
  pages     = {657-660},
  month     = {May},
  abstract  = {Modern IDEs provide limited support for developers when starting a new data-driven mobile app. App developers are currently required to write copious amounts of boilerplate code, scripts, organise complex directories, and author actual functionality. Although this scenario is ripe for automation, current tools are yet to address it adequately. In this paper we present RAPPT, a tool that generates the scaffolding of a mobile app based on a high level description specified in a Domain Specific Language (DSL). We demonstrate the feasibility of our approach by an example case study and feedback from a professional development team. Demo at: https://www.youtube.com/watch?v=ffquVgBYpLM.},
  doi       = {10.1109/ICSE.2015.216},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  issn      = {0270-5257},
  keywords  = {application program interfaces;mobile computing;specification languages;DSL;IDE;RAPPT tool;data-driven mobile app;domain specific language;integrated development environment;mobile application development;Androids;DSL;Humanoid robots;Mobile communication;Motion pictures;Productivity;Software engineering;Code Generation;Mobile App Prototyping;Model Driven Development},
}

@InProceedings{6912082,
  author    = {Q. Ma and S. Schmit and C. Glodt and P. Kelsen},
  title     = {Combining Models with Code: A Tale of Two Languages},
  booktitle = {2014 IEEE International Conference on Global Software Engineeering Workshops},
  year      = {2014},
  pages     = {27-32},
  month     = {Aug},
  abstract  = {In the pure model-driven view of software engineering, models are the sole artifacts to be created and maintained and executable source code is entirely generated from the models. However, due to the variety of modern platforms and the complexity of capturing them correctly in models, this vision has not yet been fully realized. In this paper, we propose an approach that allows combining high-level models with low-level code into an executable system. The approach is based on two modeling languages, one presenting a common abstraction of modeling and programming languages, and the other allowing to express the bridge between the model and code. We illustrate our approach using a running example of an invoicing system for which the business logic requirements are captured by an executable model and the requirements on the graphical user interface are directly mocked up using a GUI designer tool that generates Java code.},
  doi       = {10.1109/ICGSEW.2014.9},
  groups    = {SCOPUS},
  issn      = {2329-6305},
  keywords  = {graphical user interfaces;object-oriented methods;software engineering;GUI designer tool;Java code generation;business logic requirements;graphical user interface;invoicing system;modeling languages;programming languages;software artifacts;software engineering;Adaptation models;Bridges;Business;Graphical user interfaces;Java;Object oriented modeling;Unified modeling language;Domain-Specific Modeling Language;Event-Driven Communication;Heterogeneous Model Integration;Model-Driven Software Development},
}

@InProceedings{6200121,
  author    = {T. Mesz´ros and T. Levendovszky},
  title     = {Verified Operational Patterns with Graph Transformation},
  booktitle = {2012 IEEE Fifth International Conference on Software Testing, Verification and Validation},
  year      = {2012},
  pages     = {954-961},
  month     = {April},
  abstract  = {Using object-oriented patterns such as design patterns, architectural patterns, and refactoring operations has considerably simplified the design process of software systems. With the proliferation of Domain-Specific Languages, the generalization of OO patterns is a natural demand. A straightforward idea is to adapt OO patterns with automated tool support to the practice of Domain-Specific Modeling as well. A possible solution for that is using graph transformations to formalize and realize such patterns. One may expect, however, that the patterns are realized in a way that they are correct and do exactly what we expect them to. In this paper, we present how one can precisely define the requirements for a domain-specific model pattern, and how to verify the requirements on the implemented patterns. The presented concept is motivated and illustrated with a case study from the state chart domain.},
  doi       = {10.1109/ICST.2012.201},
  groups    = {ACM, SCOPUS, IEEE DSL},
  issn      = {2159-4848},
  keywords  = {graph grammars;object-oriented methods;pattern classification;software architecture;software maintenance;software tools;OO patterns;architectural patterns;automated tool support;domain-specific language proliferation;domain-specific model pattern;graph transformation;object-oriented patterns;refactoring operations;software system design process;state chart domain;verified operational patterns;Adaptation models;Containers;Joining processes;Object oriented modeling;Semantics;Software systems;Unified modeling language;Active Model Patterns;Graph Transformation;Transformation Verification},
}

@InProceedings{7582830,
  author    = {T. Szabó and S. Alperovich and S. Erdweg and M. Voelter},
  title     = {An extensible framework for variable-precision data-flow analyses in MPS},
  booktitle = {2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  year      = {2016},
  pages     = {870-875},
  month     = {Sept},
  abstract  = {Data-flow analyses are used as part of many software engineering tasks: they are the foundations of program understanding, refactorings and optimized code generation. Similar to general-purpose languages (GPLs), state-of-the-art domain-specific languages (DSLs) also require sophisticated data-flow analyses. However, as a consequence of the different economies of DSL development and their typically relatively fast evolution, the effort for developing and evolving such analyses must be lowered compared to GPLs. This tension can be resolved with dedicated support for data-flow analyses in language workbenches. In this tool paper we present MPS-DF, which is the component in the MPS language workbench that supports the definition of data-flow analyses for DSLs. Language developers can define data-flow graph builders declaratively as part of a language definition and compute analysis results efficiently based on these data-flow graphs. MPS-DF is extensible such that it does not compromise the support for language composition in MPS. Additionally, clients of MPS-DF analyses can run the analyses with variable precision thus trading off precision for performance. This allows clients to tailor an analysis to a particular use case.},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  keywords  = {data flow analysis;data flow graphs;program compilers;software maintenance;specification languages;DSL;GPL;MPS-DF analysis;code generation;data flow analysis;data flow graph;domain-specific language;extensible framework;general-purpose language;software engineering;software refactoring;Algorithm design and analysis;DSL;Encoding;Lattices;Software;Switches;Syntactics;Data-flow Analysis;Domain-specific Language;Inter-procedural Analysis;Language Workbench},
}

@InProceedings{7250222,
  author    = {M. Allison and S. Turner and A. A. Allen},
  title     = {Towards interpreting models to orchestrate IaaS multi-cloud infrastructures},
  booktitle = {Computer Science Education (ICCSE), 2015 10th International Conference on},
  year      = {2015},
  pages     = {80-85},
  month     = {July},
  abstract  = {One challenge to the cloud computing paradigm is the task complexity associated with designing and managing multi-cloud solutions based on operational objectives. Heterogeneous vendor interfaces and a lack of standardization compounds this complexity and may eventually lead to vendor lock-in. In this article we present a model driven approach to allowing network administrators to intuitively describe and rapidly realize non-trivial IaaS behavior in realtime. We have developed iCloudML, an interpreted domain-specific modeling language and its interpreter as tooling support for the domain.},
  doi       = {10.1109/ICCSE.2015.7250222},
  groups    = {IEEE DSML},
  keywords  = {cloud computing;specification languages;IaaS multicloud infrastructures;cloud computing;iCloudML;infrastructure as a service;interpreted domain-specific modeling language;model driven approach;task complexity;Biological system modeling;Cloud computing;Data models;Object oriented modeling;Quality of service;Runtime;Syntactics},
}

@InProceedings{6755332,
  author    = {W. Deneke and W. N. Li and C. Thompson},
  title     = {Automatic Composition of ETL Workflows from Business Intents},
  booktitle = {2013 IEEE 16th International Conference on Computational Science and Engineering},
  year      = {2013},
  pages     = {1036-1042},
  month     = {Dec},
  abstract  = {Extract-Transform-Load (ETL) tools have provided organizations with the ability to build and maintain workflows (consisting of graphs of data transformation tasks) that can process the flood of digital age data. Currently, however, the specification of ETL workflows is largely manual, human time intensive, and error prone. As requirements become increasingly complex, users must have considerable technical expertise and domain knowledge to build and maintain these workflows. This paper describes a domain-specific modeling approach to automate the composition of data processing workflows. A high-level domain-specific language is used to assertion ally express the desired results of a workflow, from which the composition of the procedural workflow satisfying these goal statements can be generated. This problem solving approach results in an intuitive interface that is usable even by casual users for the rapid composition of workflows that are accurate and error free.},
  doi       = {10.1109/CSE.2013.151},
  groups    = {ACM, IEEE DSL, SCOPUS},
  keywords  = {business data processing;data handling;graph theory;high level languages;ETL tools;ETL workflows;automatic composition;business intents;data processing workflows;data transformation tasks;digital age data flood;domain knowledge;domain-specific modeling approach;extract-transform-load tools;high-level domain-specific language;human time intensive;technical expertise;Data models;Data processing;Distributed databases;Organizations;Semantics;Standards organizations;content type;domain-specific language;domain-specific modeling;extract-transform-load (ETL);semantic annotation;workflows},
}

@InProceedings{6630615,
  author    = {U. Thomas and G. Hirzinger and B. Rumpe and C. Schulze and A. Wortmann},
  title     = {A new skill based robot programming language using UML/P Statecharts},
  booktitle = {Robotics and Automation (ICRA), 2013 IEEE International Conference on},
  year      = {2013},
  pages     = {461-466},
  month     = {May},
  abstract  = {This paper introduces the new robot programming language LightRocks(Light Weight Robot Coding for Skills), a domain specific language (DSL) for robot programming. The language offers three different level of abstraction for robot programming. On lowest level skills are coded by domain experts. On a more abstract level these skills are supposed to be combined by shop floor workers or technicians to define tasks. The language is designed to allow as much flexibility as necessary on the lowest level of abstraction and is kept as simple as possible with the more abstract layers. A Statechart like model is used to describe the different levels of detail. For this we apply the UML/P and the language workbench MontiCore. To this end we are able to generate code while hiding controller specific implementation details. In addition the development in LightRocks is supported by a generic graphical editor implemented as an Eclipse plugin.},
  doi       = {10.1109/ICRA.2013.6630615},
  groups    = {Compendex, IEEE DSL, SCOPUS},
  issn      = {1050-4729},
  keywords  = {Unified Modeling Language;formal specification;program compilers;robot programming;DSL;Eclipse plugin;Light Weight Robot Coding for Skills;LightRocks;MontiCore language workbench;UML/P Statecharts;abstract layer;abstraction;code generation;controller specific implementation detail hiding;domain specific language;generic graphical editor;shop floor workers;skill based robot programming language;task definition;technicians;DSL;Robot programming;Robot sensing systems;Unified modeling language},
}

@InProceedings{7185068,
  author    = {W. T. Sun and A. Girault and G. Delaval},
  title     = {A formal approach for the synthesis and implementation of fault-tolerant industrial embedded systems},
  booktitle = {10th IEEE International Symposium on Industrial Embedded Systems (SIES)},
  year      = {2015},
  pages     = {1-9},
  month     = {June},
  abstract  = {We demonstrate the feasibility of a complete workflow to synthesize and implement correct-by-construction fault tolerant distributed embedded systems consisting of real-time periodic tasks. Correct-by-construction is provided by the use of discrete controller synthesis (DCS), a formal method thanks to which we are able to guarantee that the synthesized controlled system guarantees the functionality of its tasks even in the presence of processor failures. For this step, our workflow uses the Heptagon domain specific language and the Sigali DCS tool. The correct implementation of the resulting distributed system is a challenge, all the more since the controller itself must be tolerant to the processor failures. We achieve this step thanks to the libDGALS realtime library (1) to generate the glue code that will migrate the tasks upon processor failures, maintaining their internal state through migration, and (2) to make the synthesized controller itself fault-tolerant.},
  doi       = {10.1109/SIES.2015.7185068},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  issn      = {2150-3109},
  keywords  = {embedded systems;fault tolerant computing;multiprocessing systems;HEPTAGON;SIGALI DCS tool;correct-by-construction embedded systems;discrete controller synthesis;domain specific language;fault tolerant distributed embedded systems;fault-tolerant controller;fault-tolerant industrial embedded systems;formal method;glue code;libDGALS real-time library;migration;multiprocessor distributed system;multitask distributed system;processor failures;real-time periodic tasks;Contracts;Control systems;Energy consumption;Fault tolerance;Fault tolerant systems;Integrated circuit modeling;Process control},
}

@InProceedings{6686034,
  author    = {O. Díaz and C. Arellano},
  title     = {Integrating Microblogging Into Domain Specific Language Editors},
  booktitle = {Cloud and Green Computing (CGC), 2013 Third International Conference on},
  year      = {2013},
  pages     = {219-225},
  month     = {Sept},
  abstract  = {Micro logging is emerging as a suitable means for question-answering in working settings. This leads to different efforts to seamlessly integrate microblogging into the daily-used tools. Specifically, microblogging is being regarded as particularly useful during software development, akin to the tradition of Q&A forums. This paper looks at a particular kind of software: the one being developed by domain experts through the use of Domain Specific Languages (DSLs). We believe this setting is specially amenable to benefit from Q&A microblogging due to inherent limitations of the target audience. This brings the twist of domain specific ness into microblogging, i.e. the Q&A process is now framed by the semantics of the DSL constructs. This permits the introduction of editing assistants that embed domain knowledge about the kind of questions that can be posed, and the way answers can be selected. This opens an opportunity for more focused and assisted microblogging. This paper introduces Crowd Call, an in place microblogging mediator for DSL editors. The aim is to make microblogging a natural gesture during the conception of the DSL expressions, making transparent the interplay between the DSL editor and the Social Networking Services. In addition, Crowd Call can be configured to the constructs and resolution strategies of the DSL at hand so that questions and answers are framed by the semantics of the DSL. The approach is illustrated for three DSLs: the Google Spreadsheets formula language, SQL and Sticklet. We show how Crowd Call-mediated microblogging is tuned for the semantics of each DSL.},
  doi       = {10.1109/CGC.2013.42},
  groups    = {ACM, SCOPUS, IEEE DSL},
  keywords  = {SQL;question answering (information retrieval);social networking (online);specification languages;text editing;CrowdCall-mediated microblogging;DSL constructs;DSL editors;DSL expressions;DSL semantics;Google Spreadsheets formula language;Q and A microblogging;Q and A process;SQL;Sticklet;domain experts;domain knowledge;domain specific language editors;inplace microblogging mediator;question answering;resolution strategies;social networking services;software development;Communities;Computer languages;DSL;Google;Semantics;Social network services;Software;Domain Specific Languages;Microblogging;Social Networking Services},
}

@InProceedings{6613839,
  author    = {P. Mayer and A. Schroeder},
  title     = {Patterns of cross-language linking in java frameworks},
  booktitle = {2013 21st International Conference on Program Comprehension (ICPC)},
  year      = {2013},
  pages     = {113-122},
  month     = {May},
  abstract  = {The term Cross-Language Linking refers to the ability to specify, locate, navigate, and keep intact the connections between artifacts defined in different programming languages used for building one software application. Although understanding cross-language links and keeping them intact during development and maintenance activities is an important productivity issue, there has been little research on understanding the characteristics of such connections. We have thus built a theory from case studies, specifically, three theory-selected Java cross-language frameworks, each of which links artifacts written in the Java programming language to artifacts written in a declarative, framework-specific domain specific language. Our main contribution is to identify, from these experiences, common patterns of cross-language linking in the domain of Java frameworks with DSLs, which besides their informative nature can also be seen as requirements for designing and building a linking language and tooling infrastructure.},
  doi       = {10.1109/ICPC.2013.6613839},
  groups    = {IEEE DSL},
  issn      = {1092-8138},
  keywords  = {Java;software maintenance;DSL;Java frameworks;cross-language linking;programming languages;software application;software development;software maintenance;Atmospheric modeling;Frequency control;Springs;Cross-language;artifact linking;case study;language design;patterns;semantic models},
}

@InProceedings{6645255,
  author    = {D. Asenov and P. Müller},
  title     = {Customizing the visualization and interaction for embedded domain-specific languages in a structured editor},
  booktitle = {2013 IEEE Symposium on Visual Languages and Human Centric Computing},
  year      = {2013},
  pages     = {127-130},
  month     = {Sept},
  abstract  = {Large software projects are often based on libraries that provide abstractions for a particular domain such as writing database queries, staging, or constraint solving. The API provided by such a library can be considered a domain-specific language within the implementation language of the library, a so-called internal or embedded domain-specific language (eDSL). Embedding a DSL leverages the tool infrastructure of the host language, but also restricts the syntax and IDE support to that of the host language. This restriction prevents programmers from using convenient specialized notations and, thus, has a negative effect on their productivity. To address this problem, we outline concepts for a structured code editor that enable developers of eDSLs to customize how eDSL code is rendered and what interactions are available. We demonstrate the benefits of our approach by customizing a structured editor for the .NET Code Contracts API. Our prototype shows in particular that we can customize many aspects of visualization and interaction with little effort.},
  doi       = {10.1109/VLHCC.2013.6645255},
  groups    = {Compendex, IEEE DSL, SCOPUS},
  issn      = {1943-6092},
  keywords  = {application program interfaces;embedded systems;programming languages;visual programming;.NET code contracts API;IDE;convenient specialized notations;eDSL code;editor customization;embedded domain-specific languages;internal domain-specific language;large software projects;structured code editor;visual programming;Context;Contracts;DSL;Libraries;Prototypes;Syntactics;Visualization;editor customization;embedded domain-specific languages;human-computer interaction;programming environments;structured editors;visual programming},
}

@InProceedings{6569869,
  author    = {N. Jindal and V. Lotrich and E. Deumens and B. A. Sanders},
  title     = {SIPMaP: A Tool for Modeling Irregular Parallel Computations in the Super Instruction Architecture},
  booktitle = {Parallel Distributed Processing (IPDPS), 2013 IEEE 27th International Symposium on},
  year      = {2013},
  pages     = {874-884},
  month     = {May},
  abstract  = {Performance modeling is becoming an increasingly important part of the parallel application development process, particularly for expensive computations that will be run on very high-end systems where resources are scarce. We describe a performance modeling tool SIPMaP (Super Instruction Processor Modeling and Prediction) developed for the Super-Instruction Architecture (SIA). The SIA is designed for applications where the dominant data structures are large multi-dimensional arrays and it comprises a DSL, the Super-Instruction Assembly Language (SIAL) that supports expressing algorithms in terms of blocks (tiles), and its runtime system Super Instruction Processor (SIP) that manages distribution and disk storage of the arrays. SIPMaP generates performance models from the SIAL source code. In comparison with many applications where useful performance models have been developed and reported, these programs are irregular and have other difficult to model characteristics such as extensive overlapping of communication and computation.},
  doi       = {10.1109/IPDPS.2013.35},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  issn      = {1530-2075},
  keywords  = {assembly language;data structures;parallel processing;software performance evaluation;DSL;SIA;SIAL;SIPMaP;data structures;high-end systems;irregular parallel computations;performance modeling;super instruction assembly language;super instruction processor modeling and prediction;super-instruction architecture;Arrays;Computational modeling;Data models;Indexes;Predictive models;Runtime;Servers;Domain Specific Language;High Performance Computing;Performance Modeling},
}

@InProceedings{7160285,
  author    = {J. Opiła},
  title     = {Prototyping of visualization styles of 3D scalar fields using POV-Ray rendering engine},
  booktitle = {Information and Communication Technology, Electronics and Microelectronics (MIPRO), 2015 38th International Convention on},
  year      = {2015},
  pages     = {312-317},
  month     = {May},
  abstract  = {There is a persistent quest for novel methods of visualization in order to get insight into complex phenomena in scientific domains as various as physics, biomedicine or economics. Research teams involved achieved excellent results, however some problems with elaboration of novel visualization styles connected with flexibility of the software used and quality of the final images still persist. In the paper results of inspection of four visualization styles of 3D static scalar field employing POVRay ray-tracing engine are discussed, i.e. equipotential surface method using direct implementation of isosurface{} object, cellular trilinear interpolation approach, application of texture and eventually pseudo-particles design. All styles presented have been tested for hybrid visualizations and compared concerning computing time, informativeness and general appearance. It is shown in the work that Scene Description Language (SDL), domain specific language implemented in POV-Ray is flexible enough to use it as a tool for fast prototyping of novel visualization techniques. Visualizations discussed in the paper were computed using selected components of API of ScPovPlot3D, i.e. templates written in the SDL language.},
  doi       = {10.1109/MIPRO.2015.7160285},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  keywords  = {application program interfaces;data visualisation;rendering (computer graphics);3D static scalar field;API;POV-ray rendering engine;SDL language;ScPovPlot3D;biomedicine;cellular trilinear interpolation approach;complex phenomena;computing time;domain specific language;economics;general appearance;hybrid visualizations;informativeness;inspection;isosurface{} object;physics;pseudo-particles design;scene description language;texture design;visualization styles;Electric potential;Engines;Interpolation;Isosurfaces;Software;Three-dimensional displays;POVRay;ScPovPlot3D;pseudo-particles;scalar field visualization;visual data analysis},
}

@InProceedings{6404251,
  author    = {Pham Van Huong and Nguyen Ngoc Binh},
  title     = {An approach to design embedded systems by multi-objective optimization},
  booktitle = {Advanced Technologies for Communications (ATC), 2012 International Conference on},
  year      = {2012},
  pages     = {165-169},
  month     = {Oct},
  abstract  = {Embedded system design and optimization play an important role in the development trend of embedded technology. This paper presents a new approach to design and optimize embedded systems in the design phase based on Pareto multi-objective optimization. We defined two Domain Specific Languages and developed the framework that is to design the architecture model and the component diagram of embedded systems. And we integrated the code generation technology called Text Template Transformation Toolkit to this framework to generate parameters from models automatically. Then we also do multi-objective optimization to select the best trade-off configuration of the embedded system architecture and the best hardware-software partition based on the Pareto principle and Genetic Algorithm.},
  doi       = {10.1109/ATC.2012.6404251},
  groups    = {IEEE DSL},
  issn      = {2162-1020},
  keywords  = {Pareto optimisation;Unified Modeling Language;embedded systems;genetic algorithms;program compilers;software architecture;software tools;text analysis;Pareto multiobjective optimization;Pareto principle;architecture model;code generation technology;design embedded systems;domain specific languages;embedded system architecture;embedded system design;embedded system optimize;embedded technology;genetic algorithm;hardware-software partition;text template transformation toolkit;DSL;Embedded systems;Genetic algorithms;Linear programming;Optimization;Unified modeling language;DSL - Domain Specific Language;Embedded system;GA - Genetic Algorithm;Pareto principle;T4 - Text Template Transformation Toolkit;embedded system design;hardware-software partitioning;multi-objective optimization},
}

@InProceedings{7529871,
  author    = {G. C. Durelli and F. Spada and C. Pilato and M. D. Santambrogio},
  title     = {Scala-Based Domain-Specific Language for Creating Accelerator-Based SoCs},
  booktitle = {2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  year      = {2016},
  pages     = {225-232},
  month     = {May},
  abstract  = {Nowadays, thanks to technology miniaturization and industrial standards, it is possible to create System-on-Chip (SoC) architectures featuring a combination of many components, like processor cores and specialized hardware accelerators. However, designing an SoC to accelerate an embedded application is particularly complex. After decomposing this application into tasks and assigning each of them to a processing element, the designer must create the required hardware components and integrate them into the final system. Currently, this process is not well supported by commercial tool flows and has to be manually performed. This is time consuming and error prone. This paper proposes a Domain-Specific Language (DSL) based on Scala to specify the architecture of accelerator-based SoCs. We leverage this DSL to coordinate commercial High-Level Synthesis (HLS) tools in order to create the corresponding accelerators with proper standard interfaces for system-level integration.},
  doi       = {10.1109/IPDPSW.2016.169},
  groups    = {Compendex, IEEE DSL, SCOPUS},
  keywords  = {high level synthesis;integrated circuit design;specification languages;system-on-chip;DSL;HLS tools;Scala;SoC architectures;SoC design;accelerator-based SoC;embedded application;hardware accelerators;hardware components;high-level synthesis tools;industrial standards;processor cores;scala-based domain-specific language;system-level integration;system-on-chip architectures;technology miniaturization;Acceleration;Computer architecture;DSL;Hardware;Image edge detection;Protocols;Software},
}

@InProceedings{7292577,
  author    = {E. Loiseau and P. Laforcade and S. Iksal},
  title     = {A meta-modeling approach for extending the instructional design semantics of Learning Management Systems},
  booktitle = {Software Paradigm Trends (ICSOFT-PT), 2014 9th International Conference on},
  year      = {2014},
  pages     = {72-80},
  month     = {Aug},
  abstract  = {Nowadays Learning Management Systems (LMS) are not restricted to distant learning. Nevertheless, the pedagogical expressiveness of courses designed by teachers is strongly dependent on their knowledge and level of expertise on the LMS they use. The GraphiT project aims to help teachers design pedagogically sound and technically executable learning designs. To this end, we propose to support teachers by providing them with an LMS-specific Visual Instructional Design Language, according to a Domain Specific Modeling approach and tooling. This paper focuses on the abstract syntax of such language. We propose a specific LMS-centered approach for raising the pedagogical expressiveness of their implicit learning design semantics. We discussed how the LMS low-level parameterisations could be abstracted in order to build higher-level building blocks. Based on the Moodle LMS, we present and verify our meta-modeling approach by formalising the abstract syntax of a Moodle-dedicated instructional design language.},
  groups    = {IEEE DSL},
  keywords  = {Context;Learning management systems;Least squares approximations;Metamodeling;Semantics;Syntactics;Visualization;Composition;Domain Specific Language;Meta-Modeling},
}

@InProceedings{7490558,
  author    = {S. Jäger and R. Maschotta and T. Jungebloud and A. Wichmann and A. Zimmermann},
  title     = {Creation of domain-specific languages for executable system models with the Eclipse Modeling Project},
  booktitle = {2016 Annual IEEE Systems Conference (SysCon)},
  year      = {2016},
  pages     = {1-8},
  month     = {April},
  abstract  = {Model-based systems engineering is an increasingly accepted method supporting design decisions. System engineers or modelers have the choice between tools and system description languages that are either abstract and generic or specifically adapted to their domain. The latter approach is easier and more efficient but restrictive. The success of this approach strongly relies on the support of domain-specific tools. The design or adaptation of such software tools and their underlying conceptual models is a complex task, which can be supported by a model-based approach on the meta model level itself. This paper proposes a workflow for designing complex systems by using domain-specific models which may combine structural and behavioral aspects. It is loosely based on the Object Management Group's Model Driven Architecture approach. For this purpose we use the Eclipse Modeling Framework and Eclipse Sirius Project, which are part of the Eclipse Modeling Project. The paper describes the complete workflow based on a simple real-life system example to clarify our approach. It covering the design of the domain-specific language, semi-automatic model editor generation, modeling the system, and finally executing a simulation of its behavior.},
  doi       = {10.1109/SYSCON.2016.7490558},
  groups    = {IEEE DSL, SCOPUS},
  keywords  = {SysML;software architecture;software tools;specification languages;complex system design;design decisions;domain-specific languages;eclipse Sirius project;eclipse modeling project;executable system models;meta model level;model-based systems engineering;object management group model driven architecture approach;semiautomatic model editor generation;software tools;system description languages;Adaptation models;Analytical models;Biological system modeling;Software;Systems modeling;Unified modeling language;Eclipse Modeling Project;Ecore;Model-based system design;Sirius project;domain-specific language;meta model;simulation},
}

@InProceedings{7158502,
  author    = {A. Caracciolo and M. F. Lungu and O. Nierstrasz},
  title     = {A Unified Approach to Architecture Conformance Checking},
  booktitle = {Software Architecture (WICSA), 2015 12th Working IEEE/IFIP Conference on},
  year      = {2015},
  pages     = {41-50},
  month     = {May},
  abstract  = {Software erosion can be controlled by periodically checking for consistency between the de facto architecture and its theoretical counterpart. Studies show that this process is often not automated and that developers still rely heavily on manual reviews, despite the availability of a large number of tools. This is partially due to the high cost involved in setting up and maintaining tool-specific and incompatible test specifications that replicate otherwise documented invariants. To reduce this cost, our approach consists in unifying the functionality provided by existing tools under the umbrella of a common business-readable DSL. By using a declarative language, we are able to write tool-agnostic rules that are simple enough to be understood by untrained stakeholders and, at the same time, can be interpreted as a rigorous specification for checking architecture conformance.},
  doi       = {10.1109/WICSA.2015.11},
  groups    = {ACM, SCOPUS, IEEE DSL, Compendex},
  keywords  = {program testing;software architecture;architecture conformance checking;common business-readable DSL;de facto architecture;declarative language;domain specific language;software erosion;test specifications;tool-agnostic rules;Computer architecture;Concrete;DSL;Manuals;Mathematical model;Monitoring;Software;architecture;conformance checking;erosion},
}

@InProceedings{7306135,
  author    = {E. F. d. Prado and D. Lucrédio},
  title     = {A Flexible Model-Driven Game Development Approach},
  booktitle = {Components, Architectures and Reuse Software (SBCARS), 2015 IX Brazilian Symposium on},
  year      = {2015},
  pages     = {130-139},
  month     = {Sept},
  abstract  = {Game developers are facing an increasing demand for new games every year. Game development tools can be of great help, but require highly specialized professionals. Also, just as any software development effort, game development has some challenges. Model-Driven Game Development (MDGD) is suggested as a means to solve some of these challenges, but with a loss in flexibility. We propose a MDGD approach that combines multiple domain-specific languages (DSLs) with design patterns to provide flexibility and allow generated code to be integrated with manual code. After experimentation, we observed that, with the approach, less experienced developers can create games faster and more easily, and the product of code generation can be customized with manually written code, providing flexibility. However, with MDGD, developers become less familiar with the code, making manual codification more difficult.},
  doi       = {10.1109/SBCARS.2015.24},
  groups    = {ACM, IEEE DSL, SCOPUS},
  keywords  = {computer games;program compilers;software engineering;MDGD approach;code generation;flexible model-driven game development approach;game development tool;multiple DSL;multiple domain-specific language;software development;Cameras;DSL;Engines;Games;Prototypes;Software;Vehicles;Code Generation;Model-Driven Game Development},
}

@InProceedings{7005348,
  author    = {M. Moser and M. Pfeiffer and J. Pichler},
  title     = {A novel domain-specific language for the robot welding automation domain},
  booktitle = {Proceedings of the 2014 IEEE Emerging Technology and Factory Automation (ETFA)},
  year      = {2014},
  pages     = {1-6},
  month     = {Sept},
  abstract  = {Implementation, fault analysis, and maintenance of robot welding automation solutions are traditionally restricted to professional software developers only. Program code is written in a general purpose programming language and, hence, unmanageable by other stakeholders with limited or no programming skills. To tackle this problem we have implemented a domain-specific language (DSL) specifically designed to the domain of robot welding automation and to be intuitively manageable by all stakeholders. The created DSL supports a textual and visual notation and is embedded within a full featured tool chain which let our customer fully replace the creation and maintenance of welding automation solutions by our DSL-based development approach.},
  doi       = {10.1109/ETFA.2014.7005348},
  groups    = {Compendex, IEEE DSL, SCOPUS},
  issn      = {1946-0740},
  keywords  = {programming languages;robotic welding;DSL-based development approach;domain-specific language;fault analysis;program code;programming language;robot welding automation;stakeholders;Automation;DSL;Programming;Robot control;Visualization;Welding;Domain-Specific Language;Industrial Automation},
}

@Book{6813569,
  title     = {Model-Driven Software Engineering in Practice},
  publisher = {Morgan \& Claypool},
  year      = {2012},
  author    = {Marco Brambilla and Jordi Cabot and Manuel Wimmer},
  abstract  = {This book discusses how model-based approaches can improve the daily practice of software professionals. This is known as Model-Driven Software Engineering (MDSE) or, simply, Model-Driven Engineering (MDE). MDSE practices have proved to increase efficiency and effectiveness in software development, as demonstrated by various quantitative and qualitative studies. MDSE adoption in the software industry is foreseen to grow exponentially in the near future, e.g., due to the convergence of software development and business analysis. The aim of this book is to provide you with an agile and flexible tool to introduce you to the MDSE world, thus allowing you to quickly understand its basic principles and techniques and to choose the right set of MDSE instruments for your needs so that you can start to benefit from MDSE right away. The book is organized into two main parts. The first part discusses the foundations of MDSE in terms of basic concepts (i.e., models and transformations), driving p inciples, application scenarios and current standards, like the well-known MDA initiative proposed by OMG (Object Management Group) as well as the practices on how to integrate MDSE in existing development processes. The second part deals with the technical aspects of MDSE, spanning from the basics on when and how to build a domain-specific modeling language, to the description of Model-to-Text and Model-to-Model transformations, and the tools that support the management of MDSE projects. The book is targeted to a diverse set of readers, spanning: professionals, CTOs, CIOs, and team managers that need to have a bird's eye vision on the matter, so as to take the appropriate decisions when it comes to choosing the best development techniques for their company or team; software analysts, developers, or designers that expect to use MDSE for improving everyday work productivity, either by applying the basic modeling techniques and notations or by defining new domain-specific modeling lang ages and applying end-to-end MDSE practices in the software factory; and academic teachers and students to address undergrad and postgrad courses on MDSE. In addition to the contents of the book, more resources are provided on the book's website, including the examples presented in the book. Table of Contents: Introduction / MDSE Principles / MDSE Use Cases / Model-Driven Architecture (MDA) / Integration of MDSE in your Development Process / Modeling Languages at a Glance / Developing your Own Modeling Language / Model-to-Model Transformations / Model-to-Text Transformations / Managing Models / Summary},
  booktitle = {Model-Driven Software Engineering in Practice},
  doi       = {10.2200/S00441ED1V01Y201208SWE001},
  groups    = {IEEE DSML},
  isbn      = {9781608458837},
  pages     = {182-},
  url       = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6813569},
}

@InProceedings{7207420,
  author    = {O. Günalp and C. Escoffier and P. Lalanda},
  title     = {Rondo: A Tool Suite for Continuous Deployment in Dynamic Environments},
  booktitle = {Services Computing (SCC), 2015 IEEE International Conference on},
  year      = {2015},
  pages     = {720-727},
  month     = {June},
  abstract  = {Driven by the emergence of new computing environments, dynamically evolving software systems makes it impossible for developers to deploy software with human-centric processes. Instead, there is an increasing need for automation tools that continuously deploy software into execution, in order to push updates or adapt existing software regarding contextual and business changes. Existing solutions fall short on providing fault-tolerant, reproducible deployments that can scale on heterogeneous environments. In this paper we present Rondo, a tool suite that enables continuous deployment for dynamic, service-oriented applications. At the center of these tools, we propose a deterministic and idem potent deployment process. We provide with Rondo a deployment manager that implements this process and capable of conducting deployments and continuously adapting applications according to the changes in the current target platform. The tool suite also includes a domain-specific language for describing deployment requests. We validate our approach in multiple projects, for provisioning the platform as well as for installing applications and continuous reconfigurations.},
  doi       = {10.1109/SCC.2015.102},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  keywords  = {software fault tolerance;software tools;Rondo;application installing;automation tools;computing environments;continuous deployment;deployment requests;deterministic process;domain-specific language;dynamic application;dynamic environments;fault-tolerant deployment;human-centric processes;idem potent deployment process;reproducible deployment;service-oriented application;software systems;tool suite;Assembly;Computer architecture;Context;DSL;Program processors;Runtime;Continuous Deployment;Dynamism;Service-Oriented Computing},
}

@InProceedings{7033645,
  author    = {I. Alloush and C. G. Aoun and Y. Kermarrec and S. Rouvrais},
  title     = {A Domain-Specific Framework for Creating Early Trusted Underwater Systems Relying on Enterprise Architecture},
  booktitle = {2014 IEEE 22nd International Symposium on Modelling, Analysis Simulation of Computer and Telecommunication Systems},
  year      = {2014},
  pages     = {120-125},
  month     = {Sept},
  abstract  = {Service Creation Environments facilitate the creation of complex services and play a major role in the software industry. In this context, we aim at developing a domain-specific framework (networking domain) that uses a chain of existing "off-the-shelf" tools that are integrated together from the design phase to the verification activities. In this paper, we propose a new meta-model that extends ArchiMate to provide a domain-specific modeling language concerning the Deep Sea Observatories (DSO). We instantiate, as a case study, DSO model with identification and localization functions from this language, and apply it to our framework that relies on an IMS platform to evaluate the service model. These functions can be orchestrated with other services (e.g. military or civil reaction) or interconnected with other SO Systems. On the one hand, this illustrates our approach in relying on Enterprise Architecture (EA) framework that respects: multiple-views, perspectives of stakeholders, and domain specificities. On the other hand, it shows the reusability of our framework by changing applications from different domains: Video Conference as a Telecom Service, and Localizations for DSO.},
  doi       = {10.1109/MASCOTS.2014.23},
  groups    = {SCOPUS},
  issn      = {1526-7539},
  keywords  = {DP industry;marine engineering;service-oriented architecture;software houses;ArchiMate;DSO;complex services;deep sea observatories;domain-specific modeling language;early trusted underwater systems;enterprise architecture;identification and localization functions;off-the-shelf tools;service creation environments;software industry;telecom service;video conference;Analytical models;Business;Computer architecture;Context;Data models;Sensors;Syntactics;Data Fusion;Deep Sea Observatories;Distributed Systems;Enterprise Architecture;MeDON;Model Driven Engineering;Network Simulation;Object Localization},
}

@Article{6200023,
  author   = {V. Garcia-Diaz and B. C. P. G-Bustelo and O. Sanjuan-Martinez and E. R. Nunez Valdez and J. M. C. Lovelle},
  title    = {MCTest: towards an improvement of match algorithms for models},
  journal  = {IET Software},
  year     = {2012},
  volume   = {6},
  number   = {2},
  pages    = {127-139},
  month    = {April},
  abstract = {Owing to the increasing importance of model-driven engineering (MDE) and the changes experienced by software systems over their life cycle, the calculation, representation and visualisation of matches and differences between two different versions of the same model are becoming more necessary and useful. This study shows the need for improvement in the algorithms for calculating the relationships between models and presents a tool to test different implementations, thus reducing the effort required to measure, compare or create new algorithms. To demonstrate the need for improvement and the framework developed, the authors have created different models that conform to the metamodel of a domain-specific language. Subsequently, the authors compared these models using the algorithms of the eclipse modelling framework (EMF) Compare tool, part of the eclipse modeling project, which is the framework of reference for MDE. Thus, in the case study, the authors tool is used to measure the quality of the comparisons performed by EMF Compare.},
  doi      = {10.1049/iet-sen.2011.0040},
  groups   = {SCOPUS, IEEE DSL, Compendex},
  issn     = {1751-8806},
  keywords = {data structures;data visualisation;software engineering;specification languages;EMF Compare tool;MCTest;eclipse modelling framework;match algorithm;match calculation;match representation;match visualisation;model-driven engineering;software system},
}

@InProceedings{7404633,
  author    = {C. G. Aoun and I. Alloush and Y. kermarrec and J. Champeau and O. K. Zein},
  title     = {A mapping approach for Marine Observatory relying on enterprise architecture},
  booktitle = {OCEANS 2015 - MTS/IEEE Washington},
  year      = {2015},
  pages     = {1-10},
  month     = {Oct},
  abstract  = {UnderWater Sensor Networks (UW-SNs) performs collaborative monitoring tasks over an underwater determined area. These tasks could be underwater or deep sea observatories. Acoustic sensors (Hydrophones) are responsible to acquire the data underwater then transfer it to components/devices. Marine Observatory (MO) is the scenario of data exchanged between the different components/devices of the Underwater Acoustic Sensor Networks (UW-ASNs). Hence, the MO infrastructure could be based on an (UW-ASNs). This observation should take into consideration the environmental constraints since it may require specific tools, materials and devices (marines cables, specific servers and routers, etc.). The logical and physical components that are used in these observatories supply interchange procedures between the various devices of the environment (Smart Sensors, Data Fusion Servers). These components provide new services due to the long period running of the network. In this paper, we present our extended MetaModel that is used to generate a new design tool (ArchiMO). Thus, we propose a mapping approach between the layers of the enterprise architecture standard. This approach throws instantly domain-specific concepts and constraints in layers on run-time design activity according to a satisfaction of a certain criteria/constraints. We illustrate our proposal with an underwater object localization example from the MO domain. Additionally, we generate the corresponding simulation code for a standard network simulator using our self-developed domain-specific model compiler. Our approach helps to manage the complexity, and to reduce the time of the entire development life cycle of an MO information system. It supplies in the MO context, a way to share the different viewpoints of the designers.},
  groups    = {SCOPUS},
  keywords  = {environmental monitoring (geophysics);hydrophones;oceanographic techniques;underwater acoustic communication;wireless sensor networks;ArchiMO design tool;MO information system;MetaModel;UW-ASN;acoustic sensors;collaborative monitoring tasks;deep sea observatories;enterprise architecture;hydrophones;marine observatory;self-developed domain-specific model compiler;underwater acoustic sensor networks;underwater object localization;underwater observatories;Complexity theory;Context;Design tools;Information systems;Observatories;Servers;Software;ArchiMate;Data Fusion;Domain Specific Modeling Language;Enterprise Architecture;Marine Observatory;Meta-Model;Model Driven Engineers;Models;Simulation;Smart Sensors;Underwater Object Localization},
}

@InProceedings{7119032,
  author    = {L. Pomante and S. Candia and E. Incerto},
  title     = {A Model-Driven approach for the development of an IDE for Spacecraft on-board software},
  booktitle = {2015 IEEE Aerospace Conference},
  year      = {2015},
  pages     = {1-17},
  month     = {March},
  abstract  = {This paper presents the application of a Model-Driven Engineering (MDE) approach to the aerospace domain. Specifically, it shows the Model-Driven Development (MDD) of an Integrated Development Environment (IDE) for a Domain-Specific Language (DSL) targeted to the achievement of the so called “Spacecraft on-board software flexibility”. In fact, the goal of the presented work has been to deploy a full-featured IDE to be used for the development of the “On-board Command Procedures” (OBCPs). The OBCPs coding is done by using the “OBCP Definition Language” (ODL), specified by Thales Alenia Space Italy (TASI) on the basis of the requirements stated in the “Space Engineering: Spacecraft On-board Control Procedures” ECSS standard (ECSS-E-ST-70-01, 16 April 2010). This standard does not impose specific language syntax but provides the guidelines for its specification. By following such guidelines and by exploiting some MDE technologies and tools, such as Eclipse Modeling Framework (EMF) and Xtext, it has been possible to realize an Eclipse-based IDE able to provide to the ODL developer the entire features essential in a modern environment for software development. The considered features include the “traditional” ones as syntax-highlighting, code-completion, version-control, on-line error-checking, and also “advanced” ones like syntactic validation, semantic validation, and integrated code compilation. Moreover, by means of the adopted MDE approach, a very large part of the IDE code has been automatically generated starting from the Extended Backus-Naur Form (EBNF) specification of the ODL grammar so allowing for the IDE developers to be more focused on validation issues and on the quality of product than on the coding activity. All this has been obtained by following the paradigm “coding equals modeling”, for which each program represents a behavioral model compl- ant to the meta-model specified by the grammar of the language itself. The obtained result is a professional product that satisfies all the expected requirements, but this would be just a starting point since the ultimate goal of this work is to contribute to fostering the adoption of MDE approaches in the spacecraft software domain.},
  doi       = {10.1109/AERO.2015.7119032},
  groups    = {IEEE DSL, SCOPUS},
  issn      = {1095-323X},
  keywords  = {aerospace computing;configuration management;program verification;programming environments;software quality;space vehicles;specification languages;DSL;EBNF specification;ECSS standard;ECSS-E-ST-70-01;EMF;Eclipse modeling framework;Eclipse-based IDE;IDE code;IDE development;MDD;MDE approach;MDE technologies;OBCP definition language;ODL;ODL grammar;TASI;Thales Alenia Space Italy;Xtext;aerospace domain;behavioral model;code-completion;coding activity;domain-specific language;extended Backus-Naur form specification;integrated code compilation;integrated development environment;language grammar;language syntax;model-driven engineering approach;on-board command procedures;on-line error-checking;product quality;semantic validation;software development;space engineering;spacecraft on-board software flexibility;spacecraft onboard control procedures;syntactic validation;version-control;Biographies;DSL;Syntactics;Terminology;Unified modeling language},
}

@InProceedings{6654481,
  author    = {Y. Miao and M. Samaka and J. Impagliazzo},
  title     = {Facilitating teachers in developing online PBL courses},
  booktitle = {Teaching, Assessment and Learning for Engineering (TALE), 2013 IEEE International Conference on},
  year      = {2013},
  pages     = {454-459},
  month     = {Aug},
  abstract  = {Developing a sound online problem-based learning (PBL) course plan is difficult because teachers need comprehensive PBL and technical knowledge. This paper proposes a model-driven approach to develop a PBL authoring tool that helps teachers create and customize online PBL course plans in a cost-effective and flexible manner. A pilot study was conducted to assess teacher acceptance of the tool. The results reveal that after a short training session, teachers understood the authoring tool and thought the tool was easy to use to develop online PBL course plans.},
  doi       = {10.1109/TALE.2013.6654481},
  groups    = {SCOPUS, Compendex},
  keywords  = {authoring systems;computer aided instruction;PBL authoring tool;model-driven approach;online PBL courses development;short training session;sound online problem-based learning course plan;Collaboration;Computational modeling;Computers;Conferences;Educational institutions;Unified modeling language;IMS-LD;PBL;course authoring;domain-specific modeling language;learning deisgn;model-driven architecture},
}

@InProceedings{6597186,
  author    = {L. Montrieux and Y. Yu and M. Wermelinger},
  title     = {Developing a domain-specific plug-in for a modelling platform: The good, the bad, the ugly},
  booktitle = {Developing Tools as Plug-ins (TOPI), 2013 3rd International Workshop on},
  year      = {2013},
  pages     = {1-6},
  month     = {May},
  abstract  = {Domain-Specific Modelling Languages (DSML) allow software engineers to use the techniques and tools of Model-Driven Engineering (MDE) to express, represent and analyse a particular domain. By defining DSMLs as UML profiles, i.e. domain-specific extensions of the UML metamodel, development time for DSMLs can be greatly reduced by extending existing UML tools. In this paper, we reflect on our own experience in building rbacUML, a DSML for Role-Based Access Control modelling and analysis, as a plugin for a UML modelling platform. We describe what motivated our choice, and discuss the advantages and drawbacks of using an existing platform to develop a DSML on top of UML and additional analysis tooling.},
  doi       = {10.1109/TOPI.2013.6597186},
  groups    = {SCOPUS},
  issn      = {2327-0748},
  keywords  = {Unified Modeling Language;authorisation;simulation languages;software engineering;DSML development time;MDE;UML metamodel;UML profiles;domain-specific modelling languages;domain-specific plug-in development;model-driven engineering;rbacUML;role-based access control analysis;role-based access control modelling;Access control;Biological system modeling;Engines;Generators;Software;Standards;Unified modeling language;Eclipse;MDE;Modelling;OCL;Plugin;RBAC},
}

@InProceedings{7302461,
  author    = {I. Malavolta and H. Muccini and M. Sebastiani},
  title     = {Automatically Bridging UML Profiles to MOF Metamodels},
  booktitle = {2015 41st Euromicro Conference on Software Engineering and Advanced Applications},
  year      = {2015},
  pages     = {259-266},
  month     = {Aug},
  abstract  = {In Model-Driven Engineering, UML profiles and MOF-based Domain Specific Modeling Languages (DSMLs) are the most used approaches for describing domain specific applications. The choice of the right approach depends on several aspects, such as tool support, expressivity, complexity of models, company policies. In general, profiled UML models are very much used since they are intuitive for designers and model editors already exist, however they are intrinsically complex for model manipulation (e.g., Transformation, analysis), conversely, domain specific models are more concise and easy to be manipulated, but they require an initial effort in terms of designers training and model editors development. In this paper we propose an approach that allows getting the best of the two worlds: on one side designers can use UML profiles familiar to them, on the other side DSML models (automatically generated from profiled UML models) enable a better model manipulation. Our approach is based on an automatic bridge between UML profiles and MOF metamodels (which are the main artifacts of MOF-based DSMLs). The bridge is transparent to the user since it autonomously operates both on UML profiles and all the involved models. The bridge is realized through model transformation techniques in the Eclipse platform. In this paper we show its application on a case study based on SysML.},
  doi       = {10.1109/SEAA.2015.64},
  groups    = {Compendex, SCOPUS},
  issn      = {1089-6503},
  keywords  = {Unified Modeling Language;software tools;DSMLs;Eclipse platform;MOF metamodels;MOF-based domain specific modeling languages;SysML;UML profiles;automatic bridge;company policies;designers training;domain specific applications;domain specific models;model complexity;model editors development;model manipulation;model transformation techniques;model-driven engineering;tool support;Adaptation models;Analytical models;Bridges;Complexity theory;Metamodeling;Unified modeling language;Model-driven engineering;UML;metamodeling;model transformation},
}

@InProceedings{7027503,
  author    = {N. Ferry and H. Song and A. Rossini and F. Chauvel and A. Solberg},
  title     = {CloudMF: Applying MDE to Tame the Complexity of Managing Multi-cloud Applications},
  booktitle = {Utility and Cloud Computing (UCC), 2014 IEEE/ACM 7th International Conference on},
  year      = {2014},
  pages     = {269-277},
  month     = {Dec},
  abstract  = {The market of cloud computing encompasses an ever-growing number of cloud providers offering a multitude of infrastructure-as-a-service (IaaS) and platform-as-a-service (PaaS) solutions. The heterogeneity of these solutions hinders the proper exploitation of cloud computing since it prevents interoperability and promotes vendor lock-in, which increases the complexity of executing and managing multi-cloud applications (i.e., Applications that can be deployed across multiple cloud infrastructures and platforms). Providers of multi-cloud applications seek to exploit the peculiarities of each cloud solution and to combine the delivery models of IaaS and PaaS in order to optimise performance, availability, and cost. In this paper, we show how the Cloud Modelling Framework leverages upon model-driven engineering to tame this complexity by providing: (i) a tool-supported domain-specific language for specifying the provisioning and deployment of multi-cloud applications, and (ii) a models@run-time environment for enacting the provisioning, deployment, and adaptation of these applications.},
  doi       = {10.1109/UCC.2014.36},
  groups    = {IEEE DSL},
  keywords  = {cloud computing;open systems;IaaS;MDE;PaaS;cloud MF;cloud computing;cloud modelling framework;infrastructure-as-a-service;interoperability;model-driven engineering;multicloud applications;platform-as-a-service;tool-supported domain-specific language;Adaptation models;Biological system modeling;Cloud computing;Containers;Engines;Sensors;Syntactics;Cloud ML;Cloud computing;Model-driven engineering;multi-cloud},
}

@InProceedings{6735827,
  author    = {C. Liu and B. H. Shen and S. Y. Oh and M. Gerla and J. Palsberg and C. Banner and R. Butler},
  title     = {Agnostic Protocol Translation for Cross-Domain Information Sharing},
  booktitle = {MILCOM 2013 - 2013 IEEE Military Communications Conference},
  year      = {2013},
  pages     = {1447-1452},
  month     = {Nov},
  abstract  = {Network translation gateways can provide seamless interoperability among different airborne, ground and maritime domains. Effective interconnection between waveforms and protocols through the gateways requires manual intensive development and specialized protocol expertise. Therefore, enabling building versatile gateways that can effectively translate those protocols across different network domains is of utmost importance to improve system interoperability. High-level domain specific languages have been utilized to support agnostic protocol interoperability. However, protocol-specific knowledge specification, the core of protocol translation, is still left to protocol experts with manual coding without advanced tools in support of simplification, guidance or verification. Such a manual and unsupervised method of generating translation logic is complex, time-consuming and error-prone. In order to overcome these problems with much more productive gateway development, we present a novel, visual protocol-agnostic translation toolkit in this paper. This toolkit offers three advanced features: 1) simple, intuitive visualized specification of protocol-specific knowledge, 2) graph-based translation logic verification, and 3) automatic gateway generation. The first two features have not been addressed in currently available protocol translation solutions.},
  doi       = {10.1109/MILCOM.2013.245},
  groups    = {SCOPUS, IEEE DSL},
  issn      = {2155-7578},
  keywords  = {high level languages;internetworking;open systems;protocols;agnostic protocol interoperability;agnostic protocol translation;airborne domains;automatic gateway generation;cross-domain information sharing;graph-based translation logic verification;ground domains;high-level domain specific languages;maritime domains;network translation gateways;protocol-specific knowledge specification;visual protocol-agnostic translation toolkit;DSL;Grammar;Logic gates;Protocols;Semantics;Syntactics;Visualization;automatic translation;cross domain communication;domain specific language;protocol-agnostic translation;system interoperative;visual specificatin},
}

@InProceedings{7018502,
  author    = {K. Jacek and K. Nowakowski and Ż Kamil},
  title     = {Domain-specific languages as tools for teaching 3D graphics},
  booktitle = {Model-Driven Engineering and Software Development (MODELSWARD), 2014 2nd International Conference on},
  year      = {2014},
  pages     = {498-508},
  month     = {Jan},
  abstract  = {Model-driven engineering is constantly gaining importance, expanding to domains varying from the Web to the 3D graphics. Domain-specific languages besides contributing to the development process can be used in a didactic process conducted not only in schools. Thus this paper introduces new domain-specific language and discusses its usage in teaching construction of shaders and materials while working with 3D graphics. It presents the authors stance regarding the usefulness of domain-specific languages in education of 3D graphics development.},
  groups    = {ACM, SCOPUS, IEEE DSL},
  keywords  = {computer graphics;computer science education;software engineering;specification languages;teaching;3D graphics development education;3D graphics teaching;didactic process;domain-specific languages;materials;model-driven engineering;shaders;DSL;Education;Games;Graphics;Materials;Solid modeling;Three-dimensional displays;3D Graphics;Domain-specific Languages;Model-Driven Engineering;Modeling Shaders;Teaching},
}

@InProceedings{6619498,
  author    = {D. D. Ruscio and L. Iovino and A. Pierantonio},
  title     = {Managing the Coupled Evolution of Metamodels and Textual Concrete Syntax Specifications},
  booktitle = {2013 39th Euromicro Conference on Software Engineering and Advanced Applications},
  year      = {2013},
  pages     = {114-121},
  month     = {Sept},
  abstract  = {In the context of Model Driven Engineering (MDE) the definition of a Domain Specific Modeling Language (DSML) consists of a set of coordinated artifacts specifying the abstract and concrete syntax of the language, and possibly further aspects related to semantics. Concerning the specification of concrete syntaxes a number of tools are available. They typically permit to associate syntactic elements to metamodel (abstract syntax) of the modeling language being developed and to generate a number of supporting tools (e.g., parsers, pretty printers, and editors). Currently, tools for the specification of textual concrete syntaxes lack support for propagating metamodel changes to the corresponding concrete syntax specifications. In this paper, we analyze such a co-evolution problem, and provide an approach able to automate the propagation of metamodel changes to textual concrete specifications given by means of the TCS tool. The approach relies on model-to-model transformations which are applied according to difference models which represent the occurred metamodel changes.},
  doi       = {10.1109/SEAA.2013.22},
  groups    = {SCOPUS, Compendex},
  issn      = {1089-6503},
  keywords  = {computational linguistics;formal specification;simulation languages;software maintenance;DSML;Domain Specific Modeling Language;TCS tool;abstract syntax;co-evolution problem;difference models;metamodel changes propagation automation;metamodel evolution management;model driven engineering;model-to-model transformations;textual concrete syntax specifications evolution management;Abstracts;Adaptation models;Concrete;Context;Context modeling;Semantics;Syntactics;MDE;coupled evolution;metamodeling;textual concrete syntaxes},
}

@InProceedings{6275847,
  author    = {Y. Benchaïb and C. Chaudet},
  title     = {Using VIRMANEL and SILUMOD to study protocol for mobile multihop networks},
  booktitle = {Sensor, Mesh and Ad Hoc Communications and Networks (SECON), 2012 9th Annual IEEE Communications Society Conference on},
  year      = {2012},
  pages     = {76-78},
  month     = {June},
  abstract  = {In this demonstration, we show how to use a couple of tools we developed, VIRMANEL and SIMULOD, to study how the true implementation of an ad hoc routing protocol behaves under various mobility scenarios. VIRMANEL is a tool that configure virtual machines connections with respect to mobility. It features a GUI to observe the behavior of mobile nodes. SILUMOD is a domain-specific language that allows to describe mobility models. It defines the positions of the trajectory of moving through the appropriate keywords. These tools, published under the LGPL license, are used here to study the Linux implementation of OLSR.},
  doi       = {10.1109/SECON.2012.6275847},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  issn      = {2155-5486},
  keywords  = {mobile ad hoc networks;routing protocols;GUI;LGPL license;Linux implementation;OLSR;SILUMOD;VIRMANEL;ad hoc routing protocol;domain-specific language;mobile multihop networks;mobile nodes;mobility models;mobility scenarios;virtual machines connections;Ad hoc networks;Mobile computing;Spread spectrum communication},
}

@InProceedings{6690551,
  author    = {A. Mos and T. Jacquin},
  title     = {Improving Process Robustness through Domain-Specific Model Transformations},
  booktitle = {2013 17th IEEE International Enterprise Distributed Object Computing Conference Workshops},
  year      = {2013},
  pages     = {188-193},
  month     = {Sept},
  abstract  = {Many forward-thinking organizations have adopted domain-specific languages (DSL) as the preferred method for describing business processes. Using DSL-based descriptions helps in removing uncertainty from the semantics of process models. DSLs can evolve in a managed way and with proper versioning of individual processes the original intentions of process designers can be preserved over time. However in collaborative projects, business processes written in different DSLs need to be converted to a common denominator format to facilitate exchange. Due to its widespread adoption, BPMN is ideally placed to serve as the exchange language for complex, cross-domain collaborations. This paper presents an approach for automatic two-way synchronization of domain-specific process models with BPMN diagrams. This approach can be valuable when collaboration between different stakeholders with different expertise is required, as well as when the company wants to leverage its investments in a BPM suite across its process portfolio. In addition, this approach ensures that changes to processes executed through the BPMS are valid with respect to their domain representations, minimizing the potential for runtime problems that are difficult to understand.},
  doi       = {10.1109/EDOCW.2013.28},
  groups    = {IEEE DSL},
  issn      = {2325-6583},
  keywords  = {business data processing;investment;specification languages;BPMN diagrams;DSL-based descriptions;business process description;business process model and notation;collaborative projects;domain representations;domain-specific languages;domain-specific model transformations;domain-specific process model;investments;process model semantics;process portfolio;process robustness improvement;stakeholder collaboration;two-way synchronization;DSL;Domain specific languages;Organizations;Semantics;Standards organizations;BPM;BPMN;domain-specific language;modeling;tooling, rank1},
}

@InProceedings{6601569,
  author    = {D. Lindecker and G. Simko and I. Madari and T. Levendovszky and J. Sztipanovits},
  title     = {Multi-way Semantic Specification of Domain-Specific Modeling Languages},
  booktitle = {Engineering of Computer Based Systems (ECBS), 2013 20th IEEE International Conference and Workshops on the},
  year      = {2013},
  pages     = {20-29},
  month     = {April},
  abstract  = {Increased emphasis on the use of model-based design methods, particularly for developing Cyber-Physical Systems (CPS), has created challenges in the area of developing domain-specific modeling languages (DSML). To meet the increased demand for DSMLs, rapid development tools and techniques are needed. While tools such as the Generic Modeling Environment (GME) for the specification of the syntactic structure of DSMLs are well established, proper techniques for the specification of semantics and methods for integrating the semantic specifications with the language design tool suite remain interesting challenges. Current efforts in semantic specification of DSMLs focus solely on operational semantics. In this paper we show how the specification of multiple types of semantics can bring added benefit. We also emphasize the use of FORMULA, a formal modeling and analysis language, and show how it can be used to specify the semantics of a DSML in a way that integrates with DSML development tools. As a case study, we consider the operational and denotational semantics of a Statecharts-like language and show that the two semantic specifications can be used for complementary applications.},
  doi       = {10.1109/ECBS.2013.29},
  groups    = {SCOPUS, Compendex},
  keywords  = {formal specification;simulation languages;CPS development;DSML;FORMULA language;GME tool;cyber-physical system;denotational semantics;domain-specific modeling language;generic modeling environment;multiway semantic specification;operational semantics;semantics specification;statecharts-like language;Abstracts;Analytical models;Data models;Gears;Semantics;Syntactics;Unified modeling language},
}

@InProceedings{6928791,
  author    = {E. Kühn and S. Craß and T. Hamböck},
  title     = {Approaching Coordination in Distributed Embedded Applications with the Peer Model DSL},
  booktitle = {2014 40th EUROMICRO Conference on Software Engineering and Advanced Applications},
  year      = {2014},
  pages     = {64-68},
  month     = {Aug},
  abstract  = {Coordination in distributed embedded systems requires complex synchronization of many concurrent activities. This task becomes especially difficult when network and system failures have to be assumed. The Peer Model is a novel programming model for the design of coordination strategies among multiple nodes, aiming to bridge design and implementation. A major advantage is that designs based on the Peer Model are very flexible regarding changing requirements and policies. The motivating use case is an application in the railway domain where embedded nodes detect approaching trains and route this information over several forwarder nodes to the level crossing. In this paper, we present a Domain Specific Language for the Peer Model which allows to automatically generate a graphical documentation and source code for different embedded platforms. It lays the foundations for an embedded system software development tool chain. We prove the feasibility by implementing an event notification strategy for the level crossing use case.},
  doi       = {10.1109/SEAA.2014.72},
  groups    = {IEEE DSL, Compendex, SCOPUS, ACM},
  issn      = {1089-6503},
  keywords  = {concurrency control;distributed processing;embedded systems;railway engineering;software engineering;source code (software);system documentation;approaching train detection;complex synchronization;concurrent activities;distributed embedded systems;domain specific language;embedded nodes;embedded platforms;embedded system software devel- opment toolchain;event notification strategy;forwarder nodes;graphical documentation;level crossing;peer model;programming model;railway domain;source code;system failures;Containers;Documentation;Middleware;Peer-to-peer computing;Unified modeling language;Wiring},
}

@InProceedings{7436963,
  author    = {R. I. Hadiwijaya and M. M. I. Liem},
  title     = {A domain-specific language for automatic generation of checkers},
  booktitle = {2015 International Conference on Data and Software Engineering (ICoDSE)},
  year      = {2015},
  pages     = {7-12},
  month     = {Nov},
  abstract  = {One of the important modules of a black-box automatic program grader is a "checker". In programming competition environment, a checker is a program written for the purpose to check the output of the contestant's program for a task that has many solutions. Usually, a checker is written manually as needed. In this paper, the idea of the output checker in the programming competition environment is extended to input checker and source code checker as a part of the automatic grader in our programming learning environment. Input checker validates the input coverage. The source code checker is used to validate a set of properties from a source code against the given coding specification. A Domain-Specific Language (DSL) grammar is designed and developed as a specification for the automatic generation of the output, input, and source code checkers. The DSL grammar and the checker generator tool set are used to evaluate source codes in our programming class. By writing the checkers specification in DSL, the specification is automatically documented and can be reused for similar properties.},
  doi       = {10.1109/ICODSE.2015.7436963},
  groups    = {Compendex, SCOPUS, IEEE DSL},
  keywords  = {grammars;program verification;programming languages;source code (software);DSL grammar;black-box automatic program grader;checker generator tool;checkers automatic generation;domain-specific language;input checker;source code checker;DSL;Domain specific languages;Encoding;Generators;Programming;Testing;Domain-Specific Language;automatic program grading;property checker},
}

@InProceedings{6710367,
  author    = {E. Tyugu and P. Grigorenko},
  title     = {Components in model-based software development},
  booktitle = {Computer Science and Information Technologies (CSIT), 2013},
  year      = {2013},
  pages     = {1-8},
  month     = {Sept},
  abstract  = {Model-based software development (MBSD) is rapidly gaining popularity. There are two main approaches to MBSD: transformational and compositional approaches. The first has been initiated in nineties by creating UML - a universal modeling language that has become a standard for software specification, and has influenced research in software engineering. One can say that UML has initiated model-driven software engineering (MDSE). The second - compositional approach has grown out of domain-specific language development. It uses visual specifications as input, and is represented by tools like MetaEdit+ and CoCoViLa. We give a survey of these approaches, and discuss in more detail the compositional approach, paying attention at combining compositional and object-oriented software specifications.},
  doi       = {10.1109/CSITechnol.2013.6710367},
  groups    = {SCOPUS},
  keywords  = {Unified Modeling Language;formal specification;object-oriented programming;CoCoViLa tool;MBSD;MetaEdit+ tool;UML;compositional approach;compositional specifications;domain-specific language development;model-based software development;object-oriented software specifications;software engineering;software specification;transformational approach;universal modeling language;visual specifications;Computational modeling;Java;Mathematical model;Object oriented modeling;Software;Unified modeling language;Visualization;compositional software design;domain-specific modelling;model driven software development;software components;structural synthesis of programs},
}

@InProceedings{6690566,
  author    = {M. Farwick and T. Trojer and M. Breu and S. Ginther and J. Kleinlercher and A. Doblander},
  title     = {A Case Study on Textual Enterprise Architecture Modeling},
  booktitle = {2013 17th IEEE International Enterprise Distributed Object Computing Conference Workshops},
  year      = {2013},
  pages     = {305-309},
  month     = {Sept},
  abstract  = {Today's Enterprise Architecture Management (EAM) tools are based on forms and graphical modeling capabilities via web-based applications or desktop clients. However, recent developments in textual modeling tools have not yet been considered for EA modeling in research and practice. In this paper we present a novel EAM-tool approach, called Txture, that consists of a textual modeling environment and a web-application to provide enterprise-wide architecture visualizations for different stakeholder groups. The tool is in production use at a major Austrian data center, where it proofed to be intuitive and provide efficient modeling capabilities compared to traditional approaches. In this paper we present lessons learned from the development of the tool as well as usage it and report on its benefits and drawbacks.},
  doi       = {10.1109/EDOCW.2013.40},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  issn      = {2325-6583},
  keywords  = {Internet;corporate modelling;data visualisation;Austrian data center;EA modeling;EAM tools;Txture;Web based applications;desktop clients;enterprise architecture management;enterprise wide architecture visualizations;graphical modeling;textual enterprise architecture modeling;textual modeling tools;Business;Computational modeling;Computer architecture;DSL;Data visualization;Documentation;Syntactics;DSL;case study;documentation;domain-specific language;enterprise architecture;textual;viewpoint;xtext},
}

@InProceedings{6881940,
  author    = {F. Rabbi and W. MacCaull},
  title     = {User-Friendly UIs for the Execution of Clinical Practice Guidelines},
  booktitle = {2014 IEEE 27th International Symposium on Computer-Based Medical Systems},
  year      = {2014},
  pages     = {489-490},
  month     = {May},
  abstract  = {Workflow management systems (WfMS) can be used to manage complex processes, such as those described by Clinical Practise Guidelines (CPG). Such processes involve a variety of stakeholders, however, frequently their interfaces are not suited to the needs of the stakeholders involved. Here we propose that WfMSs be integrated with tools to build a variety of interfaces to meet the needs of different users. Using a CPG for the management of hypertension as a case study, we give examples of user-friendly interfaces which can be built easily using our domain specific language, and which integrate with our WfMS. One interface guides the clinician in the management of the disease, allowing her him the opportunity to view and interact with the process in a more holistic fashion, recording and recalling information relevant to the patient or the task. A second interface is more suited to the patient for the self management of lifestyle parameters, while other interfaces can be used by the patient, the clinician or the manager to represent trends or aggregate data.},
  doi       = {10.1109/CBMS.2014.104},
  groups    = {ACM, SCOPUS, IEEE DSL},
  issn      = {1063-7125},
  keywords  = {diseases;graphical user interfaces;human computer interaction;medical computing;workflow management software;CPG execution;WfMS;clinical practice guideline execution;complex process management;disease management;domain specific language;hypertension management;lifestyle parameter self management;user-friendly UI;user-friendly interfaces;workflow management systems;Biomedical monitoring;Diseases;Educational institutions;Guidelines;Hypertension;Monitoring;clinical practice guidelines;domain specific language;user friendly interface;workflow management system},
}

@Article{7483535,
  author   = {S. R. Mello Canovas and C. E. Cugnasca},
  title    = {Extending a Metamodel for Adaptive Programs: Specifying Adaptive Functions},
  journal  = {IEEE Latin America Transactions},
  year     = {2016},
  volume   = {14},
  number   = {4},
  pages    = {1923-1929},
  month    = {April},
  abstract = {Model Driven Engineering (MDE) is a software development approach based on the use of models as essential artifacts. In the ideal scenario, source code is automatically generated from models by steps of transformations defined by mapping functions. A metamodel is a special type of model that describes the syntax of a modeling language. They are important because mapping functions reference their elements to define transformations, allowing the application of MDE. This paper proposes an extension of a metamodel of a domain specific modeling language for adaptive programs. This extension includes metaclasses, properties and constraints for specifying adaptive functions. An existing mapping function, which generates partial source code in BADAL language, was then updated to consider the new metamodel elements, becoming able to generate code for adaptive functions from the model specification. The resulting metamodel and mapping function were used as input to generate a CASE tool for adaptive programs, allowing the use of MDE in a higher level of abstraction than before for this class of application.},
  doi      = {10.1109/TLA.2016.7483535},
  groups   = {IEEE DSL},
  issn     = {1548-0992},
  keywords = {formal specification;program compilers;source code (software);BADAL language;CASE tool;MDE;adaptive function specification;adaptive programs;code generation;domain specific modeling language syntax;mapping functions;metamodel elements;model driven engineering;model specification;software development approach;source code;Adaptation models;Computer aided software engineering;Domain specific languages;Model driven engineering;Syntactics;Unified modeling language;Adaptive Programs;Domain Specific Language;Model Driven Engineering;Set Based Meta Modeling},
}

@InProceedings{6337245,
  author    = {T. Holmes},
  title     = {From Business Application Execution to Design Through Model-Based Reporting},
  booktitle = {Enterprise Distributed Object Computing Conference (EDOC), 2012 IEEE 16th International},
  year      = {2012},
  pages     = {143-153},
  month     = {Sept},
  abstract  = {Cross-disciplinary models constitute essential instruments to master complexity. Often it is easier to relate to high-level concepts than to deal with low-level technical details. In model-driven engineering (MDE) models are designated a pivotal role from which systems are generated. As such, MDE enables different stakeholders of business applications to participate in the engineering process. Until now however, MDE does not penetrate phases beyond generation and deployment such as monitoring, analysis, and reporting. To display information from runtime and analytics it would be interesting if reporting could utilize models from design time. Therefore, this paper presents model-based reporting (MbR). Bridging the gap between reporting and design, it enables stakeholders to intuitively specify the reporting through a domain-specific language (DSL) while accelerating development cycles. In non-model-driven settings, MbR can help to introduce models as a first step towards MDE.},
  doi       = {10.1109/EDOC.2012.25},
  groups    = {IEEE DSL},
  issn      = {1541-7719},
  keywords  = {business data processing;software engineering;DSL;MDE;MbR;business application execution;cross disciplinary models;domain specific language;engineering process;model based reporting;model driven engineering;Abstracts;Business;Context modeling;Correlation;DSL;Data models;Runtime;business applications;end-to-end;model-based;reporting},
}

@InProceedings{7382444,
  author    = {M. Sneps-Sneppe and D. Namiot},
  title     = {On web-based domain-specific language for Internet of Things},
  booktitle = {Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT), 2015 7th International Congress on},
  year      = {2015},
  pages     = {287-292},
  month     = {Oct},
  abstract  = {This paper discusses the challenges of the Internet of Things programming. Sensing and data gathering from the various sources are often the key elements of applications for Smart Cities. So, the effective programming models for them are very important. In this article, we discuss system software models and solutions, rather than network related aspects. In our paper, we present the web-based domain-specific language for Internet of Things applications. Our goal is to present the modern models for data processing in Internet of Things and Smart Cities applications. In our view, the use of this kind of tools should seriously reduce the time to develop new applications.},
  doi       = {10.1109/ICUMT.2015.7382444},
  groups    = {IEEE DSL, SCOPUS},
  keywords  = {Internet of Things;smart cities;systems software;Internet of Things;Web-based domain-specific language;smart cities;system software models;Computational modeling;Data models;Domain specific languages;Internet of things;Programming;Sensors;Smart cities;actors;domain-specific languages;micro-service;middleware;software standards},
}

@InProceedings{6228998,
  author    = {N. Hallenberg and P. L. Carlsen},
  title     = {Declarative automated test},
  booktitle = {Automation of Software Test (AST), 2012 7th International Workshop on},
  year      = {2012},
  pages     = {96-102},
  month     = {June},
  abstract  = {Automated tests at the business level can be expensive to develop and maintain. One common approach is to have a domain expert instruct a QA developer to implement what she would do manually in the application. Though there exist record-replay tools specifically developed for this, these tend to scale poorly for more complicated test scenarios. We present a different solution: An Embedded Domain Specific Language (EDSL) in F#, containing the means to model the user interface, and the various manipulations of it. We hope that this DSL will bridge the gap between the business domain and technical domain of applications to such a degree that domain experts may be able to construct automatic tests without depending on QA developers, and that these tests will prove more maintainable.},
  doi       = {10.1109/IWAST.2012.6228998},
  groups    = {ACM, IEEE DSL, SCOPUS},
  keywords  = {program testing;software quality;user interfaces;F#;QA developer;business level;declarative automated testing;domain expert;embedded domain specific language;record-replay tool;technical domain;user interface;Business;DSL;Documentation;Engines;Phantoms;Testing;User interfaces;Automated Testing;Domain Specific Language;F#;Functional Testing},
}

@InProceedings{7336975,
  author    = {A. Maarouf and M. E. Hamlaoui and A. Marzouk and A. Haqiq},
  title     = {Combining multi-agent systems and MDE approach for monitoring SLA violations in the Cloud Computing},
  booktitle = {Cloud Technologies and Applications (CloudTech), 2015 International Conference on},
  year      = {2015},
  pages     = {1-6},
  month     = {June},
  abstract  = {A Service Level Agreement (SLA) is a legal contract between parties to ensure the Quality of Service (QoS). It specifies one or more service level objectives (SLO), to ensure that the QoS delivered has met customer expectations. However, It becomes hard to guarantee QoS levels and detect SLA violations. Therefore, we propose to use MDE (Model Driven Engineering) to express the SLA contract requirements. This latter, created with a specific modeling language (DSML), will be used harmonically with a Multi-agent systems (MASs) in order to monitor SLA violations in real-time. Indeed, MASs are suitable tools for self-detection of failures and self-monitoring of cloud operations and services, QoS negotiation and SLA management. They are designed to operate in a dynamically changing environment. Our main motivation is firstly to use MDE technology for the creation of the SLA contract and then to integrate MASs in order to control the quality of service contract and guarantee transparency and symmetry with respect to the SLA contract between prospective signatories.},
  doi       = {10.1109/CloudTech.2015.7336975},
  groups    = {SCOPUS},
  keywords  = {cloud computing;contracts;multi-agent systems;quality of service;DSML;MAS;MDE approach;QoS negotiation;SLA contract;SLA management;SLA violations;SLO;cloud computing;cloud operations;cloud services;legal contract;model driven engineering;modeling language;multiagent systems;prospective signatories;quality of service;service level agreement;service level objectives;Cloud computing;Computational modeling;Contracts;Monitoring;Multi-agent systems;Quality of service;Real-time systems;Cloud Computing;MDE;Multi-agent systems;SLA Monitoring;Service Level Agreements},
}

@InProceedings{7323105,
  author    = {C. Huang and A. Osaka and Y. Kamei and N. Ubayashi},
  title     = {Automated DSL construction based on software product lines},
  booktitle = {Model-Driven Engineering and Software Development (MODELSWARD), 2015 3rd International Conference on},
  year      = {2015},
  pages     = {1-8},
  month     = {Feb},
  abstract  = {DSL (Domain-Specific Language) is one of the important approaches for software abstraction. In the past decades, DSLs have been provided by expert engineers familiar with domain knowledge and programming language processors. It is not easy for ordinary programmers to construct DSLs for their own purposes. To deal with this problem, we propose a language workbench called Argyle that can automatically generate a DSL by only specifying a set of functions needed to the DSL and an execution platform supported by the DSL. Argyle is based on software product lines and consists of the following two steps: 1) development of the core assets for constructing a family of DSLs and 2) DSL configuration using these core assets. To demonstrate the effectiveness of our approach, we developed a prototype DSL for supporting MSR (Mining Software Repositories), the most active research field in software engineering.},
  groups    = {ACM, Compendex, SCOPUS, IEEE DSL},
  keywords  = {programming languages;software product lines;Argyle;MSR;automated DSL construction;domain-specific language;mining software repository;programming language processor;software engineering;software product line;DSL;Encoding;Metals;Program processors;Software product lines;Syntactics;Domain-specific Language;Language Workbench;Software Product Line},
}

@InProceedings{6728120,
  author    = {M. Lethrech and I. Elmagrouni and M. Nassar and A. Kriouile and A. Kenzi},
  title     = {A generic metamodel for adaptable service oriented systems modeling using DSM approach},
  booktitle = {ISKO-Maghreb, 2013 3rd International Symposium},
  year      = {2013},
  pages     = {1-6},
  month     = {Nov},
  abstract  = {CAC (context aware computing) has recently emerged as a new computing paradigm promising adaptable systems development. Context awareness for services oriented systems (SOS) raises many challenges. Particularly, the challenge of engineering such systems which consists of the definition of modeling approaches, processes, techniques and tools to facilitate construction of these systems. In this paper, we propose a generic metamodel for Adaptable, Domain Specific and Service Oriented Systems. Our metamodel aims to facilitate the creation of Domain Specific Language (DSL) for adaptable and service oriented architecture. For a specific domain the language developer must produce their specific service metamodel based on our generic service metamodel.},
  doi       = {10.1109/ISKO-Maghreb.2013.6728120},
  groups    = {IEEE DSL, SCOPUS},
  keywords  = {high level languages;service-oriented architecture;systems software;ubiquitous computing;CAC;DSM approach;adaptable domain specific service oriented systems modeling;adaptable service oriented architecture;context aware computing;domain specific language developer;generic service metamodel;Adaptation models;Computational modeling;Context;Context modeling;DSL;Unified modeling language;Adaptability;CAC;DSM;Meta Modeling;SOC},
}

@InProceedings{6642475,
  author    = {T. Bouabana-Tebibel and S. H. Rubin and K. Habib and S. Mellah and L. Allata},
  title     = {A component-based language specific to complex systems modeling},
  booktitle = {Information Reuse and Integration (IRI), 2013 IEEE 14th International Conference on},
  year      = {2013},
  pages     = {217-224},
  month     = {Aug},
  abstract  = {The modeling and design of complex systems continues to face grand challenges in feedback and control. Existing languages and tools, either textual or graphical, bring some improvement for such purposes, but much remains to be done in order to readily insure scalability. In this paper, we propose a language, which gathers specialization and composition properties. It is our belief that the latter properties bear the necessary capabilities to overcome the difficulties raised when developing these systems. The language is designed, on one hand, in a way to be specific to complex system domains. It supports, on the other hand, a component-based structure that conforms to a user-friendly component assembly. It is conceived in the spirit of SysML concepts. Its' programs generate Internal Block Diagrams. A programming tool is built on the basis of the Eclipse framework.},
  doi       = {10.1109/IRI.2013.6642475},
  groups    = {SCOPUS, IEEE DSL},
  keywords  = {object-oriented programming;specification languages;Eclipse framework;SysML concepts;complex system modeling;component-based language;component-based structure;domain-specific language;internal block diagrams;programming tool;user-friendly component assembly;Assembly;DSL;Grammar;Ports (Computers);Standards;Syntactics;Unified modeling language;Complex Systems;Component-Based Language;Domain-Specific Language;SysML},
}

@InProceedings{7102598,
  author    = {E. Alegroth and G. Bache and E. Bache},
  title     = {On the Industrial Applicability of TextTest: An Empirical Case Study},
  booktitle = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)},
  year      = {2015},
  pages     = {1-10},
  month     = {April},
  abstract  = {Software systems are becoming more complex, not least in their Graphical User Interfaces (GUIs), which presents challenges for existing testing practices. Pressure to reduce time to market leaves less time for manual testing and increases the importance of test automation. Previous research has identified several generations of automated GUI-based test approaches with different cost-benefit tradeoffs. Whilst test automation provides fast quality feedback it can be associated with high costs and inability to identify defects not explicitly anticipated by the test designer. TextTest is a capture-replay tool for GUI-based testing with a novel approach that overcomes several of the challenges experienced with previous approaches. Firstly the tool supports Approval Testing, an approach where ASCII-art representations of the GUI's visual state are used to verify correct application behavior at the system level. Secondly it records and replays test scripts in a user defined domain specific language (DSL) that is readable by all stakeholders. In this paper we present a three phase industrial case study that aims to identify TextTest's applicability in industrial practice. The paper reports that the tool is associated with (1) low script development costs due to recording functionality, (2) low maintenance costs, on average 7 minutes per test case, (3) better defect finding ability than manual system testing, (4) high test case execution performance (In this case 500 test cases in 20 minutes), (5) high script readability due to DSL defined scripts, and (6) test suites that are robust to change (In this case 93 percent per iteration). However, the tool requires a higher degree of technical skill for customization work, test maintainers need skills in designing regular expressions and the tool's applicability is currently restricted to Java and Python based applications.},
  doi       = {10.1109/ICST.2015.7102598},
  groups    = {IEEE DSL, SCOPUS, Compendex},
  issn      = {2159-4848},
  keywords  = {Java;graphical user interfaces;program testing;software tools;ASCII-art representations;DSL defined scripts;Java based applications;Python based applications;TextTest;approval testing;automated GUI-based testing;capture-replay tool;graphical user interfaces;software systems;test automation;test case execution performance;user defined domain specific language;Companies;DSL;Data collection;Graphical user interfaces;Maintenance engineering;Manuals;Testing},
}

@InProceedings{6601288,
  author    = {A. Sarimbekov and Y. Zheng and D. Ansaloni and L. Bulej and L. Marek and W. Binder and P. Tuma and Z. Qi},
  title     = {Productive Development of Dynamic Program Analysis Tools with DiSL},
  booktitle = {2013 22nd Australian Software Engineering Conference},
  year      = {2013},
  pages     = {11-19},
  month     = {June},
  abstract  = {Dynamic program analysis tools serve many important software engineering tasks such as profiling, debugging, testing, program comprehension, and reverse engineering. Many dynamic analysis tools rely on program instrumentation and are implemented using low-level instrumentation libraries, resulting in tedious and error-prone tool development. The recently released Domain-Specific Language for Instrumentation (DiSL) was designed to boost the productivity of tool developers targeting the Java Virtual Machine, without impairing the performance of the resulting tools. DiSL offers high-level programming abstractions especially designed for development of instrumentation-based dynamic analysis tools. In this paper, we present a controlled experiment aimed at quantifying the impact of the DiSL programming model and high-level abstractions on the development of dynamic program analysis instrumentations. The experiment results show that compared with a prevailing, state-of-the-art instrumentation library, the DiSL users were able to complete instrumentation development tasks faster, and with more correct results.},
  doi       = {10.1109/ASWEC.2013.12},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  issn      = {1530-0803},
  keywords  = {Java;program debugging;reverse engineering;specification languages;system monitoring;virtual machines;DiSL;Java virtual machine;debugging;domain-specific language for instrumentation;error-prone tool development;high-level programming abstractions;instrumentation-based dynamic analysis tools;low-level instrumentation libraries;productive dynamic program analysis tool development;program comprehension;program instrumentation;reverse engineering;software engineering tasks;Context;Instruments;Java;Libraries;Productivity;Programming;Writing;Dynamic program analysis;bytecode instrumentation;controlled experiment;development productivity},
}

@InProceedings{6883052,
  author    = {K. Smeltzer},
  title     = {A language for visualization variation and transformation},
  booktitle = {2014 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
  year      = {2014},
  pages     = {195-196},
  month     = {July},
  abstract  = {Improvements in computer technology have spawned an exponential growth in both the scope and volume of data collection, as well as a corresponding shortage of capable analysts. This applies not just to scientists, but also to consumers who are gaining unprecedented access to data from their cars, homes, phones, and other devices. Meanwhile, visualization has emerged as an effective tool for exploring and gathering insight from large quantities of data. However, constructing effective visualizations is often difficult, and current tools often lack either the flexibility to extend to custom problem domains or else require low-level graphics programming expertise to generate even simple visualizations. Furthermore, most solutions are ad hoc, preventing users from transforming and evolving visualizations, instead forcing them into a rigid, linear workflow. One possible approach to solving these problems is through the definition of a domain-specific language (DSL). This approach offers a number of potential advantages, the most immediate being flexibility. A visualization DSL could support multiple levels of abstraction at once, each of which could be targeted at different user needs and expertise levels. This, in turn, could allow users with varying levels of expertise to make use of the abstraction layers they find most appropriate, and support the creation of simple and common visualizations without sacrificing the option for more detailed control when necessary. This layering could also allow implementation details to be hidden when desired. Pixel position information, for example, could be hidden behind a scalable and unitless environment which would allow the user to place and size visualization components in relation to one another.},
  doi       = {10.1109/VLHCC.2014.6883052},
  groups    = {IEEE DSL},
  issn      = {1943-6092},
  keywords  = {program diagnostics;visual languages;abstraction layers;computer technology;domain-specific language;pixel position information;visualization DSL;visualization components;visualization transformation;visualization variation;DSL;Data analysis;Data visualization;Image color analysis;Programming;Visualization},
}

@InProceedings{6696493,
  author    = {N. Yakymets and S. Dhouib and H. Jaber and A. Lanusse},
  title     = {Model-driven safety assessment of robotic systems},
  booktitle = {2013 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year      = {2013},
  pages     = {1137-1142},
  month     = {Nov},
  abstract  = {Robotic systems (RSs) are often used for performing critical tasks with little or no human intervention. Such RSs must satisfy certain dependability requirements including reliability, availability, security and safety. In this paper, we focus on the safety aspect and propose a methodology and associated framework for safety assessment of RSs in the early phases of development. The methodology relies upon model-driven engineering approach and describes a preliminary safety assessment of safety-critical RSs using fault tree (FT) analysis (FTA). The framework supports a domain specific language for RSs called RobotML and includes facilities (i) to automatically generate or manually construct FTs and perform both qualitative and quantitative FTA, (ii) to make semantic connections with formal verification and FTA tools, (iii) to represent FTA results in the RobotML modeling environment. In the case study, we illustrate the proposed methodology and framework by considering a mobile robot developed in the scope of the Proteus project.},
  doi       = {10.1109/IROS.2013.6696493},
  groups    = {SCOPUS, IEEE DSL},
  issn      = {2153-0858},
  keywords  = {control engineering computing;fault trees;formal verification;mobile robots;safety;safety-critical software;FTA tools;Proteus project;RobotML modeling environment;availability;dependability requirements;domain specific language;fault tree analysis;formal verification;mobile robot;model-driven engineering approach;model-driven safety assessment;reliability;robotic systems;safety aspect;safety assessment;safety-critical RS;security;Fault trees;Hazards;Mobile robots;Robot sensing systems;Unified modeling language},
}

@InProceedings{6197397,
  author    = {M. U. Tariq and H. A. Nasir and A. Muhammad and M. Wolf},
  title     = {Model-Driven Performance Analysis of Large Scale Irrigation Networks},
  booktitle = {Cyber-Physical Systems (ICCPS), 2012 IEEE/ACM Third International Conference on},
  year      = {2012},
  pages     = {151-160},
  month     = {April},
  abstract  = {Irrigation networks play a fundamental part in the agriculture system of various countries. In the wake of global environmental challenges and economic competition, efficient use of water resources has become extremely important. This can only be achieved by developing smarter control infrastructures for irrigation networks, via the incorporation of communication and computation technologies. Thus, future irrigation networks represent a prime example of cyber physical systems. Effective operation of these complex cyber physical systems is not possible with conventional methods and requires unprecedented levels of automation and decision-support tools. We argue that these cyber physical systems will require a complete model-driven toolset for effective operation. As a first step towards that tool flow, we have developed a model-driven simulation infrastructure for irrigation networks. In the future, we propose to complete the toolset by developing a model-driven configuration infrastructure. Our contributions in this paper include the development of a domain-specific modeling language (DSML) for irrigation networks, implementation of this DSML in Generic Modeling Environment (GME), and automatic simulator M-file generation capability from the DSML-based case diagram of an arbitrary irrigation network. Moreover, we present case studies of water distribution and flood management to show the utility as well as the effectiveness of our approach. We also present the performance of our toolset for the realistic scenario of irrigation networks in Pakistan.},
  doi       = {10.1109/ICCPS.2012.23},
  groups    = {Compendex, SCOPUS},
  keywords  = {decision support systems;floods;irrigation;water resources;water supply;Pakistan;agriculture system;automatic simulator M-file generation;cyber physical systems;decision support tools;domain specific modeling language;flood management;generic modeling environment;large scale irrigation networks;model driven performance analysis;model driven simulation infrastructures;water distribution;water resources;Analytical models;Engines;Irrigation;Logic gates;Mathematical model;Numerical models;Unified modeling language;Cyber Physical Systems;Domain Specific Modeling Languages;Irrigation Networks;Model Transformation;Model-Driven Software Development;Modeling and Simulation},
}

@InProceedings{6800525,
  author    = {W. Ecker and M. Velten and L. Zafari and A. Goyal},
  title     = {The metamodeling approach to system level synthesis},
  booktitle = {2014 Design, Automation Test in Europe Conference Exhibition (DATE)},
  year      = {2014},
  pages     = {1-2},
  month     = {March},
  abstract  = {This paper presents an industry proven Metamodeling based approach to System-Level-Synthesis which is seen as generic design automation strategy above today's implementation levels RTL (for digital) and Schematic Entry (for analog). The approach follows a new synthesis paradigm: The designer develops a simple domain and/or design specific language and a smart tool synthesizing implementation level models according to its needs. The overhead of making both a tool and a model pays off since the tool building is automated by code generation and reuse, both based on Metamodeling techniques. Also the focus on owns demand keeps development costs low. Finally, specification data is utilized. I.e. the domain specific language simplifies to a document structure as a table. This keeps also modeling effort low since specification content is used and no model need to be built. Furthermore, increases design consistency and thus decreases debug time. Using these concepts, single design steps have been speed up to a factor of 20x and implementations of chips (specification-to-tapeout) have been speed up to a factor of 3x.},
  doi       = {10.7873/DATE.2014.324},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  issn      = {1530-1591},
  keywords  = {electronic design automation;program compilers;specification languages;RTL levels;code generation;design specific language;generic design automation strategy;metamodeling approach;schematic entry;smart tool;system level synthesis;Automation;Buildings;Data models;Engines;Generators;Metamodeling;Synthesizers;code generation;metamodeling;system level synthesis},
}

@InProceedings{7582769,
  author    = {T. Szabó and S. Erdweg and M. Voelter},
  title     = {IncA: A DSL for the definition of incremental program analyses},
  booktitle = {2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  year      = {2016},
  pages     = {320-331},
  month     = {Sept},
  abstract  = {Program analyses support software developers, for example, through error detection, code-quality assurance, and by enabling compiler optimizations and refactorings. To provide real-time feedback to developers within IDEs, an analysis must run efficiently even if the analyzed code base is large. To achieve this goal, we present a domain-specific language called IncA for the definition of efficient incremental program analyses that update their result as the program changes. IncA compiles analyses into graph patterns and relies on existing incremental matching algorithms. To scale IncA analyses to large programs, we describe optimizations that reduce caching and prune change propagation. Using IncA, we have developed incremental control flow and points-to analysis for C, well-formedness checks for DSLs, and 10 FindBugs checks for Java. Our evaluation demonstrates significant speedups for all analyses compared to their non-incremental counterparts.},
  groups    = {SCOPUS, IEEE DSL},
  keywords  = {Java;program diagnostics;software engineering;specification languages;DSL;IncA analysis;Java;domain-specific language;incremental program analysis;software development;static program analysis;DSL;Java;Optimization;Pattern matching;Program processors;Runtime;Domain-specific Language;Incremental Computation;Language Workbench;Static Analysis},
}

@InProceedings{6216638,
  author    = {Y. B. Hlaoui and L. J. Ben Ayed and I. Ben Fradj},
  title     = {A model driven approach to compose and develop Grid service workflow applications},
  booktitle = {Information Technology and e-Services (ICITeS), 2012 International Conference on},
  year      = {2012},
  pages     = {1-7},
  month     = {March},
  abstract  = {We use a Domain Specific Language (DSL) based on UML activity diagrams (UML-AD) to specify and compose systematically workflow models from Grid services. To be executed, workflow activity diagram models should be translated into BPEL4WS models which will be executed by the BPEL4WS engine. To reach this objective, we propose a meta-model based transformation from UML activity diagrams to BPEL4WS language. To ensure the correctness and the completion of the transformation, we propose a graph homomorphic mapping between the activity diagram and BPEL4WS language elements. To execute the BPEL4WS provided model, we propose in this paper an execution infrastructure based on The Globus Tool Kit.},
  doi       = {10.1109/ICITeS.2012.6216638},
  groups    = {IEEE DSL, SCOPUS, Compendex},
  keywords  = {Unified Modeling Language;Web services;data models;graph theory;grid computing;meta data;BPEL4WS;Globus tool kit;UML activity diagram;UML-AD;domain specific language;graph homomorphic mapping;grid service workflow;meta model;model driven approach;workflow activity diagram model;Abstracts;Domain specific languages;Engines;Java;Semantics;Transforms;Unified modeling language;BPEL4WS;Grid service workflow;UML activity diagram s;homomorphic mapping;meta-model transformation},
}

@InProceedings{7037727,
  author    = {R. P. Mohamad and D. S. Kolovos and R. F. Paige},
  title     = {Resource Requirement Analysis for Web Applications Running in a Virtualised Environment},
  booktitle = {Cloud Computing Technology and Science (CloudCom), 2014 IEEE 6th International Conference on},
  year      = {2014},
  pages     = {632-637},
  month     = {Dec},
  abstract  = {Analysis of resource usage and precise correlation with the workload that triggered it is essential in order to conduct capacity planning in computing environments. Virtualisation enables resource optimisation and is widely used in grid, cluster and cloud computing. We present an automated approach for resource usage analysis in a virtualised environment that can support capacity planning for web applications. The approach uses Domain Specific Modelling Languages (DSMLs) and model management techniques, which support tool interoperation and provide precise ways for describing resource and request logs and requirements, and automatically generate different outputs that feed into the capacity planning process. The approach is demonstrated using a proof-of-concept example involving a media streaming web application, and the results of the analysis are presented and discussed.},
  doi       = {10.1109/CloudCom.2014.134},
  groups    = {SCOPUS},
  keywords  = {Internet;open systems;resource allocation;specification languages;virtualisation;DSML;capacity planning process;cloud computing;cluster computing;computing environments;domain specific modelling languages;grid computing;media streaming Web application;model management techniques;request logs;resource logs;resource optimisation;resource requirement analysis;resource usage analysis;tool interoperation;virtualisation;virtualised environment;Analytical models;Capacity planning;Computational modeling;Monitoring;Virtual machining;Web servers;application workload;capacity planning;domain specific modelling;resource monitoring;virtualisation},
}

@InProceedings{6502525,
  author    = {M. Valero and S. Uluagac and S. Venkatachalam and K. C. Ramalingam and R. Beyah},
  title     = {The Monitoring Core: A framework for sensor security application development},
  booktitle = {2012 IEEE 9th International Conference on Mobile Ad-Hoc and Sensor Systems (MASS 2012)},
  year      = {2012},
  pages     = {263-271},
  month     = {Oct},
  abstract  = {Wireless sensor networks (WSNs) are used for the monitoring of physical and environmental phenomena, and applicable in a range of different domains (e.g., health care, military, critical infrastructure). When using WSNs in a variety of real-world applications, security is a vital problem that should be considered by developers. As the development of security applications (SAs) for WSNs require meticulous procedures and operations, the software implementation process can be more challenging than regular applications. Hence, in an effort to facilitate the design, development and implementation of WSN security applications, we introduce the Monitoring Core (M-Core). The M-Core is a modular, lightweight, and extensible software layer that gathers necessary data including the internal and the external status of the sensor (e.g., information about ongoing communications, neighbors, and sensing), and provides relevant information for the development of new SAs. Similar to other software development tools, the M-Core was developed to facilitate the design and development of new WSN SAs on different platforms. Moreover, a new user-friendly domain-specific language, the M-Core Control Language (MCL), was developed to further facilitate the use of the M-Core and reduce the developer's coding time. With the MCL, a user can implement new SAs without the overhead of learning the details of the underlying sensor software architecture (e.g., TinyOS). The M-Core has been implemented in TinyOS-2.x and tested on real sensors (Tmote Sky and MicaZ). Using the M-Core architecture, we implemented several SAs to show that the M-Core allows easy and rapid development of security programs efficiently and effectively.},
  doi       = {10.1109/MASS.2012.6502525},
  groups    = {ACM, IEEE DSL, SCOPUS},
  issn      = {2155-6806},
  keywords  = {computerised monitoring;human computer interaction;software architecture;telecommunication security;wireless sensor networks;M-core architecture;M-core control language;MCL;SA;TinyOS-2.x;WSN security applications;environmental phenomena;extensible software layer;meticulous procedures;monitoring core;physical phenomena;real sensors;real-world applications;security applications;security programs;sensor external status;sensor internal status;sensor security application development;software implementation process;user-friendly domain-specific language;wireless sensor networks;M-Core Control Language (MCL);Monitoring Core (M-Core);Sensor Security Application Development;Wireless Sensor Network Applications},
}

@InProceedings{6339417,
  author    = {A. Unutulmaz and G. Dündar and F. V. Fernández},
  title     = {LDS based tools to ease template construction},
  booktitle = {Synthesis, Modeling, Analysis and Simulation Methods and Applications to Circuit Design (SMACD), 2012 International Conference on},
  year      = {2012},
  pages     = {61-64},
  month     = {Sept},
  abstract  = {Layout Description Script (LDS) is a domain specific language (DSL) intended to describe analog layouts. This paper introduces an LDS based tool, Capture, and an add-on, LDS Analyzer, for LDS. Capture aims to convert layout images into layout templates. Components of a layout are extracted with this tool and a template is synthesized from the extracted data. LDS Analyzer is an enhanced LDS parser. Analyzer investigates an LDS statement and conducts either simple parsing or enhanced parsing which make use of symbolic variables.},
  doi       = {10.1109/SMACD.2012.6339417},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  keywords  = {analogue circuits;circuit layout;electronic engineering computing;Layout Description Script Analyzer;analog layout;domain specific language;layout template;template construction;Circuit synthesis;Data mining;Design automation;Educational institutions;Layout;Optimization;Routing},
}

@InProceedings{7490559,
  author    = {S. Bonnet and J. L. Voirin and D. Exertier and V. Normand},
  title     = {Not (strictly) relying on SysML for MBSE: Language, tooling and development perspectives: The Arcadia/Capella rationale},
  booktitle = {2016 Annual IEEE Systems Conference (SysCon)},
  year      = {2016},
  pages     = {1-6},
  month     = {April},
  abstract  = {Using the Arcadia/Capella solution as an example, this paper explores why standard UML/SysML languages are not necessarily the unique or best alternatives for implementation of a model-based systems engineering solution (MBSE). The Thales experience is used to elicit MBSE language and tooling requirements. This paper analyzes various implementation alternatives and justifies structuring choices made regarding Capella to efficiently support the Arcadia engineering method.},
  doi       = {10.1109/SYSCON.2016.7490559},
  groups    = {SCOPUS},
  keywords  = {Adaptation models;Analytical models;Computer architecture;Object oriented modeling;Unified modeling language;Arcadia;Capella;dsml;mbse;method;sysml;tool},
}

@InProceedings{7515468,
  author    = {M. Bernardino and A. F. Zorzo and E. M. Rodrigues},
  title     = {Canopus: A Domain-Specific Language for Modeling Performance Testing},
  booktitle = {2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)},
  year      = {2016},
  pages     = {157-167},
  month     = {April},
  abstract  = {Despite all the efforts to reduce the cost of the testing phase in software development, it is still one of the most expensive phases. In order to continue to minimize those costs, in this paper, we propose a Domain-Specific Language (DSL), built on top of MetaEdit+ language workbench, to model performance testing for web applications. Our DSL, called Canopus, was developed in the context of a collaboration1 between our university and a Technology Development Laboratory (TDL) from an Information Technology (IT) company. We present, in this paper, the Canopus metamodels, its domain analysis, a process that integrates Canopus to Model-Based Performance Testing, and applied it to an industrial case study.},
  doi       = {10.1109/ICST.2016.13},
  groups    = {SCOPUS, Compendex, IEEE DSL},
  keywords  = {Internet;program testing;software cost estimation;specification languages;Canopus metamodels;DSL;IT company;MetaEdit+ language workbench;TDL;Web applications;cost minimization;cost reduction;domain-specific language;information technology company;model-based performance testing;performance testing modeling;software development testing;technology development laboratory;Analytical models;Automation;Computational modeling;DSL;Load modeling;Testing;Unified modeling language;domain-specific language;domain-specific modeling;model-based testing;performance testing},
}

@InProceedings{7306353,
  title     = {Design and Correctness},
  booktitle = {2015 Forum on Specification and Design Languages (FDL)},
  year      = {2015},
  pages     = {1-1},
  month     = {Sept},
  abstract  = {This session presents a domain-specific language for high-level synthesis of hardware for FPGA platforms and describes its memory management for pipelined target architectures. It also presents a methodology to construct test sequences starting from PSL assertions and design under test written in VHDL using VSYML and SyntHorus tools. Finally it presents a top-down design flow to refine an architecture level description of a system into an RTL implementation, while refining operation properties concurrently.},
  issn      = {1636-9874},
  keywords  = {Domain specific languages;Field programmable gate arrays;Hardware;Memory management;Refining;Systems modeling, rank5},
}

@InProceedings{7295780,
  author    = {F. Van Broeckhoven and J. Vlieghe and O. De Troyer},
  title     = {Mapping between Pedagogical Design Strategies and Serious Game Narratives},
  booktitle = {2015 7th International Conference on Games and Virtual Worlds for Serious Applications (VS-Games)},
  year      = {2015},
  pages     = {1-8},
  month     = {Sept},
  abstract  = {Successful serious games include a compelling narrative context and empirically validated pedagogical intervention methods. In order to create such games, design teams must consist of a multidisciplinary group of technical and pedagogical experts. In this paper, the authors show how the domain specific modeling language ATTAC-L facilitates communication between designers with different expertise, thus enabling and stimulating multidisciplinary collaboration. As a serious game design tool, ATTAC-L creates a link between the processes of pedagogical design and narrative modeling through its elaborate annotation system. As such, this modeling language enables designers to concentrate on aspects related to their field of expertise without losing oversight of the serious game as a whole. To support these tentative claims, the author present illustrations of how ATTAC-L is used in combination with a specific pedagogical design strategy (i.e. the Intervention Mapping Protocol) for the development of a serious game against cyber-bullying.},
  doi       = {10.1109/VS-GAMES.2015.7295780},
  groups    = {Compendex, SCOPUS},
  keywords  = {serious games (computing);specification languages;annotation system;domain specific modeling language ATTAC-L;intervention mapping protocol;multidisciplinary collaboration;pedagogical design strategy;pedagogical intervention methods;serious game design tool;serious game narratives;Adaptation models;Context;Games;Guidelines;Planning;Protocols;Unified modeling language},
}

@InProceedings{6721539,
  author    = {J. Ozik and N. T. Collier and J. T. Murphy and M. J. North},
  title     = {The ReLogo agent-based modeling language},
  booktitle = {2013 Winter Simulations Conference (WSC)},
  year      = {2013},
  pages     = {1560-1568},
  month     = {Dec},
  abstract  = {ReLogo is a new agent-based modeling (ABM) domain specific language (DSL) for developing agent-based models in the free and open source Repast Suite of ABM tools; the Java based Repast Simphony ABM toolkit and the C++ high performance computing Repast HPC toolkit both incorporate ReLogo. The language is geared towards a wide range of modeling and programming expertise, combining the sophisticated and powerful ABM infrastructure and capabilities in the Repast Suite with the ease of use of the Logo programming language and its associated programming idioms. This paper will present how ReLogo combines a number of concepts, including object-oriented programming, simple integration of existing code libraries, statically and dynamically typed languages, domain specific languages, and the use of integrated development environments, to create an ABM tool that is easy to learn yet is also capable of creating large scale ABMs of real world complex systems.},
  doi       = {10.1109/WSC.2013.6721539},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  issn      = {0891-7736},
  keywords  = {Java;multi-agent systems;parallel processing;public domain software;ABM tools;C++ high performance computing Repast HPC toolkit;DSL;Java based Repast Simphony ABM toolkit;Logo programming language;ReLogo agent-based modeling domain specific language;open source Repast Suite;Computational modeling;DSL;Java;Libraries;Object oriented modeling;Programming},
}

@InProceedings{7365791,
  author    = {B. Scholz and K. Vorobyov and P. Krishnan and T. Westmann},
  title     = {A Datalog Source-to-Source Translator for Static Program Analysis: An Experience Report},
  booktitle = {Software Engineering Conference (ASWEC), 2015 24th Australasian},
  year      = {2015},
  pages     = {28-37},
  month     = {Sept},
  abstract  = {Static program analysis has many applications including bug checking for large scale code that requires a points-to analysis. To express static program analysis frameworks concisely, it is advantageous to employ a domain-specific language. In the last two decades, Data log has emerged as a domain-specific language for static program analysis. However, existing Data log systems have problems solving large scale code with millions of program variables. This work reports on techniques that translate a Data log program to SQL queries, which are executed on a relational database system. The advantage of a relational database system as an execution platform is the effective use of memory and disks. Further, we can also use an off-the shelf tool to execute the SQL queries. In order to achieve performance, we explore some of the design choices for a source-to-source translation from Data log to SQL that implement stratified negations, totally ordered domains, and comparisons. For each design point, we explain how Data log can be efficiently translated to SQL using the semi-naive evaluation approach. We report the results of our experiments using large data-sets including the OpenJDK7-b147 dataset for points-to, which guided us in the design of our translation schemes.},
  doi       = {10.1109/ASWEC.2015.15},
  groups    = {IEEE DSL, ACM},
  issn      = {1530-0803},
  keywords  = {DATALOG;SQL;program debugging;program diagnostics;relational databases;Naıve evaluation approach;OpenJDK7-b147 dataset;SQL query;bug checking;datalog program;datalog source-to-source translator;datalog system;domain-specific language;large scale code;relational database system;source-to-source translation;static program analysis;Australia;Electronic mail;Engines;Relational databases;Resource management;Semantics;Software engineering;Datalog;SQWL;program analysis;source-to-source translation},
}

@Article{6051438,
  author   = {D. Cassou and J. Bruneau and C. Consel and E. Balland},
  title    = {Toward a Tool-Based Development Methodology for Pervasive Computing Applications},
  journal  = {IEEE Transactions on Software Engineering},
  year     = {2012},
  volume   = {38},
  number   = {6},
  pages    = {1445-1463},
  month    = {Nov},
  abstract = {Despite much progress, developing a pervasive computing application remains a challenge because of a lack of conceptual frameworks and supporting tools. This challenge involves coping with heterogeneous devices, overcoming the intricacies of distributed systems technologies, working out an architecture for the application, encoding it in a program, writing specific code to test the application, and finally deploying it. This paper presents a design language and a tool suite covering the development life-cycle of a pervasive computing application. The design language allows us to define a taxonomy of area-specific building-blocks, abstracting over their heterogeneity. This language also includes a layer to define the architecture of an application, following an architectural pattern commonly used in the pervasive computing domain. Our underlying methodology assigns roles to the stakeholders, providing separation of concerns. Our tool suite includes a compiler that takes design artifacts written in our language as input and generates a programming framework that supports the subsequent development stages, namely, implementation, testing, and deployment. Our methodology has been applied on a wide spectrum of areas. Based on these experiments, we assess our approach through three criteria: expressiveness, usability, and productivity.},
  doi      = {10.1109/TSE.2011.107},
  groups   = {SCOPUS, IEEE DSL},
  issn     = {0098-5589},
  keywords = {program compilers;software architecture;ubiquitous computing;architectural pattern;area-specific building-blocks;compiler;design artifacts;development life-cycle;distributed systems technologies;pervasive computing applications;tool-based development methodology;Computational modeling;Computer architecture;Domain specific languages;Pervasive computing;Programming;Software architecture;Taxonomy;Methodology;domain-specific language;generative programming;pervasive computing;programming support;simulation;toolkit},
}

@InProceedings{6890824,
  author    = {A. Rahman and D. Amyot},
  title     = {A DSL for importing models in a requirements management system},
  booktitle = {Model-Driven Requirements Engineering Workshop (MoDRE), 2014 IEEE 4th International},
  year      = {2014},
  pages     = {37-46},
  month     = {Aug},
  abstract  = {Requirements are artefacts often described with text and models. It is important to manage traceability between requirements and other software artefacts, including designs and test cases, also often captured with specialized models. Some Requirements Management Systems (RMS) support traceability relationships, between (textual) requirements artefacts in the RMS and model artefacts created outside the RMS, through complex standards or proprietary solutions. This paper proposes a new Domain-Specific Language (DSL) for describing the concepts of a modeling language intended to be traced using an RMS, with tool support handling the import and re-import of models and of their traceability links. The Model Import DSL (MI-DSL) is supported by an Xtext-based editor and the automatic generation of an import library targeting a leading RMS, namely IBM Rational DOORS. The language and the tools are demonstrated for model import and evolution scenarios with two different modeling languages. This work contributes a simple yet reliable mechanism to define and support traceability between requirements and models from different tools.},
  doi       = {10.1109/MoDRE.2014.6890824},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  keywords  = {formal specification;program diagnostics;program testing;software libraries;specification languages;IBM Rational DOORS;MI-DSL;RMS;Xtext-based editor;automatic generation;domain-specific language;import library;model artefacts;model import DSL;modeling language;requirements management system;software artefacts;test cases;textual requirements artefacts;tool support;traceability links;traceability relationships;Analytical models;Biological system modeling;Computational modeling;DSL;Libraries;Software;Unified modeling language;DOORS;DSL;evolution;model;requirements management;traceability},
}

@InProceedings{7153814,
  author    = {E. Doma and B. Selic and D. Levy},
  title     = {Exploring Situation Theory Using InfonLab},
  booktitle = {2015 IEEE 18th International Symposium on Real-Time Distributed Computing},
  year      = {2015},
  pages     = {260-267},
  month     = {April},
  abstract  = {Complex software systems often suffer from flaws arising either during the design or the development stages. In many cases due to the lack of formal underpinning it is difficult to assuredly define the model from which the system is generated. In our work, we investigated the suitability of mathematical situation theory as a formal foundation for a computer modelling language. This paper describes our empirical evaluation of this thesis in the real-time domain using Infon Lab, a tool based upon situation theory.},
  doi       = {10.1109/ISORC.2015.20},
  groups    = {SCOPUS},
  issn      = {1555-0885},
  keywords  = {formal specification;formal verification;Infon Lab;InfonLab;complex software systems;computer modelling language;exploring situation theory;formal foundation;formal methods;formal underpinning;mathematical situation;real-time domain;situation theory;Computational modeling;Computers;Context modeling;Mathematical model;Object oriented modeling;Semantics;Software;domain-specific modeling language;model-based software engineering;situation theory},
}

@InProceedings{6462664,
  author    = {B. Combemale and X. Crégut and M. Pantel},
  title     = {A Design Pattern to Build Executable DSMLs and Associated V \& V Tools},
  booktitle = {2012 19th Asia-Pacific Software Engineering Conference},
  year      = {2012},
  volume    = {1},
  pages     = {282-287},
  month     = {Dec},
  abstract  = {Model executability is now a key concern in model-driven engineering, mainly to support early validation and verification (V&V). Some approaches allow to weave executability into metamodels, defining executable domain-specific modeling languages (DSMLs). Model validation can then be achieved by simulation and graphical animation through direct interpretation of the conforming models. Other approaches address model executability by model compilation, allowing to reuse the virtual machines or V&V tools existing in the target domain. Nevertheless, systematic methods are currently not available to help the language designer in the definition of such an execution semantics and related tools. For instance, simulators are mostly hand-crafted in a tool specific manner for each DSML. In this paper, we propose to reify the elements commonly used to support state-based execution in a DSML. We infer a design pattern (called Executable DSML pattern) providing a general reusable solution for the expression of the executability concerns in DSMLs. It favors flexibility and improves reusability in the definition of semantics-based tools for DSMLs. We illustrate how this pattern can be applied to ease the development of V&V tools.},
  doi       = {10.1109/APSEC.2012.79},
  groups    = {Compendex, SCOPUS},
  issn      = {1530-1362},
  keywords  = {simulation languages;software reusability;virtual machines;V&V tools;design pattern;domain-specific modeling languages;early validation and verification;executable DSML;metamodels;model compilation;model executability;model-driven engineering;state-based execution;virtual machine reuse;Abstracts;Animation;Computational modeling;Concrete;Runtime;Semantics;Unified modeling language;Model Driven Engineering;Software Language Engineering;Validation &amp; Verification},
}

@InProceedings{7372080,
  author    = {C. Artho and M. Seidl and Q. Gros and E. H. Choi and T. Kitamura and A. Mori and R. Ramler and Y. Yamagata},
  title     = {Model-Based Testing of Stateful APIs with Modbat},
  booktitle = {Automated Software Engineering (ASE), 2015 30th IEEE/ACM International Conference on},
  year      = {2015},
  pages     = {858-863},
  month     = {Nov},
  abstract  = {Modbat makes testing easier by providing a user-friendly modeling language to describe the behavior of systems, from such a model, test cases are generated and executed. Modbat's domain-specific language is based on Scala, its features include probabilistic and non-deterministic transitions, component models with inheritance, and exceptions. We demonstrate the versatility of Modbat by finding a confirmed defect in the currently latest version of Java, and by testing SAT solvers.},
  doi       = {10.1109/ASE.2015.95},
  groups    = {IEEE DSL, SCOPUS},
  keywords  = {Java;application program interfaces;computability;program testing;simulation languages;Java;Modbat;SAT solvers;Scala;domain-specific language;model-based testing;nondeterministic transitions;probabilistic transitions;stateful API;user-friendly modeling language;Arrays;DSL;Data models;Java;Libraries;Testing;component-based systems;domain-specific language;exception testing;extended finite-state machines;model-based testing;software test tools},
}

@InProceedings{7483269,
  author    = {M. Lachgar and A. Abdali},
  title     = {DSL and code generator for accelerating iOs apps development},
  booktitle = {2015 Third World Conference on Complex Systems (WCCS)},
  year      = {2015},
  pages     = {1-8},
  month     = {Nov},
  abstract  = {A mobile application has become an important new way to reach customers. The use of smartphones and tablets has also increased, but it's always difficult to create a new application. This requires specific knowledge and experience to successfully operate all features. The heterogeneity development tools and languages in mobile apps makes difficult to develop multi-platform mobile applications. Thus, it requires developers to make a choice on the platform, while ensuring the widest possible dissemination. The strategy "write once, deploy anywhere" is a smart way to develop mobile applications. In fact, it equips developers with what they need to keep ahead of the game. The aim of this work is to define an independent language of the platform then generate native code for iOS applications using an MDA approach. For this, we opt for a specific language (DSL) to increase the productivity of software engineers by abstracting low-level boilerplate code.},
  doi       = {10.1109/ICoCS.2015.7483269},
  groups    = {IEEE DSL, SCOPUS},
  keywords  = {mobile computing;program compilers;smart phones;DSL;MDA approach;code generator;iOs apps development;low-level boilerplate code;multiplatform mobile applications;smartphones;software engineers;Computational modeling;DSL;Data models;Mobile communication;Operating systems;Smart phones;Unified modeling language;Automatic code generation;Domain-Specific Language;Mobile development;Model Driven Architecture;Native Code;iOS Apps},
}

@InProceedings{6899124,
  author    = {G. Karsai and D. Balasubramanian and A. Dubey and W. R. Otte},
  title     = {Distributed and Managed: Research Challenges and Opportunities of the Next Generation Cyber-Physical Systems},
  booktitle = {2014 IEEE 17th International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing},
  year      = {2014},
  pages     = {1-8},
  month     = {June},
  abstract  = {Cyber-physical systems increasingly rely on distributed computing platforms where sensing, computing, actuation, and communication resources are shared by a multitude of applications. Such 'cyber-physical cloud computing platforms' present novel challenges because the system is built from mobile embedded devices, is inherently distributed, and typically suffers from highly fluctuating connectivity among the modules. Architecting software for these systems raises many challenges not present in traditional cloud computing. Effective management of constrained resources and application isolation without adversely affecting performance are necessary. Autonomous fault management and real-time performance requirements must be met in a verifiable manner. It is also both critical and challenging to support multiple end-users whose diverse software applications have changing demands for computational and communication resources, while operating on different levels and in separate domains of security. The solution presented in this paper is based on a layered architecture consisting of a novel operating system, a middleware layer, and component-structured applications. The component model facilitates the construction of software applications from modular and reusable components that are deployed in the distributed system and interact only through well-defined mechanisms. The complexity of creating applications and performing system integration is mitigated through the use of a domain-specific model-driven development process that relies on a domain-specific modeling language and its accompanying graphical modeling tools, software generators for synthesizing infrastructure code, and the extensive use of model-based analysis for verification and validation.},
  doi       = {10.1109/ISORC.2014.36},
  groups    = {SCOPUS},
  issn      = {1555-0885},
  keywords  = {cloud computing;embedded systems;fault diagnosis;formal verification;mobile computing;program verification;resource allocation;security of data;software architecture;specification languages;application isolation;autonomous fault management;communication resources;component-structured applications;computational resources;constrained resource management;cyber-physical cloud computing platform;distributed computing platforms;domain-specific model-driven development process;domain-specific modeling language;graphical modeling tools;infrastructure code synthesis;middleware layer;mobile embedded devices;model-based analysis;modular components;next generation cyber-physical systems;operating system;real-time performance requirements;reusable components;security;software architecture;software generators;validation;verification;Computational modeling;Computer architecture;Kernel;Real-time systems;Security;Unified modeling language;cyber-physical systems;distributed systems},
}

@InProceedings{6322875,
  author    = {J. M. P. Cardoso},
  title     = {Programming strategies for runtime adaptability},
  booktitle = {Reconfigurable Communication-centric Systems-on-Chip (ReCoSoC), 2012 7th International Workshop on},
  year      = {2012},
  pages     = {1-8},
  month     = {July},
  abstract  = {Future advanced embedded computing systems are expected to dynamically adapt applications' behavior and runtime system according to, e.g., usage contexts, operating environments, resources' availability, and battery energy levels. Besides application's functionalities provided by high-level and/or executable binary codes, code for specifying strategies/policies to extend typical functionalities with adaptability behavior is required. A domain-specific language, able to program this adaptability behavior, will allow developers to specify strategies for adaptation, will improve portability, and will help tools to map those strategies to the target system. This paper presents our recent ideas for programming strategies focused on runtime adaptability. The ideas are exposed using extensions to LARA, an aspect-oriented programming language, agnostic to the target language and system. We show examples of using LARA to specify strategies and we comment on the possible implementations to make viable those strategies.},
  doi       = {10.1109/ReCoSoC.2012.6322875},
  groups    = {IEEE DSL, SCOPUS},
  keywords  = {aspect-oriented programming;binary codes;embedded systems;object-oriented languages;program compilers;program diagnostics;software portability;software process improvement;LARA;adaptability behavior;application functionalities;aspect-oriented programming language;domain-specific language;dynamic application behavior adaptation;embedded computing systems;executable binary codes;high-level binary codes;portability improvement;programming strategies;runtime adaptability;runtime system;strategy specification code;Batteries;Context;Energy states;Java;Reactive power;Runtime;Weaving;FPGAs;LARA;aspect-oriented programming;compilers;embedded computing;runtime adaptability},
}

@InProceedings{6462730,
  author    = {H. Cho and J. Gray and E. Syriani},
  title     = {Syntax Map: A Modeling Language for Capturing Requirements of Graphical DSML},
  booktitle = {2012 19th Asia-Pacific Software Engineering Conference},
  year      = {2012},
  volume    = {1},
  pages     = {705-708},
  month     = {Dec},
  abstract  = {Domain-specific modeling languages (DSMLs) are designed to model particular domains of interest using graphical, textual, or mixed syntax. Although most metamodeling tools offer an environment that automates several language development tasks, there is still a lack of support for aiding the domain expert to capture the requirements of a graphical DSML. We introduce the Syntax Map as an approach to address the challenges of graphical DSML requirements specification. It is designed to aid domain experts in describing a first-class graphical DSML requirement using a set of graphical notations. In addition, the Syntax Map can be used to generate a metamodel by means of model transformations. This short paper motivates the need for the Syntax Map, provides several brief examples, and discusses lessons learned in our investigation of this approach.},
  doi       = {10.1109/APSEC.2012.20},
  groups    = {SCOPUS},
  issn      = {1530-1362},
  keywords  = {software tools;specification languages;domain-specific modeling languages;graphical DSML requirement specification;graphical syntax;language development task;metamodeling tool;mixed syntax;requirement capturing;syntax map;textual syntax;Abstracts;Computational modeling;Concrete;Doped fiber amplifiers;Semantics;Syntactics;Unified modeling language;Abstract Syntax;Concrete Syntax;Domain-Specific Modeling Languages;General-Purpose Modeling Languages;Requirements Specification;Semantics},
}

@InProceedings{7349651,
  author    = {P. Li and E. Brunet and F. Trahay and C. Parrot and G. Thomas and R. Namyst},
  title     = {Automatic OpenCL Code Generation for Multi-device Heterogeneous Architectures},
  booktitle = {Parallel Processing (ICPP), 2015 44th International Conference on},
  year      = {2015},
  pages     = {959-968},
  month     = {Sept},
  abstract  = {Using multiple accelerators, such as GPUs or Xeon Phis, is attractive to improve the performance of large data parallel applications and to increase the size of their workloads. However, writing an application for multiple accelerators remains today challenging because going from a single accelerator to multiple ones indeed requires to deal with potentially non-uniform domain decomposition, inter-accelerator data movements, and dynamic load balancing. Writing such code manually is time consuming and error-prone. In this paper, we propose a new programming tool called STEPOCL along with a new domain specific language designed to simplify the development of an application for multiple accelerators. We evaluate both the performance and the usefulness of STEPOCL with three applications and show that: (i) the performance of an application written with STEPOCL scales linearly with the number of accelerators, (ii) the performance of an application written using STEPOCL competes with a handwritten version, (iii) larger workloads run on multiple devices that do not fit in the memory of a single device, (iv) thanks to STEPOCL, the number of lines of code required to write an application for multiple accelerators is roughly divided by ten.},
  doi       = {10.1109/ICPP.2015.105},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  issn      = {0190-3918},
  keywords  = {graphics processing units;parallel processing;program compilers;resource allocation;specification languages;GPU;STEPOCL;Xeon Phis;automatic OpenCL code generation;data parallel applications;domain specific language;dynamic load balancing;interaccelerator data movements;multidevice heterogeneous architectures;programming tool;Arrays;Hardware;Kernel;Performance evaluation;Programming;Synchronization;Writing;Accelerators;Code generation;Heterogeneous architectures;OpenCL},
}

@InProceedings{6195167,
  author    = {J. H. Hill},
  title     = {Using Parameterized Attributes to Improve Testing Capabilities with Domain-Specific Modeling Languages},
  booktitle = {Engineering of Computer Based Systems (ECBS), 2012 IEEE 19th International Conference and Workshops on},
  year      = {2012},
  pages     = {43-51},
  month     = {April},
  abstract  = {Domain-specific modeling languages (DSMLs) show promise in improving model-based testing and experimentation (T&E) capabilities for software systems. This is because its intuitive graphical languages reduce complexities associated with error-prone, tedious, and time-consuming tasks. Despite the benefits of using DSMLs to facilitate model-based T&E, it is hard for testers to capture many variations of similar tests without manually duplicating modeling effort. This paper therefore presents a method called parameterized attributes that is used to capture points-of-variation in models. It also shows how parameterized attributes is realized in an open-source tool named the Generic Modeling Environment (GME) Template Engine. Finally, this paper quantitatively evaluates applying parameterized attributes to T&E of a representative distributed software system. Experience and results so show that parameterized attributes can reduce modeling effort after an initial model (or design) is constructed.},
  doi       = {10.1109/ECBS.2012.47},
  groups    = {SCOPUS, Compendex},
  keywords  = {domain-specific modeling language;parameterized attributes},
}

@InProceedings{6676947,
  author    = {J. v. d. Bos and T. v. d. Storm},
  title     = {TRINITY: An IDE for the Matrix},
  booktitle = {Software Maintenance (ICSM), 2013 29th IEEE International Conference on},
  year      = {2013},
  pages     = {520-523},
  month     = {Sept},
  abstract  = {Digital forensics software often has to be changed to cope with new variants and versions of file formats. Developers reverse engineer the actual files, and then change the source code of the analysis tools. This process is error-prone and time consuming because the relation between the newly encountered data and how the source code must be changed is implicit. TRINITY is an integrated debugging environment which makes this relation explicit using the DERRIC DSL for describing file formats. TRINITY consists of three simultaneous views: 1) the runtime state of an analysis, 2) a hex view of the actual data, and 3) the file format description. Cross-view trace ability links allow developers to better understand how the file format description should be modified. TRINITY aims to make the process of adapting digital forensics software more effective and efficient.},
  doi       = {10.1109/ICSM.2013.86},
  groups    = {ACM, SCOPUS, IEEE DSL},
  issn      = {1063-6773},
  keywords  = {data flow analysis;digital forensics;program debugging;reverse engineering;software maintenance;DERRIC DSL;IDE;TRINITY;actual data hexview;analysis runtime state;cross-view traceability links;digital forensics software;domain-specific language;file format description;integrated debugging environment;reverse engineering;Debugging;Digital forensics;Layout;Maintenance engineering;Reverse engineering;Runtime;Software;domain-specific language;integrated development environment;model-driven engineering;reverse engineering;software maintenance},
}

@InProceedings{7245730,
  author    = {M. Schmid and O. Reiche and F. Hannig and J. Teich},
  title     = {Loop coarsening in C-based High-Level Synthesis},
  booktitle = {2015 IEEE 26th International Conference on Application-specific Systems, Architectures and Processors (ASAP)},
  year      = {2015},
  pages     = {166-173},
  month     = {July},
  abstract  = {Current tools for High-Level Synthesis (HLS) excel at exploiting Instruction-Level Parallelism (ILP), the support for Data-Level Parallelism (DLP), one of the key advantages of Field Programmable Gate Arrays (FPGAs), is in contrast very limited. This work examines the exploitation of DLP on FPGAs using code generation for C-based HLS of image filters and streaming pipelines, consisting of point and local operators. In addition to well known loop tiling techniques, we propose loop coarsening, which delivers superior performance and scalability. Loop tiling corresponds to splitting an image into separate regions, which are then processed in parallel by replicated accelerators. For data streaming, this also requires the generation of glue logic for the distribution of image data. Conversely, loop coarsening allows to process multiple pixels in parallel, whereby only the kernel operator is replicated within a single accelerator. We augment the FPGA back end of the heterogeneous Domain-Specific Language (DSL) framework HIPAcc by loop coarsening and compare the resulting FPGA accelerators to highly optimized software implementations for Graphics Processing Units (GPUs), all generated from the exact same code base. Moreover, we demonstrate the advantages of code generation for algorithm development by outlining how design space exploration enabled by HIPAcc can yield a more efficient implementation than hand-coded VHDL.},
  doi       = {10.1109/ASAP.2015.7245730},
  groups    = {IEEE DSL, SCOPUS},
  issn      = {1063-6862},
  keywords  = {C language;field programmable gate arrays;graphics processing units;hardware description languages;high level synthesis;image filtering;image segmentation;pipeline processing;program compilers;program control structures;C-based HLS;C-based high-level synthesis;DLP;FPGA accelerator;FPGA back end;GPU;HIPAcc;ILP;VHDL;algorithm development;code generation;data streaming;data-level parallelism;design space exploration;field programmable gate arrays;glue logic generation;graphics processing units;heterogeneous DSL framework;heterogeneous domain-specific language framework;image data distribution;image filter;image splitting;instruction-level parallelism;kernel operator;local operator;loop coarsening;loop tiling technique;parallel multiple pixel processing;point operator;replicated accelerators;streaming pipeline;Algorithm design and analysis;Field programmable gate arrays;Image processing;Kernel;Parallel processing;Pipelines;Streaming media},
}

@InProceedings{6645275,
  author    = {R. Deshayes},
  title     = {A domain-specific modeling approach for gestural interaction},
  booktitle = {2013 IEEE Symposium on Visual Languages and Human Centric Computing},
  year      = {2013},
  pages     = {181-182},
  month     = {Sept},
  abstract  = {Natural interaction is gaining widespread use, but more tools and techniques are required to fully support the takeup of gestural interaction. This research focus on providing an expressive an extensible framework and an executable domain-specific modeling language for specifying gestural interaction with real or virtual objects. The main targeted domains are virtual reality for gaming applications and home automation.},
  doi       = {10.1109/VLHCC.2013.6645275},
  groups    = {IEEE DSML},
  issn      = {1943-6092},
  keywords  = {computer games;gesture recognition;home automation;specification languages;virtual reality;executable domain-specific modeling language;gaming applications;gestural interaction;home automation;natural interaction;virtual reality;Adaptation models;Computational modeling;Computers;Context;Solid modeling;Three-dimensional displays;Visualization},
}

@Article{6875916,
  author   = {H. Choi and W. Choi and T. M. Quan and D. G. C. Hildebrand and H. Pfister and W. K. Jeong},
  title    = {Vivaldi: A Domain-Specific Language for Volume Processing and Visualization on Distributed Heterogeneous Systems},
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  year     = {2014},
  volume   = {20},
  number   = {12},
  pages    = {2407-2416},
  month    = {Dec},
  abstract = {As the size of image data from microscopes and telescopes increases, the need for high-throughput processing and visualization of large volumetric data has become more pressing. At the same time, many-core processors and GPU accelerators are commonplace, making high-performance distributed heterogeneous computing systems affordable. However, effectively utilizing GPU clusters is difficult for novice programmers, and even experienced programmers often fail to fully leverage the computing power of new parallel architectures due to their steep learning curve and programming complexity. In this paper, we propose Vivaldi, a new domain-specific language for volume processing and visualization on distributed heterogeneous computing systems. Vivaldi's Python-like grammar and parallel processing abstractions provide flexible programming tools for non-experts to easily write high-performance parallel computing code. Vivaldi provides commonly used functions and numerical operators for customized visualization and high-throughput image processing applications. We demonstrate the performance and usability of Vivaldi on several examples ranging from volume rendering to image segmentation.},
  doi      = {10.1109/TVCG.2014.2346322},
  groups   = {IEEE DSL},
  issn     = {1077-2626},
  keywords = {data visualisation;image processing;microscopes;parallel processing;rendering (computer graphics);telescopes;visual languages;GPU accelerators;GPU clusters;Vivaldi Python-like grammar;customized visualization;distributed heterogeneous systems;domain-specific language;flexible programming tools;high-performance distributed heterogeneous computing systems;high-performance parallel computing code;high-throughput image processing applications;high-throughput processing;image data;image segmentation;many-core processors;microscopes;numerical operators;parallel architectures;parallel processing abstractions;programming complexity;steep learning curve;telescopes;volume processing;volume rendering;volumetric data visualization;Computational modeling;Data models;Data visualization;Graphics processing units;Image classification;Parallel processing;Rendering (computer graphics);Domain-specific language;GPU computing;distributed heterogeneous systems;volume rendering;0},
}

@InProceedings{6690570,
  author    = {I. Monahov and T. Reschenhofer and F. Matthes},
  title     = {Design and Prototypical Implementation of a Language Empowering Business Users to Define Key Performance Indicators for Enterprise Architecture Management},
  booktitle = {2013 17th IEEE International Enterprise Distributed Object Computing Conference Workshops},
  year      = {2013},
  pages     = {337-346},
  month     = {Sept},
  abstract  = {To measure the achievement of predefined Enterprise Architecture Management (EAM) goals, it is essential to empower business users to define organization-specific Key Performance Indicators (KPIs). However, to support tool-based calculation of such KPIs, a formal model-based query language is required for their definition and calculation. In this paper we first examine existing general-purpose query languages regarding their suitability for the definition of business-user-specific KPIs in a collaborative environment. Thereafter, we justify the demand for a domain-specific query language ensuring a balance between the strengths of existing query languages and the size and purpose of the EAM domain. Based on this, we outline important design details and a prototypical implementation of such a language in a EAM tool. Finally, our language design is being evaluated by the implementation of suggested EAM KPIs from literature on the one hand, and by the development of a prototype for the use in an EU project on the other hand.},
  doi       = {10.1109/EDOCW.2013.44},
  groups    = {IEEE DSL, SCOPUS},
  issn      = {2325-6583},
  keywords  = {business data processing;groupware;query languages;EAM;EU project;business users;business-user-specific KPI;collaborative environment;domain-specific query language;enterprise architecture management;formal model-based query language;general-purpose query languages;language design;organization-specific key performance indicators;tool-based calculation;Business;Collaboration;Computer architecture;DSL;Database languages;Standards;Unified modeling language;Enterprise architecture management;domain specific language;key performance indicators},
}

@InProceedings{6468530,
  author    = {K. L. Spafford and J. S. Vetter},
  title     = {Aspen: A domain specific language for performance modeling},
  booktitle = {High Performance Computing, Networking, Storage and Analysis (SC), 2012 International Conference for},
  year      = {2012},
  pages     = {1-11},
  month     = {Nov},
  abstract  = {We present a new approach to analytical performance modeling using Aspen, a domain specific langauge. Aspen (Abstract Scalable Performance Engineering Notation) fills an important gap in existing performance modeling techniques and is designed to enable rapid exploration of new algorithms and architectures. It includes a formal specification of an application's performance behavior and an abstract machine model. We provide an overview of Aspen's features and demonstrate how it can be used to express a performance model for a three dimensional Fast Fourier Transform. We then demonstrate the composability and modularity of Aspen by importing and reusing the FFT model in a molecular dynamics model. We have also created a number of tools that allow scientists to balance application and system factors quickly and accurately.},
  doi       = {10.1109/SC.2012.20},
  groups    = {IEEE DSL, SCOPUS},
  issn      = {2167-4329},
  keywords  = {fast Fourier transforms;formal specification;molecular dynamics method;physics computing;specification languages;Aspen language;FFT model;abstract machine model;abstract scalable performance engineering notation;analytical performance modeling;application performance behavior;domain specific language;fast Fourier transform;formal specification;molecular dynamics model;Analytical models;Computational modeling;Computer architecture;Hardware;Kernel;Mathematical model;Predictive models},
}

@InProceedings{6575306,
  author    = {M. Biely and P. Delgado and Z. Milosevic and A. Schiper},
  title     = {Distal: A framework for implementing fault-tolerant distributed algorithms},
  booktitle = {2013 43rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)},
  year      = {2013},
  pages     = {1-8},
  month     = {June},
  abstract  = {We introduce Distal, a new framework that simplifies turning pseudocode of fault tolerant distributed algorithms into efficient executable code. Without proper tool support, even small amounts of pseudocode normally ends up in several thousands of non-trivial lines of Java or C++. Distal is implemented as a library in Scala and consists of two main parts: a domain specific language (DSL) in which algorithms are expressed and an efficient messaging layer that deals with low level issues such as connection management, threading and (de)serialization. The DSL is designed such that implementations of distributed algorithms highly resemble the pseudocode found in research papers. By writing code that is close to the protocol description, one can be more convinced that the implemented system really reflects the protocol specification on paper. Distal does not only make it simple and intuitive to implement distributed algorithms but it also leads to efficient implementations.},
  doi       = {10.1109/DSN.2013.6575306},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  issn      = {1530-0889},
  keywords  = {C++ language;Java;distributed algorithms;protocols;software fault tolerance;software libraries;C++;DSL;Distal;Java;Scala;domain specific language;executable code;fault tolerant distributed algorithms;protocol description;protocol specification;pseudocode turning;Algorithm design and analysis;DSL;Distributed algorithms;Fault tolerance;Fault tolerant systems;Java;Protocols;DSL;Paxos;SMR;fault-tolerant distributed algorithms},
}

@InProceedings{6227148,
  author    = {M. Song and E. Tilevich},
  title     = {Metadata invariants: Checking and inferring metadata coding conventions},
  booktitle = {2012 34th International Conference on Software Engineering (ICSE)},
  year      = {2012},
  pages     = {694-704},
  month     = {June},
  abstract  = {As the prevailing programming model of enterprise applications is becoming more declarative, programmers are spending an increasing amount of their time and efforts writing and maintaining metadata, such as XML or annotations. Although metadata is a cornerstone of modern software, automatic bug finding tools cannot ensure that metadata maintains its correctness during refactoring and enhancement. To address this shortcoming, this paper presents metadata invariants, a new abstraction that codifies various naming and typing relationships between metadata and the main source code of a program. We reify this abstraction as a domain-specific language. We also introduce algorithms to infer likely metadata invariants and to apply them to check metadata correctness in the presence of program evolution. We demonstrate how metadata invariant checking can help ensure that metadata remains consistent and correct during program evolution; it finds metadata-related inconsistencies and recommends how they should be corrected. Similar to static bug finding tools, a metadata invariant checker identifies metadata-related bugs as a program is being refactored and enhanced. Because metadata is omnipresent in modern software applications, our approach can help ensure the overall consistency and correctness of software as it evolves.},
  doi       = {10.1109/ICSE.2012.6227148},
  groups    = {ACM, IEEE DSL, SCOPUS},
  issn      = {0270-5257},
  keywords  = {meta data;program debugging;software maintenance;specification languages;domain-specific language;enterprise application programming model;metadata coding convention checking;metadata coding convention inferring;metadata invariant checking;naming relationships;program evolution;program source code;static bug finding tools;typing relationships;Computer bugs;Inference algorithms;Java;Programming;Runtime;Syntactics;XML;bug finding;domain-specific languages;enhancement;frameworks;invariants;metadata;refactoring;software maintenance},
}

@Article{6676814,
  author   = {S. Schivo and J. Scholma and B. Wanders and R. A. U. Camacho and P. E. van der Vet and M. Karperien and R. Langerak and J. van de Pol and J. N. Post},
  title    = {Modeling Biological Pathway Dynamics With Timed Automata},
  journal  = {IEEE Journal of Biomedical and Health Informatics},
  year     = {2014},
  volume   = {18},
  number   = {3},
  pages    = {832-839},
  month    = {May},
  abstract = {Living cells are constantly subjected to a plethora of environmental stimuli that require integration into an appropriate cellular response. This integration takes place through signal transduction events that form tightly interconnected networks. The understanding of these networks requires capturing their dynamics through computational support and models. ANIMO (analysis of Networks with Interactive Modeling) is a tool that enables the construction and exploration of executable models of biological networks, helping to derive hypotheses and to plan wet-lab experiments. The tool is based on the formalism of Timed Automata, which can be analyzed via the UPPAAL model checker. Thanks to Timed Automata, we can provide a formal semantics for the domain-specific language used to represent signaling networks. This enforces precision and uniformity in the definition of signaling pathways, contributing to the integration of isolated signaling events into complex network models. We propose an approach to discretization of reaction kinetics that allows us to efficiently use UPPAAL as the computational engine to explore the dynamic behavior of the network of interest. A user-friendly interface hides the use of Timed Automata from the user, while keeping the expressive power intact. Abstraction to single-parameter kinetics speeds up construction of models that remain faithful enough to provide meaningful insight. The resulting dynamic behavior of the network components is displayed graphically, allowing for an intuitive and interactive modeling experience.},
  doi      = {10.1109/JBHI.2013.2292880},
  groups   = {ACM, Compendex, IEEE DSL, SCOPUS},
  issn     = {2168-2194},
  keywords = {cellular biophysics;neurophysiology;ANIMO method;UPPAAL model checker;analysis of Networks with Interactive Modeling;biological pathway dynamics;cellular response;environmental stimuli;living cells;reaction kinetics;signal transduction events;tightly interconnected networks;timed automata;Automata;Biological system modeling;Computational modeling;Data models;Kinetic theory;Mathematical model;Dynamic behavior;Timed Automata;modeling;signaling pathway;0},
}

@InProceedings{7051890,
  author    = {F. P. Basso and C. M. L. Werner and T. C. Oliveira},
  title     = {Towards facilities to introduce solutions for MDE in development environments with reusable assets},
  booktitle = {Information Reuse and Integration (IRI), 2014 IEEE 15th International Conference on},
  year      = {2014},
  pages     = {195-202},
  month     = {Aug},
  abstract  = {Model Driven Engineering (MDE) is a software development paradigm that promotes improvements in productivity through reuse of software model specifications. Although much effort has been dedicated for more than ten years, MDE has not achieved expressive use. In this paper we address the problem of a lack of a knowledge base about MDE-based solutions, a reason that hampers MDE in practice. To surpass it we propose a domain specific language named RAS++ that represents these solutions as reusable assets. Assets are composed by reuse structures and semantics for the execution of technical solutions for Automated Software Engineering, fostering the integration of tasks for MDE in development environments. Facilities are introduced through some supporting tools: one to design reusable assets and other to integrate them in target development environments. Practical experiences have proven to be promising, suggesting that reusable assets promote some benefits not allowed by other approaches, such as the possibility of a distributed base of knowledge for ASE solutions.},
  doi       = {10.1109/IRI.2014.7051890},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  keywords  = {software reusability;specification languages;MDE-based solutions;RAS++;automated software engineering;domain specific language;knowledge base;model driven engineering;reusable asset design;reuse semantics;reuse structures;software development paradigm;software model specifications;Adaptation models;Automation;Context;Object oriented modeling;Proposals;Software;Unified modeling language;Asset Management Specification;Automated Software Engineering;Model Driven Engineering;Reusable Asset Specification;Reuse of Tasks},
}

@InProceedings{6229790,
  author    = {D. Ratiu and B. Schaetz and M. Voelter and B. Kolb},
  title     = {Language engineering as an enabler for incrementally defined formal analyses},
  booktitle = {Software Engineering: Rigorous and Agile Approaches (FormSERA), 2012 Formal Methods in},
  year      = {2012},
  pages     = {9-15},
  month     = {June},
  abstract  = {There is a big semantic gap between today's general purpose programming languages on the one hand and the input languages of formal verification tools on the other hand. This makes integrating formal analyses into the daily development practice artificially complex. In this paper we advocate that the use of language engineering techniques can substantially improve this situation along three dimensions. First, more abstract and thus more analyzable domain specific languages can be defined, avoiding the need for abstraction recovery from programs written in general purpose languages. Second, restrictions on the use of existing languages can be imposed and thereby more analyzable code can be obtained and analyses can be incrementally defined. Third, by expressing verification conditions and the verification results at the domain level, they are easier to define and the results of analyses are easier to interpret by end users. We exemplify our approach with three domain specific language fragments integrated into the C programming language, together with a set of analyses: completeness and consistency of decision tables, model-checking-based analyses for a dialect of state machines and consistency of feature models. The examples are based on the mbeddr stack, an extensible C language and IDE for embedded software development.},
  doi       = {10.1109/FormSERA.2012.6229790},
  groups    = {ACM, SCOPUS, IEEE DSL},
  keywords  = {C language;decision tables;finite state machines;formal verification;C programming language;abstraction recovery;daily development practice;decision tables completeness;decision tables consistency;domain level;domain specific languages;embedded software development;feature models consistency;formal analysis integration;formal verification tools;incrementally defined formal analysis;language engineering techniques;mbeddr stack;model checking-based analysis;programming languages;semantic gap;state machines;verification conditions;Abstracts;Analytical models;Computer languages;Concrete;DSL;Semantics;Syntactics},
}

@InProceedings{7306927,
  author    = {F. Pramudianto and C. A. Kamienski and E. Souto and F. Borelli and L. L. Gomes and D. Sadok and M. Jarke},
  title     = {IoT Link: An Internet of Things Prototyping Toolkit},
  booktitle = {Ubiquitous Intelligence and Computing, 2014 IEEE 11th Intl Conf on and IEEE 11th Intl Conf on and Autonomic and Trusted Computing, and IEEE 14th Intl Conf on Scalable Computing and Communications and Its Associated Workshops (UTC-ATC-ScalCom)},
  year      = {2014},
  pages     = {1-9},
  month     = {Dec},
  abstract  = {The Internet of Things (IoT) application development is a complex task that requires a wide range of expertise. Currently, the IoT community lacks a development toolkit that enables inexperienced developers to develop IoT prototypes rapidly. Filling this gap, we propose a development toolkit based on a model-driven approach, called IoT Link. IoT Link allows inexperienced developers to compose mash up applications through a graphical domain-specific language that can be easily configured and wired together to create an IoT application. Through visual components, IoT Link encapsulates the complexity of communicating with devices and services on the internet and abstracts them as virtual objects that are accessible through different communication technologies. Consequently, it solves interoperability between heterogeneous IoT components. Based on the visual model, IoT Link is able to generate a complete Java project including an extendable Java code. In a controlled experiment, IoT Link was 42% faster than using a Java library and able to outperform the Java library's user satisfactions.},
  doi       = {10.1109/UIC-ATC-ScalCom.2014.95},
  groups    = {SCOPUS, IEEE DSL},
  keywords  = {Internet of Things;Java;open systems;software prototyping;software tools;Internet of Things;IoT Link;IoT application development;IoT prototyping toolkit;Java code;interoperability;Conferences;Internet of things;Java;Mashups;Object oriented modeling;Unified modeling language;Visualization;Internet of Things;code generation;development tool;mashup;model driven development},
}

@InProceedings{6340132,
  author    = {O. Dayibas and H. Oguztüzün},
  title     = {Kutulu: A Domain-Specific Language for Feature-Driven Product Derivation},
  booktitle = {2012 IEEE 36th Annual Computer Software and Applications Conference},
  year      = {2012},
  pages     = {105-110},
  month     = {July},
  abstract  = {Software Product Line Engineering (SPLE) defines processes to facilitate the development of a family of products in a pre-defined market more effectively. Its success depends on implementation of these processes utilizing best practices with proper tool support. This paper describes how to enhance domain design and variation management processes of SPLE with a domain-specific language (DSL), namely "Kutulu". It also introduces novel modeling tools and dependency injection-based realization approach that are well-suited for product derivation in SPL. Our DSL definition, developed tools and their position in the product line context are put forth in this paper.},
  doi       = {10.1109/COMPSAC.2012.20},
  groups    = {ACM, IEEE DSL, Compendex, SCOPUS},
  issn      = {0730-3157},
  keywords  = {configuration management;formal specification;object-oriented languages;object-oriented programming;product development;Kutulu;SPLE;dependency injection-based realization approach;domain design;domain-specific language;feature-component binding;feature-driven product derivation;modeling tool;product development;software product line engineering;tool support;variation management process;Abstracts;Computer aided software engineering;DSL;Generators;Object oriented modeling;Software;Transforms;Dependency Injection;Domain-specific Language;Feature-Component Binding;Software Product Line;Variability Management},
}

@InProceedings{6375611,
  author    = {M. Lipaczewski and S. Struck and F. Ortmeier},
  title     = {Using Tool-Supported Model Based Safety Analysis -- Progress and Experiences in SAML Development},
  booktitle = {High-Assurance Systems Engineering (HASE), 2012 IEEE 14th International Symposium on},
  year      = {2012},
  pages     = {159-166},
  month     = {Oct},
  abstract  = {Software controls in technical systems are becoming more and more important and complex. Model based safety analysis can give provably correct and complete results, often in a fully automatic way. These methods can answer both logical and probabilistic questions. In common practice, the needed models must be specified in different input languages of different tools depending on the chosen verification tool for the desired aspect. This is time consuming and error-prone. To cope with this problem we developed the safety analysis modeling language (SAML). In this paper, we present a new tool to intuitively create probabilistic, non-deterministic and deterministic specifications for formal analysis. The goal is to give tool-support during modeling and thus make building a formal model less error-prone. The model is then automatically transformed into the input language of state of the art verification engines. We illustrate the approach on a case-study from nuclear power plant domain.},
  doi       = {10.1109/HASE.2012.34},
  groups    = {IEEE DSL},
  issn      = {1530-2059},
  keywords  = {formal languages;formal specification;formal verification;probability;safety-critical software;SAML development;art verification engines;deterministic specifications;formal analysis;formal model;nondeterministic specifications;nuclear power plant domain;probabilistic specifications;safety analysis modeling language;software controls;tool-supported model based safety analysis;verification tool;Analytical models;Generators;Hazards;Probabilistic logic;Switches;S3E;SAML;dependability;domain specific language;eclipse based editor;formal analysis;safety assurance},
}

@InProceedings{6957109,
  author    = {J. A. Akinyele and G. Barthe and B. Grégoire and B. Schmidt and P. Y. Strub},
  title     = {Certified Synthesis of Efficient Batch Verifiers},
  booktitle = {2014 IEEE 27th Computer Security Foundations Symposium},
  year      = {2014},
  pages     = {153-165},
  month     = {July},
  abstract  = {Many algorithms admit very efficient batch versions that compute simultaneously the output of the algorithms on a set of inputs. Batch algorithms are widely used in cryptography, especially in the setting of pairing-based computations, where they deliver significant speed-ups. AutoBatch is an automated tool that computes highly optimized batch verification algorithms for pairing-based signature schemes. Thanks to finely tuned heuristics, AutoBatch is able to rediscover efficient batch verifiers for several signature schemes of interest, and in some cases to output batch verifiers that outperform the best known verifiers from the literature. However, AutoBatch only provides weak guarantees (in the form of a LaTeX proof) of the correctness of the batch algorithms it outputs. In this paper, we verify the correctness and security of these algorithms using the EasyCrypt framework. To achieve this goal, we define a domain-specific language to describe verification algorithms based on pairings and provide an efficient algorithm for checking (approximate) observational equivalence between expressions of this language. By translating the output of AutoBatch to this language and applying our verification procedure, we obtain machine-checked correctness proofs of the batch verifiers. Moreover, we formalize notions of security for batch verifiers and we provide a generic proof in EasyCrypt that batch verifiers satisfy a security property called screening, provided they are correct and the original signature is unforgeable against chosen-message attacks. We apply our techniques to several well-known pairing-based signature schemes from the literature, and to Groth-Sahai zero-knowledge proofs.},
  doi       = {10.1109/CSF.2014.19},
  groups    = {ACM, Compendex, IEEE DSL, SCOPUS},
  issn      = {1063-6900},
  keywords  = {cryptography;digital signatures;formal verification;specification languages;theorem proving;AutoBatch;EasyCrypt framework;Groth-Sahai zero-knowledge proofs;LaTeX correctness proof;automated tool;batch versions;certified synthesis;correctness verification;cryptography;domain-specific language;generic proof;machine-checked correctness proofs;message attacks;observational equivalence checking;optimized batch verification algorithms;pairing-based computations;pairing-based signature schemes;screening;security property;Approximation algorithms;Equations;Optimization;Probabilistic logic;Public key;certified proofs;cryptographic design;cryptography;signature schemes},
}

@InProceedings{6511821,
  author    = {A. Ribeiro and A. R. da Silva},
  title     = {Survey on Cross-Platforms and Languages for Mobile Apps},
  booktitle = {Quality of Information and Communications Technology (QUATIC), 2012 Eighth International Conference on the},
  year      = {2012},
  pages     = {255-260},
  month     = {Sept},
  abstract  = {Nowadays mobile applications are becoming increasingly more present in our daily life, allowing people to perform several tasks through the use of smartphones, tablets or equivalent devices. Despite the great benefits in terms of innovation and in the variety of available solutions, the rapid and continuous growth of the mobile market has resulted in some fragmentation of the platforms that support each mobile device. The existence of different mobile operating systems with different programming languages and development tools can be a problem when someone wants to release an application in as many platforms as possible. The typical approach of simply rewriting the application for each one of those platforms is usually impracticable either in terms of budget or development time, requiring a bigger effort to be made. Therefore, a solution that could generate an application for several platforms (multi or cross-platform) without compromising the overall quality of the application would decrease the time to market of the application and increase enormously the number of potential users. Providentially, during the last years some effort has been conducted to tackle this problem, especially with the emergence of tools and frameworks that facilitate the development of crossplatform mobile applications. This paper focuses on these technologies and attempts to provide a global view of the actual state of this area.},
  doi       = {10.1109/QUATIC.2012.56},
  groups    = {ACM, IEEE DSL, SCOPUS},
  keywords  = {mobile computing;programming languages;smart phones;software tools;cross-platform mobile application development tools;mobile applications;mobile device;mobile market;mobile operating systems;programming languages;smartphones;tablets;Application;Cross-platform;Domain Specific Language;Mobile;Model-driven development},
}

@InProceedings{6800185,
  author    = {M. Viana and R. Penteado and A. D. Prado and R. Durelli},
  title     = {F3T: From Features to Frameworks Tool},
  booktitle = {Software Engineering (SBES), 2013 27th Brazilian Symposium on},
  year      = {2013},
  pages     = {89-98},
  month     = {Oct},
  abstract  = {Frameworks are used to enhance the quality of applications and the productivity of development process, since applications can be designed and implemented by reusing framework classes. However, frameworks are hard to develop, learn and reuse, due to their adaptive nature. In this paper we present the From Features to Framework Tool (F3T), which supports framework development in two steps: Domain Modeling, in which the features of the framework domain are modeled, and Framework Construction, in which the source-code and the Domain-Specific Modeling Language (DSML) of the framework are generated from the features. In addition, the F3T also supports the use of the framework DSML to model applications and generate their source-code. The F3T has been evaluated in a experiment that is also presented in this paper.},
  doi       = {10.1109/SBES.2013.15},
  groups    = {SCOPUS, Compendex},
  keywords  = {software reusability;source code (software);specification languages;DSML;F3T;From Features to Framework Tool;development process productivity;domain modeling;domain-specific modeling language;framework construction;framework development;source-code;Abstracts;Context;Frequency modulation;Generators;Java;Software;Unified modeling language},
}

@InProceedings{7000030,
  author    = {M. T. C. F. Albuquerque and G. L. Ramalho and V. Corruble and A. L. M. Santos and F. Freitas},
  title     = {Helping Developers to Look Deeper inside Game Sessions},
  booktitle = {2014 Brazilian Symposium on Computer Games and Digital Entertainment},
  year      = {2014},
  pages     = {31-40},
  month     = {Nov},
  abstract  = {Game design and development activities are increasingly relying on the analysis of gamer's behavior and preferences data. Various tools are available to the developers to track and analyze general data concerning acquisition, retention and monetization aspects of game commercialization. This is good enough to give hints on where problems are, but not to enable a precise diagnosis, which demands fine-grained data. For this kind of data, there is not enough support or guidance to decide which data to capture, to write the code to capture it, to choose the best representation of it and to allow an adequate retrieval and presentation of it. This paper introduces GameGuts (GG), a framework devoted to give further assistance to developers in choosing, representing, accessing and presenting game sessions fine-grained data. As a case study, GG recorded sessions of a game platform with over a hundred thousand users. The logs were analyzed using a Visual Domain Specific Language (as a query language) and an ensemble of rules (as a compliance test). The results are encouraging, since we could - among other results - find bugs and catch cheaters, as well as spot design flaws.},
  doi       = {10.1109/SBGAMES.2014.28},
  groups    = {ACM, IEEE DSL, SCOPUS},
  issn      = {2159-6654},
  keywords  = {computer games;data analysis;query languages;visual languages;GameGuts;bugs;catch cheaters;design flaws;game commercialization;game design;game development activities;game platform;game sessions;gamer behavior analysis;general data analysis;general data tracking;preferences data;query language;rule ensemble;visual domain specific language;DSL;Database languages;Games;Measurement;Ontologies;Servers;Visualization;game analytics;game data mining;knowledge representation},
}

@InProceedings{7139899,
  author    = {A. Nordmann and S. Wrede and J. Steil},
  title     = {Modeling of movement control architectures based on motion primitives using domain-specific languages},
  booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2015},
  pages     = {5032-5039},
  month     = {May},
  abstract  = {This paper introduces a model-driven approach for engineering complex movement control architectures based on motion primitives, which in recent years have been a central development towards adaptive and flexible control of complex and compliant robots. We consider rich motor skills realized through the composition of motion primitives as our domain. In this domain we analyze the control architectures of representative example systems to identify common abstractions. It turns out that the introduced notion of motion primitives implemented as dynamical systems with machine learning capabilities, provide the computational building block for a large class of such control architectures. Building on the identified concepts, we introduce domain-specific languages that allow the compact specification of movement control architectures based on motion primitives and their coordination respectively. Using a proper tool chain, we show how to employ this model-driven approach in a case study for the real world example of automatic laundry grasping with the KUKA LWR-IV, where executable source-code is automatically generated from the domain-specific language specification.},
  doi       = {10.1109/ICRA.2015.7139899},
  groups    = {SCOPUS, Compendex, IEEE DSL},
  issn      = {1050-4729},
  keywords  = {learning (artificial intelligence);motion control;programming languages;robots;time-varying systems;KUKA LWR-IV;domain-specific language specification;dynamical systems;executable source-code;machine learning;motion primitives;movement control architectures;robot;Adaptation models;Adaptive systems;Computer architecture;DSL;Motion control;Robot kinematics},
}

@InProceedings{6227067,
  author    = {M. Song and E. Tilevich},
  title     = {Detecting metadata bugs on the fly},
  booktitle = {2012 34th International Conference on Software Engineering (ICSE)},
  year      = {2012},
  pages     = {1455-1456},
  month     = {June},
  abstract  = {Programmers are spending a large and increasing amount of their time writing and modifying metadata, such as Java annotations and XML deployment descriptors. And yet, automatic bug finding tools cannot find metadata-related bugs introduced during program refactoring and enhancement. To address this shortcoming, we have created metadata invariants, a new programming abstraction that expresses naming and typing relationships between metadata and the main source code of a program. A paper that appears in the main technical program of ICSE 2012 describes the idea, concept, and prototype of metadata invariants [4]. The goal of this demo is to supplement that paper with a demonstration of our Eclipse plugin, Metadata Bug Finder (MBF). MBF takes as input a script written in our domain-specific language that describes a set of metadata coding conventions the programmer wishes to enforce. Then after each file save operation, MBF checks the edited codebase for the presence of any violations of the given metadata programming conventions. These violations are immediately reported to the programmer as potential metadata-related bugs. By making the programmer aware of these potential bugs, MBF prevents them from seeping into production, thereby improving the overall correctness of the edited codebase.},
  doi       = {10.1109/ICSE.2012.6227067},
  groups    = {ACM, SCOPUS, IEEE DSL},
  issn      = {0270-5257},
  keywords  = {meta data;program debugging;Eclipse plugin;ICSE 2012;Java annotations;MBF;XML deployment descriptors;domain-specific language;main source code;main technical program;metadata bug finder;metadata bugs detection;metadata coding conventions;metadata invariants;metadata programming conventions;program enhancement;program refactoring;programming abstraction;Computer bugs;Encoding;Java;Programming;Software;Testing;XML;bug finding;domain-specific languages;enhancement;frameworks;invariants;metadata;refactoring;software maintenance},
}

@InProceedings{7018471,
  author    = {J. S. Sottet and A. Vagner},
  title     = {Defining Domain Specific Transformations in Human-Computer interfaces development},
  booktitle = {Model-Driven Engineering and Software Development (MODELSWARD), 2014 2nd International Conference on},
  year      = {2014},
  pages     = {246-253},
  month     = {Jan},
  abstract  = {Early model-based approaches for Human-Computer Interaction (HCI) clearly depicted models and frameworks for generating User Interfaces (UI) but considered model transformations as black-boxes. In the 2000's, these approaches were criticized due to the poor quality of the produced UI. One of the main reasons of this poor quality can be easily observed in state of the art UI transformations: they are the heart of designers' know-how but are maintained by a minority of specialists. Meanwhile, mainstream UI design methods have shown a growing number of heterogeneous stakeholders that collaborate to produce modern and qualitative UI. We claim that these stakeholders must comprehend and interact with transformations and thus we need to make the transformation language affordable to these stakeholders. Indeed, such a simplification should hide transformations complexity and burden for any stakeholder, finally focusing on a specific part of the design domain: a Domain Specific Language (DSL) for transformations or Domain Specific Transformation Language (DSTL). We provide in this paper a method and a supporting tool for systematizing and finally executing DSTL for model-driven UI development. We depict that framework on a proof of concept implementation for an HCI-specific stakeholder: the usability expert.},
  groups    = {SCOPUS, IEEE DSL, Compendex},
  keywords  = {Abstracts;Analytical models;Complexity theory;Grammar;Human computer interaction;Usability;Domain Specific Transformation Languages;Human-Computer Interaction;Model Transformation;Model-Driven Development},
}

@InProceedings{7018464,
  author    = {J. Tatibouët and A. Cuccuru and S. Gérard and F. Terrier},
  title     = {Towards a systematic, tool-independent methodology for defining the execution semantics of UML profiles with fUML},
  booktitle = {Model-Driven Engineering and Software Development (MODELSWARD), 2014 2nd International Conference on},
  year      = {2014},
  pages     = {182-192},
  month     = {Jan},
  abstract  = {The purpose of UML profile mechanism is to design domain specific languages (DSL) based on UML. It exists a wide range of UML profiles: MARTE, ROOM, SysML. Current profile design methodology only considers the syntactic part of the language and keeps informal the execution semantics description. This impairs Model Driven Engineering (MDE) promises which advocates for executable models. This paper presents a systematic approach to formalize the execution semantics of UML profiles using foundational UML (normative specification) which defines a precise semantics for a subset of UML. This approach is integrated into the reference profile design methodology. It is illustrated on a small profile to support Turing machines. It demonstrates capability to execute resulting profiled models through the defined semantics.},
  groups    = {Compendex, IEEE DSL, SCOPUS},
  keywords  = {Abstracts;Computational modeling;Runtime;Semantics;Syntactics;Turing machines;Unified modeling language;Alf;DSML;Execution;MoC;Profile;Semantics;Turing;fUML},
}

@InProceedings{6511822,
  author    = {V. Amaral and B. Barroca and P. Carreira},
  title     = {Towards a Robust Solution in Building Automation Systems: Supporting Rapid Prototyping and Analysis},
  booktitle = {Quality of Information and Communications Technology (QUATIC), 2012 Eighth International Conference on the},
  year      = {2012},
  pages     = {261-264},
  month     = {Sept},
  abstract  = {It is presently required agile and systematic solutions aiming at streamlining the development, maintenance and configuration of complex Building Automation Systems (BASs) in an energy aware manner. We aim at defining usable Domain Specific Languages (DSLs) using a Software Language Engineering (SLE), as systematic approach for language development, and develop the right tools for specifying the behavior of BASs components along with their energy-related requirements. The goal is to not only assist the systems engineers while rapid-prototyping/developing affordable, high-quality, energy-efficient(EE) BASs, but also to take advantage of high level abstractions, efficient special-purpose verification algorithms and analysis tools for early validation and verification, in order to promote Quality of the generated software products. We are watching to the rise of Model-Driven Development as the pragmatic approach to build them, since this approach is based on the notion of explicit abstractions/models. This is achieved thanks to model transformations that, besides automatically translating any specification of a given language into other execution specifications, also allow us to derive analysis specifications. The problem with the referred types of transformation purposes is that we cannot guarantee quality and coherence between the derived specifications into execution specifications and combine it with analysis specifications unless we can either make use of testing over the execution, with the problems already known, or have mechanisms to study the transformations. While this problem is motivated by the concrete need of developing BASs, we foresee that it can be of general application in SLE. In this position paper we will give a state of the art in Building Automation and we give an overview of a possible solution that uses MDD and model transformations, in the context of a BAS solution, in order to check their correctness in w.r.t. the formal semantics of the lan- uages used in the target platforms (i.e either execution or analysis).},
  doi       = {10.1109/QUATIC.2012.59},
  groups    = {ACM, IEEE DSL, SCOPUS},
  keywords  = {building management systems;buildings (structures);civil engineering computing;energy conservation;formal specification;formal verification;rapid prototyping (industrial);software quality;BAS configuration;BAS development;BAS maintenance;DSL;SLE;analysis tool;building automation system;domain specific language;energy aware BAS;energy-related requirement;execution specification;explicit abstraction notion;formal semantics;language development;model transformation;model-driven development;rapid prototyping;software language engineering;software product quality;special-purpose verification algorithm;DSLTrans;Model Checking;Model Transformations;Model Transformations Analysis;Quality in MDD;Software Language Engineering},
}

@InProceedings{6692589,
  author    = {J. Schafer and D. Klein},
  title     = {Implementing Situation Awareness for Car-to-X Applications Using Domain Specific Languages},
  booktitle = {Vehicular Technology Conference (VTC Spring), 2013 IEEE 77th},
  year      = {2013},
  pages     = {1-5},
  month     = {June},
  abstract  = {Car-to-X i.e. Car-to-Anything communication based on standardized IEEE 802.11p radio technology is comprised with wireless communication between cars (Car-to-Car) and between vehicles and the environment (Car-to-Infrastructure). In order to develop Car-to-X applications based on this standard one needs to model parameters such as the vehicle's position, velocity, acceleration etc. and parameters of the vehicle's environment. Typically, the underlying domain models are designed in an ad-hoc manner and the domain rules become hard-coded into the source- code of the application software. In this paper we describe an alternative and more flexible approach. The model is described in almost plain English using a Domain Specific Language (DSL) and translated into target code via parser technology based on the ANTLR tool-chain. This provides more flexibility not only in creating and maintaining the domain rules, but also with regards to generating code for entirely different target languages and technology environments. For instance, we demonstrate to generate Java code for a simulation environment and C-code for the embedded device from the same rule definitions.},
  doi       = {10.1109/VTCSpring.2013.6692589},
  groups    = {Compendex, IEEE DSL, SCOPUS},
  issn      = {1550-2252},
  keywords  = {Java;mobile computing;wireless LAN;ANTLR tool-chain;C-code;Java code;car-to-anything communication;car-to-car communication;car-to-infrastructure communication;car-to-x applications;domain specific languages;model parameters;parser technology;situation awareness;source-code;standardized IEEE 802.11p radio technology;vehicle acceleration;vehicle position;vehicle velocity;wireless communication;Context;DSL;Engines;Grammar;Java;Runtime;Syntactics},
}

@InProceedings{7018466,
  author    = {E. Tyugu and M. Harf and P. Grigorenko},
  title     = {A case study of combining compositional and object-oriented software development},
  booktitle = {Model-Driven Engineering and Software Development (MODELSWARD), 2014 2nd International Conference on},
  year      = {2014},
  pages     = {201-208},
  month     = {Jan},
  abstract  = {We analyze an approach to software development where object-oriented and compositional software specifications are written in separate languages and are only loosely connected. It supports compositional design of software in a domain-specific language and automatic model-driven construction of code from classes written in Java. We justify our approach by giving examples of development of large simulation programs and services on large models. We present also an example of using our method in general purpose software development - this is bootstrapping the essential part of a software tool CoCoViLa, i.e. synthesizing CoCoViLa in CoCoViLa itself.},
  groups    = {Compendex, ACM, SCOPUS, IEEE DSL},
  keywords  = {Computational modeling;DSL;Java;Mathematical model;Object oriented modeling;Software;Unified modeling language;Compositional Software Design;Domain-specific Modeling;Model Driven Software Development;Structural Synthesis of Programs},
}

@InProceedings{6955332,
  author    = {C. H. C. Jojoa and O. M. Drews},
  title     = {Domain Specific Language for Handling Modular Ontologies},
  booktitle = {Computing Colombian Conference (9CCC), 2014 9th},
  year      = {2014},
  pages     = {48-53},
  month     = {Sept},
  abstract  = {A Knowledge Object may be characterized in different forms, corresponding to different perspectives of the object. In the same sense, knowledge of a particular domain can be organized in different interconnected ontologies. The research on ontology modularization has advanced in proposing formalisms and tools to extend ontologies with inter-ontology connectors. Tools are needed to manipulate these new connectors. Existing tools are platform dependent, which presents problems of adaptability, portability and reusability. This paper presents the design and implementation of a Specific Domain Language for Handling Modular Ontologies, based on a model driven architecture (MDA).},
  doi       = {10.1109/ColumbianCC.2014.6955332},
  groups    = {IEEE DSL},
  keywords  = {ontologies (artificial intelligence);software architecture;MDA;domain specific language;inter-ontology connectors;knowledge object;model driven architecture;modular ontologies;Adaptation models;Computer architecture;Connectors;Context modeling;Domain specific languages;OWL;Ontologies;Knowledge management;MDA architecture;e-connections;metamodels;modular ontologies},
}

@Article{5766765,
  author   = {D. D. a. V. Devedzic},
  title    = {Incorporating the Ontology Paradigm Into Software Engineering: Enhancing Domain-Driven Programming in Clojure/Java},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  year     = {2012},
  volume   = {42},
  number   = {1},
  pages    = {3-14},
  month    = {Jan},
  abstract = {There is a notable overlap of the challenges with which the semantic technologies and software engineering deal. They can also complement and mutually improve each other. Current efforts mostly focus on improving software tools around the resource description framework (RDF) and Web Ontology Language (OWL) Web-oriented ecosystem that helps ontology engineers but is alien to software engineers. This paper presents an opposite approach taken from the software developer's viewpoint - an incorporation of the ontology paradigm into a general-purpose programming language, in a simple and agile way, on a small scale, and in an unpretentious manner. The objective is to help programmers write simple domain-driven code with richer semantics. The means to achieve this objective relies on metaprogramming to internalize the ontology modeling paradigm into a mainstream programming environment based on the Java ecosystem, in a lightweight manner suitable for small teams. An embedded meta domain-specific language (DSL), which is called Magic Potion, is implemented in Clojure and blends ontology, functional, object-oriented, and concurrent paradigms. An example from the technology enhanced learning (TEL) domain is used to illustrate Magic Potion in action.},
  doi      = {10.1109/TSMCC.2011.2140316},
  groups   = {ACM, IEEE DSL, SCOPUS},
  issn     = {1094-6977},
  keywords = {Java;functional programming;object-oriented programming;ontologies (artificial intelligence);semantic Web;software engineering;Clojure;Java ecosystem;Magic Potion;Web ontology language;Web oriented ecosystem;concurrent paradigms;domain driven code;domain driven programming;embedded meta domain specific language;functional paradigms;general purpose programming language;object oriented paradigms;ontology engineers;ontology modeling paradigm;resource description framework;semantic technologies;software engineering;technology enhanced learning domain;DSL;OWL;Object oriented modeling;Ontologies;Programming;Software;Clojure;domain-specific languages;modeling spaces;multiparadigm programming;ontologies;programming languages;semantic technologies;software engineering},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:ACM\;0\;;
1 ExplicitGroup:SCOPUS\;0\;;
1 ExplicitGroup:IEEE DSL\;0\;;
1 ExplicitGroup:Science Direct\;0\;;
1 ExplicitGroup:IEEE DSML\;0\;;
1 ExplicitGroup:Compendex\;0\;;
1 ExplicitGroup:SpringerLink\;0\;;
}
