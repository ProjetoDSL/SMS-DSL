% Encoding: UTF-8

@Article{Dejanović2016,
  author   = {I. Dejanović and R. Vaderna and G. Milosavljević and Ž. Vuković},
  title    = {TextX: A Python tool for Domain-Specific Languages implementation},
  journal  = {Knowledge-Based Systems},
  year     = {2016},
  pages    = {-},
  abstract = {Abstract TextX is a meta-language and a tool for building Domain-Specific Languages in Python. It’s built on top of the Arpeggio \{PEG\} parser and takes away the burden of converting parse trees to abstract representations from language designers. From a single grammar description, textX constructs Arpeggio parser and a meta-model in run-time. The meta-model contains all the information about the language and a set of Python classes inferred from grammar rules. The parser will parse programs/models written in the new language and construct Python object graph a.k.a. the model conforming to the meta-model. The textX tool has support for error reporting, debugging, and meta-model and model visualization. It is used in industrial environments and teaching Domain-Specific Languages course at the Faculty of Technical Sciences in Novi Sad. It is a free and open-source software available at GitHub under the \{MIT\} license. },
  doi      = {http://dx.doi.org/10.1016/j.knosys.2016.10.023},
  groups   = {ScienceDirect},
  issn     = {0950-7051},
  keywords = {Domain-Specific Language, Meta-model, Model, Model-Driven software development, Parser, Python },
  url      = {http://www.sciencedirect.com/science/article/pii/S0950705116304178},
}

@Article{Kokash2015308,
  author   = {Natallia Kokash and Stuart L. Moodie and Mike K. Smith and Nick Holford},
  title    = {Implementing a Domain-specific Language for Model-based Drug Development},
  journal  = {Procedia Computer Science},
  year     = {2015},
  volume   = {63},
  pages    = {308 - 316},
  note     = {The 6th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2015)/ The 5th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2015)/ Affiliated Workshops},
  abstract = {Abstract In this paper, we present the implementation of a novel domain-specific language (DSL) for pharmacometric modeling called the Modelling Description Language (MDL). \{MDL\} is a modular, declarative language with block structures that allows users to abstract data, processes and mathematical models from auxiliary code, and hence, improves model readability, reusability and opportunities for collaborative research. The main aim of this \{DSL\} is interoperability between core software tools used in pharmacometrics. We describe the MDL-IDE, an integrated development environment for MDL, which assists users in writing \{MDL\} code. The paper focuses on language constructs and design decisions, briefly explains how models are validated and converted to a machine-readable format for processing by existing model simulation and estimation software tools. },
  doi      = {http://dx.doi.org/10.1016/j.procs.2015.08.348},
  groups   = {SCOPUS},
  issn     = {1877-0509},
  keywords = {Model-based drug development, pharmacokinetics, domain-specific language, modeling, simulation ; },
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050915024837},
}

@Article{Degueule2016,
  author   = {Thomas Degueule and Benoit Combemale and Arnaud Blouin and Olivier Barais and Jean-Marc Jézéquel},
  title    = {Safe model polymorphism for flexible modeling},
  journal  = {Computer Languages, Systems \& Structures},
  year     = {2016},
  pages    = {-},
  abstract = {Abstract Domain-Specific Languages (DSLs) are increasingly used by domain experts to handle various concerns in systems and software development. To support this trend, the Model-Driven Engineering (MDE) community has developed advanced techniques for designing new DSLs. However, the widespread use of independently developed, and constantly evolving \{DSLs\} is hampered by the rigidity imposed to the language users by the \{DSLs\} and their tooling, e.g., for manipulating a model through various similar \{DSLs\} or successive versions of a given DSL. In this paper, we propose a disciplined approach that leverages type groups׳ polymorphism to provide an advanced type system for manipulating models, in a polymorphic way, through different \{DSL\} interfaces. A \{DSL\} interface, a.k.a. model type, specifies a set of features, or services, available on the model it types, and subtyping relations among these model types define the safe substitutions. This type system complements the Melange language workbench and is seamlessly integrated into the Eclipse Modeling Framework (EMF), hence providing structural interoperability and compatibility of models between EMF-based tools. We illustrate the validity and practicability of our approach by bridging safe interoperability between different semantic and syntactic variation points of a finite-state machine (FSM) language, as well as between successive versions of the Unified Modeling Language (UML). },
  doi      = {http://dx.doi.org/10.1016/j.cl.2016.09.001},
  groups   = {ScienceDirect},
  issn     = {1477-8424},
  keywords = {Metamodeling, Model typing, Type groups polymorphism },
  url      = {http://www.sciencedirect.com/science/article/pii/S1477842416300264},
}

@Article{Erdweg201524,
  author   = {Sebastian Erdweg and Tijs van der Storm and Markus Völter and Laurence Tratt and Remi Bosman and William R. Cook and Albert Gerritsen and Angelo Hulshout and Steven Kelly and Alex Loh and Gabriël Konat and Pedro J. Molina and Martin Palatnik and Risto Pohjonen and Eugen Schindler and Klemens Schindler and Riccardo Solmi and Vlad Vergu and Eelco Visser and Kevin van der Vlist and Guido Wachsmuth and Jimi van der Woning},
  title    = {Evaluating and comparing language workbenches: Existing results and benchmarks for the future},
  journal  = {Computer Languages, Systems \& Structures},
  year     = {2015},
  volume   = {44, Part A},
  pages    = {24 - 47},
  note     = {Special issue on the 6th and 7th International Conference on Software Language Engineering (SLE 2013 and \{SLE\} 2014)},
  abstract = {Abstract Language workbenches are environments for simplifying the creation and use of computer languages. The annual Language Workbench Challenge (LWC) was launched in 2011 to allow the many academic and industrial researchers in this area an opportunity to quantitatively and qualitatively compare their approaches. We first describe all four \{LWCs\} to date, before focussing on the approaches used, and results generated, during the third LWC. We give various empirical data for ten approaches from the third LWC. We present a generic feature model within which the approaches can be understood and contrasted. Finally, based on our experiences of the existing LWCs, we propose a number of benchmark problems for future LWCs. },
  doi      = {http://dx.doi.org/10.1016/j.cl.2015.08.007},
  groups   = {SCOPUS},
  issn     = {1477-8424},
  keywords = {Language workbenches, Domain-specific languages, Questionnaire language, Survey, Benchmarks },
  url      = {http://www.sciencedirect.com/science/article/pii/S1477842415000573},
}

@Article{Weichhart201690,
  author   = {Georg Weichhart and Wided Guédria and Yannick Naudet},
  title    = {Supporting interoperability in complex adaptive enterprise systems: A domain specific language approach},
  journal  = {Data \& Knowledge Engineering},
  year     = {2016},
  volume   = {105},
  pages    = {90 - 106},
  note     = {Knowledge Engineering for Enterprise, Integration, Interoperability and Networking: Theory and Applications},
  abstract = {Abstract From a Complex Adaptive Systems (CAS) theory perspective a new approach for supporting Enterprise Interoperability (EI) is described. Particular needs informed by the theory are presented and a software environment supporting these requirements is proposed. The infrastructure aims at serving as a tool for solving problems in the \{EI\} domain, and includes a Domain Specific Language (DSL) supporting engineering interoperability solutions. The Ontology of Enterprise Interoperability (OoEI) provides the underlying conceptualisation of the Enterprise Interoperability (EI) domain and is used as basis. The \{DSL\} enhances the ontology with \{CAS\} related concepts. The \{CAS\} perspective provides a particular focus on dynamic aspects, which requires a new approach currently only addressed to a limited extend. The research interoperability infrastructure provides components to address the decentralised nature of a \{CAS\} by providing software agents and agent interaction protocols that facilitate the identification of interoperability problems and agent negotiations to find solutions. It is realised using the functional programming language Scala. },
  doi      = {http://dx.doi.org/10.1016/j.datak.2016.04.001},
  groups   = {Compendex, SCOPUS},
  issn     = {0169-023X},
  keywords = {Enterprise Interoperability, Ontology of interoperability, Complex Adaptive Systems, Multi Agent Systems, Scala },
  url      = {http://www.sciencedirect.com/science/article/pii/S0169023X16300222},
}

@Article{Troya2014863,
  author   = {Javier Troya and Antonio Vallecillo},
  title    = {Specification and simulation of queuing network models using Domain-Specific Languages},
  journal  = {Computer Standards \& Interfaces},
  year     = {2014},
  volume   = {36},
  number   = {5},
  pages    = {863 - 879},
  abstract = {Abstract Queuing network models (QNMs) provide powerful notations and tools for modeling and analyzing the performance of many different kinds of systems. Although several powerful tools currently exist for solving QNMs, some of these tools define their own model representations, have been developed in platform-specific ways, and are normally difficult to extend for coping with new system properties, probability distributions or system behaviors. This paper shows how Domain Specific Languages (DSLs), when used in conjunction with Model-driven engineering techniques, provide a high-level and very flexible approach for the specification and analysis of QNMs. We build on top of an existing metamodel for \{QNMs\} (PMIF) to define a \{DSL\} and its associated tools (editor and simulation engine), able to provide a high-level notation for the specification of different kinds of QNMs, and easy to extend for dealing with other probability distributions or system properties, such as system reliability. },
  doi      = {http://dx.doi.org/10.1016/j.csi.2014.01.002},
  groups   = {ACM, SCOPUS},
  issn     = {0920-5489},
  keywords = {Domain-Specific Languages, Queuing network models, PMIF },
  url      = {http://www.sciencedirect.com/science/article/pii/S092054891400004X},
}

@InCollection{Sadrieh20151559,
  author    = {Afshin Sadrieh and Parisa A. Bahri},
  title     = {A New Software Development Methodology for Controllability Analysis of Forced Circulation Evaporator System},
  booktitle = {12th International Symposium on Process Systems Engineering and 25th European Symposium on Computer Aided Process Engineering},
  publisher = {Elsevier},
  year      = {2015},
  editor    = {Krist V. Gernaey, Jakob K. Huusom and Rafiqul Gani},
  volume    = {37},
  series    = {Computer Aided Chemical Engineering},
  pages     = {1559 - 1564},
  abstract  = {Abstract Modern chemical process plants are becoming more and more complex due to tighter economic and environmental limitations. As a result, achieving well-controllable process system designs becomes a tedious task. Using software products to evaluate designs in early stages is beneficial in order to reduce the human error and increase the efficiency. However, developing software tools for controllability problems using traditional software development methods is inefficient due to complexity and scale of these problems as well as considerable differences between them. In this work, a graphical domain-specific language (DSL) is introduced for measuring \{RGA\} index, to assess the controllability of a process plant with an application to a forced-circulation evaporator system. },
  doi       = {http://dx.doi.org/10.1016/B978-0-444-63577-8.50105-4},
  groups    = {SCOPUS,},
  issn      = {1570-7946},
  keywords  = {Domain-specific languages, Forced circulation evaporator, Controllability analysis },
  url       = {http://www.sciencedirect.com/science/article/pii/B9780444635778501054},
}

@Article{Sequeira2015894,
  author   = {Fernando Rosa Sequeira and Rafael Z. Frantz and Iryna Yevseyeva and Michael T.M. Emmerich and Vitor Basto-Fernandes},
  title    = {An \{EAI\} Based Integration Solution for Science and Research Outcomes Information Management},
  journal  = {Procedia Computer Science},
  year     = {2015},
  volume   = {64},
  pages    = {894 - 901},
  note     = {Conference on \{ENTERprise\} Information Systems/International Conference on Project MANagement/Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / \{HCist\} 2015 October 7-9, 2015},
  abstract = {Abstract In this paper we present an Enterprise Application Integration (EAI) based proposal for research outcomes information management. The proposal is contextualized in terms of national and international science and research outcomes information management, corresponding supporting information systems and ecosystems. Information systems interoperability problems, approaches, technologies and tools are presented and applied to the research outcomes information management case. A business and technological perspective is provided, including the conceptual analysis and modelling, an integration solution based in a Domain-Specific Language (DSL) and the orchestration engine to execute the proposed solution. For illustrative purposes, the role and information system needs of a research unit is assumed as the representative case. },
  doi      = {http://dx.doi.org/10.1016/j.procs.2015.08.604},
  groups   = {SCOPUS,},
  issn     = {1877-0509},
  keywords = {Enterprise Application Integration, Domain-Specific Language, Information Management. },
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050915027398},
}

@Article{Degenne2016,
  author   = {P. Degenne and D. Lo Seen},
  title    = {Ocelet: Simulating processes of landscape changes using interaction graphs},
  journal  = {SoftwareX},
  year     = {2016},
  pages    = {-},
  abstract = {Abstract This paper introduces Ocelet, a domain specific language and simulation tool for modelling changes in geographical landscapes. It is characterised by the use of interaction graphs (graphs with interaction functions on their edges) to represent the system as composed of processes, each involving several entities distributed in space that are in interaction with each other. Entities are the vertices of the graphs, and interactions are the edges on which (interaction) functions can be applied to make the system change through time. Examples are given to illustrate the generic disposition of the simulation approach to model and study changing geographical setups. },
  doi      = {http://dx.doi.org/10.1016/j.softx.2016.05.002},
  groups   = {SCOPUS},
  issn     = {2352-7110},
  keywords = {Spatial modelling, Multi-scale, Domain specific language },
  url      = {http://www.sciencedirect.com/science/article/pii/S2352711016300103},
}

@Article{Patwari2016761,
  author   = {Puneet Patwari and Subhrojyoti Roy Chaudhuri and Swaminathan Natarajan and G Muralikrishna},
  title    = {M\&C ML: A modeling language for monitoring and control systems},
  journal  = {Fusion Engineering and Design},
  year     = {2016},
  volume   = {112},
  pages    = {761 - 765},
  abstract = {Abstract The use of System Engineering (SE) language such as SysML [1,20] is common within the community of control system designers. However the design handoff to the subsequent phases of the control system development is carried out manually in most cases without much tool support. The approach to agreeing on the control interface between components is a good example where engineers still rely on either manually created Interface Control Documents (ICD) or one off tools implemented by individual projects. Square Kilometer Array (SKA) [2] and International Thermonuclear Experimental Reactor (ITER) [3] are two good examples of such large projects adopting these approaches. This results in non-uniformity in the overall system design since individual groups invent their own vocabulary while using a language like SysML which leads to inconsistencies across the design, interface and realized code. To mitigate this, we propose the development of a Monitoring and Control Modeling Language (M&amp;CML), a domain specific language (DSL) [4,22] for specifying M&amp;C solutions. M&amp;C \{ML\} starts with defining a vocabulary borrowing concepts from standard practices used in the control domain and incorporates a language which ensures uniformity and consistency across the M&amp;C design, interfaces and implementation artifacts. In this paper we discuss this language with an analysis of its usage to point out its benefits. },
  doi      = {http://dx.doi.org/10.1016/j.fusengdes.2016.05.024},
  groups   = {Compendex, SCOPUS},
  issn     = {0920-3796},
  keywords = {Domain driven engineering, Monitoring and control systems, Domain specific language for M&amp, amp, C systems, System engineering, Model driven engineering },
  url      = {http://www.sciencedirect.com/science/article/pii/S0920379616303817},
}

@Article{Challenger201691,
  author   = {Moharram Challenger and Marjan Mernik and Geylani Kardas and Tomaž Kosar},
  title    = {Declarative specifications for the development of multi-agent systems},
  journal  = {Computer Standards \& Interfaces},
  year     = {2016},
  volume   = {43},
  pages    = {91 - 115},
  abstract = {Abstract The designing and implementation of a multi-agent system (MAS), where autonomous agents collaborate with other agents for solving problems, constitute complex tasks that may become even harder when agents work in new interactive environments such as the Semantic Web. In order to deal with the complexities of designing and implementing a MAS, a domain-specific language (DSL) can be employed inside the MAS's development cycle. In such a manner, a \{MAS\} can be completely specified by programs written in a DSL. Such programs are declarative, expressive, and at the right abstraction level. In this way the complexity of \{MAS\} development is then partially shifted to \{DSL\} development and the task herein can be much more feasible by using a proper \{DSL\} development methodology and related tools. This paper presents and discusses our methodology for \{DSL\} development based on declarative formal specifications that are easy to compose, and its usage during \{MAS\} development. A practical case-study is also provided covering an example of a MAS's development for expert finding systems. By using denotational semantics for precisely defining the language, we show that it is possible to generate the language automatically. In addition, using attribute grammars makes it possible to have modular methodology within which evolutionary language development becomes easier. },
  doi      = {http://dx.doi.org/10.1016/j.csi.2015.08.012},
  groups   = {ACM, SCOPUS},
  issn     = {0920-5489},
  keywords = {Domain-specific language, Multi-agent system, Semantic Web, Formal semantics, Declarative specifications },
  url      = {http://www.sciencedirect.com/science/article/pii/S0920548915000975},
}

@Article{Dejanović201671,
  author   = {I. Dejanović and G. Milosavljević and R. Vaderna},
  title    = {Arpeggio: A flexible \{PEG\} parser for Python},
  journal  = {Knowledge-Based Systems},
  year     = {2016},
  volume   = {95},
  pages    = {71 - 74},
  abstract = {Abstract Arpeggio is a recursive descent parser with full backtracking and memoization based on \{PEG\} (Parsing Expression Grammar) grammars. This category of parsers is known as packrat parsers. It is implemented in the Python programming language and works as a grammar interpreter. Arpeggio has a very good support for error reporting, debugging, and grammar and parse tree visualization. It is used in industrial environments and teaching Domain-Specific Languages course at the Faculty of Technical Sciences in Novi Sad. Arpeggio is a foundation of a high-level \{DSL\} meta-language and tool - textX. It is a free and open-source software available at GitHub under \{MIT\} license. },
  doi      = {http://dx.doi.org/10.1016/j.knosys.2015.12.004},
  groups   = {Compendex, ACM,},
  issn     = {0950-7051},
  keywords = {PEG, Packrat, Parser, Python, DSL, TextX },
  url      = {http://www.sciencedirect.com/science/article/pii/S0950705115004761},
}

@Article{Martini2016235,
  author   = {Ricardo Giuliani Martini and Giovani Rubert Librelotto and Pedro Rangel Henriques},
  title    = {Formal Description and Automatic Generation of Learning Spaces Based on Ontologies},
  journal  = {Procedia Computer Science},
  year     = {2016},
  volume   = {96},
  pages    = {235 - 244},
  note     = {Knowledge-Based and Intelligent Information \&amp; Engineering Systems: Proceedings of the 20th International Conference KES-2016},
  abstract = {Abstract A good virtual Learning Space (LS) should convey pertinent learning information to the visitors at the most adequate time and locations to favor their knowledge acquisition. Considering the consolidation of the internet and the improvement of the interaction, searching, and learning mechanisms, we propose a generic architecture, called CaVa, to create virtual Learning Spaces building up on cultural institution documents. More precisely, our proposal is to automatically create ontology-based virtual learning environments. Thus, to impart relevant learning materials to the virtual LS, we propose the use of ontologies to represent the key concepts and semantic relations in an user- and machine-understandable format. These concepts together with the data (extracted from the real documents) stored in a digital storage format (XML datasets, relational databases, etc.) are displayed in an ontology-based learning space that enables the visitors to use the available features and tools to learn about a specific domain. According to the approach here discussed, each desired virtual \{LS\} must be specified rigorously through a domain specific language (DSL) that was designed and implemented. To validate the proposed architecture, three case studies will be used as instances of CaVa architecture. },
  doi      = {http://dx.doi.org/10.1016/j.procs.2016.08.136},
  groups   = {SCOPUS},
  issn     = {1877-0509},
  keywords = {Learning Spaces, Exhibition Rooms, Cultural Heritage, Ontology, Domain Specific Language },
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050916319378},
}

@Article{Pereira201635,
  author   = {Maria João Varanda Pereira and João Fonseca and Pedro Rangel Henriques},
  title    = {Ontological approach for \{DSL\} development},
  journal  = {Computer Languages, Systems \& Structures},
  year     = {2016},
  volume   = {45},
  pages    = {35 - 52},
  abstract = {Abstract This paper presents a project whose main objective is to explore the ontological based development of Domain Specific Languages (DSL), more precisely, of their underlying Grammar. After reviewing the basic concepts characterizing Ontologies and DSLs, we introduce a tool, Onto2Gra, that takes profit of the knowledge described by the ontology and automatically generates a grammar for a \{DSL\} that allows to discourse about the domain described by that ontology. This approach represents a rigorous method to create, in a secure and effective way, a grammar for a new specialized language restricted to a concrete domain. The usual process of creating a grammar from the scratch is, as every creative action, difficult, slow and error prone; so this proposal is, from a grammar engineering point of view, of uttermost importance. After the grammar generation phase, the Grammar Engineer can manipulate it to add syntactic sugar to improve the final language quality or even to add specific semantic actions. The Onto2Gra project is composed of three engines. The main one is OWL2DSL, the component that converts an \{OWL\} ontology into a complete Attribute Grammar for the construction of an internal representation of all the input data. The two additional modules are Onto2OWL, converts ontologies written in OntoDL into standard OWL, and DDesc2OWL, converts domain instances written in the new \{DSL\} into the initial \{OWL\} ontology. },
  doi      = {http://dx.doi.org/10.1016/j.cl.2015.12.004},
  groups   = {ACM, SCOPUS, Compendex},
  issn     = {1477-8424},
  keywords = {DSL, Ontologies, Grammars, Problem domain concepts },
  url      = {http://www.sciencedirect.com/science/article/pii/S1477842415300270},
}

@Article{Estérie20143240,
  author   = {Pierre Estérie and Joel Falcou and Mathias Gaunard and Jean-Thierry Lapresté and Lionel Lacassagne},
  title    = {The numerical template toolbox: A modern C++ design for scientific computing},
  journal  = {Journal of Parallel and Distributed Computing},
  year     = {2014},
  volume   = {74},
  number   = {12},
  pages    = {3240 - 3253},
  note     = {Domain-Specific Languages and High-Level Frameworks for High-Performance Computing},
  abstract = {Abstract The design and implementation of high level tools for parallel programming is a major challenge as the complexity of modern architectures increases. Domain Specific Languages (or DSL) have been proposed as a solution to facilitate this design but few of those DSLs actually take full advantage of said parallel architectures. In this paper, we propose a library-based solution by designing a C++   DSLs using generative programming: \{NT\} 2 . By adapting generative programming idioms so that architecture specificities become mere parameters of the code generation process, we demonstrate that our library can deliver high performance while featuring a high level \{API\} and being easy to extend over new architectures. },
  doi      = {http://dx.doi.org/10.1016/j.jpdc.2014.07.002},
  groups   = {SCOPUS},
  issn     = {0743-7315},
  keywords = {C++, Embedded domain specific languages, Parallel skeletons, Generic programming, Generative programming },
  url      = {http://www.sciencedirect.com/science/article/pii/S0743731514001245},
}

@Article{Gibbs201569,
  author   = {Ivan Gibbs and Sergiu Dascalu and Frederick C. Harris and Jr.},
  title    = {A separation-based \{UI\} architecture with a \{DSL\} for role specialization},
  journal  = {Journal of Systems and Software},
  year     = {2015},
  volume   = {101},
  pages    = {69 - 85},
  abstract = {Abstract This paper proposes an architecture and associated methodology to separate front end \{UI\} concerns from back end coding concerns to improve the platform flexibility, shorten the development time, and increase the productivity of developers. Typical \{UI\} development is heavily dependent upon the underlying platform, framework, or tool used to create it, which results in a number of problems. We took a separation-based \{UI\} architecture and modified it with a domain specific language to support the independence of \{UI\} creation thereby resolving some of the aforementioned problems. A methodology incorporating this architecture into the development process is proposed. A climate science application was created to verify the validity of the methodology using modern practices of UX, DSLs, code generation, and model-driven engineering. Analyzing related work provides an overview of other methods similar to our method. Subsequently we evaluate the climate science application, conclude, and detail future work. },
  doi      = {http://dx.doi.org/10.1016/j.jss.2014.11.039},
  groups   = {Compendex, ACM, SCOPUS,},
  issn     = {0164-1212},
  keywords = {Domain specific language, Model driven engineering, User experience },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121214002702},
}

@InCollection{Sadrieh2014559,
  author    = {Afshin Sadrieh and Parisa A. Bahri},
  title     = {Novel Domain-Specific Language Framework for Controllability Analysis},
  booktitle = {24th European Symposium on Computer Aided Process Engineering},
  publisher = {Elsevier},
  year      = {2014},
  editor    = {Jiří Jaromír Klemeš, Petar Sabev Varbanov and Peng Yen Liew},
  volume    = {33},
  series    = {Computer Aided Chemical Engineering},
  pages     = {559 - 564},
  abstract  = {Abstract Controllability is one of the most important aspects of process systems’ operability. Failure to achieve a standard controllable process may lead to environmental disasters and economical difficulties. Therefore, the need for highly standard specific software tool for this area is now visible more than any time. However, this category of problems varies significantly from case to case, which makes providing software tools an inefficient task. In this study, a new methodology to develop software tool for controllability analysis is proposed and the maintainability of the software in terms of number of lines of code and time spent to apply a particular new request is discussed. Moreover, a controllability case study is applied to this software and the results are presented. },
  doi       = {http://dx.doi.org/10.1016/B978-0-444-63456-6.50094-6},
  groups    = {SCOPUS},
  issn      = {1570-7946},
  keywords  = {Domain-Specific Language, Maintainability, Controllability analysis, CAPE },
  url       = {http://www.sciencedirect.com/science/article/pii/B9780444634566500946},
}

@Article{Popovic201569,
  author   = {Aleksandar Popovic and Ivan Lukovic and Vladimir Dimitrieski and Verislav Djukic},
  title    = {A \{DSL\} for modeling application-specific functionalities of business applications},
  journal  = {Computer Languages, Systems \& Structures},
  year     = {2015},
  volume   = {43},
  pages    = {69 - 95},
  abstract = {Abstract Models have been widely used in the information system development process. Models are not just means for system analysis and documentation. They may be also transformed into system implementation, primarily program code. Generated program code of screen forms and transaction programs mainly implements generic functionalities that can be expressed by simple retrieval, insertion, update, or deletion operations over database records. Besides the program code of generic functionalities, each application usually includes program code for specific business logic that represents application-specific functionalities, which may include complex calculations, as well as a series of database operations. There is a lack of domain-specific and tool-supported techniques for specification of such application-specific functionalities at the level of platform-independent models (PIMs). In this paper, we propose an approach and a domain-specific language (DSL), named IIS⁎CFuncLang, aimed at enabling a complete specification of application-specific functionalities at the \{PIM\} level. We have developed algorithms for transformation of IIS⁎CFuncLang specifications into executable program code, such as PL/SQL program code. In order to support specification of application-specific functionalities using IIS⁎CFuncLang, we have also developed appropriate tree-based and textual editors. The language, editors, and the transformations are embedded into a Model-Driven Software Development tool, named Integrated Information Systems \{CASE\} (IIS⁎Case). IIS⁎Case supports platform-independent design and automated prototyping of information systems, which allows us to verify and test our approach in practice. },
  doi      = {http://dx.doi.org/10.1016/j.cl.2015.03.003},
  groups   = {SCOPUS, ACM, Compendex,},
  issn     = {1477-8424},
  keywords = {Domain-specific languages, IIS⁎CFuncLang, Application-specific functionalities, Model transformations, IIS⁎Case },
  url      = {http://www.sciencedirect.com/science/article/pii/S1477842415000263},
}

@Article{Sarimbekov2014344,
  author   = {Aibek Sarimbekov and Yudi Zheng and Danilo Ansaloni and Lubomír Bulej and Lukáš Marek and Walter Binder and Petr Tůma and Zhengwei Qi},
  title    = {Dynamic program analysis—Reconciling developer productivity and tool performance},
  journal  = {Science of Computer Programming},
  year     = {2014},
  volume   = {95, Part 3},
  pages    = {344 - 358},
  note     = {Special Section: \{ACM\} SAC-SVT 2013 + Bytecode 2013},
  abstract = {Abstract Dynamic program analysis tools serve many important software engineering tasks such as profiling, debugging, testing, program comprehension, and reverse engineering. Many dynamic analysis tools rely on program instrumentation and are implemented using low-level instrumentation libraries, resulting in tedious and error-prone tool development. Targeting this issue, we have created the Domain-Specific Language for Instrumentation (DiSL), which offers high-level programming abstractions especially designed for instrumentation-based dynamic analysis. When designing DiSL, our goal was to boost the productivity of tool developers targeting the Java Virtual Machine, without impairing the performance of the resulting tools. In this paper we assess whether DiSL meets this goal. First, we perform a controlled experiment to measure tool development time and correctness of the developed tools, comparing DiSL with a prevailing, state-of-the-art instrumentation library. Second, we recast 10 open-source software engineering tools in DiSL and compare source code metrics and performance with the original implementations. Our studies show that DiSL significantly improves developer productivity, enables concise tool implementations, and does not have any negative impact on tool performance. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2014.03.014},
  groups   = {ScienceDirect},
  issn     = {0167-6423},
  keywords = {Dynamic program analysis, Bytecode instrumentation, Development productivity, Controlled experiment },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642314001543},
}

@Article{Basten20157,
  author   = {Bas Basten and Jeroen van den Bos and Mark Hills and Paul Klint and Arnold Lankamp and Bert Lisser and Atze van der Ploeg and Tijs van der Storm and Jurgen Vinju},
  title    = {Modular language implementation in Rascal – experience report},
  journal  = {Science of Computer Programming},
  year     = {2015},
  volume   = {114},
  pages    = {7 - 19},
  note     = {\{LDTA\} (Language Descriptions, Tools, and Applications) Tool Challenge},
  abstract = {Abstract All software evolves, and programming languages and programming language tools are no exception. And just like in ordinary software construction, modular implementations can help ease the process of changing a language implementation and its dependent tools. However, the syntactic and semantic dependencies between language features make this a challenging problem. In this paper we detail how programming languages can be implemented in a modular fashion using the Rascal meta-programming language. Rascal supports extensible definition of concrete syntax, abstract syntax and operations on concrete and abstract syntax trees like matching, traversal and transformation. As a result, new language features can be added without having to change existing code. As a case study, we detail our solution of the LDTA'11 Tool Challenge: a modular implementation of Oberon-0, a relatively simple imperative programming language. The approach we sketch can be applied equally well to the implementation of domain-specific languages. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2015.11.003},
  groups   = {ScienceDirect},
  issn     = {0167-6423},
  keywords = {Language engineering, Language workbench, Meta-programming, Modularity, Compiler generators },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642315003524},
}

@Article{CórdobaSánchez2016164,
  author   = {Irene Córdoba-Sánchez and Juan de Lara},
  title    = {Ann: A domain-specific language for the effective design and validation of Java annotations},
  journal  = {Computer Languages, Systems \& Structures},
  year     = {2016},
  volume   = {45},
  pages    = {164 - 190},
  abstract = {Abstract This paper describes a new modelling language for the effective design and validation of Java annotations. Since their inclusion in the 5th edition of Java, annotations have grown from a useful tool for the addition of meta-data to play a central role in many popular software projects. Usually they are not conceived in isolation, but in groups, with dependency and integrity constraints between them. However, the native support provided by Java for expressing this design is very limited. To overcome its deficiencies and make explicit the rich conceptual model which lies behind a set of annotations, we propose a domain-specific modelling language. The proposal has been implemented as an Eclipse plug-in, including an editor and an integrated code generator that synthesises annotation processors. The environment also integrates a model finder, able to detect unsatisfiable constraints between different annotations, and to provide examples of correct annotation usages for validation. The language has been tested using a real set of annotations from the Java Persistence \{API\} (JPA). Within this subset we have found enough rich semantics expressible with Ann and omitted nowadays by the Java language, which shows the benefits of Ann in a relevant field of application. },
  doi      = {http://dx.doi.org/10.1016/j.cl.2016.02.002},
  groups   = {SCOPUS, Compendex,},
  issn     = {1477-8424},
  keywords = {Model driven engineering, Domain-specific languages, Code generation, Java annotations, Model finders },
  url      = {http://www.sciencedirect.com/science/article/pii/S1477842416300318},
}

@Article{Acher2013657,
  author   = {Mathieu Acher and Philippe Collet and Philippe Lahire and Robert B. France},
  title    = {FAMILIAR: A domain-specific language for large scale management of feature models},
  journal  = {Science of Computer Programming},
  year     = {2013},
  volume   = {78},
  number   = {6},
  pages    = {657 - 681},
  note     = {Special section: The Programming Languages track at the 26th \{ACM\} Symposium on Applied Computing (SAC 2011) \&amp; Special section on Agent-oriented Design Methods and Programming Techniques for Distributed Computing in Dynamic and Complex Environments},
  abstract = {The feature model formalism has become the de facto standard for managing variability in software product lines (SPLs). In practice, developing an \{SPL\} can involve modeling a large number of features representing different viewpoints, sub-systems or concerns of the software system. This activity is generally tedious and error-prone. In this article, we present \{FAMILIAR\} a Domain-Specific Language (DSL) that is dedicated to the large scale management of feature models and that complements existing tool support. The language provides a powerful support for separating concerns in feature modeling, through the provision of composition and decomposition operators, reasoning facilities and scripting capabilities with modularization mechanisms. We illustrate how an \{SPL\} consisting of medical imaging services can be practically managed using reusable \{FAMILIAR\} scripts that implement reasoning mechanisms. We also report on various usages and applications of \{FAMILIAR\} and its operators, to demonstrate their applicability to different domains and use for different purposes. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2012.12.004},
  groups   = {Compendex, ACM},
  issn     = {0167-6423},
  keywords = {Domain-specific language, Feature model, Software product lines, Variability, Model management },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642312002158},
}

@Article{Dinkelaker2013615,
  author   = {Tom Dinkelaker and Michael Eichberg and Mira Mezini},
  title    = {Incremental concrete syntax for embedded languages with support for separate compilation},
  journal  = {Science of Computer Programming},
  year     = {2013},
  volume   = {78},
  number   = {6},
  pages    = {615 - 632},
  note     = {Special section: The Programming Languages track at the 26th \{ACM\} Symposium on Applied Computing (SAC 2011) \&amp; Special section on Agent-oriented Design Methods and Programming Techniques for Distributed Computing in Dynamic and Complex Environments},
  abstract = {Embedded domain-specific languages (EDSLs) are known to improve the productivity of developers. However, for many domains no \{DSL\} implementation is available and two important reasons for this are: First, the effort to implement \{EDSLs\} that provide the domain’s established syntax (called concrete syntax) is very high. Second, the \{EDSL\} and its underlying general-purpose programming language (GPL) are typically tightly integrated. This hampers reusability across different GPLs. Besides these implementation issues, the productivity gains of using \{EDSLs\} are also limited by the lack of explicit tool support for \{EDSL\} users—such as syntax highlighting or code analyses. In this paper, we present an approach that significantly reduces the necessary effort to implement embedded \{DSLs\} with concrete syntax. The idea is to use island grammars to specify the EDSL’s concrete syntax. This enables the developer to implement the embedded \{DSL\} as a library and to incrementally specify the concrete syntax using meta-data. Only those parts of the EDSL’s grammar need to be specified that deviate from the grammar of the GPL. By analyzing an EDSL’s implementation using reflection, it is possible to provide tool support for \{EDSLs\} without having the developer implement it explicitly, such as syntax highlighting. An evaluation demonstrates the feasibility of our approach by embedding a real-world \{DSL\} into a GPL. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2012.12.002},
  groups   = {Compendex, ACM, SCOPUS},
  issn     = {0167-6423},
  keywords = {Language embeddings, Domain-specific languages, Language design and implementation, Program transformation, Generic pre-processor },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642312002134},
}

@Article{Wells2012309,
  author   = {S. Wells and C.A. Reed},
  title    = {A domain specific language for describing diverse systems of dialogue},
  journal  = {Journal of Applied Logic},
  year     = {2012},
  volume   = {10},
  number   = {4},
  pages    = {309 - 329},
  note     = {Selected papers from the 6th International Conference on Soft Computing Models in Industrial and Environmental Applications},
  abstract = {This paper introduces the Dialogue Game Description Language (DGDL), a domain specific language for describing dialectical games. Communication is an important topic within agent research and is a fundamental factor in the development of robust and efficient multiagent systems. Similarly, argumentation has been recognised as a key component of an agentʼs ability to make decisions using complex, dynamic, uncertain, and incomplete knowledge. Dialectical games, a type of multi-player argumentative dialogue game, provide a mechanism for communication which incorporates argumentative behaviours. However there are very few tools for working with these games and little agreement over how they should be described, shared, and reused. The \{DGDL\} provides a grammar for determining whether a game description is syntactically correct and thus provides a foundation for new tools to support the future development and wider exploitation of dialectical games. },
  doi      = {http://dx.doi.org/10.1016/j.jal.2012.09.001},
  groups   = {SCOPUS,},
  issn     = {1570-8683},
  keywords = {Argumentation, Dialectical games, Agent communication, Online argumentation, Dialogue },
  url      = {http://www.sciencedirect.com/science/article/pii/S1570868312000602},
}

@Article{Saviankou20151343,
  author   = {Pavel Saviankou and Michael Knobloch and Anke Visser and Bernd Mohr},
  title    = {Cube v4: From Performance Report Explorer to Performance Analysis Tool},
  journal  = {Procedia Computer Science},
  year     = {2015},
  volume   = {51},
  pages    = {1343 - 1352},
  note     = {International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature},
  abstract = {Abstract Cube v3 has been a powerful tool to examine reports of the parallel performance tool Scalasca, but was basically unable to perform analyses on its own. With Cube v4, we addressed several shortcomings of Cube v3. We generalized the Cube data model, extended the list of supported data types, and allow operations with nontrivial algebras, e.g. for performance models or statistical data. Additionally, we introduced two major new features that greatly enhance the performance analysis features of Cube: Derived metrics and \{GUI\} plugins. Derived metrics can be used to create and manipulate metrics directly within the GUI, using a powerful domain-specific language called CubePL. Cube \{GUI\} plugins allow the development of novel performance analysis techniques and visualizations based on Cube data without changing the source code of the Cube GUI. },
  doi      = {http://dx.doi.org/10.1016/j.procs.2015.05.320},
  groups   = {SCOPUS, Compendex},
  issn     = {1877-0509},
  keywords = {Performance analysis, Call-tree profile, Derived metrics, DSL, GUI plugins },
  url      = {http://www.sciencedirect.com/science/article/pii/S187705091501128X},
}

@Article{Tyugashev2016120,
  author   = {Andrey A. Tyugashev},
  title    = {Language and Toolset for Visual Construction of Programs for Intelligent Autonomous Spacecraft Control},
  journal  = {IFAC-PapersOnLine},
  year     = {2016},
  volume   = {49},
  number   = {5},
  pages    = {120 - 125},
  note     = {4th \{IFAC\} Conference on Intelligent Control and Automation SciencesICONS 2016Reims, France, 1–3 June 2016},
  abstract = {Abstract The paper describes approach to Autonomous Fault Tolerant Intelligent Control of Spacecraft based on usage of Onboard Real-Time Interpreter of Integrated Control Programs, including special Diagnostic Routine. Rules of the Autonomous Control Program could be added or refined from Earth in operative manner by radio channel. Specially designed Visual Domain Specific Language allowing Control Logic Designers check, analyze and construct Rules in user friendly graphical environment excluding necessity to involve Software Developers. Proposed approach allows reducing of costs and labor consuming of Space Mission because of reducing of efforts needed for common-style Flight Control Software coding, multi-stage testing and support. Special Software Engineering Toolset that including Visualizer and Graphical Constructor of these autonomous control programs presented as well as the principles of its design and development. The Prototype of the Toolset has been successfully introduced at \{JSC\} Information Satellite Systems, Krasnoyarsk Region, Russia. },
  doi      = {http://dx.doi.org/10.1016/j.ifacol.2016.07.100},
  groups   = {SCOPUS},
  issn     = {2405-8963},
  keywords = {Autonomous Control, Satellite Control, Diagnostic Programs, Software Tools, Software Engineering, Domain Specific Language, Visual Software Construction },
  url      = {http://www.sciencedirect.com/science/article/pii/S2405896316302968},
}

@Article{Belusso2016229,
  author   = {Cássio L.M. Belusso and Sandro Sawicki and Fabricia Roos-Frantz and Rafael Z. Frantz},
  title    = {A Study of Petri Nets, Markov Chains and Queueing Theory as Mathematical Modelling Languages Aiming at the Simulation of Enterprise Application Integration Solutions: A First Step},
  journal  = {Procedia Computer Science},
  year     = {2016},
  volume   = {100},
  pages    = {229 - 236},
  note     = {International Conference on \{ENTERprise\} Information Systems/International Conference on Project MANagement/International Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / \{HCist\} 2016},
  abstract = {Abstract Enterprise Application Integration (EAI) is a research field that seeks to develop methodologies, techniques and tools to design and development integration solutions. The software ecosystem of companies is comprised of several applications, usually obtained from third parties or developed internally and custom-made for their business processes. Interest in \{EAI\} has arisen due to the need to integrate different applications composing the software ecosystem to allow business processes to evolve in response to the constant demands of the business market. The main challenge facing companies in this context is that most of their applications are not designed considering integration with other applications. The development of integration solutions is not a simple task. Guaraná technology provides a domain-specific language that allows for the design of conceptual models to represent integration solutions. This paper reports on a study of Petri Nets, Markov Chains and Queueing Theory, aiming to construct simulation models from conceptual models of integration solutions modeled with Guaraná. We map the building blocks Slot and Task of Guaraná to their corresponding elements in the mathematical modelling languages studied. },
  doi      = {http://dx.doi.org/10.1016/j.procs.2016.09.147},
  groups   = {ScienceDirect,},
  issn     = {1877-0509},
  keywords = {Enterprise Application Integration, Domain-Specific Language, Conceptual Model, Simulation },
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050916323158},
}

@InCollection{Bialy201739,
  author    = {M. Bialy and V. Pantelic and J. Jaskolka and A. Schaap and L. Patcas and M. Lawford and A. Wassyng},
  title     = {Software Engineering for Model-Based Development by Domain Experts},
  booktitle = {Handbook of System Safety and Security},
  publisher = {Syngress},
  year      = {2017},
  editor    = {Griffor, Edward},
  pages     = {39 - 64},
  address   = {Boston},
  abstract  = {Abstract Model-Based Development (MBD) has been gaining traction in the development of embedded software in many industries, especially in safety-critical domains. The models are typically described using domain-specific languages and tools that are readily accessible to the domain experts. Consequently, domain experts, despite not having formal software engineering training, find themselves creating models (designs) from which code is generated, thus effectively contributing to the design and coding activities of software development. This new role for domain experts as software developers can have a direct impact on the system safety if the domain experts do not follow software engineering best practices. In this chapter, we describe our experiences as software engineers in multiyear collaborations with domain experts from the automotive industry, who are developing embedded software with the \{MBD\} approach. We provide guidelines that strengthen the collaboration between domain experts and software engineers and improve the quality, and hence safety, of embedded software systems developed using MBD. We clarify the role of some of the most commonly used software engineering principles and artefacts, while also addressing issues and misconceptions encountered in adopting software engineering practices in MBD. Although this chapter focuses on the \{MBD\} of automotive embedded software in Matlab Simulink, the guidelines we provide are applicable to the \{MBD\} of software in general. },
  doi       = {http://dx.doi.org/10.1016/B978-0-12-803773-7.00003-6},
  groups    = {SCOPUS},
  isbn      = {978-0-12-803773-7},
  keywords  = {Software engineering, domain experts, functional safety, embedded software, model-based development, Simulink, automotive },
  url       = {http://www.sciencedirect.com/science/article/pii/B9780128037737000036},
}

@Article{Hoyos20132890,
  author   = {José R. Hoyos and Jesús García-Molina and Juan A. Botía},
  title    = {A domain-specific language for context modeling in context-aware systems},
  journal  = {Journal of Systems and Software},
  year     = {2013},
  volume   = {86},
  number   = {11},
  pages    = {2890 - 2905},
  abstract = {Abstract Context-awareness refers to systems that can both sense and react based on their environment. One of the main difficulties that developers of context-aware systems must tackle is how to manage the needed context information. In this paper we present MLContext, a textual Domain-Specific Language (DSL) which is specially tailored for modeling context information. It has been implemented by applying Model-Driven Development (MDD) techniques to automatically generate software artifacts from context models. The \{MLContext\} abstract syntax has been defined as a metamodel, and model-to text transformations have been written to generate the desired software artifacts. The concrete syntax has been defined with the \{EMFText\} tool, which generates an editor and model injector. \{MLContext\} has been designed to provide a high-level abstraction, to be easy to learn, and to promote reuse of context models. A domain analysis has been applied to elicit the requirements and design choices to be taken into account in creating the DSL. As a proof of concept of the proposal, the generative approach has been applied to two different middleware platforms for context management. },
  doi      = {http://dx.doi.org/10.1016/j.jss.2013.07.008},
  groups   = {SCOPUS, ACM, Compendex,},
  issn     = {0164-1212},
  keywords = {Model Driven Development, Context modeling, Context aware },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121213001696},
}

@Article{Antonelli201595,
  author   = {Humberto Lidio Antonelli and Elias Adriano N. da Silva and Renata Pontin M. Fortes},
  title    = {A Model-driven Development for Creating Accessible Web Menus},
  journal  = {Procedia Computer Science},
  year     = {2015},
  volume   = {67},
  pages    = {95 - 104},
  note     = {Proceedings of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion},
  abstract = {Abstract Web pages are composed by several elements that allow users to interact with available content. Some of these elements, such as menus, are responsible for assisting the navigation in the website, helping in the localization and access of the information requested by the user. However, many of menus available in Internet are not developed in an accessible manner, which creates accessibility barriers for many users, especially users with disabilities. Non-accessible menus hinder users find the information that they are looking for and therefore they can give up accessing the web site. This paper aims at addressing the problem by helping developers to create accessible web menus based on model-driven approach. Adopting this approach can help developers build accessible menus without knowing the technical details about accessibility. In direction to this objective, we initially studied the different types of menus and their structures, as well as the accessibility guidelines that involve creating accessible menus. From the study, we developed a meta-model that originated the \{DSL\} (Domain Specific Language) called \{AMenu\} (Accessible Menu). Then we included all the technical details about accessibility in the transformations. Finally, we presented an exploratory evaluation of DSL, discussing their efficiency and limitations. The results indicate a reduction in efforts for developing accessible web menus, since developers do not have to deal with technical details of accessibility. Our approach provides an alternative to traditional approaches to development for creating accessible web menus. The principles used in this study can be included in \{CASE\} tools and \{IDEs\} with great acceptance in the industry and therefore facilitate and disseminate the development of accessible systems. },
  doi      = {http://dx.doi.org/10.1016/j.procs.2015.09.253},
  groups   = {SCOPUS,},
  issn     = {1877-0509},
  keywords = {Accessibility, Navigability, Menu, Domain-specific Language },
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050915030999},
}

@Article{Visser201511,
  author   = {Eelco Visser},
  title    = {Understanding software through linguistic abstraction},
  journal  = {Science of Computer Programming},
  year     = {2015},
  volume   = {97, Part 1},
  pages    = {11 - 16},
  note     = {Special Issue on New Ideas and Emerging Results in Understanding Software},
  abstract = {Abstract In this essay, I argue that linguistic abstraction should be used systematically as a tool to capture our emerging understanding of domains of computation. Moreover, to enable that systematic application, we need to capture our understanding of the domain of linguistic abstraction itself in higher-level meta languages. The argument is illustrated with examples from the SDF, Stratego, Spoofax, and WebDSL projects in which I explore these ideas. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2013.12.001},
  groups   = {SCOPUS},
  issn     = {0167-6423},
  keywords = {Linguistic abstraction, Programming languages, Domain-specific languages, Software understanding },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642313003365},
}

@Article{LópezFernández2016104,
  author   = {Jesús J. López-Fernández and Esther Guerra and Juan de Lara},
  title    = {Combining unit and specification-based testing for meta-model validation and verification},
  journal  = {Information Systems},
  year     = {2016},
  volume   = {62},
  pages    = {104 - 135},
  abstract = {Abstract Meta-models play a cornerstone role in Model-Driven Engineering as they are used to define the abstract syntax of modelling languages, and so models and all sorts of model transformations depend on them. However, there are scarce tools and methods supporting their Validation and Verification (V&amp;V), which are essential activities for the proper engineering of meta-models. In order to fill this gap, we propose two complementary meta-model V&amp;V languages. The first one has similar philosophy to the xUnit framework, as it enables the definition of meta-model unit test suites comprising model fragments and assertions on their (in-)correctness. The second one is directed to express and verify expected properties of a meta-model, including domain and design properties, quality criteria and platform-specific requirements. As a proof of concept, we have developed tooling for both languages in the Eclipse platform, and illustrate its use within an example-driven approach for meta-model construction. The expressiveness of our languages is demonstrated by their application to build a library of meta-model quality issues, which has been evaluated over the \{ATL\} zoo of meta-models and some \{OMG\} specifications. The results show that integrated support for meta-model V&amp;V (as the one we propose here) is urgently needed in meta-modelling environments. },
  doi      = {http://dx.doi.org/10.1016/j.is.2016.06.008},
  groups   = {ACM},
  issn     = {0306-4379},
  keywords = {Model-driven engineering, Meta-modelling, Domain-specific modelling languages, Validation &amp; verification, Meta-model quality },
  url      = {http://www.sciencedirect.com/science/article/pii/S0306437916301934},
}

@Article{Poncelet2016143,
  author   = {Clement Poncelet and Florent Jacquemard},
  title    = {Model-based testing for building reliable realtime interactive music systems},
  journal  = {Science of Computer Programming},
  year     = {2016},
  volume   = {132, Part 2},
  pages    = {143 - 172},
  note     = {Special Issue on Software Verification and Testing (SAC-SVT'15)},
  abstract = {Abstract The role of an Interactive Music System (IMS) is to accompany musicians during live performances, acting like a real musician. It must react in realtime to audio signals from musicians, according to a timed high-level requirement called mixed score, written in a domain specific language. Such goals imply strong requirements of temporal reliability and robustness to unforeseen errors in input, yet not much addressed by the computer music community. We present the application of Model-Based Testing techniques and tools to a state-of-the-art IMS, including in particular: offline and on-the-fly approaches for the generation of relevant input data for testing (including timing values), with coverage criteria, the computation of the corresponding expected output, according to the semantics of a given mixed score, the black-box execution of the test data on the System Under Test and the production of a verdict. Our method is based on formal models in a dedicated intermediate representation, compiled directly from mixed scores (high-level requirements), and either passed, to the model-checker Uppaal (after conversion to Timed Automata) in the offline approach, or executed by a virtual machine in the online approach. Our fully automatic framework has been applied to real mixed scores used in concerts and the results obtained have permitted to identify bugs in the target IMS. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2016.08.002},
  groups   = {SCOPUS},
  issn     = {0167-6423},
  keywords = {Model based testing, Interactive music systems, Timed automata },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642316301022},
}

@Article{Lozano201573,
  author   = {Angela Lozano and Kim Mens and Andy Kellens},
  title    = {Usage contracts: Offering immediate feedback on violations of structural source-code regularities},
  journal  = {Science of Computer Programming},
  year     = {2015},
  volume   = {105},
  pages    = {73 - 91},
  abstract = {Abstract Developers often encode design knowledge through structural regularities such as \{API\} usage protocols, coding idioms and naming conventions. As these regularities express how the source code should be structured, they provide vital information for developers using or extending that code. Adherence to such regularities tends to deteriorate over time because they are not documented and checked explicitly. This paper introduces uContracts, an internal \{DSL\} to codify and verify such regularities as ‘usage contracts’. Our \{DSL\} aims at covering most common usage regularities, while still providing a means to express less common ones. Common regularities are identified based on regularities supported by existing approaches to detect bugs or suggest missing code fragments, techniques that mine for structural regularities, as well as on the analysis of an open-source project. We validate our \{DSL\} by documenting the structural regularities of an industrial case study, and analyse how useful the information provided by checking these regularities is for the developers of that case study. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2015.01.004},
  groups   = {SCOPUS},
  issn     = {0167-6423},
  keywords = {Software development tool support, Structural regularities, Source code analysis, Internal domain-specific language, IDE integration },
  url      = {http://www.sciencedirect.com/science/article/pii/S016764231500012X},
}

@Article{Dimitrieski2015299,
  author   = {Vladimir Dimitrieski and Milan Čeliković and Slavica Aleksić and Sonja Ristić and Abdalla Alargt and Ivan Luković},
  title    = {Concepts and evaluation of the extended entity-relationship approach to database design in a multi-paradigm information system modeling tool},
  journal  = {Computer Languages, Systems \& Structures},
  year     = {2015},
  volume   = {44, Part C},
  pages    = {299 - 318},
  abstract = {Abstract Different approaches to information system (IS) development are based on different data models. The selection of a data model for conceptual design, among other things, depends on the problem domain, the knowledge, and the personal preferences of an \{IS\} designer. In some situations, a simultaneous usage of different approaches to the conceptual database design and \{IS\} development may lead to the most appropriate solutions. In our previous research we have developed a tool that provides an evolutive and incremental approach to \{IS\} development, which is based on the form type data model. The approaches based on the Extended Entity-Relationship (EER) and class data models are broadly accepted throughout the community of \{IS\} designers. In order to support the simultaneous usage of approaches based on the form type, \{EER\} and class data models, we have developed the Multi-Paradigm Information System Modeling Tool (MIST). In this paper, we present a part of our \{MIST\} tool that supports \{EER\} approach to a database design. \{MIST\} components currently provide a formal specification of an \{EER\} database schema specification and its transformation into the relational data model, or the class model. Also, \{MIST\} allows generation of Structured Query Language code for a database creation and procedural code for implementing database constraints. In addition, Java code that stores and processes data from the database, may be generated from the class model. In this paper, we present the evaluation study of the \{MIST\} \{EER\} domain-specific language. Users' perceptions of language quality characteristics are used for the evaluation. },
  doi      = {http://dx.doi.org/10.1016/j.cl.2015.08.011},
  groups   = {Compendex, ACM, SCOPUS},
  issn     = {1477-8424},
  keywords = {Entity-relationship, Domain-specific language, Model transformation, Information system design, Evaluation study },
  url      = {http://www.sciencedirect.com/science/article/pii/S1477842415000615},
}

@Article{Kraisig2016407,
  author   = {Adriana R. Kraisig and Franciéli C. Welter and Igor G. Haugg and Roberto Cargnin and Fabricia Roos-Frantz and Sandro Sawicki and Rafael Z. Frantz},
  title    = {Mathematical Model for Simulating an Application Integration Solution in the Academic Context of Unijuí University},
  journal  = {Procedia Computer Science},
  year     = {2016},
  volume   = {100},
  pages    = {407 - 413},
  note     = {International Conference on \{ENTERprise\} Information Systems/International Conference on Project MANagement/International Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / \{HCist\} 2016},
  abstract = {Abstract The enterprise applications consist of a set of applications that make up the software ecosystem. These can be developed in-house or acquired from third party companies. Generally these applications are developed in order to meet a demands/specific business need of the company without worrying of interacting with another existing system. The area of Enterprise Application Integration (EAI) is able to provide all techniques and tools in order to integrate heterogeneous applications software ecosystem of companies. The Guaraná \{DSL\} is a language that enables designing conceptual models of integration solutions using a concrete graphical and intuitive syntax. Integrating the applications is not a trivial task and solution development involves addition of costs (time and resources), risks such as the appearance of bugs that most often are observed only after the implementation of the conceptual model. In this paper we propose a simulation model using Petri Nets that enable the analysis of the behavior of an integration solution developed to a real-world integration problem at Unijuí University. },
  doi      = {http://dx.doi.org/10.1016/j.procs.2016.09.176},
  groups   = {ScienceDirect},
  issn     = {1877-0509},
  keywords = {Enterprise Application Integration, Domain-Specific Language, Conceptual Model, Simulation Model, Petri Nets },
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050916323444},
}

@Article{Cazzola201616,
  author   = {Walter Cazzola and Edoardo Vacchi},
  title    = {Language components for modular \{DSLs\} using traits},
  journal  = {Computer Languages, Systems \& Structures},
  year     = {2016},
  volume   = {45},
  pages    = {16 - 34},
  abstract = {Abstract Recent advances in tooling and modern programming languages have progressively brought back the practice of developing domain-specific languages as a means to improve software development. Consequently, the problem of making composition between languages easier by emphasizing code reuse and componentized programming is a topic of increasing interest in research. In fact, it is not uncommon for different languages to share common features, and, because in the same project different \{DSLs\} may coexist to model concepts from different problem areas, it is interesting to study ways to develop modular, extensible languages. Earlier work has shown that traits can be used to modularize the semantics of a language implementation; a lot of attention is often spent on embedded DSLs; even when external \{DSLs\} are discussed, the main focus is on modularizing the semantics. In this paper we will show a complete trait-based approach to modularize not only the semantics but also the syntax of external DSLs, thereby simplifying extension and therefore evolution of a language implementation. We show the benefits of implementing these techniques using the Scala programming language. },
  doi      = {http://dx.doi.org/10.1016/j.cl.2015.12.001},
  groups   = {ACM},
  issn     = {1477-8424},
  url      = {http://www.sciencedirect.com/science/article/pii/S1477842415300208},
}

@Article{Dubois2014199,
  author   = {Emmanuel Dubois and Christophe Bortolaso and Damien Appert and Guillaume Gauffre},
  title    = {An MDE-based framework to support the development of Mixed Interactive Systems},
  journal  = {Science of Computer Programming},
  year     = {2014},
  volume   = {89, Part B},
  pages    = {199 - 221},
  note     = {Special issue on Success Stories in Model Driven Engineering},
  abstract = {Abstract In the domain of Human–Computer Interaction (HCI), recent advances in sensors, communication technologies, miniaturization and computing capabilities have led to new and advanced forms of interaction. Among them, Mixed Interactive Systems (MIS), form a class of interactive systems that comprises augmented reality, tangible interfaces and ambient computing; \{MIS\} aim to take advantage of physical and digital worlds to promote a more transparent integration of interactive systems with the user’s environment. Due to the constant change of technologies and the multiplicity of these interaction forms, specific development approaches have been developed. As a result, numerous taxonomies, frameworks, \{API\} and models have emerged, each one covering a specific and limited aspect of the development of MIS. To support a coherent use of these multiple development resources and contribute to the increasing popularity of MIS, we have developed a framework based on Model-Driven Engineering. The goal is to take advantage of Model-Driven Engineering (MDE) standards, methodology and tools to support the manipulation of complementary Domain Specific Languages (DSL), to organize and link the use of different design and implementation resources, and to ensure a rationalized implementation based on design choices. In this paper, we first summarize existing uses of \{MDE\} in \{HCI\} before focusing on five major benefits \{MDE\} can provide in a \{MIS\} development context. We then detail which \{MDE\} tools and resources support these benefits and thus form the pillars of the success of an MDE-based \{MIS\} development approach. Based on this analysis, we introduce our framework, called Guide-Me, and illustrate its use through a case study. This framework includes two design models. Model transformations are also included to link one model to another; as a result the frameworks coverage extends from the earliest design step to a software component-based prototyping platform. A toolset based on the Eclipse Modeling Framework (EMF) that supports the use of the framework is also presented. We finally assess our MDE-based development process for \{MIS\} based on the five major \{MDE\} benefits for MIS. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2013.03.007},
  groups   = {SCOPUS, ACM,},
  issn     = {0167-6423},
  keywords = {Mixed Interactive System, Model-Driven Engineering, Development process, Domain-specific language, Flexible model transformation },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642313000671},
}
@article{Rangarajan2014124,
title = "Language-oriented rule-based reaction network generation and analysis: Algorithms of \{RING\} ",
journal = "Computers & Chemical Engineering ",
volume = "64",
number = "",
pages = "124 - 137",
year = "2014",
note = "",
issn = "0098-1354",
doi = "http://dx.doi.org/10.1016/j.compchemeng.2014.02.007",
url = "http://www.sciencedirect.com/science/article/pii/S0098135414000398",
author = "Srinivas Rangarajan and Ted Kaminski and Eric Van Wyk and Aditya Bhan and Prodromos Daoutidis",
keywords = "Automated reaction network generation",
keywords = "Isomer lumping",
keywords = "Reaction network analysis",
keywords = "Kinetic modeling",
keywords = "Domain-specific languages",
keywords = "Extensible languages ",
abstract = "Abstract The underlying algorithms of the language interface and post-generation analysis modules in RING, a network generation and analysis tool, are discussed. The front-end is a domain-specific reaction language developed with Silver, a meta-language based on attribute grammars. The language compiler translates user inputs written as a program into internal instructions, catches syntactic and semantic errors, and performs domain-specific optimization to speed up execution. In addition to generating reaction networks, \{RING\} allows post-processing analysis options to: (a) obtain reaction pathways and overall mechanisms from initial reactants to desired products using graph traversal algorithms, (b) group together isomers to reduce the size of the network through a novel molecule hashing technique, (c) calculate thermochemical quantities through semi-empirical methods such as group additivity, and (d) formulate and solve kinetic models of the entire or lumped complex network based on a rule-based kinetics specification scheme. "
}

@Article{Urma2015127,
  author   = {Raoul-Gabriel Urma and Alan Mycroft},
  title    = {Source-code queries with graph databases—with application to programming language usage and evolution},
  journal  = {Science of Computer Programming},
  year     = {2015},
  volume   = {97, Part 1},
  pages    = {127 - 134},
  note     = {Special Issue on New Ideas and Emerging Results in Understanding Software},
  abstract = {Abstract Program querying and analysis tools are of growing importance, and occur in two main variants. Firstly there are source-code query languages which help software engineers to explore a system, or to find code in need of refactoring as coding standards evolve. These also enable language designers to understand the practical uses of language features and idioms over a software corpus. Secondly there are program analysis tools in the style of Coverity which perform deeper program analysis searching for bugs as well as checking adherence to coding standards such as MISRA. The former class are typically implemented on top of relational or deductive databases and make ad-hoc trade-offs between scalability and the amount of source-code detail held—with consequent limitations on the expressiveness of queries. The latter class are more commercially driven and involve more ad-hoc queries over program representations, nonetheless similar pressures encourage user-visible domain-specific languages to specify analyses. We argue that a graph data model and associated query language provides a unifying conceptual model and gives efficient scalable implementation even when storing full source-code detail. It also supports overlays allowing a query \{DSL\} to pose queries at a mixture of syntax-tree, type, control-flow-graph or data-flow levels. We describe a prototype source-code query system built on top of Neo4j using its Cypher graph query language; experiments show it scales to multi-million-line programs while also storing full source-code detail. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2013.11.010},
  groups   = {ScienceDirect},
  issn     = {0167-6423},
  keywords = {Programming language evolution, Source-code queries and DSLs, Graph databases },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642313002943},
}

@Article{Özacar201636,
  author   = {Tuğba Özacar},
  title    = {A tool for producing structured interoperable data from product features on the web},
  journal  = {Information Systems},
  year     = {2016},
  volume   = {56},
  pages    = {36 - 54},
  abstract = {Abstract This paper introduces a tool that produces structured interoperable data from product features, i.e., attribute name–value pairs, on the web. The tool extracts the product features using a web site-specific template created by the user. The value of the extracted data is maximized by using GoodRelations, which is the standard vocabulary for modeling product types and their features. The final output of the tool is GoodRelations snippets, which contain product features encoded in \{RDFa\} or Microdata. These snippets can be embedded into existing static and dynamic web pages in a way accessible to major search engines like Google and Yahoo, mobile applications, and browser extensions. This increases the visibility of your products and services in the latest generation of search engines, recommender systems, and other novel applications. },
  doi      = {http://dx.doi.org/10.1016/j.is.2015.09.002},
  groups   = {ScienceDirect,},
  issn     = {0306-4379},
  keywords = {Information extraction, GoodRelations, Protégé, Web scraping, Ontology, Rich snippets },
  url      = {http://www.sciencedirect.com/science/article/pii/S0306437915001660},
}

@Article{Rangarajan2012114,
  author   = {Srinivas Rangarajan and Aditya Bhan and Prodromos Daoutidis},
  title    = {Language-oriented rule-based reaction network generation and analysis: Description of \{RING\}},
  journal  = {Computers \& Chemical Engineering},
  year     = {2012},
  volume   = {45},
  pages    = {114 - 123},
  abstract = {The input and output formats, and the structure of Rule Input Network Generator (RING), a computational tool for generation and analysis of complex reaction networks, are described with reference to the underlying algorithms from Cheminformatics and graph theory. \{RING\} consists of three modules: (a) a compiler that translates inputs written as a program in an English-like reaction language into internal representations and instructions, (b) a network generator that constructs an exhaustive reaction network from reaction rules and initial reactants specified, and (c) a post-processing module that can extract pathways, mechanisms, or lumps from the network based on user-specified instructions. \{RING\} can be used, in a rule-based manner, for constructing a large and complex reaction network from a set of elementary/overall reaction rules, and for elucidating transformations occurring in these networks through identifying pathways and mechanisms to specified products. \{RING\} is available open under \{GNU\} Lesser GPL. },
  doi      = {http://dx.doi.org/10.1016/j.compchemeng.2012.06.008},
  groups   = {SCOPUS},
  issn     = {0098-1354},
  keywords = {Rule-based network generation, Reaction network analysis, Pathway analysis, Mechanism elucidation, Domain specific language interface },
  url      = {http://www.sciencedirect.com/science/article/pii/S0098135412001846},
}

@Article{Marek2015100,
  author   = {Lukáš Marek and Yudi Zheng and Danilo Ansaloni and Lubomír Bulej and Aibek Sarimbekov and Walter Binder and Petr Tůma},
  title    = {Introduction to dynamic program analysis with DiSL},
  journal  = {Science of Computer Programming},
  year     = {2015},
  volume   = {98, Part 1},
  pages    = {100 - 115},
  note     = {Fifth issue of Experimental Software and Toolkits (EST): A special issue on Academics Modelling with Eclipse (ACME2012)},
  abstract = {Abstract Dynamic program analysis (DPA) tools assist in many software engineering and development tasks, such as profiling, program comprehension, and performance model construction and calibration. On the Java platform, many \{DPA\} tools are implemented either using aspect-oriented programming (AOP), or rely on bytecode instrumentation to modify the base program code. The pointcut/advice model found in \{AOP\} enables rapid tool development, but does not allow expressing certain instrumentations due to limitations of mainstream \{AOP\} languages—developers thus use bytecode manipulation to gain more expressiveness and performance. However, while the existing bytecode manipulation libraries handle some low-level details, they still make tool development tedious and error-prone. Targeting this issue, we provide the first complete presentation of DiSL, an open-source instrumentation framework that reconciles the conciseness of the \{AOP\} pointcut/advice model and the expressiveness and performance achievable with bytecode manipulation libraries. Specifically, we extend our previous work to provide an overview of the DiSL architecture, advanced features, and the programming model. We also include case studies illustrating successful deployment of DiSL-based \{DPA\} tools. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2014.01.003},
  groups   = {ACM, SCOPUS},
  issn     = {0167-6423},
  keywords = {Dynamic program analysis, Bytecode instrumentation, Aspect-oriented programming, Domain-specific languages, Java Virtual Machine },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642314000070},
}

@Article{Chanti20141625,
  author   = {H. Chanti and L. Thiry and M. Hassenforder and J-F. Brillhac and P. Fromy},
  title    = {Formalization and composition of languages for the modeling of fire safety systems},
  journal  = {\{IFAC\} Proceedings Volumes},
  year     = {2014},
  volume   = {47},
  number   = {3},
  pages    = {1625 - 1630},
  note     = {19th \{IFAC\} World Congress},
  abstract = {Abstract Modeling complex systems, such as the ones found in the certification of fire protection systems, generally requires the intervention of many specialists, each one using its own formalisms, concepts and tools. To model such systems, many specific languages are required and to be integrated they should be formally described. In this proposal, we suggest to use functional programming concepts to formalize and integrate the languages involved in the field of fire safety systems. Formalization is done by specifying constructor functions and integration by the way of generic/higher-order functions. },
  doi      = {http://dx.doi.org/10.3182/20140824-6-ZA-1003.01900},
  groups   = {SCOPUS},
  issn     = {1474-6670},
  keywords = {Domain Specific Languages, functional programming, fire safety },
  url      = {http://www.sciencedirect.com/science/article/pii/S1474667016418458},
}

@Article{Salehi201663,
  author   = {Pejman Salehi and Abdelwahab Hamou-Lhadj and Maria Toeroe and Ferhat Khendek},
  title    = {A UML-based domain specific modeling language for service availability management: Design and experience},
  journal  = {Computer Standards \& Interfaces},
  year     = {2016},
  volume   = {44},
  pages    = {63 - 83},
  abstract = {Abstract For critical systems, providing services with minimal interruption is essential. Availability Management Framework (AMF), defined by \{SA\} Forum for managing highly-available applications, requires configurations of applications consisting of various entities organized according to AMF-specific rules and constraints. Creating such configurations is difficult due to the numerous constrained entities involved. This paper presents \{UACL\} (UML-based \{AMF\} Configuration Language) and a supporting implementation that models the \{AMF\} domain, providing designers with tools needed to design, edit, and analyze \{AMF\} configurations. \{UACL\} is an extension of \{UML\} through its profiling mechanism and has been designed to represent \{AMF\} concepts, their relations, and constraints. },
  doi      = {http://dx.doi.org/10.1016/j.csi.2015.09.009},
  groups   = {SCOPUS,},
  issn     = {0920-5489},
  keywords = {Domain-specific modeling languages, UML profiles, High-availability, Availability Management Framework Standard, Service Availability Forum },
  url      = {http://www.sciencedirect.com/science/article/pii/S0920548915001063},
}

@Article{Haitzer2014135,
  author   = {Thomas Haitzer and Uwe Zdun},
  title    = {Semi-automated architectural abstraction specifications for supporting software evolution},
  journal  = {Science of Computer Programming},
  year     = {2014},
  volume   = {90, Part B},
  pages    = {135 - 160},
  note     = {Special Issue on Component-Based Software Engineering and Software Architecture},
  abstract = {Abstract In this paper we present an approach for supporting the semi-automated architectural abstraction of architectural models throughout the software life-cycle. It addresses the problem that the design and implementation of a software system often drift apart as software systems evolve, leading to architectural knowledge evaporation. Our approach provides concepts and tool support for the semi-automatic abstraction of architecture component and connector views from implemented systems and keeping the abstracted architecture models up-to-date during software evolution. In particular, we propose architecture abstraction concepts that are supported through a domain-specific language (DSL). Our main focus is on providing architectural abstraction specifications in the \{DSL\} that only need to be changed, if the architecture changes, but can tolerate non-architectural changes in the underlying source code. Once the software architect has defined an architectural abstraction in the DSL, we can automatically generate architectural component views from the source code using model-driven development (MDD) techniques and check whether architectural design constraints are fulfilled by these models. Our approach supports the automatic generation of traceability links between source code elements and architectural abstractions using \{MDD\} techniques to enable software architects to easily link between components and the source code elements that realize them. It enables software architects to compare different versions of the generated architectural component view with each other. We evaluate our research results by studying the evolution of architectural abstractions in different consecutive versions of five open source systems and by analyzing the performance of our approach in these cases. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2013.10.004},
  groups   = {Compendex, SCOPUS},
  issn     = {0167-6423},
  keywords = {Architectural abstraction, Architectural component and connector views, Software evolution, UML, Model transformation },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642313002542},
}

@Article{Kos201674,
  author   = {Tomaž Kos and Marjan Mernik and Tomaž Kosar},
  title    = {Test automation of a measurement system using a domain-specific modelling language},
  journal  = {Journal of Systems and Software},
  year     = {2016},
  volume   = {111},
  pages    = {74 - 88},
  abstract = {Abstract The construction of domain-specific modelling languages (DSMLs) is only the first step within the needed toolchain. Models need to be maintained, modified or functional errors searched for. Therefore, tool support is vital for the \{DSML\} end-user’s efficiency. This paper presents SeTT, a simple but very useful tool for \{DSML\} end-users, a testing framework integrated within a \{DSML\} Sequencer. This Sequencer, part of the \{DEWESoft\} data acquisition system, supports the development of model-based tests using a high-level abstraction. The tests are used during the whole data acquisition process and able to test different systems’ parts. This paper shows how high-level specifications can be extended to describe a testing infrastructure for a specific DSML. In this manner, the Sequencer and SeTT were combined at the metamodel level. The contribution of the paper is to show that one can leverage on the \{DSML\} to build a testing framework with relatively little effort, by implementing assertions to it. },
  doi      = {http://dx.doi.org/10.1016/j.jss.2015.09.002},
  groups   = {SCOPUS, Compendex},
  issn     = {0164-1212},
  keywords = {Test automation, Domain-specific modelling languages, Usage experience },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121215002058},
}

@Article{Ebrahimi2014338,
  author   = {Amir Hossein Ebrahimi and Pierre E.C. Johansson and Kristofer Bengtsson and Knut Åkesson},
  title    = {Managing Product and Production Variety – A Language Workbench Approach},
  journal  = {Procedia \{CIRP\}},
  year     = {2014},
  volume   = {17},
  pages    = {338 - 344},
  note     = {Variety Management in ManufacturingProceedings of the 47th \{CIRP\} Conference on Manufacturing Systems},
  abstract = {Abstract Product platforms are commonly used in industries with complex products and high competition like the car and truck industry to allow a customer to order a product that satisfy its unique needs. A consequence of product variety is that manufacturing and assembly processes need to deal with this variety as well. If the variety is low and changes of the product occur infrequently then the variety may be handled by designing the production system for a small set of typical products. But as the variety increases and changes become frequent the necessity for integrated product and production information model is high, to partially solve this problem Product Life Cycle Management (PLM) systems aim at providing an integrated model to all categories of users, e.g. product designers, product preparation engineers, line builders and shop-floor workers. All users need to access the information in the platform and refine and modify the information to reflect new knowledge that has been acquired. Today, most often multiple systems are used where some systems may store information in a structured way but often unstructured text documents are also used. This easily results in redundant information models and automated analysis is not feasible or not event possible because of issues regarding cohesion and traceability of information. The contribution in this paper is to discuss how a new type of tool for building domain specific languages and editors using language workbench approach can be used to support the different user categories in their tasks working with variability of a product and production system while at the same time provide cohesion and traceability of information. },
  doi      = {http://dx.doi.org/10.1016/j.procir.2014.01.100},
  groups   = {ScienceDirect},
  issn     = {2212-8271},
  keywords = {product life cycle management, mass customization, product platform, process platform, knowledge managment, variability },
  url      = {http://www.sciencedirect.com/science/article/pii/S2212827114003588},
}

@Article{Barclay2015490,
  author   = {Jack Barclay and Vimal Dhokia and Aydin Nassehi},
  title    = {Generating Milling Tool Paths for Prismatic Parts Using Genetic Programming},
  journal  = {Procedia \{CIRP\}},
  year     = {2015},
  volume   = {33},
  pages    = {490 - 495},
  note     = {9th \{CIRP\} Conference on Intelligent Computation in Manufacturing Engineering - \{CIRP\} \{ICME\} '14},
  abstract = {Abstract The automatic generation of milling tool paths traditionally relies on applying complex tool path generation algorithms to a geometric model of the desired part. For parts with unusual geometries or intricate intersections between sculpted surfaces, manual intervention is often required when normal tool path generation methods fail to produce efficient tool paths. In this paper, a simplified model of the machining process is used to create a domain-specific language that enables tool paths to be generated and optimised through an evolutionary process - formulated, in this case, as a genetic programming system. The driving force behind the optimisation is a fitness function that promotes tool paths whose result matches the desired part geometry and favours those that reach their goal in fewer steps. Consequently, the system is not reliant on tool path generation algorithms, but instead requires a description of the desired characteristics of a good solution, which can then be used to measure and evaluate the relative performance of the candidate solutions that are generated. The performance of the system is less sensitive to different geometries of the desired part and doesn’t require any additional rules to deal with changes to the initial stock (e.g. when rest roughing). The method is initially demonstrated on a number of simple test components and the genetic programming process is shown to positively influence the outcome. Further tests and extensions to the work are presented. },
  doi      = {http://dx.doi.org/10.1016/j.procir.2015.06.060},
  groups   = {SCOPUS, Compendex},
  issn     = {2212-8271},
  keywords = {Computer numerical control (CNC), Milling, Genetic programming },
  url      = {http://www.sciencedirect.com/science/article/pii/S2212827115007039},
}

@Article{Molina20131772,
  author   = {Ana I. Molina and Jesús Gallardo and Miguel A. Redondo and Manuel Ortega and William J. Giraldo},
  title    = {Metamodel-driven definition of a visual modeling language for specifying interactive groupware applications: An empirical study},
  journal  = {Journal of Systems and Software},
  year     = {2013},
  volume   = {86},
  number   = {7},
  pages    = {1772 - 1789},
  abstract = {This work is framed in the area of software development for Computer Supported Cooperative Work (CSCW). These software systems are called groupware systems. The development of groupware systems is a complex task, a problem that can be addressed applying the Model Driven Engineering (MDE) principles and techniques, where the use of models is essential. However, there are no proposals to address all issues to model in this kind of application (group work, shared context, coordination, etc.) and, in particular, there are no proposals that consider the modeling of both interactive and collaborative issues. To solve this deficiency, a domain-specific language (DSL) called Collaborative Interactive Application Notation (CIAN) has been proposed. To define this \{DSL\} a metamodel has been created describing the universe of discourse of the applications supporting interactive group work. We have defined the syntax and semantics of this language. We have also implemented a tool (called CIAT) for supporting the edition and validation of models created with CIAN. This tool has been implemented using the metamodeling facilities provided by the Eclipse platform. Finally, an empirical study was conducted with the aim of verifying the suitability of this approach and the perception of software engineers about its usefulness. The results obtained show that our proposal can facilitate the development process of groupware systems. },
  doi      = {http://dx.doi.org/10.1016/j.jss.2012.07.049},
  groups   = {SCOPUS, ACM, Compendex},
  issn     = {0164-1212},
  keywords = {Groupware design, Interaction Design, DSL, Metamodel, MDE },
  url      = {http://www.sciencedirect.com/science/article/pii/S016412121200221X},
}

@Article{Sloane201520,
  author   = {Anthony M. Sloane and Matthew Roberts},
  title    = {Oberon-0 in Kiama},
  journal  = {Science of Computer Programming},
  year     = {2015},
  volume   = {114},
  pages    = {20 - 32},
  note     = {\{LDTA\} (Language Descriptions, Tools, and Applications) Tool Challenge},
  abstract = {Abstract The Kiama language processing library is a collection of domain-specific languages for software language processing embedded in the Scala programming language. The standard Scala parsing library is augmented by Kiama's facilities for defining attribute grammars, strategy-based rewriting rules and combinator-based pretty-printing. We describe how we used Kiama to implement an Oberon-0 compiler as part of the 2011 \{LDTA\} Tool Challenge. In addition, we explain how Scala enabled a modular approach to the challenge. Traits were used to define components that addressed the processing tasks for each Oberon-0 sub-language. Combining the traits as mixins yielded the challenge artefacts. We conclude by reflecting on the strengths and weaknesses of Kiama that were revealed by the challenge and point to some future directions. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2015.10.010},
  groups   = {SCOPUS, ACM},
  issn     = {0167-6423},
  keywords = {Oberon-0, Attribute grammars, Term rewriting, Scala, Mixins },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642315003032},
}

@Article{Helfer2015994,
  author   = {Thomas Helfer and Bruno Michel and Jean-Michel Proix and Maxime Salvo and Jérôme Sercombe and Michel Casella},
  title    = {Introducing the open-source mfront code generator: Application to mechanical behaviours and material knowledge management within the \{PLEIADES\} fuel element modelling platform},
  journal  = {Computers \& Mathematics with Applications},
  year     = {2015},
  volume   = {70},
  number   = {5},
  pages    = {994 - 1023},
  abstract = {Abstract The \{PLEIADES\} software environment is devoted to the thermomechanical simulation of nuclear fuel elements behaviour under irradiation. This platform is co-developed in the framework of a research cooperative program between Électricité de France (EDF), \{AREVA\} and the French Atomic Energy Commission (CEA). As many thermomechanical solvers are used within the platform, one of the PLEAIADES’s main challenge is to propose a unified software environment for capitalisation of material knowledge coming from research and development programs on various nuclear systems. This paper introduces a tool called mfront which is basically a code generator based on C++  (Stroustrup and Eberhardt, 2004). Domain specific languages are provided which were designed to simplify the implementations of new material properties, mechanical behaviours and simple material models. mfront was recently released under the \{GPL\} open-source licence and is available on its web site: http://tfel.sourceforge.net/. The authors hope that it will prove useful for researchers and engineers, in particular in the field of solid mechanics. mfront interfaces generate code specific to each solver and language considered. In this paper, after a general overview of mfront functionalities, a particular focus is made on mechanical behaviours which are by essence more complex and may have significant impact on the numerical performances of mechanical simulations. mfront users can describe all kinds of mechanical phenomena, such as viscoplasticity, plasticity and damage, for various types of mechanical behaviour (small strain or finite strain behaviour, cohesive zone models). Performance benchmarks, performed using the Code_Aster finite element solver, show that the code generated using mfront is in most cases on par or better than the behaviour implementations written in fortran natively available in this solver. The material knowledge management strategy that was set up within the \{PLEIADES\} platform is briefly discussed. A material database named sirius proposes a rigorous material verification workflow. We illustrate the use of mfront through two case of studies: a simple \{FFC\} single crystal viscoplastic behaviour and the implementation of a recent behaviour for the fuel material which describes various phenomena: fuel cracking, plasticity and viscoplasticity. },
  doi      = {http://dx.doi.org/10.1016/j.camwa.2015.06.027},
  groups   = {SCOPUS},
  issn     = {0898-1221},
  keywords = {Material knowledge management, Mechanical behaviour integration, Implicit integration schemes, Single crystal plasticity, Domain specific languages },
  url      = {http://www.sciencedirect.com/science/article/pii/S0898122115003132},
}

@Article{Basso2016612,
  author   = {Fábio Paulo Basso and Raquel Mainardi Pillat and Toacy Cavalcante Oliveira and Fabricia Roos-Frantz and Rafael Z. Frantz},
  title    = {Automated design of multi-layered web information systems},
  journal  = {Journal of Systems and Software},
  year     = {2016},
  volume   = {117},
  pages    = {612 - 637},
  abstract = {Abstract In the development of web information systems, design tasks are commonly used in approaches for Model-Driven Web Engineering (MDWE) to represent models. To generate fully implemented prototypes, these models require a rich representation of the semantics for actions (e.g., database persistence operations). In the development of some use case scenarios for the multi-layered development of web information systems, these design tasks may consume weeks of work even for experienced designers. The literature pointed out that the impossibility for executing a software project with short iterations hampers the adoption of some approaches for design in some contexts, such as start-up companies. A possible solution to introduce design tasks in short iterations is the use of automated design techniques, which assist the production of models by means of transformation tasks and refinements. This paper details our methodology for MDWE, which is supported by automated design techniques strictly associated with use case patterns of type CRUD. The novelty relies on iterations that are possible for execution with short time-scales. This is a benefit from automated design techniques not observed in \{MDWE\} approaches based on manual design tasks. We also report on previous experiences and address open questions relevant for the theory and practice of MDWE. },
  doi      = {http://dx.doi.org/10.1016/j.jss.2016.04.060},
  groups   = {ScienceDirect,},
  issn     = {0164-1212},
  keywords = {Model-driven web engineering, Rapid application prototype, Domain-specific language, Prototyping, Automated design, Mockup, Experience report },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121216300358},
}

@Article{Clark2015589,
  author   = {Tony Clark},
  title    = {XPL: A language for modular homogeneous language embedding},
  journal  = {Science of Computer Programming},
  year     = {2015},
  volume   = {98, Part 4},
  pages    = {589 - 616},
  abstract = {Abstract Languages that are used for Software Language Engineering (SLE) offer a range of features that support the construction and deployment of new languages. \{SLE\} languages offer features for constructing and processing syntax and defining the semantics of language features. New languages may be embedded within an existing language (internal) or may be stand-alone (external). Modularity is a desirable \{SLE\} property for which there is no generally agreed approach. This article analyses the current tools for \{SLE\} and identifies the key features that are common. It then proposes a language called \{XPL\} that supports these features. \{XPL\} is higher-order and allows languages to be constructed and manipulated as first-class elements and therefore can be used to represent a range of approaches to modular language definition. This is validated by using \{XPL\} to define the notion of a language module that supports modular language construction and language transformation. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2014.08.005},
  groups   = {SCOPUS},
  issn     = {0167-6423},
  keywords = {Domain specific languages, Software language engineering, Language modules },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642314003670},
}

@Article{Rakotoarivelo2014173,
  author   = {Thierry Rakotoarivelo and Guillaume Jourjon and Max Ott},
  title    = {Designing and orchestrating reproducible experiments on federated networking testbeds},
  journal  = {Computer Networks},
  year     = {2014},
  volume   = {63},
  pages    = {173 - 187},
  note     = {Special issue on Future Internet Testbeds − Part \{II\}},
  abstract = {Abstract In addition to theoretical analysis and simulations, the evaluation of new networking technologies in a real-life context and scale is critical to their global adoption and deployment. Federations of experimental platforms (aka testbeds) offer a controlled and cost-effective solution to perform such an evaluation. Most recent efforts in that area focused on building those facilities and providing experimenters with tools to allow the discovery and provisioning of their shared resources. Many challenges remain in order to support the complete experiment life cycle in a federated environment. We propose OMF-F, a framework which allows the definition of networking experiments and their execution over shared resources provided by different federated administrative domains. OMF-F provides a domain-specific language enabling rich event-based experiment descriptions. It defines a specific resource model and protocol, which together with its publish-subscribe messaging system allows automatic experiment orchestrations at a large scale. OMF-F further provides interfaces to operate with existing resource discovery and provisioning tools for federated testbeds. Our contributions in this paper are threefold. First we provide detailed descriptions of OMF-F’s design, its architecture, and its involved entities. Then, we present a quantitative evaluation of its underlying messaging and event-handling systems. Finally, we discuss two real examples of OMF-F deployed and used on federated domains to define and execute experiments. },
  doi      = {http://dx.doi.org/10.1016/j.bjp.2013.12.033},
  groups   = {ScienceDirect},
  issn     = {1389-1286},
  keywords = {Federation, Testbeds, Experiment definition and orchestration },
  url      = {http://www.sciencedirect.com/science/article/pii/S1389128613004465},
}

@Article{Rupanov2014161,
  author   = {V. Rupanov and C. Buckl and L. Fiege and M. Armbruster and A. Knoll and G. Spiegelberg},
  title    = {Employing early model-based safety evaluation to iteratively derive E/E architecture design},
  journal  = {Science of Computer Programming},
  year     = {2014},
  volume   = {90, Part B},
  pages    = {161 - 179},
  note     = {Special Issue on Component-Based Software Engineering and Software Architecture},
  abstract = {Abstract \{ISO\} 26262 addresses development of safe in-vehicle functions by specifying methods potentially used in the design and development lifecycle. It does not indicate what is sufficient and leaves room for interpretation. Yet the architects of electric/electronic systems need design boundaries to make decisions during architecture evolutionary design without adding a risk of late changes. Correct selection of safety mechanisms from alternatives at early design stages is vital for time-to-market of critical systems. In this paper we present and discuss an iterative architecture design and refinement process that is centered around \{ISO\} 26262 requirements and model-based analysis of safety-related metrics. This process simplifies identification of the most sensitive parts of the architecture, selection of the best suitable safety mechanisms to reduce thereby failure rate on the system level and improve the metrics defined by the standard. To support the defined process we present the metamodels that can be integrated with existing \{DSL\} (domain-specific language) frameworks to extend them with information supporting further extraction of fault propagation behavior. We provide a framework for architecture model analysis and selection of safety mechanisms. We provide details on the model-based toolset that has been developed to support the proposed analysis and synthesis methods, and demonstrate its application to analysis of a steer-by-wire system model and selection of safety mechanisms for it. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2013.10.005},
  groups   = {ScienceDirect},
  issn     = {0167-6423},
  keywords = {Automotive systems, Embedded systems, Model-driven engineering, Quantitative safety analysis, ISO 26262 },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642313002554},
}

@Article{Sohr20121396,
  author   = {Karsten Sohr and Mirco Kuhlmann and Martin Gogolla and Hongxin Hu and Gail-Joon Ahn},
  title    = {Comprehensive two-level analysis of role-based delegation and revocation policies with \{UML\} and \{OCL\}},
  journal  = {Information and Software Technology},
  year     = {2012},
  volume   = {54},
  number   = {12},
  pages    = {1396 - 1417},
  note     = {Special Section on Software Reliability and Security},
  abstract = {Context Role-based access control (RBAC) has become the de facto standard for access management in various large-scale organizations. Often role-based policies must implement organizational rules to satisfy compliance or authorization requirements, e.g., the principle of separation of duty (SoD). To provide business continuity, organizations should also support the delegation of access rights and roles, respectively. This, however, makes access control more complex and error-prone, in particular, when delegation concepts interplay with SoD rules. Objective A systematic way to specify and validate access control policies consisting of organizational rules such as SoD as well as delegation and revocation rules shall be developed. A domain-specific language for \{RBAC\} as well as delegation concepts shall be made available. Method In this paper, we present an approach to the precise specification and validation of role-based policies based on \{UML\} and OCL. We significantly extend our earlier work, which proposed a UML-based domain-specific language for RBAC, by supporting delegation and revocation concepts. Result We show the appropriateness of our approach by applying it to a banking application. In particular, we give three scenarios for validating the interplay between SoD rules and delegation/revocation. Conclusion To the best of our knowledge, this is the first attempt to formalize advanced \{RBAC\} concepts, such as history-based SoD as well as various delegation and revocation schemes, with \{UML\} and OCL. With the rich tool support of UML, we believe our work can be employed to validate and implement real-world role-based policies. },
  doi      = {http://dx.doi.org/10.1016/j.infsof.2012.06.008},
  groups   = {Compendex, ACM, SCOPUS},
  issn     = {0950-5849},
  keywords = {UML, OCL, RBAC, Delegation, Revocation },
  url      = {http://www.sciencedirect.com/science/article/pii/S0950584912001115},
}

@Article{Brambilla201471,
  author   = {Marco Brambilla and Piero Fraternali},
  title    = {Large-scale Model-Driven Engineering of web user interaction: The WebML and WebRatio experience},
  journal  = {Science of Computer Programming},
  year     = {2014},
  volume   = {89, Part B},
  pages    = {71 - 87},
  note     = {Special issue on Success Stories in Model Driven Engineering},
  abstract = {Abstract This paper reports the experience of WebRatio, a company focusing on Model-Driven Engineering (MDE) tools (WebRatio and WebRatio BPM) and services since 2001. The adopted \{MDE\} approach is based on the transformation of models expressed in a Domain Specific Language called WebML (Web Modeling Language) into running applications, with the unique feature of creating not only the back-end data and business logic but also the Web/RIA front-end, without posing any limitation on the graphical and interaction quality of the user interface. WebRatio has been applied in many industrial projects, some of which have delivered large-scale enterprise applications, generated and maintained completely through \{MDE\} practices over the years. In this paper we present the lessons learned within this experience, describe some success stories and show some quantitative information and evaluation on the usage of the approach. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2013.03.010},
  groups   = {SCOPUS},
  issn     = {0167-6423},
  keywords = {Model-Driven Engineering, Code generation, BPM, IFML, Software engineering },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642313000701},
}

@Article{Blouin2015124,
  author   = {Arnaud Blouin and Naouel Moha and Benoit Baudry and Houari Sahraoui and Jean-Marc Jézéquel},
  title    = {Assessing the use of slicing-based visualizing techniques on the understanding of large metamodels},
  journal  = {Information and Software Technology},
  year     = {2015},
  volume   = {62},
  pages    = {124 - 142},
  abstract = {AbstractContext Metamodels are cornerstones of various metamodeling activities. Such activities consist of, for instance, transforming models into code or comparing metamodels. These activities thus require a good understanding of a metamodel and/or its parts. Current metamodel editing tools are based on standard interactive visualization features, such as physical zooms. Objective However, as soon as metamodels become large, navigating through large metamodels becomes a tedious task that hinders their understanding. So, a real need to support metamodel comprehension appears. Method In this work we promote the use of model slicing techniques to build interactive visualization tools for metamodels. Model slicing is a model comprehension technique inspired by program slicing. We show how the use of Kompren, a domain-specific language for defining model slicers, can ease the development of such interactive visualization features. Results We specifically make four main contributions. First, the proposed interactive visualization techniques permit users to focus on metamodel elements of interest, which aims at improving the understandability. Second, these proposed techniques are developed based on model slicing, a model comprehension technique that involves extracting a subset of model elements of interest. Third, we develop a metamodel visualizer, called Explen, embedding the proposed interactive visualization techniques. Fourth, we conducted experiments. showing that Explen significantly outperforms EcoreTools, in terms of time, correctness, and navigation effort, on metamodeling tasks. Conclusion The results of the experiments, in favor of Explen, show that improving metamodel understanding can be done using slicing-based interactive navigation features. },
  doi      = {http://dx.doi.org/10.1016/j.infsof.2015.02.007},
  groups   = {Compendex, ACM, SCOPUS,},
  issn     = {0950-5849},
  keywords = {Model-Driven Engineering, Metamodel, Class diagram, Visualization, Human–computer interaction, Model slicing },
  url      = {http://www.sciencedirect.com/science/article/pii/S0950584915000373},
}

@Article{Vara20122368,
  author   = {Juan Manuel Vara and Esperanza Marcos},
  title    = {A framework for model-driven development of information systems: Technical decisions and lessons learned},
  journal  = {Journal of Systems and Software},
  year     = {2012},
  volume   = {85},
  number   = {10},
  pages    = {2368 - 2384},
  note     = {Automated Software Evolution},
  abstract = {In recent years, the impact of the model-driven engineering (MDE) paradigm has resulted in the advent of a number of model-based methodological proposals that leverage the use of models at any stage of the development cycle. Apart from promoting the role of models, \{MDE\} is notable for leveraging the level of automation along the development process. For this to be achieved there is a need of supporting frameworks, tools or environments. This way, while accompanying any methodological proposal of the corresponding technical support has been traditionally recognized as a good practice, it becomes a mandatory requirement in \{MDE\} contexts. To address this task, this work presents in a systematic and reasoned way the set of methodological and technical decisions that drove the specification of M2DAT, a technical solution for model-driven development of Information Systems and its reference implementation: M2DAT-DB, a \{DSL\} toolkit for model-driven development of modern \{DB\} schemas. The objective of this work is to put forward the conclusions and decisions derived from the experience of the authors when designing and building such framework. As a result, this work will help not only \{MDE\} practitioners, but also \{SE\} practitioners wishing to bring the advantages of \{MDE\} to their fields of interest. },
  doi      = {http://dx.doi.org/10.1016/j.jss.2012.04.080},
  groups   = {SCOPUS,},
  issn     = {0164-1212},
  keywords = {Model-driven engineering, Domain-specific modeling, Software development frameworks },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121212001367},
}

@Article{Viana20133123,
  author   = {Matheus C. Viana and Rosângela A.D. Penteado and Antônio F. do Prado},
  title    = {Domain-Specific Modeling Languages to improve framework instantiation},
  journal  = {Journal of Systems and Software},
  year     = {2013},
  volume   = {86},
  number   = {12},
  pages    = {3123 - 3139},
  abstract = {Abstract Frameworks are reusable software composed of concrete and abstract classes that implement the functionality of a domain. Applications reuse frameworks to enhance quality and development efficiency. However, frameworks are hard to learn and reuse. Application developers must understand the complex class hierarchy of the framework to instantiate it properly. In this paper, we present an approach to build a Domain-Specific Modeling Language (DSML) of a framework and use it to facilitate framework reuse during application development. The \{DSML\} of a framework is built by identifying the features of this framework and the information required to instantiate them. Application generators transform models created with the \{DSML\} into application code, hiding framework complexities. In this paper, we illustrate the use of our approach in a framework for the domain of business resource transactions and a experiment that evaluated the efficiency obtained with our approach. },
  doi      = {http://dx.doi.org/10.1016/j.jss.2013.07.030},
  groups   = {ScienceDirect},
  issn     = {0164-1212},
  keywords = {Framework, Domain-Specific Modeling Language, Reuse },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121213001775},
}

@Article{Barbier2015173,
  author   = {Guillaume Barbier and Véronique Cucchi and David R.C. Hill},
  title    = {Model-driven engineering applied to crop modeling},
  journal  = {Ecological Informatics},
  year     = {2015},
  volume   = {26, Part 2},
  pages    = {173 - 181},
  note     = {Information and Decision Support Systems for Agriculture and Environment},
  abstract = {Abstract At the crossroads of two disciplines, Computer Science and Agronomy, we propose the use of Model-Driven Engineering which has the potential to be the future of software engineering. This work was initiated to tackle issues met by the \{ITK\} Company in developing and designing new crop models for decision support systems. We aim in the long-run at a full-fledge crop modeling and simulation environment. The metamodel and graphical concrete syntax designed are overcoming the lack of formal tool for conceptual modeling. The presented prototype permits to improve \{ITK\} production process through the use of code generation techniques and the feedback of its industrial use is given. },
  doi      = {http://dx.doi.org/10.1016/j.ecoinf.2014.05.004},
  groups   = {ScienceDirect},
  issn     = {1574-9541},
  keywords = {Crop model design, Model-Driven Engineering, Domain Specific Language, Visual modeling, Code generation },
  url      = {http://www.sciencedirect.com/science/article/pii/S1574954114000508},
}

@Article{FortmannRoe201428,
  author   = {Scott Fortmann-Roe},
  title    = {Insight Maker: A general-purpose tool for web-based modeling \& simulation},
  journal  = {Simulation Modelling Practice and Theory},
  year     = {2014},
  volume   = {47},
  pages    = {28 - 45},
  abstract = {Abstract A web-based, general-purpose simulation and modeling tool is presented in this paper. The tool, Insight Maker, has been designed to make modeling and simulation accessible to a wider audience of users. Insight Maker integrates three general modeling approaches – System Dynamics, Agent-Based Modeling, and imperative programming – in a unified modeling framework. The environment provides a graphical model construction interface that is implemented purely in client-side code that runs on users’ machines. Advanced features, such as model scripting and an optimization tool, are also described. Insight Maker, under development for several years, has gained significant adoption with currently more than 20,000 registered users. In addition to detailing the tool and its guiding philosophy, this first paper on Insight Maker describes lessons learned from the development of a complex web-based simulation and modeling tool. },
  doi      = {http://dx.doi.org/10.1016/j.simpat.2014.03.013},
  groups   = {ScienceDirect},
  issn     = {1569-190X},
  keywords = {Modeling, Simulation, Web-based technologies, System Dynamics, Agent-Based Modeling },
  url      = {http://www.sciencedirect.com/science/article/pii/S1569190X14000513},
}

@Article{Freudenthal201585,
  author   = {Margus Freudenthal},
  title    = {Simpl \{DSL\} toolkit},
  journal  = {Science of Computer Programming},
  year     = {2015},
  volume   = {114},
  pages    = {85 - 91},
  note     = {\{LDTA\} (Language Descriptions, Tools, and Applications) Tool Challenge},
  abstract = {Abstract This paper describes \{LDTA\} tool challenge entry that is implemented using Simpl \{DSL\} toolkit. Simpl is targeted at enterprise software development, helping to create \{DSL\} implementations that can be embedded into other systems. Simpl builds up on top of existing tools and programming languages and adds: a simple language for grammar descriptions that can be used to generate both the parser and the data types for representing abstract syntax trees; a pretty-printing library; an \{IDE\} framework; and integration layer that combines all components into a single whole and minimizes the need for boilerplate code. When implementing the challenge, Simpl provided direct support for parsing and code generation tasks. Name and type checking were implemented in Scala. In addition to the challenge task, Simpl was used to create an Eclipse-based \{IDE\} for the target language. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2014.11.018},
  groups   = {ACM, Compendex, SCOPUS},
  issn     = {0167-6423},
  keywords = {Simpl \{DSL\} toolkit, Tool challenge },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642314005590},
}

@Article{Nadas2014105,
  author   = {Andras Nadas and Tihamer Levendovszky and Ethan K. Jackson and Istvan Madari and Janos Sztipanovits},
  title    = {A model-integrated authoring environment for privacy policies},
  journal  = {Science of Computer Programming},
  year     = {2014},
  volume   = {89, Part B},
  pages    = {105 - 125},
  note     = {Special issue on Success Stories in Model Driven Engineering},
  abstract = {Abstract Privacy policies are rules designed to ensure that individuals’ health data are properly protected. Health Information Systems (HIS) are legally required to adhere to these policies. Since privacy policies are imposed on complex software systems, it is extremely hard to reason about their conformance and consistency. In order to address this problem, we have created a model-driven authoring environment to formally specify privacy policies originally defined in legal terms. In our observation, appropriate formalization of our policy language enabled formal analysis of its policies; these features were key to a successful model-driven engineering process. In this paper we present our modeling language and show its semantic anchoring to analyzable logic programs. We report on several projects where our approach is being applied and validated. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2013.05.004},
  groups   = {ACM,},
  issn     = {0167-6423},
  keywords = {Privacy policies, Model-integrated computing, Constraint logic programming },
  url      = {http://www.sciencedirect.com/science/article/pii/S016764231300124X},
}

@Article{Nguyen201562,
  author   = {Phu H. Nguyen and Max Kramer and Jacques Klein and Yves Le Traon},
  title    = {An extensive systematic review on the Model-Driven Development of secure systems},
  journal  = {Information and Software Technology},
  year     = {2015},
  volume   = {68},
  pages    = {62 - 81},
  abstract = {Abstract Context: Model-Driven Security (MDS) is as a specialised Model-Driven Engineering research area for supporting the development of secure systems. Over a decade of research on \{MDS\} has resulted in a large number of publications. Objective: To provide a detailed analysis of the state of the art in MDS, a systematic literature review (SLR ) is essential. Method: We conducted an extensive \{SLR\} on MDS. Derived from our research questions, we designed a rigorous, extensive search and selection process to identify a set of primary \{MDS\} studies that is as complete as possible. Our three-pronged search process consists of automatic searching, manual searching, and snowballing. After discovering and considering more than thousand relevant papers, we identified, strictly selected, and reviewed 108 \{MDS\} publications. Results: The results of our \{SLR\} show the overall status of the key artefacts of MDS, and the identified primary \{MDS\} studies. For example, regarding security modelling artefact, we found that developing domain-specific languages plays a key role in many \{MDS\} approaches. The current limitations in each \{MDS\} artefact are pointed out and corresponding potential research directions are suggested. Moreover, we categorise the identified primary \{MDS\} studies into 5 significant \{MDS\} studies, and other emerging or less common \{MDS\} studies. Finally, some trend analyses of \{MDS\} research are given. Conclusion: Our results suggest the need for addressing multiple security concerns more systematically and simultaneously, for tool chains supporting the \{MDS\} development cycle, and for more empirical studies on the application of \{MDS\} methodologies. To the best of our knowledge, this \{SLR\} is the first in the field of Software Engineering that combines a snowballing strategy with database searching. This combination has delivered an extensive literature study on MDS. },
  doi      = {http://dx.doi.org/10.1016/j.infsof.2015.08.006},
  groups   = {SCOPUS, ACM,},
  issn     = {0950-5849},
  keywords = {Systematic review, Model-Driven Security, MDS, Model-Driven Engineering, MDE, Software security engineering },
  url      = {http://www.sciencedirect.com/science/article/pii/S0950584915001482},
}

@Article{Sun2016146,
  author   = {Yu Sun and Jules White and Sean Eade and Douglas C. Schmidt},
  title    = {ROAR: A QoS-oriented modeling framework for automated cloud resource allocation and optimization},
  journal  = {Journal of Systems and Software},
  year     = {2016},
  volume   = {116},
  pages    = {146 - 161},
  abstract = {Abstract Cloud computing offers a fast, easy and cost-effective way to configure and allocate computing resources for web applications, such as consoles for smart grid applications, medical records systems, and security management platforms. Although a diverse collection of cloud resources (e.g., servers) is available, choosing the most optimized and cost-effective set of cloud resources for a given web application and set of quality of service (QoS) goals is not a straightforward task. Optimizing cloud resource allocation is a critical task for offering web applications using a software as a service model in the cloud, where minimizing operational cost while ensuring QoS goals are met is critical to meeting customer demands and maximizing profit. Manual load testing with different sets of cloud resources, followed by comparison of test results to QoS goals is tedious and inaccurate due to the limitations of the load testing tools, challenges characterizing resource utilization, significant manual test orchestration effort, and challenges identifying resource bottlenecks. This paper introduces our work using a modeling framework – \{ROAR\} (Resource Optimization, Allocation and Recommendation System) to simplify, optimize, and automate cloud resource allocation decisions to meet QoS goals for web applications, including complex multi-tier application distributed in different server groups. \{ROAR\} uses a domain-specific language to describe the configuration of the web application, the \{APIs\} to benchmark and the expected QoS requirements (e.g., throughput and latency), and the resource optimization engine uses model-based analysis and code generation to automatically deploy and load test the application in multiple resource configurations in order to derive a cost-optimal resource configuration that meets the QoS goals. },
  doi      = {http://dx.doi.org/10.1016/j.jss.2015.08.006},
  groups   = {SCOPUS},
  issn     = {0164-1212},
  keywords = {Cloud computing, Resource optimization, Load testing and benchmarking },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121215001715},
}

@Article{Cabanillas201555,
  author   = {Cristina Cabanillas and Manuel Resinas and Adela del-Río-Ortega and Antonio Ruiz-Cortés},
  title    = {Specification and automated design-time analysis of the business process human resource perspective},
  journal  = {Information Systems},
  year     = {2015},
  volume   = {52},
  pages    = {55 - 82},
  note     = {Special Issue on Selected Papers from \{SISAP\} 2013},
  abstract = {Abstract The human resource perspective of a business process is concerned with the relation between the activities of a process and the actors who take part in them. Unlike other process perspectives, such as control flow, for which many different types of analyses have been proposed, such as finding deadlocks, there is an important gap regarding the human resource perspective. Resource analysis in business processes has not been defined, and only a few analysis operations can be glimpsed in previous approaches. In this paper, we identify and formally define seven design-time analysis operations related to how resources are involved in process activities. Furthermore, we demonstrate that for a wide variety of resource-aware \{BP\} models, those analysis operations can be automated by leveraging Description Logic (DL) off-the-shelf reasoners. To this end, we rely on Resource Assignment Language (RAL), a domain-specific language that enables the definition of conditions to select the candidates to participate in a process activity. We provide a complete formal semantics for \{RAL\} based on \{DLs\} and extend it to address the operations, for which the control flow of the process must also be taken into consideration. A proof-of-concept implementation has been developed and integrated in a system called CRISTAL. As a result, we can give an automatic answer to different questions related to the management of resources in business processes at design time. },
  doi      = {http://dx.doi.org/10.1016/j.is.2015.03.002},
  groups   = {ACM},
  issn     = {0306-4379},
  keywords = {Automated analysis, Analysis operation, Business process management, Human resource perspective, RAL, Resource assignment },
  url      = {http://www.sciencedirect.com/science/article/pii/S0306437915000460},
}

@Article{Burton201411,
  author   = {Frank R. Burton and Richard F. Paige and Simon Poulding and Simon Smith},
  title    = {System of Systems Acquisition Trade-offs},
  journal  = {Procedia Computer Science},
  year     = {2014},
  volume   = {28},
  pages    = {11 - 18},
  note     = {2014 Conference on Systems Engineering Research},
  abstract = {Abstract During System of Systems acquisition, organisations aim to satisfy their goals through the procurement of systems, people, training and processes. The most successful organisations undertake these acquisitions as efficiently as possible. For large organisations, a set of goals may be satisfied – to varying degrees – by any one of a large number of potential resource combinations, and so it is necessary to consider the trade-offs exhibited by each combination to find an effective System of Systems architecture. In this paper, we present an approach, supported by tools, that combines techniques from the fields of goal-modelling and multi-objective optimisation to effectively explore these high-level organisational trade-offs. The decision maker can state the organisational problems and provide high-level descriptions of the existing and acquirable systems using a custom domain specific language. The tool then explores the space of potential resource combinations using a multi-objective genetic algorithm and provides the decision maker with a Pareto front of acquisition plans that represent the best trade-offs between the various goals and costs. Furthermore, the technique and tool enables acquisitions to be scheduled to take an account of such factors as maintenance costs, existing system retirement dates, upfront costs for bringing new systems into service, the budgetary constraints of the organisation and how this affects the organisation's ability to satisfy its goals through the acquisition. The approach is evaluated on a realistic case study in which new systems are acquired to support a military scenario whilst considering the existing in-place systems and through-life implications. },
  doi      = {http://dx.doi.org/10.1016/j.procs.2014.03.002},
  groups   = {SCOPUS},
  issn     = {1877-0509},
  keywords = {System of Systems, Acquisition, Trade-offs, Goal Modelling, Metaheuristic Search },
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050914000659},
}

@Article{Kosar2014622,
  author   = {Tomaž Kosar and Marjan Mernik and Jeff Gray and Tomaž Kos},
  title    = {Debugging measurement systems using a domain-specific modeling language},
  journal  = {Computers in Industry},
  year     = {2014},
  volume   = {65},
  number   = {4},
  pages    = {622 - 635},
  abstract = {Abstract Capturing physical data in the context of measurement systems is a demanding process that often requires many repetitions with different settings. To assist in this activity, a domain-specific modeling language (DSML) called Sequencer has been developed to enable the improved definition of measurement procedures. With Sequencer, the level of abstraction has been raised and sophisticated changes in measurement procedures are now enabled. Although there are numerous \{DSMLs\} like Sequencer in the existing literature, there are some obstacles working against the more widespread adoption of \{DSMLs\} in practice. One challenge is the lack of supporting tools for DSMLs, which would improve the capabilities of end-users of such languages. For instance, support for debugging a model expressed in a \{DSML\} is often neglected. The lack of a debugger at the proper abstraction level limits the domain experts in discovering and locating bugs in a model. In this paper, Sequencer is presented together with debugging facilities (called Ladybird) that are integrated in a modeling environment. Ladybird supports different execution modes (e.g., steps, breakpoints, animations, variable views, and stack traces) that can be helpful during the debugging of a model. Ladybird's primary contribution is in showing the value of error detection in complicated industrial environments, such as data acquisition in automotive testing. The paper contributes to a discussion of the implementation details of \{DSML\} debugging facilities and how such a debugger can be reused to support domains other than the measurement context of Sequencer. },
  doi      = {http://dx.doi.org/10.1016/j.compind.2014.01.013},
  groups   = {SCOPUS},
  issn     = {0166-3615},
  keywords = {Debugging aid, Domain-specific modeling languages, Graphical environments, Usage experience },
  url      = {http://www.sciencedirect.com/science/article/pii/S0166361514000293},
}

@InCollection{Selić2014183,
  author    = {Bran Selić and Sébastien Gérard},
  title     = {Chapter 9 - Foundations for Model-Based Analysis},
  booktitle = {Modeling and Analysis of Real-Time and Embedded Systems with \{UML\} and \{MARTE\}},
  publisher = {Morgan Kaufmann},
  year      = {2014},
  editor    = {Selić, Bran and , and Gérard, Sébastien},
  pages     = {183 - 200},
  address   = {Boston},
  abstract  = {In addition to providing a domain-specific language for modeling of real-time systems phenomena, \{MARTE\} also supports formal model analysis. To that end, it first defines a generic framework, called Generic Quantitative Analysis Modeling (GQAM), which serves as a common basis for a variety of different formal analysis techniques. The common characteristic shared by these analyses is that they are all used to determine whether a particular platform is capable of providing the quality of service (QoS) required by an application. Both the Schedulability Analysis Modeling (SAM) subprofile and the Performance Analysis Modeling (PAM) subprofile of \{MARTE\} are based on the general concepts defined in GQAM. This chapter first describes a generic iterative analysis process, which explains how these types of analysis methods can be used in an agile way during design exploration. This is followed by a discussion of the general \{MARTE\} approach to model analysis and an explanation of the core concepts behind the \{GQAM\} framework. The material in this chapter is a prerequisite for anyone who is interested in applying the \{SAM\} or \{PAM\} subprofiles, as well as for those who are interested in using \{GQAM\} to support additional analysis methods. },
  doi       = {http://dx.doi.org/10.1016/B978-0-12-416619-6.00009-2},
  groups    = {ScienceDirect},
  isbn      = {978-0-12-416619-6},
  keywords  = {Analysis, client/server, evolutionary prototyping, load modeling, mechanical verification, modeling and prediction, performance attributes, quality analysis and evaluation, relations between models, risk management, software process models, system-level design, tools, validation },
  url       = {http://www.sciencedirect.com/science/article/pii/B9780124166196000092},
}

@Article{Hamid2016239,
  author   = {Brahim Hamid and Jon Perez},
  title    = {Supporting pattern-based dependability engineering via model-driven development: Approach, tool-support and empirical validation},
  journal  = {Journal of Systems and Software},
  year     = {2016},
  volume   = {122},
  pages    = {239 - 273},
  abstract = {Abstract Safety-critical systems require a high level of safety and integrity. Therefore, generating such systems involves specific software building processes. Many domains are not traditionally involved in these types of software problems and must adapt their current processes accordingly. Typically, such requirements are developed ad hoc for each system, preventing further reuse beyond the domain-specific boundaries. This paper proposes a solution for software system development based on the reuse of dedicated subsystems, i.e., so-called dependability patterns that have been pre-engineered to adapt to a specific domain. We use Model-Driven Engineering (MDE) to describe dependability patterns and a methodology for developing dependable software systems using these patterns. Moreover, we describe an operational architecture for development tools to support the approach. An empirical evaluation of the proposed approach is presented through its practical application to a case study in the railway domain, which has strong dependability requirements, to support a pattern-based development approach. This case study is followed by a survey to better understand the perceptions of practitioners regarding our approach. },
  doi      = {http://dx.doi.org/10.1016/j.jss.2016.09.027},
  groups   = {ScienceDirect},
  issn     = {0164-1212},
  keywords = {Dependability, Safety, System engineering, Patterns, Meta-modeling, Model driven engineering },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121216301868},
}

@Article{Chabridon20131912,
  author   = {Sophie Chabridon and Denis Conan and Zied Abid and Chantal Taconet},
  title    = {Building ubiquitous QoC-aware applications through model-driven software engineering},
  journal  = {Science of Computer Programming},
  year     = {2013},
  volume   = {78},
  number   = {10},
  pages    = {1912 - 1929},
  note     = {Special section on Language Descriptions Tools and Applications (LDTA’08 \&amp; ’09) \&amp; Special section on Software Engineering Aspects of Ubiquitous Computing and Ambient Intelligence (UCAmI 2011)},
  abstract = {As every-day mobile devices can easily be equipped with multiple sensing capabilities, ubiquitous applications are expected to exploit the richness of the context information that can be collected by these devices in order to provide the service that is the most appropriate to the situation of the user. However, the design and implementation of such context-aware ubiquitous appplications remain challenging as there exist very few models and tools to guide application designers and developers in mastering the complexity of context information. This becomes even more crucial as context is by nature imperfect. One way to address this issue is to associate to context information meta-data representing its quality. We propose a generic and extensible design process for context-aware applications taking into account the quality of context (QoC). We demonstrate its use on a prototype application for sending flash sale offers to mobile users. We present extensive performance results in terms of memory and processing time of both elementary context management operations and the whole context policy implementing the Flash sale application. The cost of adding QoC management is also measured and appears to be limited to a few milliseconds. We show that a context policy with 120 QoC-aware nodes can be processed in less than 100 ms on a mobile phone. Moreover, a policy of almost 3000 nodes can be instantiated before exhausting the resources of the phone. This enables very rich application scenarios enhancing the user experience and will favor the development of new ubiquitous applications. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2012.07.019},
  groups   = {SCOPUS},
  issn     = {0167-6423},
  keywords = {Model-driven software engineering, Context, Quality of context, Domain specific language, Ubiquitous computing, Pervasive computing },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642312001475},
}

@Article{Yang2013167,
  author   = {Shahan Yang and Yuchen Zhou and John Baras},
  title    = {Compositional Analysis of Dynamic Bayesian Networks and Applications to Complex Dynamic System Decomposition},
  journal  = {Procedia Computer Science},
  year     = {2013},
  volume   = {16},
  pages    = {167 - 176},
  note     = {2013 Conference on Systems Engineering Research},
  abstract = {Dynamic Bayesian networks (DBNs) can be effectively used to model various problems in complex dynamic systems. We perform an empirical investigation on compositional analysis of \{DBNs\} using abstraction. In static systems and hidden Markov models, computation of a metric called treewidth induces a tree decomposition that can be used to perform logical or probabilistic inference and max + optimizations in time exponential in treewidth and linear in overall system size. Intuitively, the linear scaling means that very large systems can be analyzed as long as they are sufficiently sparse and well structured. In these simple cases, summary propagation, which uses two operations, summation (projection) and product (composition), suffices to perform the inference or optimization. Here, we begin an extension of this to structured networks of communicating dynamic systems. We define generalizations of projection and composition operators that treat labeled Markov chains as primitive objects. The projection operation, corresponding to summation, is implemented as label deletion followed by exact state reduction for Markov chains, similar to Hopcroft's \{DFA\} minimization algorithm, with O(nlogm) complexity. The composition operation is the product of state machines. We use canonical MDDs, similar to BDDs, to capture logical dependencies symbolically. Combining symbolic representations with Markov chain lumping algorithms is a novel contribution. Using this approach, we have created a tool lever- aging model based systems engineering technologies. The communicating Markov chains are specified using \{UML\} Statecharts via Papyrus extended using an \{ANTLR\} parsed domain specific language (DSL). The tool reduces the number of states in networks of Markov chains by several orders of magnitude. In one example, a network having a product state space of more than 600 million states is reduced to about 500 states. A feature of this technique is that the state space is examined incrementally, meaning that the full state space is never explicitly represented, even as an input to the reduction algorithm. The primary reduction appears to come from symmetry which is surprising because the technique includes no explicit symmetry handling. We note that composition is efficient at least for systems with high symmetry. We describe applications to a hospital intensive care unit (ICU) from a systems engineering perspective. },
  doi      = {http://dx.doi.org/10.1016/j.procs.2013.01.018},
  groups   = {SCOPUS},
  issn     = {1877-0509},
  keywords = {Bayesian networks, Treewidth, Markov chain },
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050913000197},
}

@Article{CánovasIzquierdo2012257,
  author   = {Javier Luis Cánovas Izquierdo and Frédéric Jouault and Jordi Cabot and Jesús García Molina},
  title    = {API2MoL: Automating the building of bridges between \{APIs\} and Model-Driven Engineering},
  journal  = {Information and Software Technology},
  year     = {2012},
  volume   = {54},
  number   = {3},
  pages    = {257 - 273},
  abstract = {Context A software artefact typically makes its functionality available through a specialized Application Programming Interface (API) describing the set of services offered to client applications. In fact, building any software system usually involves managing a plethora of APIs, which complicates the development process. In Model-Driven Engineering (MDE), where models are the key elements of any software engineering activity, this \{API\} management should take place at the model level. Therefore, tools that facilitate the integration of \{APIs\} and \{MDE\} are clearly needed. Objective Our goal is to automate the implementation of API–MDE bridges for supporting both the creation of models from \{API\} objects and the generation of such \{API\} objects from models. In this sense, this paper presents the \{API2MoL\} approach, which provides a declarative rule-based language to easily write mapping definitions to link \{API\} specifications and the metamodel that represents them. These definitions are then executed to convert \{API\} objects into model elements or vice versa. The approach also allows both the metamodel and the mapping to be automatically obtained from the \{API\} specification (bootstrap process). Method After implementing the \{API2MoL\} engine, its correctness was validated using several APIs. Since \{APIs\} are normally large, we then developed a tool to implement the bootstrap process, which was also validated. Results We provide a toolkit (language and bootstrap tool) for the creation of bridges between \{APIs\} and MDE. The current implementation focuses on Java APIs, although its adaptation to other statically typed object-oriented languages is straightforward. The correctness, expressiveness and completeness of the approach have been validated with the Swing, \{SWT\} and \{JTwitter\} APIs. Conclusion \{API2MoL\} frees developers from having to manually implement the tasks of obtaining models from \{API\} objects and generating such objects from models. This helps to manage \{API\} models in MDE-based solutions. },
  doi      = {http://dx.doi.org/10.1016/j.infsof.2011.09.006},
  groups   = {SCOPUS,},
  issn     = {0950-5849},
  keywords = {Application Programming Interface, Model-Driven Engineering, Domain-Specific Languages },
  url      = {http://www.sciencedirect.com/science/article/pii/S0950584911001984},
}

@Article{Bollati2013699,
  author   = {Verónica Andrea Bollati and Juan Manuel Vara and Álvaro Jiménez and Esperanza Marcos},
  title    = {Applying \{MDE\} to the (semi-)automatic development of model transformations},
  journal  = {Information and Software Technology},
  year     = {2013},
  volume   = {55},
  number   = {4},
  pages    = {699 - 718},
  abstract = {Context Model transformations play a key role in any software development project based on Model-Driven Engineering principles. However, despite the inherent complexity of developing model transformations, little attention has been paid to the application of \{MDE\} principles to the development of model transformations. Objective In order to: (a) address the inherent complexity of model transformation development and (b) alleviate the problem of the diversity of the languages that are available for model transformation, this paper proposes the application of \{MDE\} principles to the development of model transformations. In particular, we have adopted the idea of handling model transformations as transformation models in order to be able to model, transform and generate model transformations. Method The proposal follows an MDA-based approach that entails the modeling of model transformations at different abstraction levels and the connection of these models by means of model transformations. It has been empirically validated by conducting a set of case studies following a systematic research methodology. Results The proposal was supported by the introduction of MeTAGeM, a methodological and technical framework for the model-driven development of model transformations that bundles a set of Domain-Specific Languages for modeling model transformations with a set of model transformations in order to bridge these languages and (semi-)automate model transformations development. Conclusion This paper serves to show that a semi-automatic development process for model transformations is not only desirable but feasible. This process, based on \{MDE\} principles, helps to ease the task of developing model transformations and to alleviate interoperability issues between model transformation languages. },
  doi      = {http://dx.doi.org/10.1016/j.infsof.2012.11.004},
  groups   = {SCOPUS,},
  issn     = {0950-5849},
  keywords = {Model transformations, Model-driven development, Design tools and techniques },
  url      = {http://www.sciencedirect.com/science/article/pii/S0950584912002303},
}

@Article{AzadiMarand2015319,
  author   = {Elaheh Azadi Marand and Elham Azadi Marand and Moharram Challenger},
  title    = {DSML4CP: A Domain-specific Modeling Language for Concurrent Programming},
  journal  = {Computer Languages, Systems \& Structures},
  year     = {2015},
  volume   = {44, Part C},
  pages    = {319 - 341},
  abstract = {Abstract Nowadays, concurrent programs are an inevitable part of many software applications. They can increase the computation performance of the applications by parallelizing their computations. One of the approaches to realize the concurrency is using multi thread programming. However, these systems are structurally complex considering the control of the parallelism (such as thread synchronization and resource control) and also considering the interaction between their components. So, the design of these systems can be difficult and their implementation can be error-prone especially when the addressed system is big and complex. On the other hand, a Domain-specific Modeling Language (DSML) is one of the Model Driven Development (MDD) approaches which tackles this problem. Since \{DSMLs\} provide a higher abstraction level, they can lead to reduce the complexities of the concurrent programs. With increasing the abstraction level and generating the artifacts automatically, the performance of developing the software (both in design and implementation phases) is increased, and the efficiency is raised by reducing the probability of occurring errors. Thus, in this paper, a \{DSML\} is proposed for concurrent programs, called DSML4CP, to work in a higher level of abstraction than code level. To this end, the concepts of concurrent programs and their relationships are presented in a metamodel. The proposed metamodel provides a context for defining abstract syntax, and concrete syntax of the DSML4CP. This new language is supported by a graphical modeling tool which can visualize different instance models for domain problems. In order to clarify the expressions of the language; the static semantic controls are realized in the form of constraints. Finally, the architectural code generation is fulfilled via model transformation rules using the templates of the concurrent programs. To increase level of the DSML׳s leverage and to demonstrate the general support of concurrent programming by the DSML, the transformation mechanism of the tool supports two well-known and highly used programming languages for code generation; Java and C#. The performed experiments on two case studies indicate a high performance for proposed language. In this regard, the results show automatic generation of 79% of the final code and 86% of the functions/modules on average. },
  doi      = {http://dx.doi.org/10.1016/j.cl.2015.09.002},
  groups   = {Compendex},
  issn     = {1477-8424},
  keywords = {Domain-specific Modeling Language, Metamodel, Code generation, Constraint control, Concurrent programming },
  url      = {http://www.sciencedirect.com/science/article/pii/S1477842415000627},
}

@Article{Edge20129966,
  author   = {Michael E. Edge and Pedro R. Falcone Sampaio},
  title    = {The design of FFML: A rule-based policy modelling language for proactive fraud management in financial data streams},
  journal  = {Expert Systems with Applications},
  year     = {2012},
  volume   = {39},
  number   = {11},
  pages    = {9966 - 9985},
  abstract = {Developing fraud management policies and fraud detection systems is a vital capability for financial institutions towards minimising the effect of fraud upon customer service delivery, bottom line financial losses and the adverse impact on the organisation’s brand image reputation. Rapidly changing attacks in real-time financial service platforms continue to demonstrate fraudster’s ability to actively re-engineer their methods in response to ad hoc security protocol deployments, and highlights the distinct gap between the speed of transaction execution within streaming financial data and corresponding fraud technology frameworks that safeguard the platform. This paper presents the design of FFML, a rule-based policy modelling language and encompassing architecture for facilitating the conceptual level expression and implementation of proactive fraud controls within multi-channel financial service platforms. It is demonstrated how a domain specific language can be used to abstract the financial platform into a data stream based information model to reduce policy modelling complexity and deployment latencies through an innovative policy mapping language usable by both expert and non-expert users. \{FFML\} is part of a comprehensive suite of assistive tools and knowledge-based systems developed to support fraud analysts’ daily work of designing new high level fraud management policies, mapping into executable code of the underpinning application programming interface and deployment of active monitoring and compliance functionality within the financial platform. },
  doi      = {http://dx.doi.org/10.1016/j.eswa.2012.01.143},
  groups   = {SCOPUS, ACM, Compendex},
  issn     = {0957-4174},
  keywords = {Fraud detection, Financial information systems, Rule-based expert systems, Information security, Domain specific policy-based languages },
  url      = {http://www.sciencedirect.com/science/article/pii/S0957417412001637},
}

@Article{Kos2012181,
  author   = {Tomaž Kos and Tomaž Kosar and Marjan Mernik},
  title    = {Development of data acquisition systems by using a domain-specific modeling language},
  journal  = {Computers in Industry},
  year     = {2012},
  volume   = {63},
  number   = {3},
  pages    = {181 - 192},
  abstract = {Data acquisition is the process of capturing and measuring physical data and then converting the results into a digital form that is further manipulated by a computer program. Within the industry, data acquisition systems (measurement systems) are used in a wide variety of fields, including product quality testing. Usually measuring systems are complicated devices, however newer data acquisition systems tend to be easier to use. As such, they open the door for the development of customized software, which can be easily manipulated, not only by programmers but also by domain experts, enabling them to understand and modify programs. Raising the level of abstraction, particularly with those programs that use visual models, can be an effective aid for domain experts, who are then able to model their programs on their own. This paper describes the design and use of a domain-specific modeling language called the Sequencer, integrated with the measuring equipment DEWESoft, which enables domain experts to model their own data acquisitions. Specifically, in this paper the Sequencer is exposed to: domain concepts identification, the construction of modeling notation, a connection with execution framework, and the end-users’ point of view on the modeling tool. The use of the Sequencer will be presented on car brake tests. For this purpose, the Sequencer has already been successfully applied in the automotive industry. },
  doi      = {http://dx.doi.org/10.1016/j.compind.2011.09.004},
  groups   = {Compendex},
  issn     = {0166-3615},
  keywords = {Domain-specific modeling languages, Domain-specific languages, Data acquisition, Measuring systems, Brake tests, DEWESoft, Sequencer },
  url      = {http://www.sciencedirect.com/science/article/pii/S0166361511001059},
}

@Article{Bettini2016655,
  author   = {Lorenzo Bettini},
  title    = {Implementing type systems for the \{IDE\} with Xsemantics},
  journal  = {Journal of Logical and Algebraic Methods in Programming},
  year     = {2016},
  volume   = {85},
  number   = {5, Part 1},
  pages    = {655 - 680},
  note     = {Special Issue on Automated Verification of Programs and Web Systems},
  abstract = {Abstract Xsemantics is a \{DSL\} for writing type systems, reduction rules and, in general, relation rules for languages implemented in Xtext (Xtext is an Eclipse framework for rapidly building languages together with all the typical \{IDE\} tooling). Xsemantics aims at reducing the gap between the formalization of a language (i.e., type system and operational semantics) and the actual implementation in Xtext, since it uses a syntax that resembles the rules in a formal setting. In this paper we present the main features of Xsemantics for implementing type systems and reduction rules through examples (Featherweight Java and lambda calculus). We show how such implementations are close to the actual formalizations, and how Xsemantics can be a helpful tool when proving the type safety of a language. We also describe the new features of Xsemantics that help achieving a modular and efficient implementation of type systems. In particular, we focus on specific implementation techniques for implementing type systems that are suited for the \{IDE\} (in our context, Eclipse), in order to keep the tooling responsive and guarantee a good user experience. },
  doi      = {http://dx.doi.org/10.1016/j.jlamp.2015.11.005},
  groups   = {ScienceDirect},
  issn     = {2352-2208},
  keywords = {DSL, Type systems, Semantics, Implementation, Eclipse },
  url      = {http://www.sciencedirect.com/science/article/pii/S235222081500142X},
}

@Article{David2013201,
  author   = {O. David and J.C. Ascough II and W. Lloyd and T.R. Green and K.W. Rojas and G.H. Leavesley and L.R. Ahuja},
  title    = {A software engineering perspective on environmental modeling framework design: The Object Modeling System},
  journal  = {Environmental Modelling \& Software},
  year     = {2013},
  volume   = {39},
  pages    = {201 - 213},
  note     = {Thematic Issue on the Future of Integrated Modeling Science and Technology},
  abstract = {The environmental modeling community has historically been concerned with the proliferation of models and the effort associated with collective model development tasks (e.g., code generation, data transformation, etc.). Environmental modeling frameworks (EMFs) have been developed to address this problem, but much work remains before \{EMFs\} are adopted as mainstream modeling tools. Environmental model development requires both scientific understanding of environmental phenomena and software developer proficiency. \{EMFs\} support the modeling process through streamlining model code development, allowing seamless access to data, and supporting data analysis and visualization. \{EMFs\} also support aggregation of model components into functional units, component interaction and communication, temporal-spatial stepping, scaling of spatial data, multi-threading/multi-processor support, and cross-language interoperability. Some \{EMFs\} additionally focus on high-performance computing and are tailored for particular modeling domains such as ecosystem, socio-economic, or climate change research. The Object Modeling System Version 3 (OMS3) \{EMF\} employs new advances in software framework design to better support the environmental model development process. This paper discusses key \{EMF\} design goals/constraints and addresses software engineering aspects that have made \{OMS3\} framework development efficacious and its application practical, as demonstrated by leveraging software engineering efforts outside of the modeling community and lessons learned from over a decade of \{EMF\} development. Software engineering approaches employed in \{OMS3\} are highlighted including a non-invasive lightweight framework design supporting component-based model development, use of implicit parallelism in system design, use of domain specific language design patterns, and cloud-based support for computational scalability. The key advancements in \{EMF\} design presented herein may be applicable and beneficial for other \{EMF\} developers seeking to better support environmental model development through improved framework design. },
  doi      = {http://dx.doi.org/10.1016/j.envsoft.2012.03.006},
  groups   = {Compendex, ACM, SCOPUS,},
  issn     = {1364-8152},
  keywords = {Object Modeling System, Environmental modeling frameworks, Modeling and simulation, Software engineering, Software design },
  url      = {http://www.sciencedirect.com/science/article/pii/S1364815212000886},
}

@Article{Challenger2014111,
  author   = {Moharram Challenger and Sebla Demirkol and Sinem Getir and Marjan Mernik and Geylani Kardas and Tomaž Kosar},
  title    = {On the use of a domain-specific modeling language in the development of multiagent systems},
  journal  = {Engineering Applications of Artificial Intelligence},
  year     = {2014},
  volume   = {28},
  pages    = {111 - 141},
  abstract = {Abstract The study of Multiagent Systems (MASs) focuses on those systems in which many intelligent agents interact with each other. The agents are considered to be autonomous entities which contain intelligence that serves for solving their selfish or common problems, and to achieve certain goals. However, the autonomous, responsive, and proactive natures of agents make the development of agent-based software systems more complex than other software systems. Furthermore, the design and implementation of a \{MAS\} may become even more complex and difficult to implement when considering new requirements and interactions for new agent environments like the Semantic Web. We believe that both domain-specific modeling and the use of a domain-specific modeling language (DSML) may provide the required abstraction, and hence support a more fruitful methodology for the development of MASs. In this paper, we first introduce a \{DSML\} for \{MASs\} called SEA_ML with both its syntax and semantics definitions and then show how the language and its graphical tools can be used during model-driven development of real MASs. In addition to the classical viewpoints of a MAS, the proposed \{DSML\} includes new viewpoints which specifically support the development of software agents working within the Semantic Web environment. The methodology proposed for the \{MAS\} development based on SEA_ML is also discussed including its example application on the development of an agent-based stock exchange system. },
  doi      = {http://dx.doi.org/10.1016/j.engappai.2013.11.012},
  groups   = {SCOPUS},
  issn     = {0952-1976},
  keywords = {Agent, Multiagent system, Model driven development, Domain-specific modeling language, Metamodel, Semantic web },
  url      = {http://www.sciencedirect.com/science/article/pii/S0952197613002297},
}

@Article{Fernandes201546,
  author   = {Andreia Varmes Fernandes and Márcio Viana Ramos and José Hélio Costa and Ilka Maria Vasconcelos and Renato de Azevedo Moreira and Frederico Bruno Mendes Batista Moreno and Maria Eliza Caldas dos Santos and José Francisco de Carvalho Gonçalves},
  title    = {Lectin genes and their mature proteins: Still an exciting matter, as revealed by biochemistry and bioinformatics analyses of newly reported proteins},
  journal  = {Biochemical Systematics and Ecology},
  year     = {2015},
  volume   = {60},
  pages    = {46 - 55},
  abstract = {Abstract Two new lectins were purified through affinity chromatography after crude extract preparation under high ionic strength. The hemagglutinating activity of these lectins from the seeds of the legumes Dioclea bicolor (DBL) and Deguelia scandens (DSL) was inhibited by galactose and glucose, respectively, and the molecular masses were estimated at 24 and 22 kDa (via SDS-PAGE), respectively. The alignment of internal peptides of \{DBL\} (MS/MS) with known protein sequences revealed similarity to other legume lectins. The N-terminal amino acid sequence of \{DSL\} also aligned with legume lectins. Cross-similarities among the two studied lectins were observed only after sequence permutation. More than a dozen lectins have been reported for the genus Dioclea but none that recognize galactose. \{DSL\} is the first lectin reported for the Deguelia genus in the tribe Millettieae. With the aid of bioinformatics tools and searches for genome/transcriptome information about closely related sequences, new lectin members of Millettieae were also identified. Electrophoresis profiling and amino acid sequence analysis suggested that DBL-Gal and \{DSL\} do not undergo post-transcriptional ConA-like circular permutation. Molecular modeling of the deduced amino acid sequences of the Millettieae lectins suggested that the overall folding of the monomeric structures of legume lectins is conserved. This and other recent studies highlight native plants of the Amazon as renewed sources of lectins. },
  doi      = {http://dx.doi.org/10.1016/j.bse.2015.02.002},
  groups   = {SCOPUS},
  issn     = {0305-1978},
  keywords = {Hemagglutinating activity, New lectins, N-terminal protein sequencing, Seeds of Amazonian legumes },
  url      = {http://www.sciencedirect.com/science/article/pii/S0305197815000496},
}

@Article{Marnerides201572,
  author   = {A.K. Marnerides and S. Malinowski and R. Morla and H.S. Kim},
  title    = {Fault diagnosis in \{DSL\} networks using support vector machines},
  journal  = {Computer Communications},
  year     = {2015},
  volume   = {62},
  pages    = {72 - 84},
  abstract = {Abstract The adequate operation for a number of service distribution networks relies on the effective maintenance and fault management of their underlay \{DSL\} infrastructure. Thus, new tools are required in order to adequately monitor and further diagnose anomalies that other segments of the \{DSL\} network cannot identify due to the pragmatic issues raised by hardware or software misconfigurations. In this work we present a fundamentally new approach for classifying known DSL-level anomalies by exploiting the properties of novelty detection via the employment of one-class Support Vector Machines (SVMs). By virtue of the imbalance residing in the training samples that consequently lead to problematic prediction outcomes when used within two-class formulations, we adopt the properties of one-class classification and construct models for independently identifying and classifying a single type of a DSL-level anomaly. Given the fact that the greater number of the installed Digital Subscriber Line Access Multiplexers (DSLAMs) within the \{DSL\} network of a large European \{ISP\} were misconfigured, thus unable to accurately flag anomalous events, we utilize as inference solutions the models derived by the one-class \{SVM\} formulations built by the known labels as flagged by the much smaller number of correctly configured \{DSLAMs\} in the same network in order to aid the classification aspect against the monitored unlabeled events. By reaching an average over 95% on a number of classification accuracy metrics such as precision, recall and F-score we show that one-class \{SVM\} classifiers overcome the biased classification outcomes achieved by the traditional two-class formulations and that they may constitute as viable and promising components within the design of future network fault management strategies. In addition, we demonstrate their superiority over commonly used two-class machine learning approaches such as Decision Trees and Bayesian Networks that has been used in the same context within past solutions. },
  doi      = {http://dx.doi.org/10.1016/j.comcom.2015.01.006},
  groups   = {ACM},
  issn     = {0140-3664},
  keywords = {Network management, Support vector machines, Supervised learning, One-class classifiers, DSL anomalies },
  url      = {http://www.sciencedirect.com/science/article/pii/S0140366415000080},
}

@Article{Maróti20142432,
  author   = {Miklós Maróti and Róbert Kereskényi and Tamás Kecskés and Péter Völgyesi and Ákos Lédeczi},
  title    = {Online Collaborative Environment for Designing Complex Computational Systems},
  journal  = {Procedia Computer Science},
  year     = {2014},
  volume   = {29},
  pages    = {2432 - 2441},
  note     = {2014 International Conference on Computational Science},
  abstract = {Abstract Developers of information systems have always utilized various visual formalisms during the design process, albeit in an informal manner. Architecture diagrams, finite state machines, and signal flow graphs are just a few examples. Model Integrated Computing (MIC) is an approach that considers these design artifacts as first class models and uses them to generate the system or subsystems automatically. Moreover, the same models can be used to analyze the system and generate test cases and documentation. \{MIC\} advocates the formal definition of these formalisms, called domain-specific modeling languages (DSML), via metamodeling and the automatic configuration of modeling tools from the metamodels. However, current \{MIC\} infrastructures are based on desktop applications that support a limited number of platforms, discourage concurrent design collaboration and are not scalable. This paper presents WebGME, a cloud- and web-based cyberinfrastructure to support the collaborative modeling, analysis, and synthesis of complex, large-scale scientific and engineering information systems. It facilitates interfacing with existing external tools, such as simulators and analysis tools, it provides custom domain-specific visualization support and enables the creation of automatic code generators. },
  doi      = {http://dx.doi.org/10.1016/j.procs.2014.05.227},
  groups   = {SCOPUS},
  issn     = {1877-0509},
  keywords = {model-based software, online collaboration, automatic code generation, web-based design environment },
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050914004049},
}

@Article{Koshima20153,
  author   = {Amanuel Alemayehu Koshima and Vincent Englebert},
  title    = {Collaborative editing of EMF/Ecore meta-models and models: Conflict detection, reconciliation, and merging in DiCoMEF},
  journal  = {Science of Computer Programming},
  year     = {2015},
  volume   = {113, Part 1},
  pages    = {3 - 28},
  note     = {Model Driven Development (Selected \&amp; extended papers from \{MODELSWARD\} 2014)},
  abstract = {Abstract Despite the fact that Domain Specific Modeling tools are becoming very powerful and more frequently used, the support for their cooperation has not reached its full strength, and demand for model management is growing. In cooperative work, the decision agents are semi-autonomous and therefore a solution for reconciliating \{DSM\} after a concurrent evolution is needed. Conflict detection and reconciliation are important steps for merging of concurrently evolved (meta)models in order to ensure collaboration. In this work, we present a conflict detection, reconciliation and merging framework for concurrently evolved meta-models and models. Additionally, we formally specify the \{EMF\} Ecore meta-model into set constructs that help to analyze the (meta)model and operations performed on it. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2015.07.004},
  groups   = {SCOPUS, IEEE},
  issn     = {0167-6423},
  keywords = {EMF, DSML, Collaborative modeling, Conflict detection, Merging },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642315001380},
}

@Article{Pathak2016149,
  author   = {Pankaj Pathak and Vivek Dhawan and Aniket Magarkar and Reinis Danne and Srinath Govindarajan and Sandipto Ghosh and Frank Steiniger and Pradip Chaudhari and Vijaya Gopal and Alex Bunker and Tomasz Róg and Alfred Fahr and Mangal Nagarsenker},
  title    = {Design of cholesterol arabinogalactan anchored liposomes for asialoglycoprotein receptor mediated targeting to hepatocellular carcinoma: In silico modeling, in vitro and in vivo evaluation},
  journal  = {International Journal of Pharmaceutics},
  year     = {2016},
  volume   = {509},
  number   = {1–2},
  pages    = {149 - 158},
  abstract = {Abstract We have developed active targeting liposomes to deliver anticancer agents to \{ASGPR\} which will contribute to effective treatment of hepatocellular carcinoma. Active targeting is achieved through polymeric ligands on the liposome surface. The liposomes were prepared using reverse phase evaporation method and doxorubicin hydrocholoride, a model drug, was loaded using the ammonium sulphate gradient method. Liposomes loaded with \{DOX\} were found to have a particle size of 200 nm with more than 90% entrapment efficiency. Systems were observed to release the drug in a sustained manner in acidic pH in vitro. Liposomes containing targeting ligands possessed greater and selective toxicity to \{ASGPR\} positive HepG2 cell lines due to specific ligand receptor interaction. Bio-distribution studies revealed that liposomes were concentrated in the liver even after 3 h of administration, thus providing conclusive evidence of targeting potential for formulated nanosystems. Tumor regression studies indicated greater tumor suppression with targeted liposomes thereby establishing superiority of the liposomal system. In this work, we used a novel methodology to guide the determination of the optimal composition of the targeting liposomes: molecular dynamics (MD) simulation that aided our understanding of the behaviour of the ligand within the bilayer. This can be seen as a demonstration of the utility of this methodology as a rational design tool for active targeting liposome formulation. },
  doi      = {http://dx.doi.org/10.1016/j.ijpharm.2016.05.041},
  groups   = {ScienceDirect},
  issn     = {0378-5173},
  keywords = {Cholesterol, Hepatocellular carcinoma, Liposomes, Targeting, Asialoglycoprotein receptor, Arabinogalactan, Simulations },
  url      = {http://www.sciencedirect.com/science/article/pii/S0378517316304203},
}

@Article{Teruel2014922,
  author   = {Miguel A. Teruel and Elena Navarro and Víctor López-Jaquero and Francisco Montero and Pascual González},
  title    = {A \{CSCW\} Requirements Engineering \{CASE\} Tool: Development and usability evaluation},
  journal  = {Information and Software Technology},
  year     = {2014},
  volume   = {56},
  number   = {8},
  pages    = {922 - 949},
  abstract = {AbstractContext \{CSRML\} Tool 2012 is a Requirements Engineering \{CASE\} Tool for the Goal-Oriented Collaborative Systems Requirements Modeling Language (CSRML). Objective This work aims at evaluating the usability of \{CSRML\} Tool 2012, thus identifying any possible usability flaw to be solved in the next releases of the application, as well as giving a general overview on how to develop a \{DSL\} tool similar to the one evaluated in this work by means of Visual Studio Modelling SDK. Method In this evaluation, which was reported by following the ISO/IEC 25062:2006 Common Industry Format for usability tests, 28 fourth-course Computer Science students took part. They were asked to carry out a series of modifications to an incomplete \{CSRML\} requirements specification. Usability was assessed by measuring the task’s completion rate, the elapsed time, number of accesses to the help system of the tool and the instructor’s verbal assistance. The participants’ arousal and pleasantness were assessed by analyzing both facial expressions and a \{USE\} questionnaire. Results In spite of obtaining high usability levels, the test outcome revealed some usability flaws that should be addressed. Conclusion The important lessons learnt from this evaluation are also applicable to the success of other usability tests as well as to the development of new \{CASE\} tools. },
  doi      = {http://dx.doi.org/10.1016/j.infsof.2014.02.009},
  groups   = {Compendex, SCOPUS,},
  issn     = {0950-5849},
  keywords = {Usability evaluation, CASE tool, CSRML, Requirements engineering, CSCW, ISO/IEC 25062:2006 },
  url      = {http://www.sciencedirect.com/science/article/pii/S0950584914000512},
}

@Article{deLara20131128,
  author   = {Juan de Lara and Esther Guerra and Jesús Sánchez Cuadrado},
  title    = {Reusable abstractions for modeling languages},
  journal  = {Information Systems},
  year     = {2013},
  volume   = {38},
  number   = {8},
  pages    = {1128 - 1149},
  abstract = {Abstract Model-driven engineering proposes the use of models to describe the relevant aspects of the system to be built and synthesize the final application from them. Models are normally described using Domain-Specific Modeling Languages (DSMLs), which provide primitives and constructs of the domain. Still, the increasing complexity of systems has raised the need for abstraction techniques able to produce simpler versions of the models while retaining some properties of interest. The problem is that developing such abstractions for each \{DSML\} from scratch is time and resource consuming. In this paper, our goal is reducing the effort to provide modeling languages with abstraction mechanisms. For this purpose, we have devised some techniques, based on generic programming and domain-specific meta-modeling, to define generic abstraction operations that can be reused over families of modeling languages sharing certain characteristics. Abstractions can make use of clustering algorithms as similarity criteria for model elements. These algorithms can be made generic as well, and customized for particular languages by means of annotation models. As a result, we have developed a catalog of reusable abstractions using the proposed techniques, together with a working implementation in the MetaDepth multi-level meta-modeling tool. Our techniques and prototypes demonstrate that it is feasible to build reusable and adaptable abstractions, so that similar abstractions need not be developed from scratch, and their integration in new or existing modeling languages is less costly. },
  doi      = {http://dx.doi.org/10.1016/j.is.2013.06.001},
  groups   = {SCOPUS, Compendex},
  issn     = {0306-4379},
  keywords = {Model-driven engineering, Domain-specific modeling languages, Abstraction, Genericity, Domain-specific meta-modeling, MetaDepth },
  url      = {http://www.sciencedirect.com/science/article/pii/S030643791300080X},
}

@Article{Eyisi201290,
  author   = {Emeka Eyisi and Jia Bai and Derek Riley and Jiannian Weng and Wei Yan and Yuan Xue and Xenofon Koutsoukos and Janos Sztipanovits},
  title    = {NCSWT: An integrated modeling and simulation tool for networked control systems},
  journal  = {Simulation Modelling Practice and Theory},
  year     = {2012},
  volume   = {27},
  pages    = {90 - 111},
  abstract = {Networked Control Systems (NCS) are becoming increasingly ubiquitous in a growing number of applications, such as groups of unmanned aerial vehicles and industrial control systems. The evaluation of \{NCS\} properties such as stability and performance is very important given that these systems are typically deployed in critical settings. This paper presents the Networked Control Systems Wind Tunnel (NCSWT), an integrated modeling and simulation tool for the evaluation of Networked Control Systems (NCS). \{NCSWT\} integrates Matlab/Simulink and ns-2 for modeling and simulation of \{NCS\} using the High Level Architecture (HLA) standard. The tool is composed of two parts, the design-time models and the run-time components. The design-time models use Model Integrated Computing (MIC) to define HLA-based model constructs such as federates representing the simulators and interactions representing the communication between the simulators. \{MIC\} techniques facilitate the modeling and design of complex systems by using abstractions defined in domain-specific modeling languages (DSMLs) to describe the systems. The design-time models represent the control system dynamics and networking system behaviors in order to facilitate the run-time simulation of a NCS. The run-time components represent the main software components and interfaces for the actual realization of a \{NCS\} simulation using the \{HLA\} framework. Our implementation of the \{NCSWT\} based on \{HLA\} guarantees accurate time synchronization and data communication. Two case studies are presented to demonstrate the capabilities of the tool as well as evaluate the impact of network effects on NCS. },
  doi      = {http://dx.doi.org/10.1016/j.simpat.2012.05.004},
  groups   = {SCOPUS, Compendex},
  issn     = {1569-190X},
  keywords = {Modeling, Simulation, Networked control systems, HLA },
  url      = {http://www.sciencedirect.com/science/article/pii/S1569190X12000688},
}

@Article{Stevenson2014444,
  author   = {Andrew Stevenson and James R. Cordy},
  title    = {A survey of grammatical inference in software engineering},
  journal  = {Science of Computer Programming},
  year     = {2014},
  volume   = {96, Part 4},
  pages    = {444 - 459},
  note     = {Selected Papers from the Fifth International Conference on Software Language Engineering (SLE 2012)},
  abstract = {Abstract Grammatical inference – used successfully in a variety of fields such as pattern recognition, computational biology and natural language processing – is the process of automatically inferring a grammar by examining the sentences of an unknown language. Software engineering can also benefit from grammatical inference. Unlike these other fields, which use grammars as a convenient tool to model naturally occurring patterns, software engineering treats grammars as first-class objects typically created and maintained for a specific purpose by human designers. We introduce the theory of grammatical inference and review the state of the art as it relates to software engineering. },
  doi      = {http://dx.doi.org/10.1016/j.scico.2014.05.008},
  groups   = {ACM,},
  issn     = {0167-6423},
  keywords = {Grammatical inference, Software engineering, Grammar induction },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642314002469},
}

@Article{Zimmermann20122014,
  author   = {Olaf Zimmermann and Christoph Miksovic and Jochen M. Küster},
  title    = {Reference architecture, metamodel, and modeling principles for architectural knowledge management in information technology services},
  journal  = {Journal of Systems and Software},
  year     = {2012},
  volume   = {85},
  number   = {9},
  pages    = {2014 - 2033},
  note     = {Selected papers from the 2011 Joint Working IEEE/IFIP Conference on Software Architecture (WICSA 2011)},
  abstract = {Capturing and sharing design knowledge such as architectural decisions is becoming increasingly important in firms providing professional Information Technology (IT) services such as enterprise application development and strategic outsourcing. Methods, models, and tools supporting explicit knowledge management strategies have been proposed in recent years; however, several challenges remain unaddressed. In this paper, we extend our previous work to overcome these challenges and to satisfy the requirements of an additional user group, presales architects that are responsible for \{IT\} service solution proposals. In strategic outsourcing, such solution proposals require complex, contractually relevant design decisions concerning many different resources such as \{IT\} infrastructures, people, and real estate. To support both presales and project architects, we define a common reference architecture and a decision process-oriented metamodel. We also present a tool implementation of these concepts and discuss their application to outsourcing proposals and application development projects. Finally, we establish twelve decision modeling principles and practices that capture the practical experience gained and lessons learned during the application of our decision modeling concepts to both proposal development and architecture design work on projects. },
  doi      = {http://dx.doi.org/10.1016/j.jss.2012.05.003},
  groups   = {Compendex, ACM},
  issn     = {0164-1212},
  keywords = {Architectural decisions, Architectural principles, DSL, Knowledge management, Model-driven engineering, Outsourcing, SOA, Workflow },
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121212001343},
}
@article{Gramatica201525,
title = "\{PBT\} assessment and prioritization by \{PBT\} Index and consensus modeling: Comparison of screening results from structural models ",
journal = "Environment International ",
volume = "77",
number = "",
pages = "25 - 34",
year = "2015",
note = "",
issn = "0160-4120",
doi = "http://dx.doi.org/10.1016/j.envint.2014.12.012",
url = "http://www.sciencedirect.com/science/article/pii/S0160412015000045",
author = "Paola Gramatica and Stefano Cassani and Alessandro Sangion",
keywords = "\{PBT\} by consensus",
keywords = "Insubria \{PBT\} Index",
keywords = "QSARINS",
keywords = "Screening",
keywords = "Priority setting",
keywords = "Benign by design ",
abstract = "Abstract The limited availability of comprehensive data for Persistence, Bioaccumulation and Toxicity (PBT) of chemicals is a serious hindrance to the assignment of compounds to the categories of \{PBT\} and vPvB; \{REACH\} regulation requires authorization for the use of such chemicals, and additionally plans for safer alternatives. In the context of screening and priority-setting tools for PBT-assessment, the cumulative \{PBT\} Index model, implemented in \{QSARINS\} (QSAR-INSUBRIA), new software tool for the development and validation of multiple linear regression \{QSAR\} models, offers a new holistic approach for the identification of chemicals with cumulative \{PBT\} properties directly from their molecular structure. In this study the Insubria \{PBT\} Index in \{QSARINS\} is applied to the screening and prioritization of various data sets, containing a large variety of chemicals of heterogeneous molecular structure, previously screened by various authors by different methods, for their potential \{PBT\} behavior. Particular attention is devoted to the model Applicability Domain, using different approaches such as Descriptor Range, Leverage, and Principal Component Analysis (PCA) of the modeling molecular descriptors, in order to discriminate between interpolated and extrapolated predictions. The results of this screening, which is based only on the molecular structure features and is not dependent on single threshold values for P, B and T, are compared with those obtained by the on-line US-EPA \{PBT\} Profiler. Good agreement between the various approaches is found, supporting the utility of a consensus approach in priority-setting studies. The main discrepancies are highlighted and commented on. Moreover, a priority list containing the most hazardous compounds identified in agreement between the two tools is drafted. The \{PBT\} Index, implemented in QSARINS, which was demonstrated to be a practical, precautionary and reliable screening tool for PBT-behavior directly from the molecular structure, can be usefully applied for focusing experimental studies, and even before chemical synthesis, in a “benign by design” approach of safer alternatives. "
}

@Article{Tissot201338,
  author   = {Jean-Daniel Tissot and Giorgia Canellini and Olivier Rubin and Anne Angelillo-Scherrer and Julien Delobel and Michel Prudent and Niels Lion},
  title    = {Blood microvesicles: From proteomics to physiology},
  journal  = {Translational Proteomics},
  year     = {2013},
  volume   = {1},
  number   = {1},
  pages    = {38 - 52},
  abstract = {Abstract Phospholipid vesicles of less than 1 μm are present in blood in physiological state and their concentration may vary under pathological conditions. Various names such as exosomes (EXS) and microparticles (MPS) have been used to designate these extracellular vesicles (EVS). Although \{EXs\} and \{MPS\} possibly arise from separate mechanisms, they share numerous similarities representing a challenge for their purification and characterization. These vesicles generally originate from various types of cells such as red blood cells, platelets, leukocytes or endothelial cells but also from tumor cells. They participate in numerous biological processes including hemostasis. It is therefore of major scientific interest to characterize the protein content of these different types of \{EVS\} and that of their membranes in order to elucidate the essential functions of these dynamic vesicular compartments. Proteomics has been shown to be a particularly adequate tool in this study field. This review attempts to link proteomic data with physiological roles and functions of blood EVS. },
  doi      = {http://dx.doi.org/10.1016/j.trprot.2013.04.004},
  groups   = {ScienceDirect},
  issn     = {2212-9626},
  keywords = {Aging, Blood cells, Exosomes, Microparticles, Microvesicles, Proteomics },
  url      = {http://www.sciencedirect.com/science/article/pii/S2212963413000077},
}

@Article{Miller201350,
  author   = {Robert Miller and Franziska Plessow and Manfred Rauh and Michael Gröschl and Clemens Kirschbaum},
  title    = {Comparison of salivary cortisol as measured by different immunoassays and tandem mass spectrometry},
  journal  = {Psychoneuroendocrinology},
  year     = {2013},
  volume   = {38},
  number   = {1},
  pages    = {50 - 57},
  abstract = {Summary Assessing the amount of bioavailable cortisol in saliva with immunoassays and thus sampling an endocrine marker of hypothalamus–pituitary–adrenal axis activity is of major interest in both research and clinical practice. However, absolute cortisol concentrations obtained with different immunoassays (IAs) are barely comparable precluding direct comparison between studies or individuals whenever cortisol analyses were not based on the same IA. The present technical report aims to solve this problem by evaluating the validity of, as well as agreement between the most commonly used immunoassays in psychoneuroendocrinological research (i.e., IBL, DRG, Salimetrics, DSL, and DELFIA) and a reference method (LC–MS/MS) in a sample of 195 saliva specimen covering the whole range of cortisol concentrations in adults. A structural equation modelling framework is applied to decompose systematic assay variance and estimate cortisol reference values, which are adjusted for measurement error and interference of salivary cortisone. Our findings reveal nonlinear relations between \{IAs\} and LC–MS/MS, which are discussed in terms of \{IA\} cross-reactivity with saliva matrix components. Finally guidelines for converting cortisol concentrations being obtained by these immunoassays into comparable reference values are proposed by providing conversion functions, a conversion table, and an online conversion tool. },
  doi      = {http://dx.doi.org/10.1016/j.psyneuen.2012.04.019},
  groups   = {SCOPUS},
  issn     = {0306-4530},
  keywords = {Salivary cortisol, Cortisone, Immunoassays, Cross-reactivity, Liquid chromatography, Mass spectrometry, Measurement model, Conversion },
  url      = {http://www.sciencedirect.com/science/article/pii/S0306453012001692},
}

@Article{Díaz2012737,
  author   = {Oscar Díaz and Gorka Puente},
  title    = {Wiki Scaffolding: Aligning wikis with the corporate strategy},
  journal  = {Information Systems},
  year     = {2012},
  volume   = {37},
  number   = {8},
  pages    = {737 - 752},
  note     = {Special Issue: Advanced Information Systems Engineering (CAiSE'11)},
  abstract = {Wikis are main exponents of collaborative development by user communities. This community may be created around the wiki itself (e.g., community of contributors in Wikipedia) or already exist (e.g., company employees in corporate wikis). In the latter case, the wiki is not created in a vacuum but as part of the information ecosystem of the hosting organization. As any other Information System resource, wiki success highly depends on the interplay of technology, work practice and the organization. Thus, wiki contributions should be framed along the concerns already in use in the hosting organization in terms of glossaries, schedules, policies, organigrams and the like. The question is then, how can corporate strategies permeate wiki construction while preserving wiki openness and accessibility? We advocate for the use of “Wiki Scaffoldings”, i.e., a wiki installation that is provided at the onset to mimic these corporate concerns: categories, users, templates, articles initialized with boilerplate text, are all introduced in the wiki before any contribution is made. To retain wikis' friendliness and engage layman participation, we propose scaffoldings to be described as mind maps. Mind maps are next “exported” as wiki installations. We show the feasibility of the approach introducing a Wiki Scaffolding Language (WSL). \{WSL\} is realized as a plugin for FreeMind, a popular tool for mind mapping. Finally, we validate the expressiveness of \{WSL\} in four case studies. \{WSL\} is available for download. },
  doi      = {http://dx.doi.org/10.1016/j.is.2012.05.002},
  groups   = {Compendex, SCOPUS},
  issn     = {0306-4379},
  keywords = {Wiki, Wiki management, DSL, Mind map, FreeMind },
  url      = {http://www.sciencedirect.com/science/article/pii/S0306437912000695},
}

@Article{Arouche20151397,
  author   = {Nassim Arouche and Jean-Yves Picard and Danielle Monniaux and Soazik P. Jamin and Bernard Vigier and Nathalie Josso and Richard L. Cate and Nathalie di Clemente and Joëlle Taieb},
  title    = {The \{BOC\} ELISA, a ruminant-specific \{AMH\} immunoassay, improves the determination of plasma \{AMH\} concentration and its correlation with embryo production in cattle},
  journal  = {Theriogenology},
  year     = {2015},
  volume   = {84},
  number   = {8},
  pages    = {1397 - 1404},
  abstract = {Abstract Plasma anti-Müllerian hormone (AMH) concentrations have been recently found to be predictive of the number of embryos recovered after \{FSH\} superovulatory treatment in the cow. However, the sensitivity of the Active Müllerian-inhibiting substance/AMH \{ELISA\} (ref. 10–14400; DSL-Beckman-Coulter) used to make these measurements in bovine plasma samples is low because it was developed to measure human \{AMH\} levels. To overcome this limitation, we developed an immunoassay specific for the bovine (B), ovine (O), and caprine (C) species, the bovine-ovine-caprine (BOC) ELISA. For this purpose, we produced recombinant bovine \{AMH\} for standardization, and we used monoclonal antibodies raised against bovine AMH, previously prepared by our laboratory. We evaluated the precision, accuracy, specificity, limit of detection, and functional sensitivity of the assay. The intra-assay coefficient of variation ranged between 3.4% and 11.3% for \{AMH\} concentrations between 23.68 and 1.74 ng/mL, and the interassay coefficient of variation ranged between 4.8% and 20.5% for concentrations between 25.53 and 1.42 ng/mL, respectively. The assay displayed a good linearity, had a detection limit of 0.4 ng/mL and a functional sensitivity of 1.4 ng/mL. It also cross-reacted with ovine and caprine AMHs. Both the mean and median \{AMH\} levels measured in 40 cow plasma samples using the \{BOC\} \{ELISA\} were approximately 44 fold higher than the mean and median \{AMH\} levels measured with the Active Müllerian-inhibiting substance/AMH ELISA. Moreover, a higher correlation was observed between the average number of embryos recovered from each cow after superovulatory treatment and \{AMH\} concentrations measured with the \{BOC\} ELISA. This BOC \{ELISA\} provides a very efficient tool for evaluating the ovarian follicular reserve of cows and predicting their embryo production capacity. },
  doi      = {http://dx.doi.org/10.1016/j.theriogenology.2015.07.026},
  groups   = {SCOPUS},
  issn     = {0093-691X},
  keywords = {Anti-Müllerian hormone, Müllerian-inhibiting substance, Immunoassay, Bovine },
  url      = {http://www.sciencedirect.com/science/article/pii/S0093691X15003854},
}

@Article{Liu2013143,
  author   = {Wenbin Liu},
  title    = {Bmdelta phenotype implies involvement of Notch signaling in body segmentation and appendage development of silkworm, Bombyx mori},
  journal  = {Arthropod Structure \& Development},
  year     = {2013},
  volume   = {42},
  number   = {2},
  pages    = {143 - 151},
  abstract = {The domesticated silkworm, Bombyx mori, belongs to the intermediate germband insects, in which the anterior segments are specified in the blastoderm, while the remaining posterior segments are sequentially generated from the cellularized growth zone. The pattern formation is distinct from Drosophila but somewhat resembles a vertebrate. Notch signaling is involved in the segmentation of vertebrates and spiders. Here, we studied the function of Notch signaling in silkworm embryogenesis via \{RNA\} interference (RNAi). Depletion of Bmdelta, the homolog of the Notch signaling ligand, led to severe defects in segment patterning, including a loss of posterior segments and irregular segment boundaries. The paired appendages on each segment were symmetrically fused along the ventral midline in Bmdelta \{RNAi\} embryos. An individual segment seemed to possess only one segmental appendage. Segmentation in prolegs could be observed. Our results show that Notch signaling is employed in not only appendage development but also body segmentation. Thus, conservation of Notch-mediated segmentation could also be extended to holometabolous insects. The involvement of Notch signaling seems to be the ancestral segmentation mechanism of arthropods. },
  doi      = {http://dx.doi.org/10.1016/j.asd.2012.10.002},
  groups   = {ScienceDirect},
  issn     = {1467-8039},
  keywords = {Silkworm, Segmentation, delta, Notch signaling },
  url      = {http://www.sciencedirect.com/science/article/pii/S1467803912000795},
}

@Article{Naegel2013191,
  author   = {Arne Naegel and Michael Heisig and Gabriel Wittum},
  title    = {Detailed modeling of skin penetration—An overview},
  journal  = {Advanced Drug Delivery Reviews},
  year     = {2013},
  volume   = {65},
  number   = {2},
  pages    = {191 - 207},
  note     = {Modeling the human skin barrier - Towards a better understanding of dermal absorption},
  abstract = {Abstract In recent years, the combination of computational modeling and experiments has become a useful tool that is proving increasingly powerful for explaining biological complexity. As computational power is increasing, scientists are able to explore ever more complex models in finer detail and to explain very complex real world data. This work provides an overview of one-, two- and three-dimensional diffusion models for penetration into mammalian skin. Besides diffusive transport this includes also binding of substances to skin proteins and metabolism. These models are based on partial differential equations that describe the spatial evolution of the transport process through the biological barrier skin. Furthermore, the work focuses on analytical and numerical techniques for this type of equations such as discretization schemes or homogenization (upscaling) techniques. Finally, the work compares different geometry models with respect to the permeability. },
  doi      = {http://dx.doi.org/10.1016/j.addr.2012.10.009},
  groups   = {ScienceDirect},
  issn     = {0169-409X},
  keywords = {Skin, Stratum corneum, Geometry models, Brick-and-mortar, Cuboid, Tetrakaidekahedra, Mathematical modeling, Numerical simulation, Homogenization, Drug diffusion },
  url      = {http://www.sciencedirect.com/science/article/pii/S0169409X12003559},
}

@article{Nguyen2016,
title = "Model-based security engineering for cyber-physical systems: A systematic mapping study ",
journal = "Information and Software Technology ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "0950-5849",
doi = "http://dx.doi.org/10.1016/j.infsof.2016.11.004",
url = "http://www.sciencedirect.com/science/article/pii/S0950584916303214",
author = "Phu H. Nguyen and Shaukat Ali and Tao Yue",
keywords = "Cyber-physical systems",
keywords = "Security",
keywords = "Model-based engineering",
keywords = "Security engineering",
keywords = "Systematic mapping",
keywords = "Snowballing",
keywords = "Survey ",
abstract = "AbstractContext Cyber-physical systems (CPSs) have emerged to be the next generation of engineered systems driving the so-called fourth industrial revolution. \{CPSs\} are becoming more complex, open and more prone to security threats, which urges security to be engineered systematically into CPSs. Model-Based Security Engineering (MBSE) could be a key means to tackle this challenge via security by design, abstraction, and automation. Objective We aim at providing an initial assessment of the state of the art in \{MBSE\} for \{CPSs\} (MBSE4CPS). Specifically, this work focuses on finding out 1) the publication statistics of \{MBSE4CPS\} studies; 2) the characteristics of \{MBSE4CPS\} studies; and 3) the open issues of \{MBSE4CPS\} research. Method We conducted a systematic mapping study (SMS) following a rigorous protocol that was developed based on the state-of-the-art \{SMS\} and systematic review guidelines. From thousands of relevant publications, we systematically identified 48 primary \{MBSE4CPS\} studies for data extraction and synthesis to answer predefined research questions. Results \{SMS\} results show that for three recent years (2014–2016) the number of primary \{MBSE4CPS\} studies has increased significantly. Within the primary studies, the popularity of using Domain-Specific Languages (DSLs) is comparable with the use of the standardised \{UML\} modelling notation. Most primary studies do not explicitly address specific security concerns (e.g., confidentiality, integrity) but rather focus on security analyses in general on threats, attacks or vulnerabilities. Few primary studies propose to engineer security solutions for CPSs. Many focus on the early stages of development lifecycle such as security requirement engineering or analysis. Conclusion The \{SMS\} does not only provide the state of the art in MBSE4CPS, but also points out several open issues that would deserve more investigation, e.g., the lack of engineering security solutions for CPSs, limited tool support, too few industrial case studies, and the challenge of bridging \{DSLs\} in engineering secure CPSs. "
}
@article{Castelltort2016,
title = "Rogue behavior detection in NoSQL graph databases ",
journal = "Journal of Innovation in Digital Ecosystems ",
volume = "",
number = "",
pages = " - ",
year = "2016",
note = "",
issn = "2352-6645",
doi = "http://dx.doi.org/10.1016/j.jides.2016.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S2352664516300177",
author = "Arnaud Castelltort and Anne Laurent",
keywords = "Rogue behavior",
keywords = "Fraud rings",
keywords = "NoSQL graph databases",
keywords = "Fuzzy DSL",
keywords = "Approximate cypher queries ",
abstract = "Abstract Rogue behaviors refer to behavioral anomalies that can occur in human activities and that can thus be retrieved from human generated data. In this paper, we aim at showing that NoSQL graph databases are a useful tool for this purpose. Indeed these database engines exploit property graphs that can easily represent human and object interactions whatever the volume and complexity of the data. These interactions lead to fraud rings in the graphs in the form of sophisticated chains of indirect links between fraudsters representing successive transactions (money, communications, etc.) from which rogue behaviours are detected. Our work is based on two extensions of such NoSQL graph databases. The first extension allows the handling of time-variant data while the second one is devoted to the management of imprecise queries with a \{DSL\} (to define flexible operators and operations with Scala) and the Cypherf declarative flexible query language over NoSQL graph databases. These extensions allow to better address and describe sophisticated frauds. Feasibility have been studied to assess our proposition. "
}


@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:IEEE\;0\;;
1 ExplicitGroup:SCOPUS\;0\;;
1 ExplicitGroup:ACM\;0\;;
1 ExplicitGroup:Compendex\;0\;;
1 ExplicitGroup:ScienceDirect\;0\;;
}
